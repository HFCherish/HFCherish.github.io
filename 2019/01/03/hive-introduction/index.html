<!DOCTYPE html>
<html lang="Chinese">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0-rc1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hfcherish.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="apache hive 是一个 data warehouse 应用。支持分布式存储的大数据读、写和管理，并且支持使用标准的 SQL 语法查询。Hive is not a database. This is to make use of SQL capabilities by defining a metadata to the files in HDFS. Long story short, it">
<meta property="og:type" content="article">
<meta property="og:title" content="hive introduction">
<meta property="og:url" content="http://hfcherish.github.io/2019/01/03/hive-introduction/index.html">
<meta property="og:site_name" content="Cherish&#39;s Blog">
<meta property="og:description" content="apache hive 是一个 data warehouse 应用。支持分布式存储的大数据读、写和管理，并且支持使用标准的 SQL 语法查询。Hive is not a database. This is to make use of SQL capabilities by defining a metadata to the files in HDFS. Long story short, it">
<meta property="og:locale">
<meta property="og:image" content="https://cwiki.apache.org/confluence/download/attachments/27362072/system_architecture.png?version=1&modificationDate=1414560669000&api=v2">
<meta property="article:published_time" content="2019-01-03T06:50:02.000Z">
<meta property="article:modified_time" content="2023-05-25T01:16:40.429Z">
<meta property="article:author" content="Cherish">
<meta property="article:tag" content="big data">
<meta property="article:tag" content="storage">
<meta property="article:tag" content="hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cwiki.apache.org/confluence/download/attachments/27362072/system_architecture.png?version=1&modificationDate=1414560669000&api=v2">


<link rel="canonical" href="http://hfcherish.github.io/2019/01/03/hive-introduction/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"Chinese","comments":true,"permalink":"http://hfcherish.github.io/2019/01/03/hive-introduction/","path":"2019/01/03/hive-introduction/","title":"hive introduction"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>hive introduction | Cherish's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Cherish's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#database-v-s-warehouse"><span class="nav-number">1.</span> <span class="nav-text">database v.s. warehouse</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#database%EF%BC%9A"><span class="nav-number">1.1.</span> <span class="nav-text">database：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#data-warehouse"><span class="nav-number">1.2.</span> <span class="nav-text">data warehouse</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#installation"><span class="nav-number"></span> <span class="nav-text">installation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#install-hadoop-on-mac"><span class="nav-number">0.1.</span> <span class="nav-text">install hadoop on mac</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#install-hive-on-mac"><span class="nav-number">0.2.</span> <span class="nav-text">install hive on mac</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#set-env"><span class="nav-number">0.3.</span> <span class="nav-text">set env</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#running-using-beeline"><span class="nav-number">0.4.</span> <span class="nav-text">running using beeline</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Configure-Hive"><span class="nav-number"></span> <span class="nav-text">Configure Hive</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#analysis-on-hive"><span class="nav-number"></span> <span class="nav-text">analysis on hive</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#storage-on-hive"><span class="nav-number"></span> <span class="nav-text">storage on hive</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive-Partition"><span class="nav-number">1.</span> <span class="nav-text">Hive Partition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive-bucket"><span class="nav-number">2.</span> <span class="nav-text">Hive bucket</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ORC-vs-Parquet"><span class="nav-number">3.</span> <span class="nav-text">ORC vs Parquet</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hive-Transactional"><span class="nav-number"></span> <span class="nav-text">Hive Transactional</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#architecture"><span class="nav-number"></span> <span class="nav-text">architecture</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Hive-Data-Types"><span class="nav-number"></span> <span class="nav-text">Hive Data Types</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Common-used-commands"><span class="nav-number"></span> <span class="nav-text">Common used commands</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#auto-increment-id"><span class="nav-number">1.</span> <span class="nav-text">auto increment id</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#get-latest-partition"><span class="nav-number">2.</span> <span class="nav-text">get latest partition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#create-table-from-another-table"><span class="nav-number">3.</span> <span class="nav-text">create table from another table</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#select-all-without-some-columns"><span class="nav-number">4.</span> <span class="nav-text">select all without some columns</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#select-latest-in-group"><span class="nav-number">5.</span> <span class="nav-text">select latest in group</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive-cli-pretty"><span class="nav-number">6.</span> <span class="nav-text">hive cli pretty</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Optimization"><span class="nav-number"></span> <span class="nav-text">Optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%8F%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98"><span class="nav-number">1.</span> <span class="nav-text">小文件问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E4%BD%BF%E7%94%A8-concatenate"><span class="nav-number">1.1.</span> <span class="nav-text">1. 使用 concatenate</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E4%BD%BF%E7%94%A8%E4%B8%80%E4%BA%9B%E9%85%8D%E7%BD%AE%EF%BC%8C%E5%9C%A8%E5%86%99%E6%96%87%E4%BB%B6%E6%97%B6%EF%BC%8C%E8%87%AA%E5%8A%A8-merge"><span class="nav-number">1.2.</span> <span class="nav-text">2. 使用一些配置，在写文件时，自动 merge</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Issues"><span class="nav-number"></span> <span class="nav-text">Issues</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#count-return-0"><span class="nav-number">1.</span> <span class="nav-text">count(*) return 0</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hive-not-recognizing-alias-names-in-select-part"><span class="nav-number">2.</span> <span class="nav-text">hive not recognizing alias names in select part</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#In-not-in-substitution"><span class="nav-number">3.</span> <span class="nav-text">In, not in substitution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VERTEX-FAILURE"><span class="nav-number">4.</span> <span class="nav-text">VERTEX_FAILURE</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#explain"><span class="nav-number">5.</span> <span class="nav-text">explain</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#xa0"><span class="nav-number">6.</span> <span class="nav-text">\xa0</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cherish</p>
  <div class="site-description" itemprop="description">从心所欲不逾矩</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">72</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button animated">
    <button><i class="fa fa-comment"></i>
      Chat
    </button>
  </div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hfcherish" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hfcherish" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:pzcherishhf@gmail.com" title="E-Mail → mailto:pzcherishhf@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="Chinese">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2019/01/03/hive-introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="hive introduction | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          hive introduction
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2019-01-03 14:50:02" itemprop="dateCreated datePublished" datetime="2019-01-03T14:50:02+08:00">2019-01-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-05-25 09:16:40" itemprop="dateModified" datetime="2023-05-25T09:16:40+08:00">2023-05-25</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><a href="https://cwiki.apache.org/confluence/display/Hive/Home#Home-HiveDocumentation">apache hive</a> 是一个 data warehouse 应用。支持分布式存储的大数据读、写和管理，并且支持使用标准的 SQL 语法查询。Hive is not a database.  This is to make use of SQL capabilities by defining a metadata to the files in HDFS.  Long story short, it brings the possibility to query the hdfs file.</p>
<p>hive 并没有固定的数据存储方式。自带的是 csv（comma-separated value）和 tsv (tab-separated values) connectors，也可以使用 connector for other formats。</p>
<h2 id="database-v-s-warehouse"><a href="#database-v-s-warehouse" class="headerlink" title="database v.s. warehouse"></a>database v.s. warehouse</h2><p>参见 <a href="https://panoply.io/data-warehouse-guide/the-difference-between-a-database-and-a-data-warehouse/">the difference between database and data warehouse</a></p>
<h3 id="database："><a href="#database：" class="headerlink" title="database："></a>database：</h3><p>存储具体的业务数据，完善支持 concurrent transaction 操作（CRUD）。</p>
<p>database contains highly detailed data as well as a detailed relational views. Tables are normalized to achieve efficient storage, concurrent transaction processing, as well as return quick query results.</p>
<ul>
<li>**主要用于 OLTP (online trancaction processing)**。</li>
<li><strong>use a normalized structure</strong>. 即通常会组织成 table、row、column，冗余信息很少（比如三张表 product、color、product-color），所以节省空间。在查询时就需要通过复杂的 join 来实现，所以分析性的查询会比较耗时</li>
<li><strong>no historical data</strong>. 主要处理 transaction 数据，只保存现在的数据，进行的查询和分析也是基于现有数据。即它的分析是 static one-time reports</li>
<li><strong>optimization 主要是优化写速度、读速度</strong>。复杂分析因为涉及很多 join，其性能提升也是一个主要的问题。</li>
<li><strong>经常需要满足关系型数据库的 ACID 原则</strong>（atomicity, consistency, isolation, and durability）。所以它需要支持并发操作下的数据完整性。对 concurrent transaction 的支持要求比较高。</li>
</ul>
<h3 id="data-warehouse"><a href="#data-warehouse" class="headerlink" title="data warehouse"></a>data warehouse</h3><p>将企业中的各种数据收集起来，重新组织，对这些数据做高效 <em><strong>分析</strong></em></p>
<blockquote>
<p>A <a href="https://panoply.io/data-warehouse-guide">data warehouse</a> is a system that pulls together data from many different sources within an organization for reporting and analysis. The reports created from complex queries within a data warehouse are used to make business decisions.</p>
<p>The primary focus of a data warehouse is to provide a correlation between data from existing systems, i.e., product inventory stored in one system, purchase orders for a specific customer, stored in another system. Data warehouses are used for online analytical processing (OLAP), which uses complex queries to analyze rather than process transactions.</p>
</blockquote>
<ul>
<li><strong>主要用于 OLAP (online analysis processing)</strong>. 它收集企业内各个数据源的数据，建立数据关联，对这些数据做复杂的查询分析，以辅佐业务决策。</li>
<li><strong>use a denormalized structure</strong>. 它收集多个相关数据源的数据，将这些 table <a href="https://searchdatamanagement.techtarget.com/definition/denormalization">denormailize</a>、transform，获得 summarized data、multidimentional views，并基于这些数据实现快速分析和查询。它不在乎冗余，相反，很多时候正是通过冗余重新组织数据，使得查询更方便。</li>
<li><strong>store historical data</strong>. data warehouse 主要是用于分析的，所以通常会存储历史数据，以实现对历史数据和现有数据的对比分析。</li>
<li><strong>optimization 主要是查询响应速度</strong>。它对大数据做分析，响应速度是主要的衡量标准。</li>
<li><strong>一般不支持高并发操作</strong>。支持一定并发，但支持程度远不如 database</li>
</ul>
<h1 id="installation"><a href="#installation" class="headerlink" title="installation"></a>installation</h1><p>See <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html">hadoop: setting up a single-node cluster</a>, <a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">GettingStarted</a></p>
<p>Hive relies on hadoop. And we need a db (eg. mysql) to store hive metadata. So the prerequisites are:</p>
<ul>
<li><strong>hadoop installed</strong></li>
<li><strong>mysql installed</strong>: to store hive metadata</li>
<li><strong>java installed</strong>: ??</li>
<li><strong>ssh installed and sshd running</strong>: when running hadoop scripts and managing remote hadoop daemons, it use ssh to authenticate.</li>
</ul>
<h3 id="install-hadoop-on-mac"><a href="#install-hadoop-on-mac" class="headerlink" title="install hadoop on mac"></a><a href="https://hfcherish.github.io/2019/01/07/hadoop/">install hadoop on mac</a></h3><h3 id="install-hive-on-mac"><a href="#install-hive-on-mac" class="headerlink" title="install hive on mac"></a><a href="https://www.cnblogs.com/micrari/p/7067968.html">install hive on mac</a></h3><blockquote>
<p>After init mysql, you may find that you can’t connect mysql using ‘-uhive -pxxx’. Then try to grant privileges to <code>&#39;hive&#39;@&#39;%&#39;</code> instead of <code>&#39;hive&#39;@&#39;localhost&#39;</code>. Use wildcard <code>%</code> to match all hosts.</p>
</blockquote>
<p>After installation, can try the <a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-SimpleExampleUseCases">simple example</a> to see how to conduct analysis on hive.</p>
<h3 id="set-env"><a href="#set-env" class="headerlink" title="set env"></a>set env</h3><p>To use hadoop and hive conveniently, set the bin in Path. Just add the follow config into <code>~/.zshrc</code>, and then source it <code>source ~/.zshrc</code>.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/local/Cellar/hadoop/3.1.1/libexec</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/local/Cellar/hive/3.1.1/libexec</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure>

<h3 id="running-using-beeline"><a href="#running-using-beeline" class="headerlink" title="running using beeline"></a><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-RunningHiveServer2andBeeline.1">running using beeline</a></h3><p>beeline is a new hive client to replace the deprecated HiveCli. With beeline, you can execute write, load, query, etc. on hive.</p>
<p>To connect simply, type the following:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hiveserver2</span><br><span class="line">$ beeline -u jdbc:hive2://</span><br></pre></td></tr></table></figure>

<p>To create, alter database&#x2F;table&#x2F;column&#x2F;etc. on hive, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">Hive Data Definition Language</a>.</p>
<p>To get the query commands, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select">LanguageManual Select</a></p>
<p>To load data from file, insert, delete, merge, update data, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML">DML (data manipulation language)</a></p>
<p>Other non-sql commands to use in HiveQL or beeline, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Commands">LanguageManual Commands</a>. The <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Cli#LanguageManualCli-HiveResources">Hive Resources</a> related commands are non-sql commands.</p>
<h1 id="Configure-Hive"><a href="#Configure-Hive" class="headerlink" title="Configure Hive"></a>Configure Hive</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration#AdminManualConfiguration-ConfiguringHive">how to configure hive properties</a></p>
<p>To show hive config in hive cli: (<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ShowConf">show conf</a>)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to show current: `set confName`</span></span><br><span class="line">0: jdbc:hive2://slave1:2181,slave2:2181,maste&gt; <span class="built_in">set</span> hive.fetch.task.conversion;</span><br></pre></td></tr></table></figure>

<p>There are two hive-site.xml files. See <a href="https://community.cloudera.com/t5/Support-Questions/Why-do-I-have-two-hive-site-xml-config-files-on-my-HDP-host/td-p/209500">two hive-site.xml config files on HDP</a></p>
<ul>
<li><p>&#x2F;etc&#x2F;hive&#x2F;conf&#x2F;hive-site.xml is the config for Hive service itself and is managed via Ambari through the Hive service config page.</p>
</li>
<li><p>&#x2F;usr&#x2F;hdp&#x2F;current&#x2F;spark-client&#x2F;conf&#x2F;hive-site.xml actually points to &#x2F;etc&#x2F;spark&#x2F;conf&#x2F;hive-site.xml . This is the minimal hive config that Spark needs to access Hive. This is managed via Ambari through the Spark service config page. Ambari correctly configures this hive site for Kerberos. Depending upon your version of HDP you may not have the correct support in Ambari for configuring Livy.  The hive-site.xml in Spark doesn’t have the same template as Hive’s. Ambari will notice the hive-site.xml and overwrite it in the Spark directory whenever Spark is restarted.</p>
</li>
</ul>
<h1 id="analysis-on-hive"><a href="#analysis-on-hive" class="headerlink" title="analysis on hive"></a>analysis on hive</h1><p>When you start a sql function (eg. <code>select count(*) from xxx</code>), it in fact  starts an map-reduce job based on hadoop to search among all datanodes. Such functions are simple analysis implemented by hive.</p>
<blockquote>
<p>Hive compiler generates map-reduce jobs for most queries. These jobs are then submitted to the Map-Reduce cluster indicated by the variable:</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mapred.job.tracker</span><br></pre></td></tr></table></figure>

<p>For complex analysis, you may need to write custom mappers (map data) &amp; reducers (collect data) scripts. Use<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Transform"><code>TRANSFORM</code></a> keyword in hive to achieve this.</p>
<p>For example, the <code>weekday_mapper.py</code> to convert <code>unixtime</code> to <code>weekday</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">  line = line.strip()</span><br><span class="line">  userid, movieid, rating, unixtime = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">  weekday = datetime.datetime.fromtimestamp(<span class="built_in">float</span>(unixtime)).isoweekday()</span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;\t&#x27;</span>.join([userid, movieid, rating, <span class="built_in">str</span>(weekday)])</span><br></pre></td></tr></table></figure>

<p>And then use the script:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> u_data_new (</span><br><span class="line">  userid <span class="type">INT</span>,</span><br><span class="line">  movieid <span class="type">INT</span>,</span><br><span class="line">  rating <span class="type">INT</span>,</span><br><span class="line">  weekday <span class="type">INT</span>)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">add</span> FILE weekday_mapper.py;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> u_data_new</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  TRANSFORM (userid, movieid, rating, unixtime)</span><br><span class="line">  <span class="keyword">USING</span> <span class="string">&#x27;python weekday_mapper.py&#x27;</span></span><br><span class="line">  <span class="keyword">AS</span> (userid, movieid, rating, weekday)</span><br><span class="line"><span class="keyword">FROM</span> u_data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> weekday, <span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> u_data_new</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> weekday;</span><br></pre></td></tr></table></figure>

<h1 id="storage-on-hive"><a href="#storage-on-hive" class="headerlink" title="storage on hive"></a>storage on hive</h1><p>Hive relies on Hadoop. The data in hive is saved in hdfs in fact. And the metadata is saved in mysql (the db can be configured). When check <code>localhost:9870</code>, you can see a new folder <code>/user/hive/warehouse</code>. All tables in hive are dirs in <code>/user/hive/warehouse</code>.</p>
<h2 id="Hive-Partition"><a href="#Hive-Partition" class="headerlink" title="Hive Partition"></a>Hive Partition</h2><p><a href="https://blog.csdn.net/helloxiaozhe/article/details/78445276">hive中简单介绍分区表(partition table)，含动态分区(dynamic partition)与静态分区(static partition)</a></p>
<blockquote>
<p>Hive organizes tables into partitions. It is a way of dividing a table into related parts based on the values of partitioned columns such as date, city, and department. Using partition, it is easy to query a portion of the data.<br>Tables or partitions are sub-divided into <strong>buckets,</strong> to provide extra structure to the data that may be used for more efficient querying. Bucketing works based on the value of hash function of some column of a table.<br>For example, a table named <strong>Tab1</strong> contains employee data such as id, name, dept, and yoj (i.e., year of joining). Suppose you need to retrieve the details of all employees who joined in 2012. A query searches the whole table for the required information. However, if you partition the employee data with the year and store it in a separate file, it reduces the query processing time. The following example shows how to partition a file and its data:</p>
</blockquote>
<h2 id="Hive-bucket"><a href="#Hive-bucket" class="headerlink" title="Hive bucket"></a>Hive bucket</h2><p><a href="https://sparkbyexamples.com/apache-hive/hive-partitioning-vs-bucketing-with-examples/">hive partitioning vs bucket with examples</a></p>
<p><a href="https://sparkbyexamples.com/apache-hive/hive-partitioning-vs-bucketing-with-examples/">stack-overflow: hive partition vs bucket</a></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> zipcodes(</span><br><span class="line">RecordNumber <span class="type">int</span>,</span><br><span class="line">Country string,</span><br><span class="line">City string,</span><br><span class="line">Zipcode <span class="type">int</span>)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(state string)</span><br><span class="line">CLUSTERED <span class="keyword">BY</span> Zipcode <span class="keyword">INTO</span> <span class="number">10</span> BUCKETS</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">PARTITIONING</th>
<th align="left">BUCKETING</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Directory is created on HDFS for each partition.</td>
<td align="left">File is created on HDFS for each bucket.</td>
</tr>
<tr>
<td align="left">You can have one or more Partition columns</td>
<td align="left">You can have only one Bucketing column</td>
</tr>
<tr>
<td align="left">You can’t manage the number of partitions to create</td>
<td align="left">You can manage the number of buckets to create by specifying the count</td>
</tr>
<tr>
<td align="left">NA</td>
<td align="left">Bucketing can be created on a partitioned table</td>
</tr>
<tr>
<td align="left">Uses PARTITIONED BY</td>
<td align="left">Uses CLUSTERED BY</td>
</tr>
</tbody></table>
<p>partition  和 bucket 都是将大数据集拆成更小的数据集，加速查询处理的方式。比如按日期拆分区，很多分析只拿当天的分区，处理的数据量、读取的 hdfs 文件很少，就快。</p>
<p>最大的区别是 partition 拆数据就是按 column 值拆，bucket 拆数据是按 column hash 值拆，所以 bucket 最终的桶的数目是固定的，同时一个桶里可能有多个 column 值（parition 每个分区只会存一种 column 的值）</p>
<p>相对来讲，bucket 粒度可能更细。比如一个场景，我们将 order 按 date 分区，分区后每天的数据量还是特别大，如果我们很多查询&#x2F;join是基于 employee，此时可以基于 employe_id 再分成更多的小集合，即按 employe_id 字段 hash 到 n 个桶里，这种拆桶方式特别有利于宏宇今天说的 map-side join，而且相比 partition，可以控制文件数量（有时想用的 partition 字段可能会分成特别特别多小分区，这个时候 bucket 就更合适些）</p>
<p>上边那个例子，假如 order 按 date+employee_id partition，分区就会特别多（对 hdfs namenode 造成大压力，hive metadata 也有压力），所以按 date partition, 按 employee_id bucket 就比较合适</p>
<h2 id="ORC-vs-Parquet"><a href="#ORC-vs-Parquet" class="headerlink" title="ORC vs Parquet"></a>ORC vs Parquet</h2><p><a href="https://community.cloudera.com/t5/Support-Questions/ORC-vs-Parquet-When-to-use-one-over-the-other/td-p/95942">orc vs Parquet</a></p>
<p><a href="https://blog.cloudera.com/orcfile-in-hdp-2-better-compression-better-performance/">ORCFile in HDP 2: Better Compression, Better Performance</a></p>
<h1 id="Hive-Transactional"><a href="#Hive-Transactional" class="headerlink" title="Hive Transactional"></a>Hive Transactional</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions#HiveTransactions-NewConfigurationParametersforTransactions">hive transaction</a></p>
<p>Close:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">set hive.support.concurrency = false;</span><br><span class="line">set hive.optimize.index.filter = false;</span><br><span class="line">set hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager;</span><br><span class="line">set hive.compactor.initiator.on = false;</span><br><span class="line">set hive.compactor.worker.threads = 0;</span><br><span class="line">set hive.strict.managed.tables = false;</span><br><span class="line"></span><br><span class="line">TBLPROPERTIES (&#x27;transactional&#x27;=&#x27;false&#x27;)</span><br></pre></td></tr></table></figure>

<h1 id="architecture"><a href="#architecture" class="headerlink" title="architecture"></a><a href="https://cwiki.apache.org/confluence/display/Hive/Design">architecture</a></h1><p><img src="https://cwiki.apache.org/confluence/download/attachments/27362072/system_architecture.png?version=1&modificationDate=1414560669000&api=v2" alt="hive architecture"></p>
<h1 id="Hive-Data-Types"><a href="#Hive-Data-Types" class="headerlink" title="Hive Data Types"></a>Hive Data Types</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-decimal">hive data types</a></p>
<h1 id="Common-used-commands"><a href="#Common-used-commands" class="headerlink" title="Common used commands"></a>Common used commands</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://slave1:2181&gt; use dbname;</span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; show tables;</span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; describe formatted tablename;</span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; describe extended tableName</span><br></pre></td></tr></table></figure>

<h2 id="auto-increment-id"><a href="#auto-increment-id" class="headerlink" title="auto increment id"></a>auto increment id</h2><p><a href="https://cloud.tencent.com/developer/article/1433240">two ways hive auto increment id</a></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">## use row_number</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl_dim  </span><br><span class="line"><span class="keyword">select</span> <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> tbl_stg.id) <span class="operator">+</span> t2.sk_max, tbl_stg.<span class="operator">*</span>  </span><br><span class="line"><span class="keyword">from</span> tbl_stg </span><br><span class="line"><span class="keyword">cross</span> <span class="keyword">join</span> (<span class="keyword">select</span> <span class="built_in">coalesce</span>(<span class="built_in">max</span>(sk),<span class="number">0</span>) sk_max <span class="keyword">from</span> tbl_dim) t2; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## use UDFRowSequence</span><br><span class="line"><span class="keyword">add</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">-</span>contrib<span class="number">-2.0</span><span class="number">.0</span>.jar;  </span><br><span class="line"><span class="keyword">create</span> temporary <span class="keyword">function</span> row_sequence <span class="keyword">as</span> <span class="string">&#x27;org.apache.hadoop.hive.contrib.udf.udfrowsequence&#x27;</span>; </span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl_dim  </span><br><span class="line"><span class="keyword">select</span> row_sequence() <span class="operator">+</span> t2.sk_max, tbl_stg.<span class="operator">*</span>  </span><br><span class="line"><span class="keyword">from</span> tbl_stg </span><br><span class="line"><span class="keyword">cross</span> <span class="keyword">join</span> (<span class="keyword">select</span> <span class="built_in">coalesce</span>(<span class="built_in">max</span>(sk),<span class="number">0</span>) sk_max <span class="keyword">from</span> tbl_dim) t2;</span><br></pre></td></tr></table></figure>

<h2 id="get-latest-partition"><a href="#get-latest-partition" class="headerlink" title="get latest partition"></a>get latest partition</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">## will <span class="keyword">only</span> scan <span class="number">2</span><span class="number">-3</span> partitions</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">max</span>(ingest_date) <span class="keyword">from</span> db.table_name</span><br><span class="line"><span class="keyword">where</span> ingest_date<span class="operator">&gt;</span>date_add(<span class="built_in">current_date</span>,<span class="number">-3</span>)</span><br></pre></td></tr></table></figure>

<h2 id="create-table-from-another-table"><a href="#create-table-from-another-table" class="headerlink" title="create table from another table"></a>create table from another table</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> new_test </span><br><span class="line">    <span class="type">row</span> format delimited </span><br><span class="line">    fields terminated <span class="keyword">by</span> <span class="string">&#x27;|&#x27;</span> </span><br><span class="line">    STORED <span class="keyword">AS</span> RCFile </span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> source <span class="keyword">where</span> col<span class="operator">=</span><span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="select-all-without-some-columns"><a href="#select-all-without-some-columns" class="headerlink" title="select all without some columns"></a>select all without some columns</h2><p><a href="https://blog.csdn.net/Kikitious_Du/article/details/84754240">blog</a></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.support.quoted.identifiers<span class="operator">=</span><span class="keyword">none</span>;</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">`(num<span class="operator">|</span>uid)?<span class="operator">+</span>.<span class="operator">+</span>`</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> </span><br><span class="line">    <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> uid <span class="keyword">order</span> <span class="keyword">by</span> pay_time <span class="keyword">asc</span>) <span class="keyword">as</span> num</span><br><span class="line">    ,<span class="operator">*</span></span><br><span class="line">    <span class="keyword">from</span> <span class="keyword">order</span>) first_order</span><br><span class="line"><span class="keyword">where</span> num <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="select-latest-in-group"><a href="#select-latest-in-group" class="headerlink" title="select latest in group"></a>select latest in group</h2><p><a href="https://stackoverflow.com/questions/35520193/how-to-find-most-recent-records-for-every-group-in-hive">link</a></p>
<p>use rank</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">  <span class="keyword">select</span> id, name, starttime, <span class="built_in">rank</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> name <span class="keyword">order</span> <span class="keyword">by</span> unix_timestamp(starttime, <span class="string">&#x27;EEE, dd MMM yyyy hh:mm:ss z&#x27;</span>) <span class="keyword">desc</span>) <span class="keyword">as</span> rnk <span class="keyword">from</span> hive_table) a </span><br><span class="line"> <span class="keyword">where</span> a.rnk<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<h2 id="hive-cli-pretty"><a href="#hive-cli-pretty" class="headerlink" title="hive cli pretty"></a>hive cli pretty</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.cli.print.header<span class="operator">=</span><span class="literal">true</span>; <span class="operator">/</span><span class="operator">/</span> 打印列名</span><br><span class="line"><span class="keyword">set</span> hive.cli.print.row.to.vertical<span class="operator">=</span><span class="literal">true</span>; <span class="operator">/</span><span class="operator">/</span> 开启行转列功能, 前提必须开启打印列名功能</span><br><span class="line"><span class="keyword">set</span> hive.cli.print.row.to.vertical.num<span class="operator">=</span><span class="number">1</span>; <span class="operator">/</span><span class="operator">/</span> 设置每行显示的列数</span><br></pre></td></tr></table></figure>

<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="小文件问题"><a href="#小文件问题" class="headerlink" title="小文件问题"></a>小文件问题</h2><p>和 spark 的小文件问题一样，hive 的运算引擎（mapreduce 或 Tez），为了提高性能，最后都会采用多个 reducer 来写数据，这个时候就会有小文件。不同于 Spark，Hive 本身提供了多种措施来优化小文件存储，我们只需要设置就行</p>
<h3 id="1-使用-concatenate"><a href="#1-使用-concatenate" class="headerlink" title="1. 使用 concatenate"></a>1. 使用 concatenate</h3><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-AlterTable/PartitionConcatenate">hive concatenate</a> 主要针对 orc 和 rcfile 文件格式存储的文件，特别是 orc ，可以直接执行 stripe level 的 merge，省掉 deserialize 和 decode 的开销，很高效。（concatenate 可以执行多次，最终文件数量不会变化）</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> (partition_key <span class="operator">=</span> <span class="string">&#x27;partition_value&#x27;</span> [, ...])] CONCATENATE;</span><br></pre></td></tr></table></figure>

<h3 id="2-使用一些配置，在写文件时，自动-merge"><a href="#2-使用一些配置，在写文件时，自动-merge" class="headerlink" title="2. 使用一些配置，在写文件时，自动 merge"></a>2. 使用一些配置，在写文件时，自动 merge</h3><p>输入时合并：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--  每个Map最大输入大小，决定合并后的文件数</span></span><br><span class="line"><span class="keyword">set</span>  mapred. max .split.size<span class="operator">=</span><span class="number">256000000</span>;</span><br><span class="line"><span class="comment">-- 一个节点上split的至少的大小 ，决定了多个data node上的文件是否需要合并</span></span><br><span class="line"><span class="keyword">set</span>  mapred. min .split.size.per.node<span class="operator">=</span><span class="number">100000000</span>;</span><br><span class="line"><span class="comment">-- 一个交换机下split的至少的大小，决定了多个交换机上的文件是否需要合并</span></span><br><span class="line"><span class="keyword">set</span>  mapred. min .split.size.per.rack<span class="operator">=</span><span class="number">100000000</span>;</span><br><span class="line"><span class="comment">-- 执行Map前进行小文件合并</span></span><br><span class="line"><span class="keyword">set</span>  hive.input.format<span class="operator">=</span>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; </span><br></pre></td></tr></table></figure>

<p>输出时合并：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- hive 输出时合并的配置参数</span></span><br><span class="line"><span class="comment">-- 在Map-only的任务结束时合并小文件</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.mapfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 在Map-Reduce的任务结束时合并小文件, 默认 false</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.tezfiles<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.merge.mapredfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 合并文件的大小, 默认 256000000</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.size.per.task<span class="operator">=</span><span class="number">256000000</span>;</span><br><span class="line"><span class="comment">-- 当输出文件的平均大小小于该值时, 启动一个独立的map-reduce任务进行文件merge， 默认 16000000</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.smallfiles.avgsize<span class="operator">=</span><span class="number">256000000</span>;</span><br><span class="line"><span class="comment">-- 当这个参数设置为true,orc文件进行stripe Level级别的合并,当设置为false,orc文件进行文件级别的合并。默认 true</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.orcfile.stripe.level<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>Hive在对结果文件进行合并时会执行一个额外的map-only脚本，mapper的数量是文件总大小除以size.per.task参数所得的值，触发合并的条件是：</p>
<p>根据查询类型不同，相应的mapfiles&#x2F;mapredfiles参数需要打开；</p>
<p>结果文件的平均大小需要大于avgsize参数的值。</p>
<h1 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h1><h2 id="count-return-0"><a href="#count-return-0" class="headerlink" title="count(*) return 0"></a>count(*) return 0</h2><p><a href="https://community.cloudera.com/t5/Support-Questions/hive-count-not-working/td-p/216889">hive count(*) not working</a></p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/StatsDev#StatsDev-ExistingTables%E2%80%93ANALYZE">hive analyze</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以设，但不好</span></span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; <span class="built_in">set</span> hive.fetch.task.conversion=none;</span><br><span class="line"><span class="comment"># 或者设</span></span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; <span class="built_in">set</span> hive.compute.query.using.stats=<span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 推荐</span></span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; analyze table t [partition p] compute statistics <span class="keyword">for</span> [columns c,...];</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Its better not to disturb the properties on the statistics usage like hive.compute.query.using.stats. It impacts the way the statistics are used in your query for performance optimization and execution plans. It has tremendous influence on execution plans, the statistics stored depends on the file format as well. Therefore definitely not a solution to change any property with regards to statistics.<br>The real reason for count not working correctly is the statistics not updated in the hive due to which it returns 0. When a table is created first, the statistics is written with no data rows. Thereafter any data append&#x2F;change happens hive requires to update this statistics in the metadata. Depending on the circumstances hive might not be updating this real time.<br>Therefore running the ANALYZE command recomputes this statistics to make this work correctly.</p>
</blockquote>
<h2 id="hive-not-recognizing-alias-names-in-select-part"><a href="#hive-not-recognizing-alias-names-in-select-part" class="headerlink" title="hive not recognizing alias names in select part"></a>hive not recognizing alias names in select part</h2><p>The where clause is evaluated before the select clause, which is why you can’t refer to select aliases in your where clause.</p>
<p>You can however refer to aliases from a derived table.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * from (</span><br><span class="line">  <span class="keyword">select</span> user as u1, url as u2 from rank_test</span><br><span class="line">) t1 <span class="built_in">where</span> u1 &lt;&gt; <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * from (</span><br><span class="line">  <span class="keyword">select</span> user, count(*) as cnt from rank_test group by user</span><br><span class="line">) t1 <span class="built_in">where</span> cnt &gt;= 2;</span><br></pre></td></tr></table></figure>

<p>Side note: a more efficient way to write the last query would be</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> user, count(*) as cnt from rank_test group by user</span><br><span class="line">having count(*) &gt;= 2</span><br></pre></td></tr></table></figure>

<h2 id="In-not-in-substitution"><a href="#In-not-in-substitution" class="headerlink" title="In, not in substitution"></a>In, not in substitution</h2><p>Hive supports sub-query in <code>in</code> , <code>not in</code> only after 0.13. And <code>in</code> may be slow, so we can replace it with join.</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- in</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">where</span> id <span class="keyword">in</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b)</span><br><span class="line"><span class="comment">-- in substitutionn</span></span><br><span class="line"><span class="keyword">select</span> a.<span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">join</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b) b1 <span class="keyword">on</span> a.id <span class="operator">=</span> b1.id</span><br></pre></td></tr></table></figure>

<h2 id="VERTEX-FAILURE"><a href="#VERTEX-FAILURE" class="headerlink" title="VERTEX_FAILURE"></a>VERTEX_FAILURE</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.partitions=8000;</span><br><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.partitions.pernode=8000;</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> hive.tez.log.level=DEBUG;</span><br></pre></td></tr></table></figure>

<h2 id="explain"><a href="#explain" class="headerlink" title="explain"></a>explain</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="built_in">sum</span>(id) <span class="keyword">from</span> my;</span><br></pre></td></tr></table></figure>

<h2 id="xa0"><a href="#xa0" class="headerlink" title="\xa0"></a>\xa0</h2><p>(<code>SPACE_SEPARATOR</code>, <code>LINE_SEPARATOR</code>, or <code>PARAGRAPH_SEPARATOR</code>) but is not also a non-breaking space (<code>&#39;\u00A0&#39;</code>, <code>&#39;\u2007&#39;</code>, <code>&#39;\u202F&#39;</code>).</p>
<p><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Character.html#isWhitespace-char-">java isWhiteSpace()</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(res.selectExpr(&quot;trim(translate(mobile1, &#x27;\u00A0&#x27;, &#x27; &#x27;))&quot;).collect())</span><br><span class="line">print(res.selectExpr(&quot;trim(regexp_replace(mobile1, &#x27;\u00A0|\u2007|\u202F&#x27;, &#x27; &#x27;))&quot;).collect())</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/big-data/" rel="tag"># big data</a>
              <a href="/tags/storage/" rel="tag"># storage</a>
              <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2018/12/13/responsive-web-design/" rel="prev" title="responsive-web-design">
                  <i class="fa fa-chevron-left"></i> responsive-web-design
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2019/01/07/hdfs/" rel="next" title="hdfs">
                  hdfs <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cherish</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>Word count total: </span>
    <span title="Word count total">528k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>Reading time total &asymp;</span>
    <span title="Reading time total">8:01</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>
<script class="next-config" data-name="chatra" type="application/json">{"enable":true,"async":true,"id":null}</script>
<script src="/js/third-party/chat/chatra.js"></script>
<script async src="https://call.chatra.io/chatra.js"></script>






  





</body>
</html>
