<!DOCTYPE html>
<html lang="Chinese">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0-rc1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hfcherish.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.15.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="从心所欲不逾矩">
<meta property="og:type" content="website">
<meta property="og:title" content="Cherish&#39;s Blog">
<meta property="og:url" content="http://hfcherish.github.io/index.html">
<meta property="og:site_name" content="Cherish&#39;s Blog">
<meta property="og:description" content="从心所欲不逾矩">
<meta property="og:locale">
<meta property="article:author" content="Cherish">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://hfcherish.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"Chinese","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Cherish's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Cherish's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cherish</p>
  <div class="site-description" itemprop="description">从心所欲不逾矩</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">63</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">53</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button animated">
    <button><i class="fa fa-comment"></i>
      Chat
    </button>
  </div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hfcherish" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hfcherish" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:pzcherishhf@gmail.com" title="E-Mail → mailto:pzcherishhf@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2022/10/22/react-native-components-apis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/22/react-native-components-apis/" class="post-title-link" itemprop="url">react native components & apis</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-10-22 14:22:52" itemprop="dateCreated datePublished" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>react 提倡组件化开发，以促进复用。react native 也一样是组件化开发思想。不同的是，react 中是使用原生的 html 组件作为基本组件（div、a…），而 react native 使用的是另一些原生组件。用户的自定义组件也是基于这些原生组件。</p>
<p>所以要用 react native，必须了解这些原生组件（就跟学 html 组件差不多）</p>
<h1 id="general-props"><a href="#general-props" class="headerlink" title="general props"></a>general props</h1><p>一些所有组件或大部分组件都有的属性。</p>
<h2 id="style"><a href="#style" class="headerlink" title="style"></a><a href="https://reactnative.cn/docs/0.51/style.html#content">style</a></h2><p>所有的核心组件都接受名为 <code>style</code> 的属性（类似 html 标签中的 <code>html</code>）。这些样式名基本上是遵循了 web 上的 CSS 的命名，只是按照 JS 的语法要求使用了驼峰命名法，例如将 <code>background-color</code> 改为<code>backgroundColor</code>。</p>
<p>实际开发中组件的样式会越来越复杂，我们建议使用StyleSheet.create来集中定义组件的样式。常见的做法是按顺序声明和使用 <code>style</code> 属性，以借鉴 CSS 中的“层叠”做法（即后声明的属性会覆盖先声明的同名属性）。比如像下面这样：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123; <span class="title class_">Component</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">AppRegistry</span>, <span class="title class_">StyleSheet</span>, <span class="title class_">Text</span>, <span class="title class_">View</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react-native&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">LotsOfStyles</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.red&#125;</span>&gt;</span>just red<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.bigblue&#125;</span>&gt;</span>just bigblue<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;[styles.bigblue,</span> <span class="attr">styles.red</span>]&#125;&gt;</span>bigblue, then red<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;[styles.red,</span> <span class="attr">styles.bigblue</span>]&#125;&gt;</span>red, then bigblue<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> styles = <span class="title class_">StyleSheet</span>.<span class="title function_">create</span>(&#123;</span><br><span class="line">  <span class="attr">bigblue</span>: &#123;</span><br><span class="line">    <span class="attr">color</span>: <span class="string">&#x27;blue&#x27;</span>,</span><br><span class="line">    <span class="attr">fontWeight</span>: <span class="string">&#x27;bold&#x27;</span>,</span><br><span class="line">    <span class="attr">fontSize</span>: <span class="number">30</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">red</span>: &#123;</span><br><span class="line">    <span class="attr">color</span>: <span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册应用(registerComponent)后才能正确渲染</span></span><br><span class="line"><span class="comment">// 注意：只把应用作为一个整体注册一次，而不是每个组件/模块都注册</span></span><br><span class="line"><span class="title class_">AppRegistry</span>.<span class="title function_">registerComponent</span>(<span class="string">&#x27;LotsOfStyles&#x27;</span>, <span class="function">() =&gt;</span> <span class="title class_">LotsOfStyles</span>);</span><br></pre></td></tr></table></figure>

<h3 id="组件宽度高度"><a href="#组件宽度高度" class="headerlink" title="组件宽度高度"></a><a href="https://reactnative.cn/docs/0.51/height-and-width.html#content">组件宽度高度</a></h3><p>有两种设定方法：</p>
<p><strong>1. 指定宽高</strong></p>
<p>最简单的给组件设定尺寸的方式就是在样式中指定固定的 <code>width</code>和 <code>height</code>。React Native中的尺寸都是无单位的，表示的是与设备像素密度无关的逻辑像素点。</p>
<p><strong>2. 弹性宽高</strong></p>
<p>在组件样式中使用 <code>flex</code> 可以使其在可利用的空间中动态地扩张或收缩。一般而言我们会使用 <code>flex:1</code> 来指定某个组件扩张以撑满所有剩余的空间。如果有多个并列的子组件使用了 <code>flex:1</code>，则这些子组件会平分父容器中剩余的空间。如果这些并列的子组件的 <code>flex</code> 值不一样，则谁的值更大，谁占据剩余空间的比例就更大（即占据剩余空间的比等于并列组件间 <code>flex</code> 值的比）。</p>
<blockquote>
<p>组件能够撑满剩余空间的前提是其父容器的尺寸不为零。如果父容器既没有固定的 <code>width</code> 和 <code>height</code>，也没有设定 <code>flex</code>，则父容器的尺寸为零。其子组件如果使用了 <code>flex</code>，也是无法显示的。</p>
</blockquote>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123; <span class="title class_">Component</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">AppRegistry</span>, <span class="title class_">View</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react-native&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">FlexDimensionsBasics</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="comment">// 试试去掉父View中的`flex: 1`。</span></span><br><span class="line">      <span class="comment">// 则父View不再具有尺寸，因此子组件也无法再撑开。</span></span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;flex:</span> <span class="attr">1</span>&#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">      // 这里设定的是固定宽高</span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;width:</span> <span class="attr">50</span>, <span class="attr">height:</span> <span class="attr">50</span>, <span class="attr">backgroundColor:</span> &#x27;<span class="attr">powderblue</span>&#x27;&#125;&#125; /&gt;</span></span></span><br><span class="line"><span class="language-xml">        // 弹性宽高</span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;flex:</span> <span class="attr">2</span>, <span class="attr">backgroundColor:</span> &#x27;<span class="attr">skyblue</span>&#x27;&#125;&#125; /&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;flex:</span> <span class="attr">3</span>, <span class="attr">backgroundColor:</span> &#x27;<span class="attr">steelblue</span>&#x27;&#125;&#125; /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="title class_">AppRegistry</span>.<span class="title function_">registerComponent</span>(<span class="string">&#x27;AwesomeProject&#x27;</span>, <span class="function">() =&gt;</span> <span class="title class_">FlexDimensionsBasics</span>);</span><br></pre></td></tr></table></figure>

<h3 id="flexbox-布局"><a href="#flexbox-布局" class="headerlink" title="flexbox 布局"></a><a href="https://reactnative.cn/docs/0.51/layout-with-flexbox.html#content">flexbox 布局</a></h3><p>一般用以下三个属性就可以完成布局的要求了，完整的布局样式属性参照 <a href="https://reactnative.cn/docs/0.51/layout-props.html">这篇文章</a>（也可以参考<a href="https://weibo.com/1712131295/CoRnElNkZ?ref=collection&type=comment#_rnd1526464804589">图解布局模式</a>）：</p>
<ol>
<li><code>flexDirection</code>: 定义布局主轴。<code>row</code>（水平轴）、<code>column</code>（default）</li>
<li><code>justifyContent</code>: 定义主轴上元素排列的方式。<code>flex-start</code>、<code>center</code>、<code>flex-end</code>、<code>space-around</code>（元素在主轴上均匀分布）、<code>space-between</code>(元素间距均匀分布)</li>
<li><code>alignItems</code>: 定义子元素在次轴（与主轴垂直）上的排列方式。<code>flex-start</code>、<code>flex-end</code>、<code>center</code>、<code>stretch</code>（要使 <code>stretch</code> 选项生效的话，子元素在次轴方向上不能有固定的尺寸）</li>
</ol>
<h1 id="核心组件-components"><a href="#核心组件-components" class="headerlink" title="核心组件 components"></a>核心组件 components</h1><p>react native 提供了很多内置的 components，社区也有很多开发者提供有很多实用的 components（可以直接从 npm 搜 <a href="https://www.npmjs.com/search?q=react-native&page=1&ranking=optimal"><code>react native</code></a>，或者查看 <a href="http://www.awesome-react-native.com/#components">awesome react native</a> 里总结的一些列表）</p>
<p>大部分组件，最终都是基于下边这些基本组件写的。<a href="https://facebook.github.io/react-native/docs/components-and-apis.html#user-interface">components &amp; apis</a> 总结了 basic components、用于 ui 渲染的、list 的、ios specific 的、android specific 的（学习这些相当于是学习 html 基本组件的过程）</p>
<h2 id="View"><a href="#View" class="headerlink" title="View"></a><a href="https://reactnative.cn/docs/0.51/view.html#content">View</a></h2><p>View 常用作其他组件的容器，来帮助控制布局和样式（类似于 div）</p>
<h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a><a href="https://reactnative.cn/docs/0.51/text.html#content">Text</a></h2><p>写文本的</p>
<h2 id="TextInput"><a href="#TextInput" class="headerlink" title="TextInput"></a><a href="https://reactnative.cn/docs/0.51/textinput.html#content">TextInput</a></h2><p>是一个允许用户输入文本的基础组件</p>
<h2 id="Image"><a href="#Image" class="headerlink" title="Image"></a><a href="https://reactnative.cn/docs/0.51/image.html#content">Image</a></h2><p>放图片的</p>
<h2 id="SrollView"><a href="#SrollView" class="headerlink" title="SrollView"></a><a href="https://reactnative.cn/docs/0.51/scrollview.html#content">SrollView</a></h2><p><code>ScrollView</code> 是一个通用的可滚动的容器，你可以在其中放入多个组件和视图，而且这些组件并不需要是同类型的。<code>ScrollView</code> 不仅可以垂直滚动，还能水平滚动（通过 <code>horizontal</code> 属性来设置）。</p>
<h2 id="StyleSheet"><a href="#StyleSheet" class="headerlink" title="StyleSheet"></a><a href="https://reactnative.cn/docs/0.51/stylesheet.html#content">StyleSheet</a></h2><p>这其实是一个接口</p>
<p>StyleSheet提供了一种类似CSS样式表的抽象</p>
<h2 id="FlatList"><a href="#FlatList" class="headerlink" title="FlatList"></a><a href="https://reactnative.cn/docs/0.51/flatlist.html#content">FlatList</a></h2><p>react native 有几种用于显示长列表的组件：<code>flatlist</code>、<code>sectionlist</code>、<code>scrollview</code> 等。</p>
<p><code>FlatList</code> 组件用于显示一个垂直的滚动列表，其中的元素之间结构近似而仅数据不同，且元素个数可以增删。和 <code>ScrollView</code> 不同的是，<code>FlatList</code> 并不立即渲染所有元素，而是优先渲染屏幕上可见的元素。而那些已经渲染好了但移动到了屏幕之外的元素，则会从原生视图结构中移除（以提高性能）.</p>
<p><code>FlatList</code> 组件必须的两个属性是 <code>data</code> 和 <code>renderItem</code>。<code>data</code> 是列表的数据源，而 <code>renderItem</code> 则从数据源中逐个解析数据，然后返回一个设定好格式的组件来渲染。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">FlatListBasics</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.container&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">FlatList</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">data</span>=<span class="string">&#123;[</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Devin</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Jackson</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">James</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Joel</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">John</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Jillian</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Jimmy</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Julie</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          ]&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">renderItem</span>=<span class="string">&#123;(&#123;item&#125;)</span> =&gt;</span> <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.item&#125;</span>&gt;</span>&#123;item.key&#125;<span class="tag">&lt;/<span class="name">Text</span>&gt;</span>&#125;</span></span><br><span class="line"><span class="language-xml">        /&gt;</span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SectionList"><a href="#SectionList" class="headerlink" title="SectionList"></a><a href="https://reactnative.cn/docs/0.51/sectionlist.html#content">SectionList</a></h2><p>如果要渲染的是一组需要分组的数据，也许还带有分组标签的，那么 <code>SectionList</code> 将是个不错的选择</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.container&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">SectionList</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">sections</span>=<span class="string">&#123;[</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">title:</span> &#x27;<span class="attr">D</span>&#x27;, <span class="attr">data:</span> [&#x27;<span class="attr">Devin</span>&#x27;]&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">title:</span> &#x27;<span class="attr">J</span>&#x27;, <span class="attr">data:</span> [&#x27;<span class="attr">Jackson</span>&#x27;, &#x27;<span class="attr">James</span>&#x27;, &#x27;<span class="attr">Jillian</span>&#x27;, &#x27;<span class="attr">Jimmy</span>&#x27;, &#x27;<span class="attr">Joel</span>&#x27;, &#x27;<span class="attr">John</span>&#x27;, &#x27;<span class="attr">Julie</span>&#x27;]&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          ]&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">renderItem</span>=<span class="string">&#123;(&#123;item&#125;)</span> =&gt;</span> <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.item&#125;</span>&gt;</span>&#123;item&#125;<span class="tag">&lt;/<span class="name">Text</span>&gt;</span>&#125;</span></span><br><span class="line"><span class="language-xml">          renderSectionHeader=&#123;(&#123;section&#125;) =&gt; <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.sectionHeader&#125;</span>&gt;</span>&#123;section.title&#125;<span class="tag">&lt;/<span class="name">Text</span>&gt;</span>&#125;</span></span><br><span class="line"><span class="language-xml">        /&gt;</span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><p>接口其实是仅提供接口功能的简单组件。这些组件可能没有渲染功能。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2022/10/22/java-stream-parallel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/22/java-stream-parallel/" class="post-title-link" itemprop="url">java stream parallel 有时比 sequential 还慢？</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-10-22 14:22:52" itemprop="dateCreated datePublished" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="为什么-java-stream-parallel-有时比-sequential-执行还慢？"><a href="#为什么-java-stream-parallel-有时比-sequential-执行还慢？" class="headerlink" title="为什么 java stream parallel 有时比 sequential 执行还慢？"></a>为什么 java stream parallel 有时比 sequential 执行还慢？</h1><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>考虑下边的代码，并行执行不一定比顺序执行快，甚至很多时候都是更慢的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_not_sure_if_without_warm_up</span><span class="params">()</span> &#123;</span><br><span class="line">        String[] array = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">1000000</span>];</span><br><span class="line">        Arrays.fill(array, <span class="string">&quot;AbabagalamagA&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Benchmark...&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i) &#123;</span><br><span class="line">            System.out.printf(<span class="string">&quot;Run %d:  sequential %s  -  parallel %s\n&quot;</span>,</span><br><span class="line">                    i,</span><br><span class="line">                    test(() -&gt; sequential(array)),</span><br><span class="line">                    test(() -&gt; parallel(array)));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">sequential</span><span class="params">(String[] array)</span> &#123;</span><br><span class="line">        Arrays.stream(array).map(String::toLowerCase).collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">parallel</span><span class="params">(String[] array)</span> &#123;</span><br><span class="line">        Arrays.stream(array).parallel().map(String::toLowerCase).collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String <span class="title function_">test</span><span class="params">(Runnable runnable)</span> &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">        runnable.run();</span><br><span class="line">        <span class="type">long</span> <span class="variable">elapsed</span> <span class="operator">=</span> System.currentTimeMillis() - start;</span><br><span class="line">        <span class="keyword">return</span> String.format(<span class="string">&quot;%4.2fs&quot;</span>, elapsed / <span class="number">1000.0</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="为什么？"><a href="#为什么？" class="headerlink" title="为什么？"></a>为什么？</h2><p>有几个原因（<a href="http://www.theserverside.com/definition/just-in-time-compiler-JIT">stackoverflow</a>）：</p>
<ol>
<li><strong>stream 的并行执行比串行执行要做更多的事</strong>。并行执行需要拆分程序，使得程序可以并行执行，最后要合并结果。例如，上述并行执行涉及到 new 线程池、分配线程执行特定的 string 操作并加到一个 list、最终合并 list。这个程序本身已经执行很快，此时，这些额外开销比本身执行的时间可能还要长，就影响了它最终带来的性能。</li>
<li><strong>编译器、jvm、GC 等会影响代码执行效率，因此对 java 做这些基准测试很微妙</strong>。例如 <a href="http://www.theserverside.com/definition/just-in-time-compiler-JIT">JIT compiler</a>、GC 等就会很大程度的影响测试结果。<ol start="3">
<li>测试很大程度受 JIT compiler 执行的影响<ol start="4">
<li>在 JIT compiler 完成之前，可能测试已经跑完了。此时顺序执行和并行执行哪个 JIT compiler 先跑完，可能测试就会跑的更快一些</li>
<li>而且 JIT compiler 什么时候开始跑也不确定。</li>
<li>并且 JIT compiler 会做一些运行时优化，比如有些代码，其输出没有在任何地方被使用，JIT compiler 会直接消除这些代码的执行。这种情况还是非常容易发生的。此时，你这些测试衡量就更微妙了，因为可能最终执行的测试并不是你所写的测试，而是优化之后的。</li>
<li>如果在测试执行之前，加上一些预热，就可以保证程序都已经再编译完成，此时评估的就是同等条件下的程序执行效率了（参见下边的 code）。</li>
</ol>
</li>
<li>GC 会影响执行效率，不同的代码会产生不同的 eliminated objects<ol start="5">
<li>stream、并行运行等会涉及到很多中间变量的构建、copy 等，比如中间 string、list 等，这时 GC 执行工作量就比较大，会影响最终的测试执行时间，使得测试结果也不可信。</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>对 java 做这些基准测试，有时结果会比较 confusing，所以建议采用专门的 benchmark 框架来做基准测试，比如 <a href="http://openjdk.java.net/projects/code-tools/jmh/">JMH</a>，这框架执行过程中，可以看到很多 java 额外执行的一些操作时间等，就可以更好的观察测试结果了。        </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 更改测试，加上预热，保证 JIT 编译已完成，此时基本是在同等条件下测试，测试结果相对更可信一些</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_parallel_faster_if_has_warm_up</span><span class="params">()</span> &#123;</span><br><span class="line">    String[] array = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">1000000</span>];</span><br><span class="line">    Arrays.fill(array, <span class="string">&quot;AbabagalamagA&quot;</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;Warmup...&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">        sequential(array);</span><br><span class="line">        parallel(array);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="string">&quot;Benchmark...&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i) &#123;</span><br><span class="line">        System.out.printf(<span class="string">&quot;Run %d:  sequential %s  -  parallel %s\n&quot;</span>,</span><br><span class="line">                i,</span><br><span class="line">                test(() -&gt; sequential(array)),</span><br><span class="line">                test(() -&gt; parallel(array)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="什么是-JIT-compiler"><a href="#什么是-JIT-compiler" class="headerlink" title="什么是 JIT compiler"></a>什么是 <a href="http://www.theserverside.com/definition/just-in-time-compiler-JIT">JIT compiler</a></h3><p>JIT (just-in-time) compiler 指在运行时执行的编译器。</p>
<p>(1) java 是编译成字节码，然后在运行时解释执行的</p>
<p>c、C++ 等编程语言都是直接编译成机器码，可以在机器上直接执行的。但是不同平台处理器有差异，导致用户可能需要为不同平台写多套程序。</p>
<p>java 就提出了 JVM，将代码一次编译成字节码，然后提供不同的 JVM，JVM 会将字节码解释执行为可运行的机器码。</p>
<p>但是解释执行是一行一行做的，就影响了执行效率。这也是为啥 c++ 等会诟病 java 很慢的原因。</p>
<p>(2) 为了提高解释执行的效率，使用了 JIT compiler</p>
<p>正如上文所说，因为解释执行慢，所以在程序运行起来后，同时会执行 JIT compiler，将字节码编译成可执行代码（相当于二次编译）。这就可以一定程度的加快解释执行的效率。而且 JIT compiler 因为可以获取运行时环境、参数等，所以可以做更多的优化</p>
<h1 id="parallel-慎用？？？"><a href="#parallel-慎用？？？" class="headerlink" title="parallel 慎用？？？"></a>parallel 慎用？？？</h1><p><a href="https://dzone.com/articles/think-twice-using-java-8">DZone: parallel 慎用</a> 说因为 stream 公用线程池，一个 broken thread 会影响所有 healthy 线程的执行，所以要慎用。</p>
<p>简单看了一些，比如这个 <a href="https://stackoverflow.com/questions/20375176/should-i-always-use-a-parallel-stream-when-possible">stackoverflow</a>，应该是说 stream 提供了方便的形式去写 function、可读性高、promote 大家写出 side-effects-free 的代码，但是 stream 本身还是有很多缺陷的。</p>
<p>公用线程池的测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_be_influenced_by_long_tasks</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="comment">/** Simulating multiple threads in the system</span></span><br><span class="line"><span class="comment">    * if one of them is executing a long-running task.</span></span><br><span class="line"><span class="comment">    * Some of the other threads/tasks are waiting</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">MAX</span> <span class="operator">=</span> <span class="number">12</span>;</span><br><span class="line">    <span class="type">ExecutorService</span> <span class="variable">es</span> <span class="operator">=</span> Executors.newCachedThreadPool();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这个线程执行很慢，但是因为共享线程池，因此会影响其他线程的执行。极端情况，这里是一个 broken tread，其他 healthy thread 都会受影响</span></span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">1000</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行结果不确定，因为有上边的长线程。如果注释掉上边线程，下边这个可以很快执行</span></span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.shutdown();</span><br><span class="line">    es.awaitTermination(<span class="number">60</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">countPrimes</span><span class="params">(<span class="type">int</span> max, <span class="type">int</span> delay)</span> &#123;</span><br><span class="line">    System.out.println(Thread.currentThread().getId() + <span class="string">&quot;: &quot;</span> + range(<span class="number">1</span>, max).parallel().filter(<span class="built_in">this</span>::isPrime).peek(i -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            sleep(delay);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;).count());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">isPrime</span><span class="params">(<span class="type">long</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> n &gt; <span class="number">1</span> &amp;&amp; rangeClosed(<span class="number">2</span>, (<span class="type">long</span>) sqrt(n)).noneMatch(divisor -&gt; n % divisor == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="ForkJoinPool"><a href="#ForkJoinPool" class="headerlink" title="ForkJoinPool"></a><a href="http://tutorials.jenkov.com/java-util-concurrent/java-fork-and-join-forkjoinpool.html">ForkJoinPool</a></h2><p><a href="https://www.jianshu.com/p/bd825cb89e00">这个文章</a> 介绍了 ForkJoinPool，说是 parallel stream 实现的主要原理和背后手段</p>
<p>stream 的并发执行现在基本上都是采用分治法，先拆分用多线程逐个处理，然后再合并结果。最后的合并操作必须在前边某几个线程执行完之后才做。</p>
<p>而普通的线程池 <a href="">ThreadPoolExecutor</a> 就是构建一个线程池，并发执行，但是它没办法决定线程执行的父子关系。</p>
<p>ForkJoinPool 就是为了解决上述问题而存在，它可以让子任务并发执行完成之后，才开始执行父任务。除此以外，和 ThreadPoolExecutor 一样，都是用一个无限队列来保存待执行的任务。</p>
<p>ForkJoinPool 采用了一个通用线程池，实现了 **<a href="http://ifeve.com/talk-concurrency-forkjoin/">工作窃取</a>**。工作窃取指某个线程从其他队列里窃取任务来执行。ForkJoinPool 就可以？？？？？</p>
<h1 id="什么时候用-parallel"><a href="#什么时候用-parallel" class="headerlink" title="什么时候用 parallel"></a>什么时候用 parallel</h1><p>目前来说，在 java 中：</p>
<ol>
<li>如果是数据量很大的操作，可以考虑用 parallel</li>
<li>如果有性能问题，再考虑用 parallel</li>
<li>如果确实有多核，再考虑用</li>
<li>如果确实是无 side effect 的函数，才可以考虑用</li>
<li>如果已经有其他并行措施，可以不用 parallel</li>
<li>如果数据操作很慢，慎用（可能 block 其他 thread）</li>
<li>如果数据操作很快，也慎用（可能这个时候用并行的额外开销会超过它所能带来的优势）</li>
</ol>
<p><a href="https://blog.oio.de/2016/01/22/parallel-stream-processing-in-java-8-performance-of-sequential-vs-parallel-stream-processing/">这篇文章</a>也对比了并行和串行 stream，然后画了个决策象限图，如下图所示：</p>
<p><img src="https://blog.oio.de/wp-content/uploads/2016/01/stream_performance_image3.png" alt="parallel 决策象限图"></p>
<p>跟上边类似，关注下边四个方面：</p>
<ol>
<li><code>number_of_elements * cost_per_element</code> 比较大。这可以比较好的解决这种状况：每个元素运行很快时，如果数据量大就可以用；如果每个元素运行稍费时些，即使数据量不那么大，也 ok。但是应该要避免过于费时的那些场景，见上边的分析。</li>
<li>source collection 可以很高效的被拆分（这样才方便拆线程处理）</li>
<li>每个元素的函数执行是独立的（这才可以并行处理，即并行首先要求 side effect free）</li>
<li>多核</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2022/10/22/fantastic-tools/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/22/fantastic-tools/" class="post-title-link" itemprop="url">fantastic tools</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-10-22 14:22:52" itemprop="dateCreated datePublished" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><p>收集一些在设计时可能会用到的比较好的网站</p>
<ul>
<li><a href="https://fontawesome.com/v4.7.0/icons/">icons from the fontawesome</a>: 各种各样的图标，很漂亮</li>
<li><a href="https://ant.design/docs/spec/introduce-cn">ant design</a>：里边有 UI 设计价值观及图标资源等，还有前端组件库</li>
</ul>
<h2 id="前端组件库"><a href="#前端组件库" class="headerlink" title="前端组件库"></a>前端组件库</h2><p><a href="https://zhuanlan.zhihu.com/p/24650288">组件库大合集</a></p>
<p><a href="https://github.com/JingwenTian/awesome-frontend">组件库大合集2</a></p>
<h1 id="mac"><a href="#mac" class="headerlink" title="mac"></a>mac</h1><p><a href="https://insights.thoughtworks.cn/ocds-guide-to-setting-up-mac/">强迫症的Mac设置指南</a></p>
<h2 id="terminal"><a href="#terminal" class="headerlink" title="terminal"></a>terminal</h2><p>[10 Must know terminal commands and tips for productivity](10 Must know terminal commands and tips for productivity) 介绍了一些，简单罗列下：</p>
<ol>
<li><code>iterm2</code>：是一种 terminal，将其作为默认 terminal，可以方便的分屏等</li>
<li><code>oh my zsh</code>：管理 zsh 配置的，使用 <code>~/.zshrc</code>，利用 <code>source ~/.zshrc</code> 可以是配置立马生效<ol>
<li><a href="https://hustyichi.github.io/2018/09/19/oh-my-zsh/">oh my zsh 插件</a></li>
</ol>
</li>
<li><code>cat</code>：不打开文件的情况下查看内容</li>
<li><code>imgcat</code>：同上，不过查看的是图片</li>
<li><code>less [filename]</code>：同 <code>cat</code>，不过如果长文件，可以用这个，仅显示一部分</li>
<li><code>pbcopy &lt; [filename]</code>：复制文件内容到 clipboard</li>
<li><code>touch</code>：创建各种各样的文件，可以同时创建多个。eg. <code>touch index.html readme.md index.php</code></li>
<li><code>lsof -i :[port]</code>：查看端口占用</li>
<li><code>&amp;&amp;</code>：实现 command chaining，即同时写多个命令，依次执行。eg. <code>npm i &amp;&amp; npm start</code></li>
<li><code>open .</code>：打开当前目录</li>
</ol>
<h3 id="iterm2-oh-my-zsh-theme-配置"><a href="#iterm2-oh-my-zsh-theme-配置" class="headerlink" title="iterm2 + oh my zsh + theme 配置"></a>iterm2 + oh my zsh + theme 配置</h3><ol>
<li><a href="https://www.iterm2.com/">download iterm2</a>，解压安装</li>
<li>设置 iterm2 为默认 terminal：iterm2 -&gt; make iterm2 default Term</li>
<li>安装 <a href="https://github.com/robbyrussell/oh-my-zsh">oh my zsh</a>: <ul>
<li><code>sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; </code></li>
</ul>
</li>
<li>配置主题和颜色<ol start="4">
<li>主题，我选用默认的 robbyrussell。其他下载主题然后在 <code>~/.zshrc</code> 中配置 <code>ZSH_THEME</code></li>
<li>颜色，下载 <a href="https://github.com/mbadolato/iTerm2-Color-Schemes">iterm2 color schemes</a>，然后在 iterm2 perferences -&gt; profiles -&gt; colors -&gt; color presets -&gt; import -&gt; 从前边下载的库中选择自己喜欢的 scheme</li>
</ol>
</li>
<li>配置高亮<ul>
<li><code>brew install zsh-syntax-highlighting</code></li>
<li>在 <code>~/.zshrc</code> 中添加：<code>source /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh</code></li>
<li>刷新配置使其生效：<code>source ~/.zshrc</code></li>
</ul>
</li>
<li>显示快捷键配置<ul>
<li>preferences -&gt; keys -&gt; hotKey -&gt; Show&#x2F;Hide all… -&gt; 设置为 <code>⌘.</code></li>
</ul>
</li>
<li>常用的配置：<ol>
<li>配置新开重开使用之前的目录：preferences -&gt; profiles -&gt; general -&gt; working directory -&gt; reuse previous session’s directory</li>
<li>配置快速切换 iterm 的快捷键：preferences -&gt; keys -&gt; hot key -&gt; show&#x2F;hide all windows with a system-wide hotkey</li>
<li>配置窗口透明度和默认启动大小：preferences -&gt; profiles -&gt; window</li>
<li>配置 command line move-by-word, delete-by-word: preferences -&gt; profiles -&gt; keys (<a href="https://apple.stackexchange.com/questions/154292/iterm-going-one-word-backwards-and-forwards">stackoverflow</a>)<ol>
<li>向左移动 by word (⌥b)，向右移动 by word (⌥f)，删除右边 by word (⌥d)<ol>
<li>Under Profile Shortcut Keys, click the + sign.</li>
<li>Type your key shortcut (option-b, option-f, option-d, option-left, etc.)</li>
<li>For Action, choose Send Escape Sequence.</li>
<li>Write b, d or f in the input field.</li>
</ol>
</li>
<li>删除左边 by word (⌥⌫)<ol>
<li>preferences -&gt; profiles -&gt; keys -&gt; left option (⌥) key : Esc+</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="iterm2-常用快捷键"><a href="#iterm2-常用快捷键" class="headerlink" title="iterm2 常用快捷键"></a>iterm2 常用快捷键</h3><ul>
<li><code>⌘d</code>：横分屏</li>
<li><code>⌘⇧d</code>：竖分屏</li>
<li><code>⌘⌥ + direction</code>：navigate between panes</li>
<li><code>⌘.</code>：show&#x2F;hide iterm2</li>
<li><code>⌘⇧↩︎</code>: 最大化当前 pane &#x2F; 回复当前 pane</li>
</ul>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><ul>
<li><a href="https://github.com/newren/git-filter-repo">git-fitler-repo</a></li>
<li>常用的 git config 配置</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 ~/.zshrc 中添加 alias</span></span><br><span class="line">$ vi ~/.zshrc</span><br><span class="line"><span class="built_in">alias</span> g=<span class="string">&quot;/usr/bin/git&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 .gitconfig 中添加 alias 配置</span></span><br><span class="line">$ vi ~/.gitconfig</span><br><span class="line">[user]</span><br><span class="line">        name = xxx</span><br><span class="line">        email = xxx@some.com</span><br><span class="line"></span><br><span class="line">[<span class="built_in">alias</span>]</span><br><span class="line">        a = add</span><br><span class="line">        aa = add .</span><br><span class="line">        b = branch</span><br><span class="line">        c = commit</span><br><span class="line">        cm = commit -m</span><br><span class="line">        ca = commit --amend</span><br><span class="line">        d = diff</span><br><span class="line">        l = <span class="built_in">log</span> --graph --pretty=format:<span class="string">&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr)%Creset | %C(bold)%an&#x27;</span> --abbrev-commit --<span class="built_in">date</span>=relative</span><br><span class="line">        o = checkout</span><br><span class="line">        pl = pull</span><br><span class="line">        pb = pull --rebase</span><br><span class="line">        ps = push</span><br><span class="line">        r = reset</span><br><span class="line">        st = status</span><br></pre></td></tr></table></figure>



<h1 id="reading"><a href="#reading" class="headerlink" title="reading"></a>reading</h1><ul>
<li><a href="http://www.shuwu.mobi/">我的小书屋</a></li>
<li><a href="http://readfree.me/">readfree</a>：可以直接推送到 kindle，很方便</li>
<li><a href="http://bulaoge.cn/">不老歌</a>：写日记</li>
<li><a href="https://www.baoshuu.com/">宝书网</a></li>
</ul>
<h1 id="music"><a href="#music" class="headerlink" title="music"></a>music</h1><ul>
<li><a href="https://www.sq688.com/">超高无损音乐下载</a></li>
</ul>
<h1 id="json"><a href="#json" class="headerlink" title="json"></a>json</h1><ul>
<li><a href="https://jsonformatter.org/xml-viewer">json formatter</a>: json、xml 等都支持，可以格式化，有 json tree，统计了节点数</li>
<li><a href="https://jsoneditoronline.org/">json editor online</a>: 界面简单，有 json tree，统计了 tree 节点数</li>
<li><a href="http://jsonviewer.stack.hu/">json viewer</a>: 功能精简，格式化 json，没有 tree</li>
<li><a href="https://codebeautify.org/yaml-to-json-xml-csv">yaml to json</a>: yaml 和 json 之间的转化</li>
</ul>
<h1 id="Editing"><a href="#Editing" class="headerlink" title="Editing"></a>Editing</h1><ul>
<li>typora: markdown tool</li>
<li><a href="https://github.com/Clipy/Clipy">clipy</a>: free tool for pasting</li>
</ul>
<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><ul>
<li><a href="https://karabiner-elements.pqrs.org/">karabiner</a>: 定义快捷键。可以将 caps 键重新映射，在自定义快捷键时避免冲突</li>
<li><a href="https://github.com/fikovnik/ShiftIt">shiftit</a>: 窗口 size &amp; location 定义。用 brew 安装 <code>brew cask install shiftit</code></li>
<li>Eudic: 好用的词典，可以有一个简单悬浮窗口</li>
<li>Alfred: easy used spotlight substitute to search in Mac</li>
<li><a href="https://mediaatelier.com/CheatSheet/?lang=en">cheatsheet</a>: 显示当前应用的快捷键。Just hold the ⌘-Key a bit longer to get a list of all active short cuts of the current application.</li>
</ul>
<h1 id="给图片加水印"><a href="#给图片加水印" class="headerlink" title="给图片加水印"></a>给图片加水印</h1><ul>
<li>美图秀秀：批量添加水印，编辑水印位置、大小、透明度</li>
<li><a href="https://jingyan.baidu.com/article/0eb457e555170643f1a90592.html">Photoshop 批量添加水印</a></li>
<li>免费软件：<ul>
<li><a href="https://www.xnview.com/en/xnconvert/#downloads">XnConvert</a>：<a href="https://uiiiuiii.com/software/202192.html">使用 XnConvert 批量添加水印</a></li>
<li><a href="https://imagemagick.org/index.php">imagemagick</a>: 基于命令行的图形处理库（现有的图像处理软件大多都用到此库）</li>
</ul>
</li>
<li><a href="https://sspai.com/post/53079">6 个小工具，打造图片批处理工作流</a></li>
</ul>
<h2 id="ImageMagick"><a href="#ImageMagick" class="headerlink" title="ImageMagick"></a>ImageMagick</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">$ brew install imagemagick</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /images</span><br><span class="line"><span class="comment"># 获取图片基本信息</span></span><br><span class="line">$ identify a.jpg</span><br><span class="line"><span class="comment"># 转换图片格式</span></span><br><span class="line">$ magick a.jpg a.png</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量为图片添加水印</span></span><br><span class="line">  1 <span class="comment">#!/bin/bash</span></span><br><span class="line">  2</span><br><span class="line">  3 <span class="built_in">dir</span>=<span class="variable">$1</span></span><br><span class="line">  4 mark=<span class="variable">$2</span></span><br><span class="line">  5</span><br><span class="line">  6 <span class="built_in">echo</span> <span class="string">&quot;the images dir to process: <span class="variable">$dir</span>&quot;</span></span><br><span class="line">  7 <span class="built_in">echo</span> <span class="string">&quot;the mark location: <span class="variable">$mark</span>&quot;</span></span><br><span class="line">  8</span><br><span class="line">  9 <span class="built_in">shopt</span> -s nullglob <span class="comment"># 如果不添加这个，当目录中没有 .png 类型的文件时，他会产生 &quot;$dir&quot;/*.png，那么后边就会报错</span></span><br><span class="line"> 10 <span class="keyword">for</span> each <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$dir</span>&quot;</span>/&#123;*.jpg,*.jpeg,*.png&#125;</span><br><span class="line"> 11 <span class="keyword">do</span></span><br><span class="line"> 12         <span class="built_in">echo</span> <span class="string">&quot;each is: <span class="variable">$each</span>&quot;</span></span><br><span class="line"> 13         convert <span class="variable">$each</span> <span class="variable">$mark</span> -gravity southeast -geometry +5+20 -composite <span class="variable">$each</span></span><br><span class="line"> 14         convert <span class="variable">$each</span> <span class="variable">$mark</span> -gravity center -composite <span class="variable">$each</span></span><br><span class="line"> 15         convert <span class="variable">$each</span> <span class="variable">$mark</span> -gravity northwest -geometry +5+20 -composite <span class="variable">$each</span></span><br><span class="line"> 16         <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$each</span>: done&quot;</span></span><br><span class="line"> 17 <span class="keyword">done</span></span><br><span class="line"> 18 <span class="built_in">shopt</span> -u nullglob</span><br><span class="line"> 19 <span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>

<h1 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h1><h2 id="terminal-1"><a href="#terminal-1" class="headerlink" title="terminal"></a>terminal</h2><p><a href="https://p3terx.com/archives/the-strongest-terminal-solution-under-windows-10.html">打造 Windows 10 下最强终端方案：WSL + Terminus + Oh My Zsh + The Fuck</a></p>
<blockquote>
<p>注意这里装的是 wsl1，可以改成 wsl2，参见<a href="https://docs.microsoft.com/en-us/windows/wsl/install">install wsl</a></p>
</blockquote>
<h2 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h2><p>mac 下有免费的 clipy 来实现 copy history，windows 下有 <a href="https://copyq.readthedocs.io/en/latest/basic-usage.html">copyq</a>（也可以用于 mac）</p>
<p>copyq 在它的窗口里可以配置各种命令的快捷键（全局或程序内），包括显示和隐藏 copyq 窗口的</p>
<h2 id="search"><a href="#search" class="headerlink" title="search"></a>search</h2><p>mac 下有 alfred 来搜索文件，windows 有一些替代的：</p>
<ol>
<li>listary：有免费版</li>
<li>wox：开源</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2021/02/24/clean-mac-other-storage/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/02/24/clean-mac-other-storage/" class="post-title-link" itemprop="url">clean mac other storage</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-02-24 19:43:25" itemprop="dateCreated datePublished" datetime="2021-02-24T19:43:25+08:00">2021-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-02-14 17:00:14" itemprop="dateModified" datetime="2023-02-14T17:00:14+08:00">2023-02-14</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>other storage 主要是存的系统的一些缓存、日志等数据。有时会占特别大空间，可以按下列步骤清理</p>
<h2 id="1-暂时关闭-SIP，以能查看和删除系统文件（解决-not-permitted-问题）"><a href="#1-暂时关闭-SIP，以能查看和删除系统文件（解决-not-permitted-问题）" class="headerlink" title="1. 暂时关闭 SIP，以能查看和删除系统文件（解决 not permitted 问题）"></a>1. 暂时关闭 SIP，以能查看和删除系统文件（解决 not permitted 问题）</h2><ol>
<li>以 recover mode 重启电脑：启动时，按 command + R 即可</li>
<li>选择 Utilities -&gt; Terminal</li>
<li>在 Terminal 中输入 <code>csrutil disable</code> 关闭 SIP</li>
<li>重启电脑</li>
</ol>
<p>在完成 clean 后，应该重复 1、2，并在 terminal 中输入 <code>csrutil enable</code> 来启动 SIP</p>
<p>重启电脑后，可以通过 <code>csrutil status</code> 来查看 SIP 服务是否启动（清理完成后应该启动）</p>
<h2 id="2-按-size-查找大文件"><a href="#2-按-size-查找大文件" class="headerlink" title="2. 按 size 查找大文件"></a>2. 按 size 查找大文件</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /</span><br><span class="line">$ sudo <span class="built_in">du</span> -sh  -- *| <span class="built_in">sort</span> -hr</span><br></pre></td></tr></table></figure>

<h2 id="3-常见的大文件"><a href="#3-常见的大文件" class="headerlink" title="3.  常见的大文件"></a>3.  常见的大文件</h2><h3 id="x2F-Libraray-x2F-Caches-和-x2F-Library-x2F-Caches"><a href="#x2F-Libraray-x2F-Caches-和-x2F-Library-x2F-Caches" class="headerlink" title="~&#x2F;Libraray&#x2F;Caches 和  &#x2F;Library&#x2F;Caches"></a>~&#x2F;Libraray&#x2F;Caches 和  &#x2F;Library&#x2F;Caches</h3><p><code>~/Libraray</code> 和  <code>/Library</code> 下的 <code>Caches</code> 和 <code>logs</code> 等都是可以安全删除的。可以查看一下大小，把自己不用的 cache 删掉。</p>
<p>当然也可以查看 <code>Library</code> 下的所有大文件，确认是否可以删除</p>
<h3 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h3><p>Docker 的 images、volumes 等可能占很大空间，可以查看到 <code>~/Library/Containers/com.docker.docker</code> 文件夹的大小</p>
<p><a href="https://docs.docker.com/docker-for-mac/space/">docker space for mac</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/Library/Containers</span><br><span class="line">$ sudo <span class="built_in">du</span> -sh  -- *| <span class="built_in">sort</span> -hr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 docker 的系统占用，这是清理后了，占用很小</span></span><br><span class="line">$ docker system <span class="built_in">df</span></span><br><span class="line">TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE</span><br><span class="line">Images              1                   1                   100.8kB             0B (0%)</span><br><span class="line">Containers          1                   0                   0B                  0B</span><br><span class="line">Local Volumes       0                   0                   0B                  0B</span><br><span class="line">Build Cache         0                   0                   0B                  0B</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理磁盘，删除关闭的容器、无用的数据卷和网络，以及 dangling 镜像(即无 tag 的镜像)</span></span><br><span class="line">$ docker system prune</span><br><span class="line"><span class="comment"># 清理得更加彻底，可以将没有容器使用 Docker 镜像都删掉</span></span><br><span class="line">$ docker system prune -a</span><br><span class="line"><span class="comment"># 如果需要同时删除未被任何容器引用的数据卷需要显式的指定 --volumns 参数</span></span><br><span class="line">$ docker system prune --all --force --volumes</span><br><span class="line"><span class="comment"># 删除所有 dangling 数据卷(即无用的 volume)</span></span><br><span class="line">$ docker volume <span class="built_in">rm</span> $(docker volume <span class="built_in">ls</span> -qf dangling=<span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 有时删完后，需要一段时间 reclaim space，可以使用以下命令，手动 trigger relamation</span></span><br><span class="line">$ docker run --privileged --pid=host docker/desktop-reclaim-space</span><br></pre></td></tr></table></figure>

<h3 id="x2F-Library-x2F-Updates"><a href="#x2F-Library-x2F-Updates" class="headerlink" title="&#x2F;Library&#x2F;Updates"></a>&#x2F;Library&#x2F;Updates</h3><p>这里可能会有很多文件，都可以删。这里正常应该在执行 App Store 里的 Update 时，才会有文件，但不知道为啥，即使 App Store 没有 Update 也会有。</p>
<p>如果这里有大文件，那么：</p>
<ol>
<li>先尝试去执行 App Store 里的 Update</li>
<li>如果还有文件，可以删除文件夹里的所有文件（建议不要删那几个 <code>.plist</code> 文件），不要删除 <code>/Library/Updates</code> 文件夹本身，删除里边的内容</li>
</ol>
<h3 id="x2F-private-x2F-var-x2F-tmp-x2F-WiFiDiagnostics"><a href="#x2F-private-x2F-var-x2F-tmp-x2F-WiFiDiagnostics" class="headerlink" title="&#x2F;private&#x2F;var&#x2F;tmp&#x2F;WiFiDiagnostics*"></a>&#x2F;private&#x2F;var&#x2F;tmp&#x2F;WiFiDiagnostics*</h3><p><code>/private/var/tmp/</code> 里的文件删除的时候要小心些。</p>
<p><code>WiFiDiagnostics</code> 是 wifi log，这些文件<strong>可以安全删除</strong></p>
<p>但它可以用  <code>command+control+option+shift+w</code> 或 <code>command+control+option+shift+&gt;</code> 触发。如果你正好使用 karabiner 并且 remap 了 <code>command+control+option+shift</code>，在使用过程中可能正好和 +w 或 +&gt; 冲突了，那么每次都会启动 logging。所以需要修改配置。</p>
<ol>
<li>karabiner -&gt; Misc -&gt; Open config folder</li>
<li>open karabiner.json，在其中加入下面的配置</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;rules&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Disabling command+control+option+shift+w. This triggers wifi logging.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;manipulators&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;w&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;mandatory&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;command&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;control&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;option&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;shift&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;escape&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;basic&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Disabling command+control+option+shift+&gt;. This triggers wifi logging also.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;manipulators&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;mandatory&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;command&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;control&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;option&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;shift&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;escape&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;basic&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Change caps_lock key to command+control+option+shift. (Post escape key when pressed alone)&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;manipulators&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;caps_lock&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;optional&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;any&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;left_shift&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;left_command&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;left_control&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;left_option&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to_if_alone&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;escape&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;basic&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>/private/var/tmp</code> 文件夹下可能还有很多 <code>sysdiagnose</code> 文件，这个应该是可以删，是系统诊断结果。但不太确定，我没删。</p>
<p>Sysdiagnose 可以通过 <code>command+control+option+shift+.</code> 来启动一次，所以也要注意</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2020/12/21/%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/21/%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">多维数据模型</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-12-21 16:05:11" itemprop="dateCreated datePublished" datetime="2020-12-21T16:05:11+08:00">2020-12-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-22 14:22:52" itemprop="dateModified" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a href="https://zhuanlan.zhihu.com/p/159061537">数据仓库建模</a></p>
<p><a href="https://www.cnblogs.com/cyechina/p/5425842.html">数据仓库的多维数据模型</a></p>
<p><a href="http://webdataanalysis.net/web-data-warehouse/multidimensional-data-model/">数据仓库的多维数据模型 – 非常好的一系列文章</a></p>
<h1 id="Kimball-维度建模"><a href="#Kimball-维度建模" class="headerlink" title="Kimball 维度建模"></a>Kimball 维度建模</h1><p><strong>维度建模就是时刻考虑如何能够提供简单性，以业务为驱动，以用户理解性和查询性能为目标</strong></p>
<p><a href="https://segmentfault.com/a/1190000038938864">kimball维度建模详解</a></p>
<p>维度建模分为两种表：事实表和维度表</p>
<ol>
<li><strong>事实表</strong>：必然存在的一些数据，像采集的日志文件，订单表，都可以作为事实表</li>
</ol>
<p>特征：<strong>是一堆主键的集合</strong>，每个主键对应维度表中的一条记录，客观存在的，根据主题确定出需要使用的数据</p>
<ol>
<li><strong>维度表</strong>：维度就是所分析的数据的一个量，维度表就是以合适的角度来创建的表，分析问题的一个角度：时间、地域、终端、用户等角度</li>
</ol>
<h1 id="多维数据模型的定义和作用"><a href="#多维数据模型的定义和作用" class="headerlink" title="多维数据模型的定义和作用"></a>多维数据模型的定义和作用</h1><p>　　多维数据模型是为了满足用户从多角度多层次进行数据查询和分析的需要而建立起来的基于事实和维的数据库模型，其基本的应用是为了实现OLAP（Online Analytical Processing）。</p>
<p>　　当然，通过多维数据模型的数据展示、查询和获取就是其作用的展现，但其真的作用的实现在于，通过数据仓库可以根据不同的数据需求建立起各类多维模型，并组成数据集市开放给不同的用户群体使用，也就是根据需求定制的各类数据商品摆放在数据集市中供不同的数据消费者进行采购。</p>
<p><strong>多维数据模型最大的优点就是其基于分析优化的数据组织和存储模式。</strong></p>
<h2 id="主题建模"><a href="#主题建模" class="headerlink" title="主题建模"></a>主题建模</h2><p><a href="https://zhuanlan.zhihu.com/p/113790356">多维分析仓库构建-面向主题的建模</a></p>
<h3 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h3><p>主题建模是对原始数据、原始业务理解的基础上，将数据归类为多个主题（e.g. 销量主题、维修订单主题、线索转化主题…）。</p>
<p>一般，一个主题就是由一张事实表、多张维表、以及结果聚合表所组成。</p>
<ol>
<li>基于多维数据模型构建底层：事实表+维表</li>
<li>基于上述模型，聚合结果，生成聚合数据。</li>
</ol>
<p>事实表要尽可能宽，尽可能容纳此主题下所有指标，如果有新指标需求，则动态添加指标。但是事实表太宽可能导致后续计算资源不足，如果需要拆分事实，拆分事实表的过程即拆分子主题。对事实表的拆分不明确，即主题不明确，会导致后续资源的浪费或者维护成本的提高。因为后续可能出现衍生指标需要两个主题出的情况，那么需要再新出一个综合主题。</p>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><p>主题建模是对数据的分类，这需要对领域或企业内数据特征有深刻理解。清晰的主题规划往往是数仓设计成败的关键。</p>
<p>与主题建模相对的，是按需输出数据，按照产品的需求出对应指标。</p>
<p>按需出指标，不必等待多维分析数仓建立完成即可开始，前期开发周期短。</p>
<p>主题建模是提前将维度和指标的全集定义好，聚合尽可能多的维度属性和指标的组合，与产品需求解耦，不会随产品需求增加而将数仓变得臃肿，可维护性好，长远来看性能上也更好。</p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>原子指标、衍生指标的增长：需要增加结果表的schema，所有数据库是兼容的，产生结果表的SQL修改其中读取事实表的查询，可以向后兼容</p>
<p>维度属性的增长：在维度表中增加具体的维度属性即可，不需要其他修改。</p>
<p>维度的增长：产生结果表的SQL增加新的维度表，结果表的schema也进行相应修改。</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>在看实例前，这里需要先了解两个概念：<strong>事实表和维表</strong>。事实表是用来记录具体事件的，包含了每个事件的具体要素，以及具体发生的事情；维表则是对事实表中事件的要素的描述信息。比如一个事件会包含时间、地点、人物、事件，事实表记录了整个事件的信息，但对时间、地点和人物等要素只记录了一些关键标记，比如事件的主角叫“Michael”，那么Michael到底“长什么样”，就需要到相应的维表里面去查询“Michael”的具体描述信息了。基于事实表和维表就可以构建出多种多维模型，包括星形模型、雪花模型和星座模型。这里不再展开了，解释概念真的很麻烦，而且基于我的理解的描述不一定所有人都能明白，还是直接上实例吧：</p>
<p><img src="http://webdataanalysis.net/wp-content/uploads/2010/08/Star-Schemas.png" alt="Star-Schemas"></p>
<p>事实表里面主要包含两方面的信息：<strong>维和度量</strong>，维的具体描述信息记录在维表，事实表中的维属性只是一个关联到维表的键，并不记录具体信息；度量一般都会记录事件的相应数值，比如这里的产品的销售数量、销售额等。维表中的信息一般是可以分层的，比如时间维的年月日、地域维的省市县等，这类分层的信息就是为了满足事实表中的度量可以在不同的粒度上完成聚合，比如2010年商品的销售额，来自上海市的销售额等。</p>
<h2 id="事实表"><a href="#事实表" class="headerlink" title="事实表"></a>事实表</h2><p>事实表是用来记录具体事件的，包含了每个事件的具体要素，以及具体发生的事情；如<strong>系统</strong>的<strong>日志</strong>、<strong>销售记录</strong>、<strong>用户访问日志</strong>等信息，<strong>事实表的记录是动态的增长的</strong>，所以<strong>体积是大于维度表</strong>。<strong>即：用户关心的业务数据，如销售数量，库存数量，销售金额</strong></p>
<h2 id="维表"><a href="#维表" class="headerlink" title="维表"></a>维表</h2><p>维表则是对事实表中事件的要素的描述信息。比如一个事件会包含时间、地点、人物、事件，事实表记录了整个事件的信息，但对时间、地点和人物等要素只记录了一些关键标记，比如事件的主角叫“Michael”，那么Michael到底“长什么样”，就需要到相应的维表里面去查询“Michael”的具体描述信息了。</p>
<p><strong>维度表</strong>（Dimension Table）也称为<strong>查找表</strong>（Lookup Table）是<strong>与事实表相对应的表</strong>，这个表保存了<strong>维度的属性值</strong>，可以跟事实表做关联，<strong>相当于</strong>是将<strong>事实表</strong>中<strong>经常重复的数据抽取</strong>、<strong>规范出来用一张表管理</strong>，常见的有日期（日、周、月、季度等属性）、地区表等，所以<strong>维度表的变化通常不会太大</strong>。<strong>即：用来描述业务数据的数据，如日期、产品数据、地区、渠道</strong></p>
<p>基于事实表和维表就可以构建出多种多维模型，包括星形模型、雪花模型和星座模型。</p>
<h2 id="星型模型"><a href="#星型模型" class="headerlink" title="星型模型"></a>星型模型</h2><p>当所有维表都直接连接到“事实表”上时，整个图解就像星星一样，故将该模型称为星型模型。<strong>数据有一定的冗余</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-1d39380d9238ca7c5876ac92d27750b2_1440w.jpg" alt="img"></p>
<h2 id="雪花模型"><a href="#雪花模型" class="headerlink" title="雪花模型"></a>雪花模型</h2><p>当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，其图解就像多个雪花连接在一起，故称雪花模型。<strong>雪花模型是对星型模型的扩展</strong>。它对星型模型的维表进一步层次化，原有的各维表可能被扩展为小的事实表，形成一些局部的 “层次 “ 区域，这些被分解的表都连接到主维度表而不是事实表。如图 2，将地域维表又分解为国家，省份，城市等维表。它的优点是：<strong>通过最大限度地减少数据存储量以及联合较小的维表来改善查询性能。雪花型结构去除了数据冗余</strong>。</p>
<p><img src="https://pic4.zhimg.com/80/v2-e7e1a7403be3ffb217f623d89771a573_1440w.jpg" alt="img">****</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2020/12/18/airflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/12/18/airflow/" class="post-title-link" itemprop="url">airflow</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-12-18 15:33:14" itemprop="dateCreated datePublished" datetime="2020-12-18T15:33:14+08:00">2020-12-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-22 14:22:52" itemprop="dateModified" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="install"><a href="#install" class="headerlink" title="install"></a>install</h1><p><a href="https://airflow.apache.org/docs/apache-airflow/stable/start.html">quickstart</a></p>
<blockquote>
<p>Airflow is published as <code>apache-airflow</code> package in PyPI. Installing it however might be sometimes tricky because Airflow is a bit of both a library and application. Libraries usually keep their dependencies open and applications usually pin them, but we should do neither and both at the same time. We decided to keep our dependencies as open as possible (in <code>setup.cfg</code> and <code>setup.py</code>) so users can install different version of libraries if needed. This means that from time to time plain <code>pip install apache-airflow</code> will not work or will produce unusable Airflow installation.</p>
<p>In order to have repeatable installation, however, starting from <strong>Airflow 1.10.10</strong> and updated in <strong>Airflow 1.10.13</strong> we also keep a set of “known-to-be-working” constraint files in the <code>constraints-master</code> and <code>constraints-1-10</code> orphan branches. Those “known-to-be-working” constraints are per major&#x2F;minor python version. You can use them as constraint files when installing Airflow from PyPI. Note that you have to specify correct Airflow version and python versions in the URL.</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --use-deprecated legacy-resolver <span class="string">&quot;apache-airflow==1.10.14&quot;</span> --constraint <span class="string">&quot;https://raw.githubusercontent.com/apache/airflow/constraints-1.10.14/constraints-3.8.txt&quot;</span> </span><br><span class="line"></span><br><span class="line">pip3 install <span class="string">&quot;apache-airflow==1.10.14&quot;</span> --constraint <span class="string">&quot;https://raw.githubusercontent.com/apache/airflow/constraints-1.10.14/constraints-3.8.txt&quot;</span> </span><br></pre></td></tr></table></figure>

<blockquote>
<p>On November 2020, new version of PIP (20.3) has been released with a new, 2020 resolver. This resolver does not yet work with Apache Airflow and might leads to errors in installation - depends on your choice of extras. In order to install Airflow you need to either downgrade pip to version 20.2.4 <code>pip upgrade --pip==20.2.4</code> or, in case you use Pip 20.3, you need to add option <code>--use-deprecated legacy-resolver</code> to your pip install command.</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># airflow needs a home, ~/airflow is the default,</span></span><br><span class="line"><span class="comment"># but you can lay foundation somewhere else if you prefer</span></span><br><span class="line"><span class="comment"># (optional)</span></span><br><span class="line"><span class="built_in">export</span> AIRFLOW_HOME=~/airflow</span><br><span class="line"></span><br><span class="line"><span class="comment"># install from pypi using pip</span></span><br><span class="line">pip install apache-airflow</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the database</span></span><br><span class="line">airflow db init</span><br><span class="line"></span><br><span class="line">airflow <span class="built_in">users</span> create \</span><br><span class="line">    --username admin \</span><br><span class="line">    --firstname petrina \</span><br><span class="line">    --lastname zheng \</span><br><span class="line">    --role Admin \</span><br><span class="line">    --email spiderman@superhero.org</span><br><span class="line"></span><br><span class="line"><span class="comment"># start the web server, default port is 8080</span></span><br><span class="line">airflow webserver --port 8080</span><br><span class="line"></span><br><span class="line"><span class="comment"># start the scheduler</span></span><br><span class="line"><span class="comment"># open a new terminal or else run webserver with ``-D`` option to run it as a daemon</span></span><br><span class="line">airflow scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># visit localhost:8080 in the browser and use the admin account you just</span></span><br><span class="line"><span class="comment"># created to login. Enable the example_bash_operator dag in the home page</span></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2020/11/23/ambari-install-offline/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/11/23/ambari-install-offline/" class="post-title-link" itemprop="url">HDP install (offline using ambari)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-11-23 15:36:44" itemprop="dateCreated datePublished" datetime="2020-11-23T15:36:44+08:00">2020-11-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-22 14:22:52" itemprop="dateModified" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a href="https://wbaseurlww.cnblogs.com/shook/p/12409759.html">reference</a></p>
<p><a href="https://docs.cloudera.com/HDPDocuments/Ambari-latest/bk_ambari-installation/content/set_up_password-less_ssh.html">官方安装指导</a></p>
<h1 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h1><p>除非说明，默认以下操作都是在所有节点上执行</p>
<h2 id="修改-host"><a href="#修改-host" class="headerlink" title="修改 host"></a>修改 host</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]<span class="comment"># vi /etc/hosts</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1             localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.105.137 master</span><br><span class="line">192.168.105.191 slave1</span><br><span class="line">192.168.105.13 slave2</span><br></pre></td></tr></table></figure>

<h2 id="修改-network-config"><a href="#修改-network-config" class="headerlink" title="修改 network config"></a>修改 network config</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]<span class="comment"># vi /etc/sysconfig/network</span></span><br><span class="line"><span class="comment"># Created by anaconda</span></span><br><span class="line">NETWORKING=<span class="built_in">yes</span></span><br><span class="line">HOSTNAME=master</span><br><span class="line"></span><br><span class="line">[root@master ~]<span class="comment"># hostnamectl set-hostname master</span></span><br><span class="line">[root@master ~]<span class="comment"># hostname</span></span><br><span class="line">master</span><br><span class="line"></span><br><span class="line"><span class="comment"># ping 各个节点，查看是否可连通</span></span><br><span class="line">[root@master ~]<span class="comment"># ping slave1</span></span><br><span class="line">PING slave1 (192.168.105.191) 56(84) bytes of data.</span><br></pre></td></tr></table></figure>

<h2 id="同步时间-ntp"><a href="#同步时间-ntp" class="headerlink" title="同步时间 ntp"></a>同步时间 ntp</h2><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><h2 id="关闭-Selinux-和-THP"><a href="#关闭-Selinux-和-THP" class="headerlink" title="关闭 Selinux 和 THP"></a>关闭 Selinux 和 THP</h2><h2 id="修改文件打开最大限制"><a href="#修改文件打开最大限制" class="headerlink" title="修改文件打开最大限制"></a><del>修改文件打开最大限制</del></h2><h2 id="SSH-无密码登录（主节点）"><a href="#SSH-无密码登录（主节点）" class="headerlink" title="SSH 无密码登录（主节点）"></a>SSH 无密码登录（主节点）</h2><h2 id="Reboot"><a href="#Reboot" class="headerlink" title="Reboot"></a>Reboot</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ shutdown -r now</span><br></pre></td></tr></table></figure>

<h1 id="制作本地源（离线安装）"><a href="#制作本地源（离线安装）" class="headerlink" title="制作本地源（离线安装）"></a>制作本地源（离线安装）</h1><h2 id="文件目录访问（http-服务方式）"><a href="#文件目录访问（http-服务方式）" class="headerlink" title="文件目录访问（http 服务方式）"></a>文件目录访问（http 服务方式）</h2><h2 id="制作本地源（主节点）"><a href="#制作本地源（主节点）" class="headerlink" title="制作本地源（主节点）"></a>制作本地源（主节点）</h2><h3 id="安装本地源制作相关工具"><a href="#安装本地源制作相关工具" class="headerlink" title="安装本地源制作相关工具"></a>安装本地源制作相关工具</h3><h3 id="修改文件里面的源地址"><a href="#修改文件里面的源地址" class="headerlink" title="修改文件里面的源地址"></a>修改文件里面的源地址</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@master ambari]<span class="comment"># vi ambari/centos7/2.7.4.0-118/ambari.repo</span></span><br><span class="line"><span class="comment">#VERSION_NUMBER=2.7.4.0-118</span></span><br><span class="line">[ambari-2.7.4.0]</span><br><span class="line"><span class="comment">#json.url = http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json</span></span><br><span class="line">name=ambari Version - ambari-2.7.4.0</span><br><span class="line">baseurl=http://192.168.105.137/ambari/ambari/centos7/2.7.4.0-118</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.105.137/ambari/ambari/centos7/2.7.4.0-118/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line">[root@master ambari]<span class="comment"># cp ambari/centos7/2.7.4.0-118/ambari.repo /etc/yum.repos.d/</span></span><br><span class="line">[root@master ambari]<span class="comment"># vi HDP/centos7/3.1.4.0-315/hdp.repo</span></span><br><span class="line"><span class="comment">#VERSION_NUMBER=3.1.4.0-315</span></span><br><span class="line">[HDP-3.1.4.0]</span><br><span class="line">name=HDP Version - HDP-3.1.4.0</span><br><span class="line">baseurl=http://192.168.105.137/ambari/HDP/centos7/3.1.4.0-315</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.105.137/ambari/HDP/centos7/3.1.4.0-315/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[HDP-UTILS-1.1.0.22]</span><br><span class="line">name=HDP-UTILS Version - HDP-UTILS-1.1.0.22</span><br><span class="line">baseurl=http://192.168.105.137/ambari/HDP-UTILS/centos7/1.1.0.22</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.105.137/ambari/HDP-UTILS/centowwws7/1.1.0.22/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line">[root@master ambari]<span class="comment"># cp HDP/centos7/3.1.4.0-315/hdp.repo /etc/yum.repos.d/</span></span><br></pre></td></tr></table></figure>



<h3 id="将创建好的源文件（-repo）拷贝到子节点"><a href="#将创建好的源文件（-repo）拷贝到子节点" class="headerlink" title="将创建好的源文件（.repo）拷贝到子节点"></a>将创建好的源文件（.repo）拷贝到子节点</h3><h1 id="安装-ambari-server"><a href="#安装-ambari-server" class="headerlink" title="安装 ambari-server"></a>安装 ambari-server</h1><h2 id="安装-ambari-server-1"><a href="#安装-ambari-server-1" class="headerlink" title="安装 ambari-server"></a>安装 ambari-server</h2><p>先安装，然后开始配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum -y install ambari-server</span><br></pre></td></tr></table></figure>

<h2 id="设置并启动-ambari-server（主节点）"><a href="#设置并启动-ambari-server（主节点）" class="headerlink" title="设置并启动 ambari-server（主节点）"></a>设置并启动 ambari-server（主节点）</h2><p><a href="https://www.baeldung.com/find-java-home">how to find JAVA_HOME</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ java -XshowSettings:properties -version 2&gt;&amp;1 &gt; /dev/null | grep <span class="string">&#x27;java.home&#x27;</span> </span><br></pre></td></tr></table></figure>

<h3 id="使用默认-postgresql"><a href="#使用默认-postgresql" class="headerlink" title="使用默认 postgresql"></a>使用默认 postgresql</h3><p>Setup server 时，有几个交互式配置：</p>
<ol>
<li><p>是否自定义用户账户：</p>
<ol>
<li>选 n。即默认设置了 Ambari GUI 的登录用户为 admin&#x2F;admin。并且指定 Ambari Server 的运行用户为 root。</li>
</ol>
<blockquote>
<p>If you want to create a different user to run the Ambari Server, or to assign a previously created user, select <strong><code>y</code></strong> at the <code>Customize user account for ambari-server daemon</code> prompt, then provide a user name.</p>
</blockquote>
</li>
<li><p>JDK：</p>
<ol>
<li>选 2. 因为默认会安装并使用 oracle jdk，但是（1）不能联网下载（2）好像 oracle jdk 不会下载依赖包。所以自己安装好，在这指定 path 即可</li>
</ol>
</li>
<li><p>数据库：</p>
<ol>
<li>按默认配置创建 postgres 数据库</li>
</ol>
</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@master yum.repos.d]<span class="comment"># ambari-server setup</span></span><br><span class="line">Using python  /usr/bin/python</span><br><span class="line">Setup ambari-server</span><br><span class="line">Checking SELinux...</span><br><span class="line">SELinux status is <span class="string">&#x27;disabled&#x27;</span></span><br><span class="line">Customize user account <span class="keyword">for</span> ambari-server daemon [y/n] (n)? n</span><br><span class="line">Adjusting ambari-server permissions and ownership...</span><br><span class="line">Checking firewall status...</span><br><span class="line">Checking JDK...</span><br><span class="line">[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8</span><br><span class="line">[2] Custom JDK</span><br><span class="line">Enter choice (1): 2</span><br><span class="line">WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.</span><br><span class="line">WARNING: JCE Policy files are required <span class="keyword">for</span> configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.</span><br><span class="line">Path to JAVA_HOME: /usr/java/jdk1.8.0_202</span><br><span class="line">Validating JDK on Ambari Server...<span class="keyword">done</span>.</span><br><span class="line">Completing setup...</span><br><span class="line">Configuring database...</span><br><span class="line">Enter advanced database configuration [y/n] (n)? n</span><br><span class="line">Configuring database...</span><br><span class="line">Default properties detected. Using built-in database.</span><br><span class="line">Configuring ambari database...</span><br><span class="line">Checking PostgreSQL...</span><br><span class="line">Running initdb: This may take up to a minute.</span><br><span class="line">Initializing database ... OK</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">About to start PostgreSQL</span><br><span class="line">Configuring <span class="built_in">local</span> database...</span><br><span class="line">Configuring PostgreSQL...</span><br><span class="line">Restarting PostgreSQL</span><br><span class="line">Creating schema and user...</span><br><span class="line"><span class="keyword">done</span>.</span><br><span class="line">Creating tables...</span><br><span class="line"><span class="keyword">done</span>.</span><br><span class="line">Extracting system views...</span><br><span class="line">ambari-admin-2.7.4.0-118.jar</span><br><span class="line">...........</span><br><span class="line">Adjusting ambari-server permissions and ownership...</span><br><span class="line">Ambari Server <span class="string">&#x27;setup&#x27;</span> completed successfully.</span><br></pre></td></tr></table></figure>

<h3 id="使用-mysql"><a href="#使用-mysql" class="headerlink" title="使用 mysql"></a>使用 mysql</h3><p><a href="https://programmer.group/linux-centos-7-mysql-5.7-offline-installation.html">离线安装 mysql</a></p>
<h4 id="离线安装"><a href="#离线安装" class="headerlink" title="离线安装"></a>离线安装</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户组</span></span><br><span class="line">$ groupadd hdp</span><br><span class="line"><span class="comment"># 创建用户</span></span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql</span><br><span class="line">$ useradd -g hdp hive -d /home/mysql/hive</span><br><span class="line">$ passwd hive</span><br><span class="line">yourPassword</span><br><span class="line"><span class="comment"># 创建临时目录</span></span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql/hive/3306/data</span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql/hive/3306/log</span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql/hive/3306/tmp</span><br><span class="line">$ <span class="built_in">chown</span> -R hive:hdp /home/mysql/hive</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">$ <span class="built_in">mv</span> mysql-5.7.32-linux-glibc2.12-x86_64.tar.gz /usr/local</span><br><span class="line">$ <span class="built_in">cd</span> /usr/local</span><br><span class="line">$ tar -xzvf mysql-5.7.32-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"><span class="comment"># Establish soft links for future upgrades</span></span><br><span class="line">$ <span class="built_in">ln</span> -s mysql-5.7.27-linux-glibc2.12-x86_64 mysql</span><br><span class="line"><span class="comment"># Modify users and user groups of all files under mysql folder</span></span><br><span class="line">$ <span class="built_in">chown</span> -R mysql:mysql mysql/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line">$ <span class="built_in">cd</span> /etc</span><br><span class="line">$ vi my.cnf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 mysql</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/local/mysql/bin</span><br><span class="line">$ ./mysqld --initialize --user=hive</span><br></pre></td></tr></table></figure>

<h4 id="安装-driver-并配置与-ambari-server-的-jdbc-连接"><a href="#安装-driver-并配置与-ambari-server-的-jdbc-连接" class="headerlink" title="安装 driver, 并配置与 ambari-server 的 jdbc 连接"></a>安装 driver, 并配置与 ambari-server 的 jdbc 连接</h4><p><a href="https://dev.mysql.com/downloads/connector/j/">mysql-connector-driver 下载</a> （选 RedHat 8 那个操作系统）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压</span></span><br><span class="line">$ rpm -ivh mysql80-community-release-el7-3.noarch.rpm</span><br><span class="line">$ <span class="built_in">cp</span> /usr/share/java/mysql-connector-java.jar /var/lib/ambari-server/resources/mysql-jdbc-driver.jar</span><br><span class="line"><span class="comment"># 配置 driver path</span></span><br><span class="line">$ vi /etc/ambari-server/conf/ambari.properties</span><br><span class="line">添加server.jdbc.driver.path=/usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure>

<h4 id="配置-mysql"><a href="#配置-mysql" class="headerlink" title="配置 mysql"></a>配置 mysql</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置开机启动，并启动 mysql</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/local/mysql</span><br><span class="line"><span class="comment"># Copy the startup script to the resource directory and modify mysql.server. It&#x27;s better to modify mysqld as well. These two files are best synchronized.</span></span><br><span class="line">$ <span class="built_in">cp</span> ./support-files/mysql.server /etc/rc.d/init.d/mysqld</span><br><span class="line"><span class="comment"># Increase the execution privileges of mysqld service control scripts</span></span><br><span class="line">$ <span class="built_in">chmod</span> +x /etc/rc.d/init.d/mysqld</span><br><span class="line"><span class="comment"># Add mysqld service to system service</span></span><br><span class="line">$ chkconfig --add mysqld</span><br><span class="line"><span class="comment"># Check whether the mysqld service is in effect</span></span><br><span class="line">$ chkconfig --list mysqld </span><br><span class="line"><span class="comment"># mysql start</span></span><br><span class="line">$ service mysqld start</span><br><span class="line"><span class="comment"># View mysql status</span></span><br><span class="line">$ service mysqld status</span><br><span class="line"><span class="comment"># Check mysql related processes</span></span><br><span class="line">$ ps aux|grep mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line">$ vi /etc/profile</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/local/mysql/bin</span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新 root 密码</span></span><br><span class="line">$ mysql -uroot -p</span><br><span class="line">$ mysql&gt; <span class="built_in">set</span> password <span class="keyword">for</span> root@localhost=password(<span class="string">&quot;root&quot;</span>);</span><br><span class="line"><span class="comment"># 配置 remote access to the mysql</span></span><br><span class="line">$ mysql&gt; use mysql</span><br><span class="line">$ mysql&gt; update user <span class="built_in">set</span> host=<span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span> user=<span class="string">&#x27;root&#x27;</span>;</span><br><span class="line">$ mysql&gt; <span class="keyword">select</span> host,user from user;</span><br><span class="line">$ mysql&gt; grant all privileges on *.* to <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> identified by <span class="string">&#x27;yourPassword&#x27;</span>;</span><br><span class="line">$ mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure>

<h4 id="创建-database"><a href="#创建-database" class="headerlink" title="创建 database"></a>创建 database</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE ambari;  </span><br><span class="line">use ambari;  </span><br><span class="line">CREATE USER &#x27;ambari&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;ambari&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;ambari&#x27;@&#x27;%&#x27;;  </span><br><span class="line">CREATE USER &#x27;ambari&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;ambar&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;ambari&#x27;@&#x27;localhost&#x27;;  </span><br><span class="line">CREATE USER &#x27;ambari&#x27;@&#x27;master&#x27; IDENTIFIED BY &#x27;ambari&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;ambari&#x27;@&#x27;master&#x27;;  </span><br><span class="line">FLUSH PRIVILEGES;  </span><br><span class="line">source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql  </span><br><span class="line"></span><br><span class="line">CREATE DATABASE hive;  </span><br><span class="line">use hive;  </span><br><span class="line">CREATE USER &#x27;hive&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;hive&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;hive&#x27;@&#x27;%&#x27;;  </span><br><span class="line">CREATE USER &#x27;hive&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;hive&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;hive&#x27;@&#x27;localhost&#x27;;  </span><br><span class="line">CREATE USER &#x27;hive&#x27;@&#x27;master&#x27; IDENTIFIED BY &#x27;hive&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;hive&#x27;@&#x27;master&#x27;;  </span><br><span class="line">FLUSH PRIVILEGES;  </span><br><span class="line">CREATE DATABASE oozie;  </span><br><span class="line">use oozie;  </span><br><span class="line">CREATE USER &#x27;oozie&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;oozie&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;oozie&#x27;@&#x27;%&#x27;;  </span><br><span class="line">CREATE USER &#x27;oozie&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;oozie&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;oozie&#x27;@&#x27;localhost&#x27;;  </span><br><span class="line">CREATE USER &#x27;oozie&#x27;@&#x27;master&#x27; IDENTIFIED BY &#x27;oozie&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;oozie&#x27;@&#x27;master&#x27;;  </span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>



<h4 id="Mysql-conf"><a href="#Mysql-conf" class="headerlink" title="Mysql conf"></a>Mysql conf</h4><p>上边 cnf 的内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">[client]                                        # Client settings, the default connection parameters for the client</span><br><span class="line">port = 3306                                    # Default connection port</span><br><span class="line">socket = /home/mysql/hive/3306/tmp/mysql.sock                        # For socket sockets for local connections, the mysqld daemon generates this file</span><br><span class="line"></span><br><span class="line">[mysqld]                                        # Server Basic Settings</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Foundation setup</span></span><br><span class="line">user = hive</span><br><span class="line">bind-address = 0.0.0.0                         # Allow any ip host to access this database</span><br><span class="line">server-id = 1                                  # The unique number of Mysql service Each MySQL service Id needs to be unique</span><br><span class="line">port = 3306                                    # MySQL listening port</span><br><span class="line">basedir = /usr/local/mysql                      # MySQL installation root directory</span><br><span class="line">datadir = /home/mysql/hive/3306/data                      # MySQL Data File Location</span><br><span class="line">tmpdir  = /home/mysql/hive/3306/tmp                                  # Temporary directories, such as load data infile, will be used</span><br><span class="line">socket = /home/mysql/hive/3306/tmp/mysql.sock        # Specify a socket file for local communication between MySQL client program and server</span><br><span class="line">pid-file = /home/mysql/hive/3306/log/mysql.pid      # The directory where the pid file is located</span><br><span class="line">skip_name_resolve = 1                          # Only use IP address to check the client&#x27;s login, not the host name.</span><br><span class="line">character-set-server = utf8mb4                  # Database default character set, mainstream character set support some special emoticons (special emoticons occupy 4 bytes)</span><br><span class="line">transaction_isolation = READ-COMMITTED          # Transaction isolation level, which is repeatable by default. MySQL is repeatable by default.</span><br><span class="line">collation-server = utf8mb4_general_ci          # The character set of database corresponds to some sort rules, etc. Be careful to correspond to character-set-server.</span><br><span class="line">init_connect=&#x27;SET NAMES utf8mb4&#x27;                # Set up the character set when client connects mysql to prevent scrambling</span><br><span class="line">lower_case_table_names = 1                      # Is it case sensitive to sql statements, 1 means insensitive</span><br><span class="line">max_connections = 400                          # maximum connection</span><br><span class="line">max_connect_errors = 1000                      # Maximum number of false connections</span><br><span class="line">explicit_defaults_for_timestamp = true          # TIMESTAMP allows NULL values if no declaration NOT NULL is displayed</span><br><span class="line">max_allowed_packet = 128M                      # The size of the SQL packet sent, if there is a BLOB object suggested to be modified to 1G</span><br><span class="line">interactive_timeout = 1800                      # MySQL connection will be forcibly closed after it has been idle for more than a certain period of time (in seconds)</span><br><span class="line">wait_timeout = 1800                            # The default value of MySQL wait_timeout is 8 hours. The interactive_timeout parameter needs to be configured concurrently to take effect.</span><br><span class="line">tmp_table_size = 16M                            # The maximum value of interior memory temporary table is set to 128M; for example, group by, order by with large amount of data may be used as temporary table; if this value is exceeded, it will be written to disk, and the IO pressure of the system will increase.</span><br><span class="line">max_heap_table_size = 128M                      # Defines the size of memory tables that users can create</span><br><span class="line">query_cache_size = 0                            # Disable mysql&#x27;s cached query result set function; later test to determine whether to turn on or not based on business conditions; in most cases, close the following two items</span><br><span class="line">query_cache_type = 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Memory settings allocated by user processes, and each session will allocate memory size <span class="keyword">for</span> parameter settings</span></span><br><span class="line">read_buffer_size = 2M                          # MySQL read buffer size. Requests for sequential table scans allocate a read buffer for which MySQL allocates a memory buffer.</span><br><span class="line">read_rnd_buffer_size = 8M                      # Random Read Buffer Size of MySQL</span><br><span class="line">sort_buffer_size = 8M                          # Buffer size used for MySQL execution sort</span><br><span class="line">binlog_cache_size = 1M                          # A transaction produces a log that is recorded in Cache when it is not committed, and persists the log to disk when it needs to be committed. Default binlog_cache_size 32K</span><br><span class="line"></span><br><span class="line">back_log = 130                                  # How many requests can be stored on the stack in a short time before MySQL temporarily stops responding to new requests; the official recommendation is back_log = 50 + (max_connections/5), with a cap of 900</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">log</span> setting</span></span><br><span class="line">log_error = /home/mysql/hive/3306/log/error.log                          # Database Error Log File</span><br><span class="line">slow_query_log = 1                              # Slow Query sql Log Settings</span><br><span class="line">long_query_time = 1                            # Slow query time; Slow query over 1 second</span><br><span class="line">slow_query_log_file = /home/mysql/hive/3306/log/slow.log                  # Slow Query Log Files</span><br><span class="line">log_queries_not_using_indexes = 1              # Check sql that is not used in the index</span><br><span class="line">log_throttle_queries_not_using_indexes = 5      # Represents the number of SQL statements per minute that are allowed to be logged to a slow log and are not indexed. The default value is 0, indicating that there is no limit.</span><br><span class="line">min_examined_row_limit = 100                    # The number of rows retrieved must reach this value before they can be recorded as slow queries. SQL that returns fewer than the rows specified by this parameter is not recorded in the slow query log.</span><br><span class="line">expire_logs_days = 5                            # MySQL binlog log log file saved expiration time, automatically deleted after expiration</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Master-slave replication settings</span></span><br><span class="line">log-bin = mysql-bin                            # Open mysql binlog function</span><br><span class="line">binlog_format = ROW                            # The way a binlog records content, recording each row being manipulated</span><br><span class="line">binlog_row_image = minimal                      # For binlog_format = ROW mode, reduce the content of the log and record only the affected columns</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Innodb settings</span></span><br><span class="line">innodb_open_files = 500                        # Restrict the data of tables Innodb can open. If there are too many tables in the library, add this. This value defaults to 300</span><br><span class="line">innodb_buffer_pool_size = 64M                  # InnoDB uses a buffer pool to store indexes and raw data, usually 60% to 70% of physical storage; the larger the settings here, the less disk I/O you need to access the data in the table.</span><br><span class="line">innodb_log_buffer_size = 2M                    # This parameter determines the size of memory used to write log files in M. Buffers are larger to improve performance, but unexpected failures can result in data loss. MySQL developers recommend settings between 1 and 8M</span><br><span class="line">innodb_flush_method = O_DIRECT                  # O_DIRECT reduces the conflict between the cache of the operating system level VFS and the buffer cache of Innodb itself.</span><br><span class="line">innodb_write_io_threads = 4                    # CPU multi-core processing capability settings are adjusted according to read-write ratio</span><br><span class="line">innodb_read_io_threads = 4</span><br><span class="line">innodb_lock_wait_timeout = 120                  # InnoDB transactions can wait for a locked timeout second before being rolled back. InnoDB automatically detects transaction deadlocks and rolls back transactions in its own lock table. InnoDB notices the lock settings with the LOCK TABLES statement. The default value is 50 seconds.</span><br><span class="line">innodb_log_file_size = 32M                      # This parameter determines the size of the data log file. Larger settings can improve performance, but also increase the time required to recover the failed database.</span><br></pre></td></tr></table></figure>



<h2 id="停止-ambari-server"><a href="#停止-ambari-server" class="headerlink" title="停止 ambari-server"></a>停止 ambari-server</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~] ambari-server stop    <span class="comment">#停止命令</span></span><br><span class="line"></span><br><span class="line">[root@master ~]<span class="comment"># # ambari-server reset   #重置命令</span></span><br><span class="line">[root@master ~]<span class="comment"># # ambari-server setup   #重新设置 </span></span><br><span class="line">[root@master ~]<span class="comment"># # ambari-server start   #启动命令</span></span><br></pre></td></tr></table></figure>

<h1 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h1><h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><p>集群名字：ftms_hdp_qat</p>
<p>选择版本：</p>
<ul>
<li>hdp 3.1</li>
<li>redhat7</li>
</ul>
<h2 id="配置服务"><a href="#配置服务" class="headerlink" title="配置服务"></a>配置服务</h2><p>选择服务</p>
<p>选择 master&#x2F;slave for 各服务</p>
<p><img src="/images/ambari-20201125154733621.png" alt="image-20201125154733621"></p>
<h3 id="配置-hive-x2F-ozzie-x2F-ranger-database"><a href="#配置-hive-x2F-ozzie-x2F-ranger-database" class="headerlink" title="配置 hive&#x2F;ozzie&#x2F;ranger database"></a>配置 hive&#x2F;ozzie&#x2F;ranger database</h3><h3 id="使用-postgresql"><a href="#使用-postgresql" class="headerlink" title="使用 postgresql"></a>使用 postgresql</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 先执行下边这句话，再继续配置</span></span><br><span class="line">$ ambari-server setup --jdbc-db=postgres --jdbc-driver=/usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure>

<h3 id="使用-mysql-1"><a href="#使用-mysql-1" class="headerlink" title="使用 mysql"></a>使用 mysql</h3><p>使用 mysql（生产环境推荐使用），且 mysql 在其他地方也在用，而 postgresql 和 mysql 的语法是有区别的。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先执行下边这句话，再继续配置</span></span><br><span class="line">$ ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure>

<h3 id="配置-directories"><a href="#配置-directories" class="headerlink" title="配置 directories"></a>配置 directories</h3><p>采用默认的</p>
<h3 id="configurations"><a href="#configurations" class="headerlink" title="configurations"></a>configurations</h3><p>采用默认的</p>
<h1 id="异常调试"><a href="#异常调试" class="headerlink" title="异常调试"></a>异常调试</h1><h2 id="查看-ambari-的配置"><a href="#查看-ambari-的配置" class="headerlink" title="查看 ambari 的配置"></a>查看 ambari 的配置</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 ambari-server 的配置</span></span><br><span class="line">$ vi /etc/ambari-server/conf/ambari.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 hdp 各服务的配置</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/hdp/3.1.4.0-315/hbase/conf</span><br><span class="line"><span class="comment"># 运行服务</span></span><br><span class="line">$ /usr/hdp/3.1.4.0-315/hbase/bin/hbase shell</span><br></pre></td></tr></table></figure>

<h2 id="查看错误日志"><a href="#查看错误日志" class="headerlink" title="查看错误日志"></a>查看错误日志</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 ambari-server 启动的错误日志</span></span><br><span class="line">$ <span class="built_in">tail</span> /var/log/ambari-server/ambari-server.log -n 10 -f | less</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 hdp 各服务的日志</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/hdp/3.1.4.0-315/hbase/logs/hbase/hbase-hbase-regionserver-slave2.<span class="built_in">log</span></span><br><span class="line"><span class="comment"># 或者在 var 下看也一样，不知道是放了软 link 还是什么，日志好像是一样的</span></span><br><span class="line">$ <span class="built_in">cd</span> /var/log/hbase/hbase-hbase-regionserver-slave2.<span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 ranger service 的配置</span></span><br><span class="line">$ /etc/ranger/</span><br></pre></td></tr></table></figure>

<h2 id="重新安装"><a href="#重新安装" class="headerlink" title="重新安装"></a>重新安装</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ambari-server stop</span><br><span class="line">$ ambari-server reset</span><br><span class="line">$ ambari-server setup</span><br></pre></td></tr></table></figure>

<h2 id="安装找不到包"><a href="#安装找不到包" class="headerlink" title="安装找不到包"></a>安装找不到包</h2><h3 id="找不到-hdp-repo"><a href="#找不到-hdp-repo" class="headerlink" title="找不到 hdp.repo"></a>找不到 hdp.repo</h3><p>在实际安装时，ambari 会生成一个新的 ambari-hdp-1.repo，其中也定义了 hdp 的 baseurl 之类，这里对 hdp 定义的 name 可能是 <code>[HDP-3.1-repo-1]</code> , 而前边准备本地库时，定义的 hdp 的 name 是 <code>[HDP-3.1.4.0]</code>，这两个名字必须保持一致，否则 ambari 就找不到包（这是 ambari 的一个 bug）。</p>
<blockquote>
<p>解决方案：</p>
<p>将 <code>hdp.repo</code> 中的 [HDP-3.1.4.0] 改为 [HDP-3.1-repo-1]，并重新 scp 到各个节点</p>
</blockquote>
<h3 id="postfix找不到libmysqlclient-so-18"><a href="#postfix找不到libmysqlclient-so-18" class="headerlink" title="postfix找不到libmysqlclient.so.18"></a>postfix找不到libmysqlclient.so.18</h3><blockquote>
<p>还有一种简单的方法（没试过）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;$ yum reinstall mysql-libs -y</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先删除现在安装的 postfix</span></span><br><span class="line">$ systemctl <span class="built_in">disable</span> postfix</span><br><span class="line">$ systemctl stop postfix</span><br><span class="line">$ yum remove postfix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给 libmysqlclient.so.18 加上软链</span></span><br><span class="line">$ find / -name <span class="string">&#x27;*libmysqlclient.so.18*&#x27;</span></span><br><span class="line">/usr/lib64/mysql/libmysqlclient.so.18</span><br><span class="line">$ <span class="built_in">ln</span> -s /usr/lib64/mysql/libmysqlclient.so.18 /usr/lib/libmysqlclient.so.18</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新安装 postfix 并启动</span></span><br><span class="line">$ yum install postfix</span><br><span class="line">$ systemctl <span class="built_in">enable</span> postfix</span><br><span class="line">$ systemctl start postfix</span><br><span class="line">$ systemctl status postfix.service</span><br></pre></td></tr></table></figure>

<h3 id="找不到-libtirpc-devel"><a href="#找不到-libtirpc-devel" class="headerlink" title="找不到 libtirpc-devel"></a>找不到 libtirpc-devel</h3><p>如果出错，可能各个节点都需要做这件事</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不能联网</span></span><br><span class="line"><span class="comment"># 先下载 https://centos.pkgs.org/7/centos-x86_64/libtirpc-devel-0.2.4-0.16.el7.x86_64.rpm.html 包</span></span><br><span class="line">$ yum-config-manager --<span class="built_in">enable</span> rhui-REGION-rhel-server-optional</span><br><span class="line">$ yum install libtirpc-devel-0.2.4-0.16.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果可以联网。这个可以从 CentOs-Base.repo 里下，但不能联网就没办法了</span></span><br><span class="line">$ <span class="built_in">cd</span> /etc/yum.repos.d</span><br><span class="line">$ <span class="built_in">cp</span> backup/CentOs-Base.repo .</span><br></pre></td></tr></table></figure>

<h2 id="ranger-admin-start-fail"><a href="#ranger-admin-start-fail" class="headerlink" title="ranger-admin start fail"></a>ranger-admin start fail</h2><p>start ranger-admin fail.</p>
<blockquote>
<p>error detail:<br>This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you <em>might</em> want to use the less safe log_bin_trust_function_creators variable)</p>
</blockquote>
<p>Solution (<a href="https://stackoverflow.com/questions/26015160/deterministic-no-sql-or-reads-sql-data-in-its-declaration-and-binary-logging-i">stackflow</a>):</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Execute the following in the MySQL console:</span></span><br><span class="line">SET GLOBAL log_bin_trust_function_creators = 1;</span><br></pre></td></tr></table></figure>

<h2 id="atlas-server-启动失败"><a href="#atlas-server-启动失败" class="headerlink" title="atlas server 启动失败"></a>atlas server 启动失败</h2><h3 id="Ranger-authorization-失败"><a href="#Ranger-authorization-失败" class="headerlink" title="Ranger authorization 失败"></a>Ranger authorization 失败</h3><blockquote>
<p>执行 <code>cat /var/lib/ambari-agent/tmp/atlas_hbase_setup.rb | hbase shell -n</code> 命令时，失败报 404</p>
<p>Error detail:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ERROR Java::OrgApacheHadoopHbaseIpc::RemoteWithExtrasException: org.apache.hadoop.hbase.coprocessor.CoprocessorException: HTTP 404 Error: HTTP 404</span><br><span class="line">	at org.apache.ranger.authorization.hbase.RangerAuthorizationCoprocessor.grant(RangerAuthorizationCoprocessor.java:1261)</span><br><span class="line">	at org.apache.ranger.authorization.hbase.RangerAuthorizationCoprocessor.grant(RangerAuthorizationCoprocessor.java:1072)</span><br><span class="line">	at org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$AccessControlService<span class="variable">$1</span>.grant(AccessControlProtos.java:10023)</span><br><span class="line">	at org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos<span class="variable">$AccessControlService</span>.callMethod(AccessControlProtos.java:10187)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:8135)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execServiceOnRegion(RSRpcServices.java:2426)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(RSRpcServices.java:2408)</span><br><span class="line">	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService<span class="variable">$2</span>.callBlockingMethod(ClientProtos.java:42010)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:131)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor<span class="variable">$Handler</span>.run(RpcExecutor.java:324)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor<span class="variable">$Handler</span>.run(RpcExecutor.java:304)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<p>这个原因是 atlas 通过 ranger 访问 hbase 的时候没有权限。可能是由于安装先后顺序的原因，也有 atlas + ranger 本身需要手动配置的原因，导致 ranger 中没有配置 atlas 对 hbase、kafka 的访问权限。因此需要做做几件事：</p>
<ol>
<li><p>在 ambari 的 ranger config 中，启动 hbase ranger plugin，并重启相关服务</p>
</li>
<li><p>在 ambari 的 ranger config 中，启动 kafka ranger  plugin，并重启相关服务 &#x3D;&#x3D;&#x3D;&gt; 暂时没做</p>
</li>
<li><p>在 ranger 添加 hbase 的 service（参照 <a href="https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.5/authorization-ranger/content/resource_service_configure_an_hbase_service.html">Configure a Resource-based Service: HBase</a>)</p>
<ol>
<li>这里 service 的名称必须和 <code>/usr/hdp/3.1.4.0-315/ranger-hbase-plugin/install.properties</code> 里配置 <code>REPOSITORY_NAME</code> 保持一致（但是似乎并不需要？）</li>
<li>username，password 说是 The end system username that can be used for connection.（目前来看，我现在是随便写的 admin 的账号）</li>
<li>Zookeeper 和 hbase.authentication 的配置是和  <code>/usr/hdp/3.1.4.0-315/hbase/conf/hbase-site.xml</code> 中的配置保持一致</li>
</ol>
<p><img src="/images/ambari-20201130112641591.png" alt="image-20201130112641591"></p>
<p><img src="/images/ambari-20201130112704671.png" alt="image-20201130112704671"></p>
</li>
<li><p>添加 atlas 对 hbase tables、kafka topic 的访问 policies（可参看：<a href="https://github.com/emaxwell-hw/Atlas-Ranger-Tag-Security/blob/master/README.md">tag-based security with atlas + ranger</a>）&#x3D;&#x3D;&#x3D;》 暂时没做 kafka</p>
<ol>
<li><strong>创建 hbase 的 policies 时，必须给 all - table, column-family, column 加上 <code>hbase</code> 这个 user</strong>，否则可能会遇到 403。这个原因是启动 metadata server 时，会执行 <code>cat /var/lib/ambari-agent/tmp/atlas_hbase_setup.rb | hbase shell -n</code> 这么一条命令，执行时，会切换到 <code>hbase</code> 这个用户，如果这里不加权限，这条命令就会执行失败</li>
</ol>
<p><img src="/images/ambari-20201130112445208.png" alt="image-20201130112445208"></p>
</li>
</ol>
<p>ranger 的访问链接: <a href="http://ranger-server-host:6080/index.html">http://ranger-server-host:6080/index.html</a> (可以从 ambari ranger config 中看到)</p>
<h3 id="生成-jar-包失败（报-no-such-file-or-directory"><a href="#生成-jar-包失败（报-no-such-file-or-directory" class="headerlink" title="生成 jar 包失败（报 no such file or directory)"></a>生成 jar 包失败（报 no such file or directory)</h3><blockquote>
<p>在执行 <code>source /usr/hdp/current/atlas-server/conf/atlas-env.sh ; /usr/hdp/current/atlas-server/bin/atlas_start.py</code> 时报错，</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">  File <span class="string">&quot;/usr/hdp/current/atlas-server/bin/atlas_start.py&quot;</span>, line 163, <span class="keyword">in</span> </span><br><span class="line">    returncode = main()</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/current/atlas-server/bin/atlas_start.py&quot;</span>, line 73, <span class="keyword">in</span> main</span><br><span class="line">    mc.expandWebApp(atlas_home)</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/3.1.4.0-315/atlas/bin/atlas_config.py&quot;</span>, line 160, <span class="keyword">in</span> expandWebApp</span><br><span class="line">    jar(atlasWarPath)</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/3.1.4.0-315/atlas/bin/atlas_config.py&quot;</span>, line 213, <span class="keyword">in</span> jar</span><br><span class="line">    process = runProcess(commandline)</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/3.1.4.0-315/atlas/bin/atlas_config.py&quot;</span>, line 249, <span class="keyword">in</span> runProcess</span><br><span class="line">    p = subprocess.Popen(commandline, stdout=stdoutFile, stderr=stderrFile, shell=shell)</span><br><span class="line">  File <span class="string">&quot;/usr/lib64/python2.7/subprocess.py&quot;</span>, line 711, <span class="keyword">in</span> __init__</span><br><span class="line">    errread, errwrite)</span><br><span class="line">  File <span class="string">&quot;/usr/lib64/python2.7/subprocess.py&quot;</span>, line 1327, <span class="keyword">in</span> _execute_child</span><br><span class="line">    raise child_exception</span><br><span class="line">OSError: [Errno 2] No such file or directory</span><br></pre></td></tr></table></figure>
</blockquote>
<p>通过在 <code>atlas_config.py</code> 中添加 log，发现最后是在执行 <code>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b03-1.el7.x86_64/jre/bin/jar -xf /usr/hdp/3.1.4.0-315/atlas/server/webapp/atlas.war</code> 时报错，找不到的是 jar 命令. 原因是 jar 是 jdk 中的命令，而使用的默认 openjdk 其实只安装了 jre.</p>
<blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有的 openjdk 列表</span></span><br><span class="line">$ yum list | grep jdk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 jdk</span></span><br><span class="line">$ yum install java-1.8.0-openjdk.x86_64</span><br><span class="line"></span><br><span class="line"><span class="comment"># copy jar 到指定目录</span></span><br><span class="line">$ <span class="built_in">cp</span> /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b03-1.el7.x86_64/bin/jar /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b03-1.el7.x86_64/jre/bin/</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="Host-Disk-Usage-alert"><a href="#Host-Disk-Usage-alert" class="headerlink" title="Host Disk Usage alert"></a>Host Disk Usage alert</h2><p>安装过程下载了挺多乱七八糟的东西，导致硬盘报警了</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看目前各文件系统的硬盘使用情况，如果设置的 80% 报警，则只要有某个文件系统的使用哪个超了，就会报警</span></span><br><span class="line">$ <span class="built_in">df</span> -h</span><br><span class="line">文件系统                       容量  已用  可用 已用% 挂载点</span><br><span class="line">devtmpfs                        32G     0   32G    0% /dev</span><br><span class="line">tmpfs                           32G     0   32G    0% /dev/shm</span><br><span class="line">tmpfs                           32G  824M   31G    3% /run</span><br><span class="line">tmpfs                           32G     0   32G    0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root         50G   31G   20G   61% /</span><br><span class="line">/dev/sda1                     1014M  154M  861M   16% /boot</span><br><span class="line">/dev/mapper/vg_data2-lv_data2  200G   55M  200G    1% /data02</span><br><span class="line">/dev/mapper/centos-home         47G  444M   47G    1% /home</span><br><span class="line">/dev/mapper/vg_data1-lv_data1  200G  4.9G  196G    3% /data01</span><br><span class="line">tmpfs                          6.3G     0  6.3G    0% /run/user/0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看现在系统中的文件占用情况，找大文件去清</span></span><br><span class="line">$ <span class="built_in">du</span> -hs /*</span><br><span class="line">$ <span class="built_in">du</span> -hs /root/*</span><br><span class="line">$ <span class="built_in">du</span> -hs /var/log/*</span><br><span class="line">$ <span class="built_in">du</span> -h /var/* -d 1 | <span class="built_in">sort</span> -n -r</span><br></pre></td></tr></table></figure>



<h1 id="验证各服务可用"><a href="#验证各服务可用" class="headerlink" title="验证各服务可用"></a>验证各服务可用</h1><h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="创建文件夹（可选？？？）"><a href="#创建文件夹（可选？？？）" class="headerlink" title="创建文件夹（可选？？？）"></a>创建文件夹（可选？？？）</h3><p><a href="https://www.tutorialspoint.com/hive/hive_quick_guide.htm">hive 验证可用</a></p>
<h3 id="配置-ranger-service-amp-policies"><a href="#配置-ranger-service-amp-policies" class="headerlink" title="配置 ranger service &amp; policies"></a>配置 ranger service &amp; policies</h3><p><a href="https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.5/authorization-ranger/content/resource_service_configure_a_hive_service.html">ranger-hive-service</a></p>
<p>service 命名</p>
<p>url: get from ambari-hive, or when you connect hive, it will show the whole connect string</p>
<p>policy 中 <code>all-database,table,column</code> 加上 <code>hive</code> user </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 重启 spark 服务</span><br><span class="line">Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br></pre></td></tr></table></figure>

<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ManagedandExternalTables">hive managed &amp; external tables</a></p>
<p>acid table not supported now （acid new feature in hive，many others does not support it)</p>
<p><a href="https://github.com/Gowthamsb12/BigData-Blogs/blob/master/Spark_ACID">spark-acids thoughts</a></p>
<p><img src="/images/ambari-table-create-in-hive.png" alt="image-20201211154708672"></p>
<p><img src="/images/ambari-table-create-in-spark.png" alt="image-20201211154728273"></p>
<p>I figured it out. Just set: <code>mapred.input.dir.recursive</code> and <code>hive.mapred.supports.subdirectories</code> to <code>true</code>. (Hive-site.xml)</p>
<p> &#x2F;warehouse&#x2F;tablespace&#x2F;managed&#x2F;hive&#x2F;ftms_ods.db&#x2F;test_user6&#x2F;delta_0000001_0000001_0000</p>
<p>&#x2F;warehouse&#x2F;tablespace&#x2F;managed&#x2F;hive&#x2F;ftms_ods.db&#x2F;test_user7&#x2F;part-00000-2a86feec-be9a-413d-a696-8ff115d14075-c000.snappy.orc</p>
<h2 id="包冲突"><a href="#包冲突" class="headerlink" title="包冲突"></a>包冲突</h2><p>xbean-asm5-shaded-4.4.jar</p>
<p>xmlbeans-3.1.0.jar</p>
<p>xercesImpl-2.9.1.jar</p>
<p>xerces2-xsd11-2.11.1.jar</p>
<p>Xmlapis.jar</p>
<h2 id="Xml"><a href="#Xml" class="headerlink" title="Xml"></a>Xml</h2><p>删除 &#x2F;user&#x2F;ftms&#x2F;lib&#x2F;xercesImpl-2.9.1.jar 和 &#x2F;user&#x2F;ftms&#x2F;lib&#x2F;xml-apis-1.3.04.jar</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: User class threw exception: javax.xml.parsers.FactoryConfigurationError: Provider for class javax.xml.parsers.DocumentBuilderFactory cannot be created</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.findServiceProvider(FactoryFinder.java:311)</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.find(FactoryFinder.java:267)</span><br><span class="line">	at javax.xml.parsers.DocumentBuilderFactory.newInstance(DocumentBuilderFactory.java:120)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.asXmlDocument(Configuration.java:3442)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3417)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3388)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3384)</span><br><span class="line">	at org.apache.hadoop.hive.conf.HiveConf.getConfVarInputStream(HiveConf.java:2410)</span><br><span class="line">	at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:2703)</span><br><span class="line">	at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:2657)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.hiveConf(HiveMetaStoreUtil.scala:18)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.createHiveMetaStoreClient(HiveMetaStoreUtil.scala:23)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.getHiveMetaStoreClient(HiveMetaStoreUtil.scala:34)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.getHiveTablePartitionCols(HiveMetaStoreUtil.scala:78)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.getHiveTablePartitionColNames(HiveMetaStoreUtil.scala:73)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveDataSource$.buildInsertSql(HiveDataSource.scala:7)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveDataSource$.save(HiveDataSource.scala:42)</span><br><span class="line">	at com.ftms.datapipeline.tasks.dwd.DCompany$.main(DCompany.scala:197)</span><br><span class="line">	at com.ftms.datapipeline.tasks.dwd.DCompany.main(DCompany.scala)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721)</span><br><span class="line">Caused by: java.lang.RuntimeException: Provider for class javax.xml.parsers.DocumentBuilderFactory cannot be created</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.findServiceProvider(FactoryFinder.java:308)</span><br><span class="line">	... 23 more</span><br><span class="line">Caused by: java.util.ServiceConfigurationError: javax.xml.parsers.DocumentBuilderFactory: Provider org.apache.xerces.jaxp.DocumentBuilderFactoryImpl not found</span><br><span class="line">	at java.util.ServiceLoader.fail(ServiceLoader.java:239)</span><br><span class="line">	at java.util.ServiceLoader.access$300(ServiceLoader.java:185)</span><br><span class="line">	at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:372)</span><br><span class="line">	at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)</span><br><span class="line">	at java.util.ServiceLoader$1.next(ServiceLoader.java:480)</span><br><span class="line">	at javax.xml.parsers.FactoryFinder$1.run(FactoryFinder.java:294)</span><br><span class="line">	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.findServiceProvider(FactoryFinder.java:289)</span><br><span class="line">	... 23 more</span><br></pre></td></tr></table></figure>



<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="在-yarn-client-模式下运行-spark"><a href="#在-yarn-client-模式下运行-spark" class="headerlink" title="在 yarn-client 模式下运行 spark"></a>在 yarn-client 模式下运行 spark</h3><p>会出现 <code>Library directory &#39;...\assembly\target\scala-2.11\jars&#39; does not exist; make sure Spark is built.</code>，这个大致原因是 yarn-client 模式下</p>
<p><a href="https://www.jianshu.com/p/016fbd2a421b"><code>spark.yarn.jar</code>和<code>spark.yarn.archive</code>的使用</a></p>
<blockquote>
<p>Running Spark on YARN requires a binary distribution of Spark which is built with YARN support. Binary distributions can be downloaded from the <a href="https://spark.apache.org/downloads.html">downloads page</a> of the project website. To build Spark yourself, refer to <a href="https://spark.apache.org/docs/latest/building-spark.html">Building Spark</a>.<br> To make Spark runtime jars accessible from YARN side, you can specify <code>spark.yarn.archive</code> or <code>spark.yarn.jars</code>. For details please refer to <a href="https://spark.apache.org/docs/latest/running-on-yarn.html#spark-properties">Spark Properties</a>. If neither <code>spark.yarn.archive</code> nor <code>spark.yarn.jars</code> is specified, Spark will create a zip file with all jars under <code>$SPARK_HOME/jars</code> and upload it to the distributed cache</p>
</blockquote>
<h1 id="Install-ClickHouse"><a href="#Install-ClickHouse" class="headerlink" title="Install ClickHouse"></a>Install ClickHouse</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 clickhouse</span></span><br><span class="line">$ rpm -ivh clickhouse-server-common-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line">$ rpm -ivh clickhouse-common-static-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line">$ rpm -ivh clickhouse-server-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line">$ rpm -ivh clickhouse-client-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">$ service clickhouse-server start</span><br><span class="line">Start clickhouse-server service: Path to data directory <span class="keyword">in</span> /etc/clickhouse-server/config.xml: /var/lib/clickhouse/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 client 验证运行成功</span></span><br><span class="line">$ clickhouse-client</span><br><span class="line">ClickHouse client version 19.4.3.11.</span><br><span class="line">Connecting to localhost:9000 as user default.</span><br><span class="line">Connected to ClickHouse server version 19.4.3 revision 54416.</span><br><span class="line"></span><br><span class="line">master :) <span class="keyword">select</span> 1</span><br><span class="line"></span><br><span class="line">SELECT 1</span><br><span class="line"></span><br><span class="line">┌─1─┐</span><br><span class="line">│ 1 │</span><br><span class="line">└───┘</span><br><span class="line"></span><br><span class="line">1 rows <span class="keyword">in</span> <span class="built_in">set</span>. Elapsed: 0.001 sec.</span><br></pre></td></tr></table></figure>

<h2 id="client-启动失败"><a href="#client-启动失败" class="headerlink" title="client 启动失败"></a>client 启动失败</h2><blockquote>
<p>error detail:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ClickHouse client version 20.8.3.18.</span><br><span class="line">Connecting to localhost:9000 as user default.</span><br><span class="line">Code: 102. DB::NetException: Unexpected packet from server localhost:9000 (expected Hello or Exception, got Unknown packet)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>这个错表示，clickhouse-client 收到返回了，但是返回的结果是非预期错误。这个错一般是由于端口占用。可以通过 <code>netstat -antp|grep LIST|grep 9000</code> 查询。</p>
<h3 id="Solution："><a href="#Solution：" class="headerlink" title="Solution："></a>Solution：</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新 clickHouse 的端口为 9011</span></span><br><span class="line">$ vi /etc/clickhouse-server/config.xml</span><br><span class="line">:%s/9000/9011</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动时带上端口号</span></span><br><span class="line">$ clickhouse-client --port 9011</span><br></pre></td></tr></table></figure>

<h1 id="安装-python3"><a href="#安装-python3" class="headerlink" title="安装 python3"></a>安装 python3</h1><p><a href="https://www.python.org/downloads/release/python-361/">https://www.python.org/downloads/release/python-361/</a></p>
<p><a href="https://www.jianshu.com/p/758b592387d1">reference doc</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压并安装 python3</span></span><br><span class="line">$ tar -xf Python-3.?.?.tar.xz</span><br><span class="line">$ <span class="built_in">cd</span> Python-3.?.?</span><br><span class="line">$ ./configure</span><br><span class="line">$ make altinstall</span><br><span class="line">$ python3.x -V</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建软链</span></span><br><span class="line">$ <span class="built_in">which</span> python3.6</span><br><span class="line">$ <span class="built_in">ln</span> -s /usr/local/bin/python3.6.1 /usr/bin/python3</span><br><span class="line">$ python3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 pip</span></span><br><span class="line">$ python3 -m ensurepip</span><br><span class="line">$ pip3</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果安装 pip 时报错 zlib not found：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 zlib 相关依赖包</span></span><br><span class="line">$ yum -y install zlib*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入 python安装包,修改Module路径的setup文件，Modules/Setup.dist （或者 Modules/Setup） 文件</span></span><br><span class="line">$ vi Module/Setup</span><br><span class="line"><span class="comment">#zlib zlibmodule.c -I$(prefix)/include -L$(exec_prefix)/lib -lz</span></span><br><span class="line">去掉注释</span><br><span class="line">     zlib zlibmodule.c -I$(prefix)/include -L$(exec_prefix)/lib -lz</span><br></pre></td></tr></table></figure>
</blockquote>
<h1 id="安装-airflow"><a href="#安装-airflow" class="headerlink" title="安装 airflow"></a>安装 airflow</h1><p>为了方便管理，可以安装个 mpack，然后就可以从 ambari 安装、管理、监控 airflow</p>
<ul>
<li><a href="https://miho120.medium.com/integrating-apache-airflow-with-apache-ambari-ccab2c90173">install airflow from ambari</a></li>
<li><a href="https://github.com/miho120/ambari-airflow-mpack">git</a></li>
</ul>
<p>这个插件在安装&#x2F;启动时，其实就是执行了 <code>/var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts/airflow_scheduler_control.py</code> ，脚本中提供了安装、启动、停止。安装时，本质是执行了以下内容：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install apache-airflow[all]==1.9.0 apache-airflow[celery]==1.9.0</span><br></pre></td></tr></table></figure>

<blockquote>
<p>相关的安装、启动等脚本都在 <code>/var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts</code> 目录下</p>
</blockquote>
<p>但上述过程只能在有线环境执行，离线环境还是得自己下。</p>
<h2 id="install-airflow-offline"><a href="#install-airflow-offline" class="headerlink" title="install airflow offline"></a>install airflow offline</h2><p><a href="https://airflow.apache.org/docs/stable/installation.html">airflow installation 官方</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先下载相关包</span></span><br><span class="line">$ <span class="built_in">mkdir</span> airflow-install</span><br><span class="line">$ <span class="built_in">cd</span> airflow-install</span><br><span class="line">$ pip download <span class="string">&#x27;apache-airflow[all]==1.10.12&#x27;</span> \</span><br><span class="line">--constraint  <span class="string">&#x27;https://raw.githubusercontent.com/apache/airflow/constraints-1.10.12/constraints-3.6.txt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来更新上述 `airflow_scheduler_control.py` 中的安装脚本，选择从本地文件安装即可</span></span><br><span class="line">$ vi /var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts/airflow_scheduler_control.py</span><br><span class="line">$ vi /var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts/airflow_webserver_control.py</span><br><span class="line"><span class="comment"># 下边这个命令是上述脚本的内容，这里只是介绍一下执行的命令</span></span><br><span class="line">$ pip install apache-airflow==1.10.12 --no-index -f ./</span><br><span class="line"></span><br><span class="line"><span class="comment"># 过程中可能会有些包缺，例如 docutils、pytest-runner 等，从 https://pypi.org/ 下载相应的 .whl 文件，放到该目录下</span></span><br><span class="line"><span class="comment"># 然后通过 --no-index -f ./ 或者 --no-index -f ./xxx.whl 来安装即可</span></span><br><span class="line">$ pip install pytest-runner --no-index -f ./</span><br></pre></td></tr></table></figure>

<p>实际操作时，下载完 airflow 后，就更新 airflow_scheduler_control.py 和 airflow_webserver_control.py （两个文件的 install method 是一模一样的，按同样的方式修改就行）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">################# 源文件</span></span><br><span class="line">     <span class="number">11</span>         <span class="keyword">def</span> <span class="title function_">install</span>(<span class="params">self, env</span>):</span><br><span class="line">     <span class="number">12</span>                 <span class="keyword">import</span> params</span><br><span class="line">     <span class="number">13</span>                 env.set_params(params)</span><br><span class="line">     <span class="number">14</span>                 <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">30</span>)</span><br><span class="line">     <span class="number">15</span>                 <span class="built_in">print</span>(env)</span><br><span class="line">     <span class="number">16</span>                 <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">30</span>)</span><br><span class="line">     <span class="number">17</span>                 self.install_packages(env)</span><br><span class="line">     <span class="number">18</span>                 Logger.info(<span class="built_in">format</span>(<span class="string">&quot;Installing Airflow Service&quot;</span>))</span><br><span class="line">     <span class="number">19</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; pip&quot;</span>))</span><br><span class="line">     <span class="number">20</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; setuptools&quot;</span>))</span><br><span class="line">     <span class="number">21</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; docutils pytest-runner Cython==0.28&quot;</span>))</span><br><span class="line">     <span class="number">22</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-        installed apache-airflow[all]==1.10.0&quot;</span>))</span><br><span class="line">     <span class="number">23</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-        installed apache-airflow[celery]==1.10.0&quot;</span>))</span><br><span class="line">     <span class="number">24</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chmod 755 /bin/airflow /usr/bin/airflow&quot;</span>))</span><br><span class="line">     <span class="number">25</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;useradd &#123;airflow_user&#125;&quot;</span>), ignore_failures=<span class="literal">True</span>)</span><br><span class="line">     <span class="number">26</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;mkdir -p &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">27</span>                 airflow_make_startup_script(env)</span><br><span class="line">     <span class="number">28</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chown -R &#123;airflow_user&#125;:&#123;airflow_group&#125; &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">29</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export AIRFLOW_HOME=&#123;airflow_home&#125; &amp;&amp; airflow initdb&quot;</span>),</span><br><span class="line">     <span class="number">30</span>                         user=params.airflow_user</span><br><span class="line">     <span class="number">31</span>                 )</span><br><span class="line"></span><br><span class="line"><span class="comment">################### 修改后的</span></span><br><span class="line">     <span class="number">11</span>         <span class="keyword">def</span> <span class="title function_">install</span>(<span class="params">self, env</span>):</span><br><span class="line">     <span class="number">12</span>                 <span class="keyword">import</span> params</span><br><span class="line">     <span class="number">13</span>                 env.set_params(params)</span><br><span class="line">    <span class="comment"># 这里是去安装 pip，已经装好了，就不装了</span></span><br><span class="line">     <span class="number">14</span> <span class="comment">#               self.install_packages(env)</span></span><br><span class="line">     <span class="number">15</span>                 Logger.info(<span class="built_in">format</span>(<span class="string">&quot;Installing Airflow Service&quot;</span>))</span><br><span class="line">     <span class="number">16</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; pip&quot;</span>))</span><br><span class="line">     <span class="number">17</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; setuptools&quot;</span>))</span><br><span class="line">    <span class="comment"># 从指定目录找安装包 --no-index -f ./xxx</span></span><br><span class="line">     <span class="number">18</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; docutils pytest-runner Cython --no-index -f /install/python_install/airflow-install/&quot;</span>))</span><br><span class="line">    <span class="comment"># 从指定目录找安装包 --no-index -f ./xxx，并更新版本为 1.10.12，且仅安装 minimal packages</span></span><br><span class="line">     <span class="number">19</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-installed apache-airflow==1.10.12 --no-index -f /install/python_install/airflow-install/&quot;</span>))</span><br><span class="line">    <span class="comment"># 从指定目录找安装包 --no-index -f ./xxx，并更新版本为 1.10.12</span></span><br><span class="line">     <span class="number">20</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-installed apache-airflow[celery]==1.10.12 --no-index -f /install/python_install/airflow-install/&quot;</span>))</span><br><span class="line">    <span class="comment"># 目前系统中默认是安装在 /usr/local/bin/airflow</span></span><br><span class="line">     <span class="number">21</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chmod 755 /usr/local/bin/airflow&quot;</span>))</span><br><span class="line">     <span class="number">22</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;useradd &#123;airflow_user&#125;&quot;</span>), ignore_failures=<span class="literal">True</span>)</span><br><span class="line">     <span class="number">23</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;mkdir -p &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">24</span>                 airflow_make_startup_script(env)</span><br><span class="line">     <span class="number">25</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chown -R &#123;airflow_user&#125;:&#123;airflow_group&#125; &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">26</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export AIRFLOW_HOME=&#123;airflow_home&#125; &amp;&amp; airflow initdb&quot;</span>),</span><br><span class="line">     <span class="number">27</span>                         user=params.airflow_user</span><br><span class="line">     <span class="number">28</span>                 )</span><br></pre></td></tr></table></figure>

<h1 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h1><p><strong>Admin Name</strong> : admin </p>
<p><strong>Cluster Name</strong> : ftms_hdp_qat </p>
<p><strong>Total Hosts</strong> : 3 (3 new) </p>
<p><strong>Repositories</strong>:</p>
<p>redhat7 (HDP-3.1):<br> <a href="http://10.66.18.11/ambari/HDP/centos7/3.1.4.0-315/">http://10.66.18.11/ambari/HDP/centos7/3.1.4.0-315/</a></p>
<p>redhat7 (HDP-3.1-GPL):<br> <a href="http://10.66.18.11/ambari/HDP-GPL/centos7/3.1.4.0-315/">http://10.66.18.11/ambari/HDP-GPL/centos7/3.1.4.0-315/</a></p>
<p>redhat7 (HDP-UTILS-1.1.0.22):<br> <a href="http://10.66.18.11/ambari/HDP-UTILS/centos7/1.1.0.22/">http://10.66.18.11/ambari/HDP-UTILS/centos7/1.1.0.22/</a></p>
<p><strong>Services:</strong></p>
<p><em>HDFS</em> </p>
<p>DataNode : 2 hosts </p>
<p>NameNode : master </p>
<p>NFSGateway : 0 host </p>
<p>SNameNode : slave1 </p>
<p><em>YARN + MapReduce2</em> </p>
<p>Timeline Service V1.5 : slave1 </p>
<p>NodeManager : 1 host </p>
<p>ResourceManager : master </p>
<p>Timeline Service V2.0 Reader : master </p>
<p>Registry DNS : master </p>
<p><em>Tez</em> </p>
<p>Clients : 1 host </p>
<p><em>Hive</em> </p>
<p>Metastore : slave1 </p>
<p>HiveServer2 : slave1 </p>
<p>Database : Existing MySQL &#x2F; MariaDB Database </p>
<p><em>HBase</em> </p>
<p>Master : master </p>
<p>RegionServer : 1 host </p>
<p>Phoenix Query Server : 0 host </p>
<p><em>Sqoop</em> </p>
<p>Clients : 1 host </p>
<p><em>Oozie</em> </p>
<p>Server : master </p>
<p>Database : Existing MySQL &#x2F; MariaDB Database </p>
<p><em>ZooKeeper</em> </p>
<p>Server : 3 hosts </p>
<p><em>Infra Solr</em> </p>
<p>Infra Solr Instance : master </p>
<p><em>Ambari Metrics</em> </p>
<p>Metrics Collector : slave2 </p>
<p>Grafana : master </p>
<p><em>Atlas</em> </p>
<p>Metadata Server : slave1 </p>
<p><em>Kafka</em> </p>
<p>Broker : master </p>
<p><em>Ranger</em> </p>
<p>Admin : slave1 </p>
<p>Tagsync : 1 host </p>
<p>Usersync : slave1 </p>
<p><em>SmartSense</em> </p>
<p>Activity Analyzer : master </p>
<p>Activity Explorer : master </p>
<p>HST Server : master </p>
<p><em>Spark2</em> </p>
<p>Livy for Spark2 Server : 0 host </p>
<p>History Server : master </p>
<p>Thrift Server : 0 host </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2020/11/13/atlas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/11/13/atlas/" class="post-title-link" itemprop="url">atlas</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-11-13 10:04:33" itemprop="dateCreated datePublished" datetime="2020-11-13T10:04:33+08:00">2020-11-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-22 14:22:52" itemprop="dateModified" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p><img src="http://atlas.apache.org/public/images/twiki/architecture.png" alt="img"></p>
<h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><p><a href="https://atlas.apache.org/2.0.0/InstallationSteps.html">install steps</a></p>
<p>Access Apache Atlas UI using a browser: <a href="http://localhost:21000/">http://localhost:21000</a> </p>
<p>You can also access the rest api <code>http://localhost:21000/api/atlas/v2</code></p>
<p>默认的用户名密码是 (admin, admin)</p>
<h1 id="Atlas-Features"><a href="#Atlas-Features" class="headerlink" title="Atlas Features"></a>Atlas Features</h1><h2 id="定义元模型，规范元数据"><a href="#定义元模型，规范元数据" class="headerlink" title="定义元模型，规范元数据"></a>定义元模型，规范元数据</h2><p>atlas 可以维护（增删改查） metadata types，支持</p>
<ul>
<li>创建多种类型的 metadata types<ul>
<li>businessmetadatadef：业务元数据的元模型</li>
<li>classificationdef：标签数据的元模型</li>
<li>entitydef：一般元数据的元模型</li>
<li>enumdef</li>
<li>relationshipdef：关系元数据的元模型</li>
<li>structdef</li>
</ul>
</li>
<li>元模型支持定义属性约束、索引、唯一性等</li>
<li>按 id&#x2F;typename&#x2F;query 来检索</li>
</ul>
<blockquote>
<p><a href="http://atlas.apache.org/api/v2/resource_TypesREST.html#resource_TypesREST_createAtlasTypeDefs_POST">相关 API 定义</a></p>
<p><a href="http://atlas.apache.org/api/v2/json_AtlasTypesDef.html">typedef request schema object</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># DELETE/GET/POST/PUT</span><br><span class="line">/v2/types/typedef</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h3><ul>
<li>typename 全局唯一</li>
</ul>
<h2 id="可以维护元数据"><a href="#可以维护元数据" class="headerlink" title="可以维护元数据"></a>可以维护元数据</h2><h3 id="import-metadata"><a href="#import-metadata" class="headerlink" title="import metadata"></a>import metadata</h3><p>atlas 提供以下途径将元数据引入系统：</p>
<ol>
<li>REST API：atlas 提供 api 可以 bulk saveOrUpdate 某个 type 的元数据</li>
<li>文件：atlas 可以上传文件，并 saveOrUpdate 文件中所定义的元模型、元数据等</li>
<li>atlas hook：atlas 通过监听 kafka topic <code>ATLAS_HOOK</code> ，来实时引入数据源中的元数据。目前已提供 Apache Hive&#x2F;Apache HBase&#x2F;Apache Storm&#x2F;Apache Sqoop 的 hook<ol>
<li>hive hook<ol>
<li>可以 import hive databases &amp; tables 元数据</li>
<li>可以监听以下类型的 hive 操作，capture 其中的元数据：<ol>
<li>create database</li>
<li>create table&#x2F;view, create table as select</li>
<li>load, import, export</li>
<li>DMLs (insert)</li>
<li>alter database</li>
<li>alter table (skewed table information, stored as, protection is not supported)</li>
<li>alter view</li>
</ol>
</li>
</ol>
</li>
<li>sqoop<ol>
<li>目前仅支持监听 sqoop 的 hiveimport operation 完成后，capture 其中的元数据。</li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="业务元数据"><a href="#业务元数据" class="headerlink" title="业务元数据"></a>业务元数据</h2><p>atlas 可以:</p>
<ol>
<li>定义业务元数据元模型规范业务元数据</li>
<li>在技术元数据上，添加业务元数据，来实现关联</li>
<li>支持按业务元数据检索</li>
</ol>
<h2 id="血缘"><a href="#血缘" class="headerlink" title="血缘"></a>血缘</h2><p>atlas 可以查询元数据血缘关系。应该是基于关系图实现。</p>
<p>目前 hive 表可以支撑到 column 级别的血缘分析。</p>
<h2 id="可以维护标签"><a href="#可以维护标签" class="headerlink" title="可以维护标签"></a>可以维护标签</h2><p>atlas 中的 classification 即标签，可以打在元数据、术语等地方。</p>
<p>可以基于 classification 检索元数据。</p>
<p>可以做 classification 的传播：</p>
<ul>
<li>基于继承关系链的传播</li>
<li>基于血缘关系链的传播</li>
</ul>
<h3 id="Classification-vs-label"><a href="#Classification-vs-label" class="headerlink" title="Classification vs label"></a>Classification vs label</h3><p>Atlas 中的 classification 和 label 都是标签的概念，label 是轻量级、谁都可以加的简单标签，classification 则有更多的支持。</p>
<p><a href="https://docs.cloudera.com/runtime/7.2.1/atlas-working-with-classifications/topics/atlas-working-with-classifications.html">atlas classification vs label</a></p>
<h2 id="可以维护企业术语表"><a href="#可以维护企业术语表" class="headerlink" title="可以维护企业术语表"></a>可以维护企业术语表</h2><p>atlas 可以维护企业的术语，并将术语与元数据关联，支持按术语检索元数据，通过以下三个概念来实现细粒度的术语管理：</p>
<ol>
<li>glossary：术语表，最高级别，所有的术语都必须属于某个术语表</li>
<li>category：术语分类，必须挂在某个 glossary。可以拥有 childCategories</li>
<li>term：术语。必须挂在某个 glossary。可以挂在某个 category</li>
</ol>
<h2 id="Notifications"><a href="#Notifications" class="headerlink" title="Notifications"></a>Notifications</h2><p>atlas 通过 kafka 实现 hook，引入元数据；也通过 kafka 广播元数据修改，供消费者使用。</p>
<ul>
<li><p>notifications to atlas：<code>ATLAS_HOOK</code>. 目前已提供 Apache Hive&#x2F;Apache HBase&#x2F;Apache Storm&#x2F;Apache Sqoop 的 hook，来监听这些数据源的元数据</p>
</li>
<li><p>notifications from atlas: <code>ATLAS_ENTITIES</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 监听并发布以下事件的通知</span><br><span class="line">ENTITY_CREATE:         sent when an entity instance is created</span><br><span class="line">ENTITY_UPDATE:         sent when an entity instance is updated</span><br><span class="line">ENTITY_DELETE:         sent when an entity instance is deleted</span><br><span class="line">CLASSIFICATION_ADD:    sent when classifications are added to an entity instance</span><br><span class="line">CLASSIFICATION_UPDATE: sent when classifications of an entity instance are updated</span><br><span class="line">CLASSIFICATION_DELETE: sent when classifications are removed from an entity instance</span><br><span class="line"></span><br><span class="line"># notification data</span><br><span class="line">AtlasEntity  entity;</span><br><span class="line">OperationType operationType;</span><br><span class="line">List&lt;AtlasClassification&gt;  classifications</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h2><p>atlas 所有的元数据存储在图数据库 JanusGraph，而索引数据则存储在 index store（solr &#x2F; elasticsearch）来做全文检索</p>
<p>atlas 支持以下检索方式：</p>
<ol>
<li>唯一定位元数据：通过 id</li>
<li>basic 检索：基于 type、attributes、classifciation、terms 等 query parameter 做全文检索</li>
<li>advance 检索：可以使用 dsl 语言做全文检索</li>
</ol>
<h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><ol>
<li>基础设施高可用。<ol>
<li>atlas 使用 JanusGraph 存储元数据，并将 HBase（默认，可采用其他数据库）作为 backing store。HBase 本身的高可用特性支撑了 metadata store 的高可用</li>
<li>atlas 使用 solr &#x2F; elasticsearch 存储元数据索引。这些组件同样支持高可用</li>
</ol>
</li>
<li>Web Service 高可用。<ol>
<li>目前 atlas 的 web service 同一时间只能有一个 active instance 响应，以实现元数据维护、缓存等的一致性问题。高可用模式即有多个备用（passive）instances，当 active instance down 后，可以自动切换某个 passive instance，作为新的 active instance。</li>
</ol>
</li>
</ol>
<h2 id="访问控制"><a href="#访问控制" class="headerlink" title="访问控制"></a>访问控制</h2><p>atlas 支持非常细粒度的访问控制：</p>
<ul>
<li><p>元模型：基于某个元模型或某类元模型的访问控制。典型 example：</p>
<blockquote>
<ul>
<li>Admin users can create&#x2F;update&#x2F;delete types of all categories</li>
<li>Data stewards can create&#x2F;update&#x2F;delete classification types</li>
<li>Healthcare data stewards can create&#x2F;update&#x2F;delete types having names start with “hc”</li>
</ul>
</blockquote>
</li>
<li><p>元数据：基于元模型、标签、元数据 id 的元数据访问控制。典型 example：</p>
<blockquote>
<ul>
<li>Admin users can perform all entity operations on entities of all types</li>
<li>Data stewards can perform all entity operations, except delete, on entities of all types</li>
<li>Data quality admins can add&#x2F;update&#x2F;remove DATA_QUALITY classification</li>
<li>Users in specific groups can read&#x2F;update entities with PII classification or its sub-classification</li>
<li>Finance users can read&#x2F;update entities whose ID start with ‘finance’</li>
</ul>
</blockquote>
</li>
<li><p>admin 操作：可以控制 user&#x2F;group 来 import&#x2F;export entities</p>
</li>
</ul>
<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><p>有个 ui 可以管理元数据、标签、术语</p>
<h1 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h1><ol>
<li>web service 只有一个 active instance</li>
<li>Typename 全局唯一</li>
<li>ui 挺慢的</li>
</ol>
<h1 id="基于-atlas-我们可以做什么"><a href="#基于-atlas-我们可以做什么" class="headerlink" title="基于 atlas 我们可以做什么"></a>基于 atlas 我们可以做什么</h1><ol>
<li>数据集发现<ol>
<li>数据字典浏览和检索</li>
</ol>
</li>
<li>数据集导入和导出<ol>
<li>导出数据集，供系统之间交互使用</li>
<li>导入数据集（数据标准、指标口径等）</li>
</ol>
</li>
<li>标签管理：<ol>
<li>维护用户画像标签 (增删改查)</li>
<li>基于标签检索数据集</li>
</ol>
</li>
<li>数据标准维护和浏览：（可以通过术语做？）<ol>
<li>维护数据标准（增删改查）</li>
<li>可以为数据标准加标签</li>
</ol>
</li>
<li>指标和口径维护和浏览<ol>
<li>维护指标口径（增删改查）</li>
<li>可以为指标口径加标签</li>
</ol>
</li>
<li>数据集 staticstics<ol>
<li>数据接入和使用情况统计</li>
</ol>
</li>
<li>辅助数据分析师生成分析：<ol>
<li>通过关联技术元数据和业务元数据，当数据分析师按业务语言定义分析后，可以快速查找相关的表、字段等</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2020/11/11/import-data-to-hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/11/11/import-data-to-hive/" class="post-title-link" itemprop="url">数据导入 hive</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-11-11 11:58:27" itemprop="dateCreated datePublished" datetime="2020-11-11T11:58:27+08:00">2020-11-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-22 14:22:52" itemprop="dateModified" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ftp-csv-文件导入"><a href="#ftp-csv-文件导入" class="headerlink" title="ftp .csv 文件导入"></a>ftp .csv 文件导入</h1><p>可以先将文件弄到 HDFS，然后创建&#x2F;更新 hive 表来关联到 HDFS 文件。</p>
<p>将文件弄到 HDFS有以下一些方法：</p>
<ol>
<li><strong>ftp -&gt; local -&gt; hdfs:</strong> 将文件先下载到本地，再通过 hdfs 命令拷贝到 hdfs 中</li>
<li><strong>ftp -&gt; hdfs</strong>: 直接连接 FTP，将文件拷到 hdfs 中，省却本地拷贝</li>
<li><strong>已有的数据采集工具</strong>：使用实时数据流处理系统，来实现不同系统之间的流通</li>
</ol>
<h2 id="一、ftp-gt-local-gt-hdfs"><a href="#一、ftp-gt-local-gt-hdfs" class="headerlink" title="一、ftp -&gt; local -&gt;hdfs"></a>一、ftp -&gt; local -&gt;hdfs</h2><p>几种方案：</p>
<ol>
<li><p><code>hadoop fs -get ftp://uid:password@server_url/file_path temp_file | hadoop fs -moveFromLocal tmp_file hadoop_path/dest_file</code> </p>
</li>
<li><p>参照<a href="https://community.cloudera.com/t5/Support-Questions/How-read-ftp-server-files-and-load-into-hdfs-in-incremental/m-p/223519/highlight/true#M185384">这个实现</a>用 python 包从 ftp 中读，然后用 hdfs 命令写到 hdfs</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> hdfs <span class="keyword">import</span> InsecureClient</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can also use KerberosClient or custom client</span></span><br><span class="line">namenode_address = <span class="string">&#x27;your namenode address&#x27;</span></span><br><span class="line">webhdfs_port = <span class="string">&#x27;your webhdfs port&#x27;</span> <span class="comment"># default for Hadoop 2: 50070, Hadoop 3: 9870</span></span><br><span class="line">user = <span class="string">&#x27;your user name&#x27;</span></span><br><span class="line">client = InsecureClient(<span class="string">&#x27;http://&#x27;</span> + namenode_address + <span class="string">&#x27;:&#x27;</span> + webhdfs_port, user=user)</span><br><span class="line"></span><br><span class="line">ftp_address = <span class="string">&#x27;your ftp address&#x27;</span></span><br><span class="line">hdfs_path = <span class="string">&#x27;where you want to write&#x27;</span></span><br><span class="line"><span class="keyword">with</span> urlopen(ftp_address) <span class="keyword">as</span> response:</span><br><span class="line">    content = response.read()</span><br><span class="line">    <span class="comment"># You can also use append=True</span></span><br><span class="line">    <span class="comment"># Further reference: https://hdfscli.readthedocs.io/en/latest/api.html#hdfs.client.Client.write</span></span><br><span class="line">    <span class="keyword">with</span> client.write(hdfs_path) <span class="keyword">as</span> writer:</span><br><span class="line">        writer.write(content</span><br></pre></td></tr></table></figure>
</li>
<li><p>参考 <a href="https://blog.csdn.net/yiluohan0307/article/details/79364525">ftp 提取文件到 hdfs</a></p>
</li>
</ol>
<h2 id="二、ftp-gt-hdfs"><a href="#二、ftp-gt-hdfs" class="headerlink" title="二、ftp -&gt; hdfs"></a>二、ftp -&gt; hdfs</h2><p>几种方案：(参考 <a href="https://blog.csdn.net/yiluohan0307/article/details/79364525">ftp 提取文件到 hdfs</a>)</p>
<ol>
<li><p>用 <a href="http://hadoop101.blogspot.com/?view=classic">FTP To HDFS</a> 连接 ftp，把文件直接放到 hdfs</p>
</li>
<li><p>HDFS dfs -cp: 简单快速，但不显示进度，适用于小文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hdfs dfs –<span class="built_in">cp</span> [ftp://username:password@hostname/ftp_path] [hdfs:///hdfs_path]</span><br></pre></td></tr></table></figure>
</li>
<li><p>Hadoop distcp: 分布式提取，快，能显示拷贝进度，不支持流式写入（即拷贝的文件不能有其他程序在写入），适合大量文件或大文件的拷贝</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop distcp [ftp://username:password@hostname/ftp_path] [hdfs:///hdfs_path]</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="三、已有的数据采集工具"><a href="#三、已有的数据采集工具" class="headerlink" title="三、已有的数据采集工具"></a>三、已有的数据采集工具</h2><h3 id="文件导入"><a href="#文件导入" class="headerlink" title="文件导入"></a>文件导入</h3><ol>
<li><p><a href="https://nifichina.github.io/general/GettingStarted.html#%E6%9C%89%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%88%AB%E7%9A%84%E5%A4%84%E7%90%86%E5%99%A8">apache NiFi</a> 来实现不同系统之间的流通，似乎拷贝完，会直接删除 ftp 上的文件</p>
</li>
<li><p>Apache Flume是一个分布式、可靠、高可用的日志收集系统，支持各种各样的数据来源。基于流式数据，适用于日志和事件类型的数据收集，重构后的Flume-NG版本中一个agent（数据传输流程）中的source（源）和sink（目标）之间通过channel进行链接，同一个源可以配置多个channel。多个agent还可以进行链接组合共同完成数据收集任务，使用起来非常灵活。</p>
<p><a href="https://blog.csdn.net/qq_39160721/article/details/80255588">flume 采集 ftp 文件 上传到 hadoop</a> 使用 <a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source">spooldir source</a>（不确定是不是能用）, 也可以使用第三方 source 组件 <a href="https://github.com/keedio/flume-ftp-source">flume-ftp-source</a></p>
<blockquote>
<p>Flume 也支持 sql source 的流式导入（使用 <a href="https://github.com/keedio/flume-ng-sql-source">flume-ng-sql-source</a> 插件），并提供对数据进行简单处理，并写到各数据接收方的能力。因此它的实时性更好。</p>
</blockquote>
</li>
<li><p>DataX：阿里的开源框架，本身社区不太活跃，但有很多 fork 再改的，似乎架构不错</p>
</li>
<li><p>Gobllin: Gobblin是用来整合各种数据源的通用型ETL框架，Gobblin的接口封装和概念抽象做的很好，作为一个ETL框架使用者，我们只需要实现我们自己的Source，Extractor，Conventer类，再加上一些数据源和目的地址之类的配置文件提交给Gobblin就行了。Gobblin相对于其他解决方案具有普遍性、高度可扩展性、可操作性。</p>
</li>
<li><p>kettle：一款开源的ETL工具</p>
</li>
</ol>
<h3 id="其他数据源（非-FTP-文件）"><a href="#其他数据源（非-FTP-文件）" class="headerlink" title="其他数据源（非 FTP 文件）"></a>其他数据源（非 FTP 文件）</h3><ol>
<li>Apache Sqoop：RDBMS &lt;–&gt; HDFS</li>
<li>Aegisthus：针对 Cassandra 数据源</li>
<li>mongo-hadoop：针对 mongodb 数据源</li>
</ol>
<h1 id="数据导入需要关注的问题"><a href="#数据导入需要关注的问题" class="headerlink" title="数据导入需要关注的问题"></a>数据导入需要关注的问题</h1><ol>
<li><strong>数据源都有哪些？</strong><ol>
<li>结构化（sql）、半结构化（json, xml…)、非结构化（video、image、file…)</li>
<li>日志数据（csv)、业务数据</li>
</ol>
</li>
<li><strong>是否可以直接连接数据库？</strong><ol>
<li>针对关系型数据，如果可连接数据库，可以通过 sqoop 导入数据到 hive<ol>
<li>增量式导入？？</li>
</ol>
</li>
<li>针对关系型数据，如果不能连接数据库：<ol>
<li><strong>是否可以默认周期性导出符合特定标准的 .csv 文件？</strong><ol>
<li>如果数据库导出 dump 文件，再将 dump 文件导入到 hadoop，则比较麻烦，以 oracle 为例，可能需要使用 COPYToBDA 来创建 hive table <a href="https://weidongzhou.wordpress.com/2016/11/12/data-query-between-bda-and-exadata-part-4-query-oracle-dump-file-on-bda-using-copy2bda/">Query Oracle Dump File on BDA Using Copy2BDA</a> ，或者将 dump 文件先导入到一个 temp oracle 数据库中，再用 sqoop 导入到 hive</li>
<li>如果数据库周期性导出 .csv 文件，将这些 .csv 文件使用上述工具（flume 等）导入到 hive，需要关注增量式导出和导入<ol>
<li>增量式导出：文件的组织结构、命名规范 ，.csv 内 record 要求包含 modified date, delete date（在增量式导入时，需要基于这些时间来合并表）</li>
<li>增量式导入：将新增的 .csv 文件作为 hive external table，然后通过中间 view 来合并基表和incremental 表，并更新基表、清空 incremental 表。<a href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.5/bk_data-access/content/incrementally-updating-hive-table-with-sqoop-and-ext-table.html">Incrementally Updating a Table</a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>导入周期和实时性需求<ol>
<li><strong>哪些需要每天批量导入、哪些需要流式实时导入</strong></li>
<li><strong>哪些需要全量导入、哪些需要增量式导入？</strong></li>
</ol>
</li>
<li><strong>如何实现增量式导入？删除的数据是否有删除标识（软删除）？</strong><ol>
<li>如果用 sqoop，参考 <a href="https://hfcherish.github.io/2020/11/10/sqoop/">sqoop 增量导入</a>，不支持对删除数据的处理</li>
<li>如果用 flume<ol>
<li>如果是 sql source，使用 <a href="https://github.com/keedio/flume-ng-sql-source">flume-ng-sql-source</a>, 对于 mysql 可以通过 query <code>agent.sources.sqlSource.custom.query</code> 来获取增量 source</li>
<li>如果是文件导入，则需要通过 <a href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.5/bk_data-access/content/incrementally-updating-hive-table-with-sqoop-and-ext-table.html">Incrementally Updating a Table</a> 来合并表</li>
</ol>
</li>
<li>Spark SQL</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://hfcherish.github.io/2020/11/10/sqoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Cherish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cherish's Blog">
      <meta itemprop="description" content="从心所欲不逾矩">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Cherish's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/11/10/sqoop/" class="post-title-link" itemprop="url">sqoop</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-11-10 13:39:30" itemprop="dateCreated datePublished" datetime="2020-11-10T13:39:30+08:00">2020-11-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-10-22 14:22:52" itemprop="dateModified" datetime="2022-10-22T14:22:52+08:00">2022-10-22</time>
    </span>

  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Word count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Word count in article: </span>
      <span>0</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>1 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h1><p>Sqoop: sq are the first two of “sql”, oop are the last three of “hadoop”. It <strong>transfers bulk data between hdfs and relational database servers</strong>. It supports:</p>
<ul>
<li>Full Load</li>
<li>Incremental Load</li>
<li>Parallel Import&#x2F;Export (throught mapper jobs)</li>
<li>Compression</li>
<li>Kerberos Security Integration</li>
<li>Data  loading directly to HIVE</li>
</ul>
<blockquote>
<p>Sqoop cannot import .csv files into hdfs&#x2F;hive. It only support databases &#x2F; mainframe datasets import.</p>
</blockquote>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p>Sqoop provides CLI, thus you can use a simple command to conduct import&#x2F;export.</p>
<p>The import&#x2F;export are executes in fact through map tasks.</p>
<p><img src="/images/sqoop-20201110134912159.png" alt="sqoop-20201110134912159.png"></p>
<p>When Import from DB:</p>
<ul>
<li>it split to some map tasks. And each map task will connect to DB, and fetch some rows&#x2F;tables, and write it to a file into HDFS</li>
</ul>
<p>When export to DB:</p>
<ul>
<li>it also split to some map tasks. And each map task will fetch a HDFS file, and write each record in the file as a row by specified delimiter to some table.</li>
</ul>
<p><img src="/images/sqoop-20201110135220097.png" alt="sqoop-20201110135220097.png"></p>
<h1 id="Sqoop-v-s-Spark-jdbc"><a href="#Sqoop-v-s-Spark-jdbc" class="headerlink" title="Sqoop v.s. Spark jdbc"></a>Sqoop v.s. Spark jdbc</h1><p>sqoop uses mapreduce technique, while spark is a revolutionary engine to replace mapreduce technique with its in-memory execution and DAG smartness. Thus Spark jdbc is way faster than sqoop.</p>
<ol>
<li>You can combine all the read, transform and write operations into one script&#x2F;program instead of reading it separately through SQOOP in one script and then doing transformation and write in another.</li>
<li>You can define a new split column on the fly (using functions like ORA_HASH) if you want the data to be partitioned in a proper way.</li>
<li>You can control the number of connection to the database. Increasing the number of connection will surely speed up your data import.</li>
</ol>
<h1 id="Common-Commands"><a href="#Common-Commands" class="headerlink" title="Common Commands"></a>Common Commands</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$  sqoop import \</span><br><span class="line">	--connect jdbc:mysql://&lt;ipaddress&gt;/&lt;database name&gt;</span><br><span class="line">	--table &lt;my_table name&gt;</span><br><span class="line">	--username &lt;username_for_my_sql&gt; --password &lt;password&gt;</span><br><span class="line">  --target-dir &lt;target <span class="built_in">dir</span> <span class="keyword">in</span> HDFS <span class="built_in">where</span> data needs to be imported&gt;</span><br><span class="line">  </span><br><span class="line">$  sqoop <span class="built_in">export</span> \</span><br><span class="line">	--connect jdbc:mysql://&lt;ipaddress&gt;/&lt;database name&gt;</span><br><span class="line">	--table &lt;my_table name&gt;</span><br><span class="line">	--username &lt;username_for_my_sql&gt; --password &lt;password&gt;</span><br><span class="line">  --export-dir &lt;target <span class="built_in">dir</span> <span class="keyword">in</span> HDFS <span class="built_in">where</span> data needs to be exported&gt;</span><br></pre></td></tr></table></figure>

<h1 id="Incremental-Import"><a href="#Incremental-Import" class="headerlink" title="Incremental Import"></a>Incremental Import</h1><p>增量导入时，sqoop 需要识别到增量数据，有三种方法：</p>
<ol>
<li>根据自增字段识别新数据（append 模式）：可以直接识别新数据并导入到 hive 中</li>
<li>根据修改时间识别新数据（lastmodified 模式）：要求这个字段会随数据的改变而改变，但是似乎只能导入到 hdfs 中，不能直接导入到 hive 中。导入时，可以通过制定<code>--merge-key id</code> 来按 id 字段进行合并，或者之后通过 <code>sqoop merge</code> 功能单独运行</li>
<li>根据 where 或 query 识别新数据：可能之后只能通过 <code>sqoop merge</code> 来 merge 数据</li>
</ol>
<blockquote>
<p>目前 <strong>sqoop 导入时不能识别删除数据</strong>，都需要通过其他方式来解决（对比数据，或者数据上有 delete 标识符时，通过 <a href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.5/bk_data-access/content/incrementally-updating-hive-table-with-sqoop-and-ext-table.html">Incrementally Updating a Table</a> 来实现）</p>
</blockquote>
<h2 id="append-模式"><a href="#append-模式" class="headerlink" title="append 模式"></a>append 模式</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/doit_mall \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--table oms_order \</span><br><span class="line">--target-dir  /tmp/query  \</span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table doit12.oms_order \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--compress   \</span><br><span class="line">--compression-codec gzip \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--incremental append \	<span class="comment"># append 模式</span></span><br><span class="line">--check-column <span class="built_in">id</span> \			<span class="comment"># 自增字段</span></span><br><span class="line">--last-value 22 \				<span class="comment"># 自增字段的 last value</span></span><br><span class="line">-m 2 </span><br></pre></td></tr></table></figure>

<h2 id="lastmodified-模式"><a href="#lastmodified-模式" class="headerlink" title="lastmodified 模式"></a>lastmodified 模式</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/dicts \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--table doit_stu \</span><br><span class="line">--target-dir  /doit_stu/2020-02-09  \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--incremental lastmodified \		<span class="comment"># lastmodified 模式</span></span><br><span class="line">--check-column update_time \		<span class="comment"># 时间字段</span></span><br><span class="line">--last-value <span class="string">&#x27;2020-02-09 23:59:59&#x27;</span> \	<span class="comment"># 上一次获取的数据时间</span></span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--merge-key <span class="built_in">id</span> \					<span class="comment">#按照id字段进行合并</span></span><br><span class="line">-m 1 </span><br></pre></td></tr></table></figure>

<h2 id="条件查询"><a href="#条件查询" class="headerlink" title="条件查询"></a>条件查询</h2><p>这里写的都是全量导入 hive。如果要增量，只能先导入到 hdfs，然后再做 merge</p>
<h3 id="–where"><a href="#–where" class="headerlink" title="–where"></a>–where</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/doit_mall \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--table oms_order \</span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table doit12.oms_order \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--compress   \</span><br><span class="line">--compression-codec gzip \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">-m 2   \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--<span class="built_in">where</span> <span class="string">&quot;delivery_company is null&quot;</span> \	<span class="comment"># filter condition</span></span><br><span class="line">--hive-overwrite</span><br></pre></td></tr></table></figure>

<h3 id="–query"><a href="#–query" class="headerlink" title="–query"></a>–query</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/doit_mall \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--target-dir  /tmp/query  \		<span class="comment"># sqoop 导入数据到 hive，本质就是先将数据导入到 hdfs，然后再去 hive 数据库创建元数据。这里需要手动指定中间临时目标目录（不太清楚为啥）</span></span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table doit12.oms_order \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--compress   \</span><br><span class="line">--compression-codec gzip \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--hive-overwrite \</span><br><span class="line">--query <span class="string">&quot;select id,member_id,order_sn,total_amount,pay_amount,status from oms_order where status=4 and \$CONDITIONS&quot;</span>  \			<span class="comment"># 查询语句，也支持复杂查询</span></span><br><span class="line">-m 2</span><br></pre></td></tr></table></figure>

<h1 id="运行-sqoop-action"><a href="#运行-sqoop-action" class="headerlink" title="运行 sqoop action"></a>运行 sqoop action</h1><p>在数据接入时，特别是连接数据库增量导入数据时，这种周期性任务的执行，有很多种方式：</p>
<ol>
<li>写一个 long running 脚本，不断执行增量 import</li>
<li><a href="https://www.cnblogs.com/xing901022/p/6091306.html">采用 Oozie 等调度工具来运行</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cherish</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Word count total">275k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">4:10</span>
  </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>
<script class="next-config" data-name="chatra" type="application/json">{"enable":true,"async":true,"id":null}</script>
<script src="/js/third-party/chat/chatra.js"></script>
<script async src="https://call.chatra.io/chatra.js"></script>






  





</body>
</html>
