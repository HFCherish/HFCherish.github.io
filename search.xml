<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>nginx 502 vs 504</title>
    <url>/2020/04/27/502-vs-504/</url>
    <content><![CDATA[<p><a href="https://juejin.im/post/5b54635ae51d451951133d85">nginx 502 和 504 超时演示</a></p>
<blockquote>
<p>502 Bad Gateway: The server was acting as a <a href="https://www.wikiwand.com/en/Gateway_(telecommunications)">gateway</a> or proxy and received an invalid response from the upstream server.</p>
<p>504: he server was acting as a gateway or proxy and did not receive a timely response from the upstream server.</p>
</blockquote>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p><strong>504 是 nginx 没有及时从上游服务获取响应，超时了：</strong></p>
<ul>
<li>上游服务响应慢，读取 response &#x2F; 发送 request 超时（<code>upstream timed out (110: Operation timed out) **while** reading response header from upstream</code>）<ul>
<li>某些请求处理就是慢。此时就应该调大 <a href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_read_timeout"><strong>proxy_read_timeout</strong></a> (默认 60s)</li>
<li>上游服务压力太大，响应变慢。此时可以增加上游服务的响应能力，也可以适当提升 <a href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_send_timeout"><strong>proxy_send_timeout</strong></a>, <a href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_read_timeout"><strong>proxy_read_timeout</strong></a></li>
</ul>
</li>
<li>连接上游服务超时。可能是上游服务已经断了，但由于 keepalive，nginx 依然保有 tcp 连接，但实际操作时，却连不上，就超时了。</li>
</ul>
<p><strong>502 是一般是上游服务器故障导致的</strong>。比如停机，进程被杀死，上游服务 reset 了连接，进程僵死等各种原因。在 nginx 的日志中我们能够发现 502 错误的具体原因，分别为：<code>104: Connection reset by peer</code>，<code>113: Host is unreachable</code>，<code>111: Connection refused</code></p>
]]></content>
  </entry>
  <entry>
    <title>Cache Memory</title>
    <url>/2020/06/28/Cache-Memory/</url>
    <content><![CDATA[<h1 id="General-Concept"><a href="#General-Concept" class="headerlink" title="General Concept"></a>General Concept</h1><p><img src="/images/cache-memory-simple.003.jpeg" alt="cache-memory-simple.003"></p>
<p><img src="/images/cache-memory-simple.004.jpeg" alt="cache-memory-simple.004"></p>
<p><img src="/images/cache-memory-simple.005.jpeg" alt="cache-memory-simple.005"></p>
<p><img src="/images/cache-memory-simple.006.jpeg" alt="cache-memory-simple.006"></p>
<h1 id="CPU-Core-Caching"><a href="#CPU-Core-Caching" class="headerlink" title="CPU Core Caching"></a>CPU Core Caching</h1><p><img src="/images/cache-memory-simple.008.jpeg" alt="cache-memory-simple.008"></p>
<p><img src="/images/cache-memory-simple.009.jpeg" alt="cache-memory-simple.009"></p>
<p><img src="/images/cache-memory-simple.010.jpeg" alt="cache-memory-simple.010"></p>
<p><img src="/images/cache-memory-simple.011.jpeg" alt="cache-memory-simple.011"></p>
<p><img src="/images/cache-memory-simple.012.jpeg" alt="cache-memory-simple.012"></p>
<p><img src="/images/cache-memory-simple.013.jpeg" alt="cache-memory-simple.013"></p>
<h1 id="Cache-Lines"><a href="#Cache-Lines" class="headerlink" title="Cache Lines"></a>Cache Lines</h1><p><img src="/images/cache-memory-simple.015.jpeg" alt="cache-memory-simple.015"></p>
<p><img src="/images/cache-memory-simple.016.jpeg" alt="cache-memory-simple.016"></p>
<h1 id="Cache-Memory"><a href="#Cache-Memory" class="headerlink" title="Cache Memory"></a>Cache Memory</h1><h2 id="Associative-Memory"><a href="#Associative-Memory" class="headerlink" title="Associative Memory"></a>Associative Memory</h2><p><img src="/images/cache-memory-simple.019.jpeg" alt="cache-memory-simple.019"></p>
<p><img src="/images/cache-memory-simple.020.jpeg" alt="cache-memory-simple.020"></p>
<p><img src="/images/cache-memory-simple.021.jpeg" alt="cache-memory-simple.021"></p>
<p><img src="/images/cache-memory-simple.022.jpeg" alt="cache-memory-simple.022"></p>
<h2 id="Direct-Mapped-Memory"><a href="#Direct-Mapped-Memory" class="headerlink" title="Direct-Mapped Memory"></a>Direct-Mapped Memory</h2><p><img src="/images/cache-memory-simple.024.jpeg" alt="cache-memory-simple.024"></p>
<p><img src="/images/cache-memory-simple.025.jpeg" alt="cache-memory-simple.025"></p>
<p><img src="/images/cache-memory-simple.026.jpeg" alt="cache-memory-simple.026"></p>
<p><img src="/images/cache-memory-simple.027.jpeg" alt="cache-memory-simple.027"></p>
<h2 id="Set-Associative-Memory"><a href="#Set-Associative-Memory" class="headerlink" title="Set Associative Memory"></a>Set Associative Memory</h2><p><img src="/images/cache-memory-simple.029.jpeg" alt="cache-memory-simple.029"></p>
<p><img src="/images/cache-memory-simple.030.jpeg" alt="cache-memory-simple.030"></p>
<p><img src="/images/cache-memory-simple.031.jpeg" alt="cache-memory-simple.031"></p>
<h1 id="Cache-Read-x2F-Write-Policies"><a href="#Cache-Read-x2F-Write-Policies" class="headerlink" title="Cache Read&#x2F;Write Policies"></a>Cache Read&#x2F;Write Policies</h1><p><img src="/images/cache-memory-simple.033.jpeg" alt="cache-memory-simple.033"></p>
<p><img src="/images/cache-memory-simple.034.jpeg" alt="cache-memory-simple.034"></p>
<p><img src="/images/cache-memory-simple.035.jpeg" alt="cache-memory-simple.035"></p>
<p><img src="/images/cache-memory-simple.036.jpeg" alt="cache-memory-simple.036"></p>
<p><a href="https://www.infoq.cn/article/cache-coherency-primer">cache coherency</a></p>
<p>MESI protocol: (Modified, Exclusive, Shared, Invalid)</p>
<blockquote>
<ul>
<li><strong>I</strong>nvalid lines are cache lines that are either not present in the cache, or whose contents are known to be stale. For the purposes of caching, these are ignored. Once a cache line is invalidated, it’s as if it wasn’t in the cache in the first place.</li>
<li><strong>S</strong>hared lines are clean copies of the contents of main memory. Cache lines in the shared state can be used to serve reads but they can’t be written to. Multiple caches are allowed to have a copy of the same memory location in “shared” state at the same time, hence the name.</li>
<li><strong>E</strong>xclusive lines are also clean copies of the contents of main memory, just like the S state. The difference is that when one core holds a line in E state, no other core may hold it at the same time, hence “exclusive”. That is, the same line must be in the I state in the caches of all other cores.</li>
<li><strong>M</strong>odified lines are dirty; they have been locally modified. If a line is in the M state, it must be in the I state for all other cores, same as E. In addition, modified cache lines need to be written back to memory when they get evicted or invalidated – same as the regular dirty state in a write-back cache.</li>
</ul>
</blockquote>
<h1 id="Principle-Of-Locality"><a href="#Principle-Of-Locality" class="headerlink" title="Principle Of Locality"></a>Principle Of Locality</h1><p><img src="/images/cache-memory-simple.038.jpeg" alt="cache-memory-simple.038"></p>
<p><img src="/images/cache-memory-simple.039.jpeg" alt="cache-memory-simple.039"></p>
<p><img src="/images/cache-memory-simple.040.jpeg" alt="cache-memory-simple.040"></p>
<p><img src="/images/cache-memory-simple.041.jpeg" alt="cache-memory-simple.041"></p>
<p><img src="/images/cache-memory-simple.042.jpeg" alt="cache-memory-simple.042"></p>
<p><img src="/images/cache-memory-simple.043.jpeg" alt="cache-memory-simple.043"></p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p><img src="/images/cache-memory-simple.045.jpeg" alt="cache-memory-simple.045"></p>
]]></content>
      <tags>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title>Cache - MicroService</title>
    <url>/2020/06/03/Cache-MicroService/</url>
    <content><![CDATA[<h1 id="Where-is-my-cache-for-a-service"><a href="#Where-is-my-cache-for-a-service" class="headerlink" title="Where is my cache for a service"></a>Where is my cache for a service</h1><p>[Architectural Patterns for Caching Microservices](Architectural Patterns for Caching Microservices)</p>
<p>Patterns:</p>
<ol>
<li><strong>embedded</strong>: save cache in the service</li>
<li><strong>client-server</strong>: a completely separate cache server</li>
<li><strong>reverse-proxy</strong>: put the cache in front of each service</li>
<li><strong>Sidecar</strong>: put the cache as a sidecar container that belongs to the service</li>
</ol>
<p>How does cache work? The application receives the request and checks if <strong>the same request</strong> was already executed (and stored in the cache)</p>
<h2 id="Embedded"><a href="#Embedded" class="headerlink" title="Embedded"></a>Embedded</h2><p><strong>Embedded Distributed Cache</strong></p>
<p>Why distributed?</p>
<ol>
<li>Same requests happen on different instances, and we want to use cache on the second same request no matter whether they reached the same instance.</li>
<li>An update request reached one instance, and we want all the cache of this resource on all instances should be updated.</li>
</ol>
<h2 id="Client-Server"><a href="#Client-Server" class="headerlink" title="Client-Server"></a>Client-Server</h2><p>pros:</p>
<ul>
<li>sperarate server, so you can use any programming language you want</li>
<li>separate management. you can scale up&#x2F;down, do backup, design security separatly on need.</li>
</ul>
<p>cons:</p>
<ul>
<li>a new deployment &amp; related ops work (cloud can make this simple)</li>
</ul>
<h2 id="Sidecar"><a href="#Sidecar" class="headerlink" title="Sidecar"></a>Sidecar</h2><p>A mixture of Embedded &amp; client-server. (<a href="https://hazelcast.com/blog/hazelcast-sidecar-container-pattern/">sidecar container pattern</a>)</p>
<p>Take k8s as example (now most of the sidecar pattern is implemented on k8s, becaused it supports this pattern inborn), we put the cache server with the service as separate containers on the same pod. The request reach the service container first, and then the service can access the cache server by <code>localhost</code> .</p>
<blockquote>
<p>The <a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/sidecar">sidecar pattern</a> is a technique of attaching an additional container to the main parent container so that both would share the same lifecycle and the same resources. You may think of it as a perfect tool for decomposing your application into reusable modules, in which each part is written in a different technology or programming language.</p>
</blockquote>
<h2 id="Reverse-proxy"><a href="#Reverse-proxy" class="headerlink" title="Reverse proxy"></a>Reverse proxy</h2><ol>
<li>Everytime you try to access the servcie, you go to the reverse proxy (e.g. nginx). </li>
<li>And the proxy will first check the cache for the request. If cache exists, return immediately, else, forward to the service and write the cache.</li>
</ol>
<p>pros: </p>
<ul>
<li>In this way, the service has no idea about the cache, so nothing will change on the service when cache introduced.</li>
</ul>
<p>cons:</p>
<ul>
<li>cannot use any application-based code to invalidate the cache.</li>
</ul>
<p>Also, you can put the reverse proxy into the side-car, that is, <strong>reverse-proxy-sidecar</strong> pattern.</p>
<p>Now, there is no mature <strong>HTTP Reverse Proxy Cache Sidecar</strong> solution at all. Nginx can do it, but it’s not a good choice since it’s not mature.</p>
<h1 id="Caching-Practices"><a href="#Caching-Practices" class="headerlink" title="Caching Practices"></a>Caching Practices</h1><ul>
<li>Always use caching in one place for a service. Mutliple caches will make the cache invalication and error-prone difficult.</li>
</ul>
]]></content>
      <tags>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title>MPP (Massively Parallel Processing)</title>
    <url>/2020/11/10/MPP/</url>
    <content><![CDATA[<h1 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h1><p><a href="https://zhuanlan.zhihu.com/p/148621151">5分钟了解MPP数据库</a></p>
<p>MPP (Massively Parallel Processing)，即大规模并行处理。简单来说，MPP是将任务并行的分散到多个服务器和节点上，在每个节点上计算完成后，将各自部分的结果汇总在一起得到最终的结果(与Hadoop相似，但主要针对大规模关系型数据的分析计算)。</p>
<h2 id="MPP架构特征"><a href="#MPP架构特征" class="headerlink" title="MPP架构特征"></a>MPP架构特征</h2><ul>
<li>任务并行执行;</li>
<li>数据分布式存储(本地化);</li>
<li>分布式计算;</li>
<li>私有资源;</li>
<li>横向扩展;</li>
<li><a href="#share-nothing">Shared Nothing</a>架构。</li>
</ul>
<h1 id="MPPDB-v-s-Hadoop"><a href="#MPPDB-v-s-Hadoop" class="headerlink" title="MPPDB v.s. Hadoop"></a>MPPDB v.s. Hadoop</h1><p><a href="https://www.zhihu.com/question/22799482/answer/81615602">知乎-为什么说HADOOP扩展性优于MPP架构的关系型数据库？</a></p>
<p>hadoop 和 MPPDB <strong>最大的区别在于：对数据管理理念的不同。</strong> </p>
<ol>
<li>HDFS&#x2F;Hadoop 对于数据管理是<strong>粗放型管理</strong>，以一个文件系统的模式，让用户根据文件夹层级，把文件直接塞到池子里。处理也<strong>以批处理为主，就是拼命 scan</strong>。如果想在一大堆数据里找符合条件的数据，hadoop 就是粗暴的把所有文件从头到尾 scan 一遍，因为对于这些文件他没有索引、分类等，他管的少，知道的也少，用的时候每次就要全 scan。</li>
<li>数据库的本质在于数据管理，对外提供在线访问、增删改查等一系列操作。数据库的<strong>内存管理比较精细</strong>，有一套很完善的数据管理和分布体系。如果想在一大堆数据里找符合条件的数据，他可以根据分区信息先落到某个机器，再根据多维分区落到某个文件，再在文件里通过索引数据页的树形结构查询，可以直接定位到记录。</li>
<li>因为这样的基本理念不同，使得 hadoop 的扩展只需要简单的增加机器，内部平衡和迁移 data block；而数据库的扩充则涉及到数据拓扑结构的变更、或者不同机器间数据的迁移，当变化迁移的时候，依然需要维护分区、索引等，这种复杂度就比粗放的 HDFS 要高很多了。目前两者的存储模型不同。hadoop 用的是 HDFS，而 MPP 需要自己切分扩展。HDFS 扩展是通过元数据做的，name node 存元数据，增加一个节点，修改元数据就行，所以 HDFS 的扩展能力受到管理元数据的机器（name node） 的性能限制，一般来说可以到 10k 的规模。但 MPP 采用没有中心节点的存储模型，比如 hash，每次增加节点，都需要 rehash，规模增加到几百台的时候，扩展能力就有下降下来了。</li>
</ol>
<p>通常来讲，MPP数据库有对SQL的完整兼容和一些事务的处理能力，Hadoop在处理非结构化和半结构化数据上具备优势，所以MPP适合多维度数据自助分析、数据集市等；Hadoop适合海量数据存储查询、批量数据ETL、非结构化数据分析(日志分析、文本分析)等海量<strong>数据批处理</strong>应用要求。但通过 sql 还是 map-reduce 来查，其实只是一种查询形式。目前也有很多 sql on hadoop 的方案，例如 impala （sql on hadoop，其实是一个 MPP engine，所以它的查询性能会更好，提供更低的延迟和更少的处理时间）、spark Sql 等。现在Spark的重点都在Spark SQL，因为它已经不仅仅是SQL了，而是新的 “spark core”。（详见最后链接中Reynold Xin对此的解释）</p>
<blockquote>
<p>Spark SQL is not just about SQL. It turns out the primitives required for general data processing (eg ETL) are not that different from the relational operators, and that is what Spark SQL is. Spark SQL is the new Spark core with the Catalyst optimizer and the Tungsten execution engine, which powers the DataFrame, Dataset, and last but not least SQL.</p>
</blockquote>
<p><img src="https://pic2.zhimg.com/80/v2-2195887a063e35952ffb9c94d3e18755_720w.jpg" alt="img"></p>
<h1 id="常用的MPP数据库有哪些"><a href="#常用的MPP数据库有哪些" class="headerlink" title="常用的MPP数据库有哪些"></a>常用的MPP数据库有哪些</h1><ul>
<li>自我管理的数据仓库<ul>
<li>HPE vertica</li>
<li>MemSql</li>
<li>Teradata</li>
</ul>
</li>
<li>按需 MPP 数据库<ul>
<li>aws redshift</li>
<li>azure sql 数据仓库</li>
<li>google bigQuery</li>
</ul>
</li>
<li><strong>GreenPlum</strong></li>
<li>Sybase IQ</li>
<li>TD Aster Data</li>
</ul>
<h1 id="Share-Nothing"><a href="#Share-Nothing" class="headerlink" title="Share Nothing"></a>Share Nothing<a name="share-nothing" /></h1><p><a href="https://www.cnblogs.com/kzwrcom/p/6397709.html">数据库架构设计的三种模式：share nothing , share everythong , share disk</a></p>
<p>数据库构架设计中主要有Shared Everthting、Shared Nothing、和Shared Disk：</p>
<ol>
<li><p>Shared Everthting:一般是针对单个主机，完全透明共享CPU&#x2F;MEMORY&#x2F;IO，并行处理能力是最差的，典型的代表SQLServer</p>
</li>
<li><p>Shared Disk：各个处理单元使用自己的私有 CPU和Memory，共享磁盘系统。典型的代表Oracle Rac， 它是数据共享，可通过增加节点来提高并行处理的能力，扩展能力较好。其类似于SMP（对称多处理）模式，但是当存储器接口达到饱和的时候，增加节点并不能获得更高的性能 。</p>
</li>
<li><p>Shared Nothing：各个处理单元都有自己私有的CPU&#x2F;内存&#x2F;硬盘等，不存在共享资源，类似于MPP（大规模并行处理）模式，各处理单元之间通过协议通信，并行处理和扩展能力更好。典型代表DB2 DPF和Hadoop ，各节点相互独立，各自处理自己的数据，处理后的结果可能向上层汇总或在节点间流转。<br>我们常说的 Sharding 其实就是Share Nothing架构，它是把某个表从物理存储上被水平分割，并分配给多台服务器（或多个实例），每台服务器可以独立工作，具备共同的schema，比如MySQL Proxy和Google的各种架构，只需增加服务器数就可以增加处理能力和容量。</p>
</li>
</ol>
<h1 id="GreenPlum"><a href="#GreenPlum" class="headerlink" title="GreenPlum"></a>GreenPlum</h1><p><a href="https://gpdb.docs.pivotal.io/5280/admin_guide/intro/arch_overview.html#arch_segments">greenplum</a></p>
]]></content>
      <tags>
        <tag>big data</tag>
      </tags>
  </entry>
  <entry>
    <title>FluentValidator</title>
    <url>/2020/01/17/FluentValidator/</url>
    <content><![CDATA[<p><a href="https://fluentvalidation.net/start#setting-the-cascade-mode">FluentValidation</a></p>
<h1 id="Knowledge"><a href="#Knowledge" class="headerlink" title="Knowledge"></a>Knowledge</h1><ul>
<li>The <code>RuleFor</code> method create a validation rule.</li>
</ul>
<blockquote>
<p>To specify a validation rule for a particular property, call the <code>RuleFor</code> method, passing a lambda expression that indicates the property that you wish to validate. </p>
</blockquote>
<ul>
<li>Rules are run syncronously</li>
</ul>
<blockquote>
<p>By default, all rules in FluentValidation are separate and cannot influence one another. This is intentional and necessary for asynchronous validation to work.</p>
</blockquote>
<ul>
<li><code>Must</code>, <code>NotNull</code>…. are <a href="https://fluentvalidation.net/built-in-validators">built-in validators</a>. <code>WithMessage</code> is a method on a validator. <code>When</code> defines condition for validator(s).</li>
<li>Append multiple validators on a same property are called chaining validators.</li>
<li>Chainning Validators are executed by sequence. <code>CascadeMode</code> can define how these chaining validators are exectued. <code>Continue</code> is default which means even a validator fail, the latter validators will still be invoked. <code>StopOnFirstFailure</code> will stop at the first failure of these chaining validators.</li>
<li><code>When</code> defines condition for validator(s)&#x2F;rules. <code>ApplyConditionTo.AllValidators</code> is the default setting. <code>ApplyConditionTo.CurrentValidator</code>  will make the condition only work to the preceding validator.</li>
</ul>
<blockquote>
<p>By default FluentValidation will apply the condition to all preceding validators in the same call to <code>RuleFor</code></p>
</blockquote>
]]></content>
      <tags>
        <tag>DTO validator</tag>
      </tags>
  </entry>
  <entry>
    <title>MSSQL: multiple cascade paths</title>
    <url>/2020/05/27/MSSQL-multiple-cascade-paths/</url>
    <content><![CDATA[<h1 id="Symptoms"><a href="#Symptoms" class="headerlink" title="Symptoms"></a>Symptoms</h1><p>You may receive the following error message when you create a FOREIGN KEY constraint: (<a href="https://support.microsoft.com/en-us/help/321843/error-message-1785-occurs-when-you-create-a-foreign-key-constraint-tha">microsoft report</a>)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Server: Msg 1785, Level 16, State 1, Line 1 Introducing FOREIGN KEY constraint &#x27;fk_two&#x27; on table &#x27;table2&#x27; may cause cycles or multiple cascade paths. Specify ON DELETE NO ACTION or ON UPDATE NO ACTION, or modify other FOREIGN KEY constraints. Server: Msg 1750, Level 16, State 1, Line 1 Could not create constraint. See previous errors.</span><br></pre></td></tr></table></figure>

<p>For example, the table definition is like this:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">Table t1:</span></span><br><span class="line">    <span class="attr">Id:</span> <span class="string">primaryKey</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Table t2:</span></span><br><span class="line">    <span class="attr">Id:</span> <span class="string">primaryKey</span></span><br><span class="line">    <span class="attr">parent:</span> <span class="string">ForeignKey(t1,</span> <span class="string">Id)</span> <span class="string">on</span> <span class="string">cascade</span> <span class="string">delete</span></span><br><span class="line">    <span class="attr">child:</span> <span class="string">ForeignKey(t1,</span> <span class="string">Id)</span> <span class="string">on</span> <span class="string">cascade</span> <span class="string">delete</span></span><br><span class="line"><span class="comment"># this would raise the above exception</span></span><br></pre></td></tr></table></figure>

<h1 id="Cause"><a href="#Cause" class="headerlink" title="Cause"></a>Cause</h1><p>Basically, you can’t create multiple cascade paths to same table with cascade delete&#x2F;update. Since you may define <code>t2.parent</code> with cascade delete, <code>t2.child</code> with cascade update(e.g. update as null), this will make sql server ambiguous when t1 is deleted. MSSQL doesn’t detect whether there’re actual circle or not, it just forbids the operation to make the design simple.</p>
<blockquote>
<p>A table cannot appear more than one time in a list of all the cascading referential actions that are started by either a DELETE or an UPDATE statement. For example, the tree of cascading referential actions must only have one path to a particular table on the cascading referential actions tree.</p>
</blockquote>
<p><a href="https://stackoverflow.com/questions/851625/foreign-key-constraint-may-cause-cycles-or-multiple-cascade-paths">stackoverflow</a></p>
<blockquote>
<p>SQL Server does simple counting of cascade paths and, rather than trying to work out whether any cycles actually exist, it assumes the worst and refuses to create the referential actions (CASCADE): you can and should still create the constraints without the referential actions. If you can’t alter your design (or doing so would compromise things) then you should consider using triggers as a last resort.</p>
<p>FWIW resolving cascade paths is a complex problem. Other SQL products will simply ignore the problem and allow you to create cycles, in which case it will be a race to see which will overwrite the value last, probably to the ignorance of the designer (e.g. ACE&#x2F;Jet does this). I understand some SQL products will attempt to resolve simple cases. Fact remains, SQL Server doesn’t even try, plays it ultra safe by disallowing more than one path and at least it tells you so.<br>Microsoft themselves <a href="https://support.microsoft.com/en-us/help/321843/error-message-1785-occurs-when-you-create-a-foreign-key-constraint-tha">advises</a> the use of triggers instead of FK constraints.</p>
</blockquote>
<h1 id="Workaround"><a href="#Workaround" class="headerlink" title="Workaround"></a>Workaround</h1><p>Use trigger instead of ForeignKey to keep the integrity and avoid the exceptions.</p>
<ol>
<li>Set cascade delete on t2.child</li>
<li>Use <code>instead of</code> trigger to cascade delete on t2.parent (you can also use trigger for all fields instead of foreign key constraints)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TRIGGER [DELETE_t2]</span><br><span class="line">   ON dbo.[t1]</span><br><span class="line">   INSTEAD OF DELETE</span><br><span class="line">AS </span><br><span class="line">BEGIN</span><br><span class="line"> SET NOCOUNT ON;</span><br><span class="line"> DELETE FROM [t2] WHERE parent IN (SELECT Id FROM DELETED)</span><br><span class="line"> DELETE FROM [t1] WHERE Id IN (SELECT Id FROM DELETED)</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title>NHibernate: inverse, cascade</title>
    <url>/2020/05/25/NHibernate-inverse-cascade/</url>
    <content><![CDATA[<p><a href="https://dzone.com/articles/playing-nhibernate-inverse-and">playing-nhibernate-inverse-and-cascade</a>,</p>
<p><a href="https://web.archive.org/web/20080415101633/http://simoes.org/docs/hibernate-2.1/155.html">nhibernate-inverse</a></p>
<p><a href="https://nhibernate.info/doc/nhibernate-reference/collections.html#collections-bidirectional">bidirectional associations</a></p>
<p>In database, there may be biodirectional relationships, e.g. Parent has multiple child, and Child has a parent. </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#### class definition</span></span><br><span class="line"><span class="attr">class Parent:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">String</span> <span class="string">id</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">IList&lt;Child&gt;</span> <span class="string">childs</span>    </span><br><span class="line"><span class="attr">class Child:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">String</span> <span class="string">id</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">Parent</span> <span class="string">parent</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### db definition</span></span><br><span class="line"><span class="attr">table Parent:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">id</span></span><br><span class="line"><span class="attr">table Child:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">id</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">parentId</span></span><br></pre></td></tr></table></figure>

<h2 id="Inverse"><a href="#Inverse" class="headerlink" title="Inverse"></a>Inverse</h2><p><code>Inverse</code> focus on the association. It defines which side is responsible of the association maintenance (create, update, delete), that is, the assignment of <code>parentId</code> column. It doesn’t care about the maintenance of associated objects which is what <code>cascade</code> cares).</p>
<p>By default, <code>invert=false</code>, then the assignment of <code>parentId</code> is maintened when parent is created&#x2F;updated&#x2F;deleted. If we set <code>parent.child.inverse=true</code> and the <code>child.parent is not-null</code>, then the assignment of <code>parentId</code> is maintened when child is created&#x2F;updated&#x2F;deleted. </p>
<blockquote>
<p><code>many-to-one</code> is <strong>always</strong> <code>inverse=&quot;false&quot;</code> (the attribute does not exist), that is, it means nothing to set <code>child.parent.inverse=true</code></p>
</blockquote>
<h2 id="Cascade"><a href="#Cascade" class="headerlink" title="Cascade"></a>Cascade</h2><p><code>cascade</code> instead will focus on the associated objects. It defines if the current object is responsible of the maintenance of associated objects.</p>
<p>By default, <code>cascade=None</code>, that is, when saving parent, the childs on parent won’t be saved cascadelly.</p>
<p>See <a href="https://stackoverflow.com/questions/1994433/nhibernate-cascade">cascade stackoverflow</a></p>
<blockquote>
<ul>
<li>none - do not do any cascades, let users handle them by themselves.</li>
<li>save-update - when the object is saved&#x2F;updated, check the associations and save&#x2F;update any object that requires it (including save&#x2F;update the associations in many-to-many scenario).</li>
<li>delete - when the object is deleted, delete all the objects in the association.</li>
<li>delete-orphan - when the object is deleted, delete all the objects in the association. In addition, when an object is removed from the association and not associated with another object (orphaned), also delete it.</li>
<li>all - when an object is save&#x2F;update&#x2F;delete, check the associations and save&#x2F;update&#x2F;delete all the objects found.</li>
<li>all-delete-orphan - when an object is save&#x2F;update&#x2F;delete, check the associations and save&#x2F;update&#x2F;delete all the objects found. In additional to that, when an object is removed from the association and not associated with another object (orphaned), also delete it.</li>
</ul>
</blockquote>
]]></content>
      <tags>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title>VPN</title>
    <url>/2020/05/06/VPN/</url>
    <content><![CDATA[<p><a href="https://www.youtube.com/watch?v=q4P4BjjXghQ">the great video</a></p>
<h1 id="History"><a href="#History" class="headerlink" title="History"></a>History</h1><h2 id="Why-does-we-create-internet"><a href="#Why-does-we-create-internet" class="headerlink" title="Why does we create internet?"></a>Why does we create internet?</h2><p>It’s created from the need of American military, to protect the communication in the wars. </p>
<p>The old communication system, phone, connects Lily with Tom through fixed central offices. If some of the central offices are destroyed by nuclear, then the rerouting of the communication line is difficult, that the commnunication will fail.</p>
<p>Ta Da.. Internet comes. It communicates through millions of routers. Even half of the routers are destroyed, there may still be the way to communicate.</p>
<h2 id="Why-does-we-create-VPN-virtual-private-network"><a href="#Why-does-we-create-VPN-virtual-private-network" class="headerlink" title="Why does we create VPN (virtual private network)?"></a>Why does we create VPN (virtual private network)?</h2><p>Internet way secure the communication from high level, however, the data from a computer are in danger now. If a hacker can get all the data from a router, then data of users are leaked since it will go through the router.</p>
<p>To protect the communication from one to another, you can build physical private line. However, it’s too expensive, and <a href="https://en.wikipedia.org/wiki/Virtual_private_network">VPN</a> provides another way. The VPN secure the data in the following ways:</p>
<ol>
<li>creates tunnel between two communicators, </li>
<li>the data in the tunnel is encrepted</li>
<li>if the tunnel detects attack, it will destroy the old tunnel &amp; create a new one.</li>
</ol>
<p>Client-Server infrastructure. We need to know:</p>
<ol>
<li><p>external address (the address of vpn server)</p>
</li>
<li><p>username &amp; password</p>
</li>
</ol>
<p>These factors may influence the VPN quality:</p>
<ol>
<li><p>hacker penetrate. (like said above, during the rebuilt of tunnel, packets maybe lost)</p>
</li>
<li><p>old wiring, which will cause frequent tunnel rebuilt, too</p>
</li>
<li><p>old routers that not allow vpn passing through</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>airflow</title>
    <url>/2020/12/18/airflow/</url>
    <content><![CDATA[<h1 id="install"><a href="#install" class="headerlink" title="install"></a>install</h1><p><a href="https://airflow.apache.org/docs/apache-airflow/stable/start.html">quickstart</a></p>
<blockquote>
<p>Airflow is published as <code>apache-airflow</code> package in PyPI. Installing it however might be sometimes tricky because Airflow is a bit of both a library and application. Libraries usually keep their dependencies open and applications usually pin them, but we should do neither and both at the same time. We decided to keep our dependencies as open as possible (in <code>setup.cfg</code> and <code>setup.py</code>) so users can install different version of libraries if needed. This means that from time to time plain <code>pip install apache-airflow</code> will not work or will produce unusable Airflow installation.</p>
<p>In order to have repeatable installation, however, starting from <strong>Airflow 1.10.10</strong> and updated in <strong>Airflow 1.10.13</strong> we also keep a set of “known-to-be-working” constraint files in the <code>constraints-master</code> and <code>constraints-1-10</code> orphan branches. Those “known-to-be-working” constraints are per major&#x2F;minor python version. You can use them as constraint files when installing Airflow from PyPI. Note that you have to specify correct Airflow version and python versions in the URL.</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">pip3 install --use-deprecated legacy-resolver <span class="string">&quot;apache-airflow==1.10.14&quot;</span> --constraint <span class="string">&quot;https://raw.githubusercontent.com/apache/airflow/constraints-1.10.14/constraints-3.8.txt&quot;</span> </span><br><span class="line"></span><br><span class="line">pip3 install <span class="string">&quot;apache-airflow==1.10.14&quot;</span> --constraint <span class="string">&quot;https://raw.githubusercontent.com/apache/airflow/constraints-1.10.14/constraints-3.8.txt&quot;</span> </span><br></pre></td></tr></table></figure>

<blockquote>
<p>On November 2020, new version of PIP (20.3) has been released with a new, 2020 resolver. This resolver does not yet work with Apache Airflow and might leads to errors in installation - depends on your choice of extras. In order to install Airflow you need to either downgrade pip to version 20.2.4 <code>pip upgrade --pip==20.2.4</code> or, in case you use Pip 20.3, you need to add option <code>--use-deprecated legacy-resolver</code> to your pip install command.</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># airflow needs a home, ~/airflow is the default,</span></span><br><span class="line"><span class="comment"># but you can lay foundation somewhere else if you prefer</span></span><br><span class="line"><span class="comment"># (optional)</span></span><br><span class="line"><span class="built_in">export</span> AIRFLOW_HOME=~/airflow</span><br><span class="line"></span><br><span class="line"><span class="comment"># install from pypi using pip</span></span><br><span class="line">pip install apache-airflow</span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize the database</span></span><br><span class="line">airflow db init</span><br><span class="line"></span><br><span class="line">airflow <span class="built_in">users</span> create \</span><br><span class="line">    --username admin \</span><br><span class="line">    --firstname petrina \</span><br><span class="line">    --lastname zheng \</span><br><span class="line">    --role Admin \</span><br><span class="line">    --email spiderman@superhero.org</span><br><span class="line"></span><br><span class="line"><span class="comment"># start the web server, default port is 8080</span></span><br><span class="line">airflow webserver --port 8080</span><br><span class="line"></span><br><span class="line"><span class="comment"># start the scheduler</span></span><br><span class="line"><span class="comment"># open a new terminal or else run webserver with ``-D`` option to run it as a daemon</span></span><br><span class="line">airflow scheduler</span><br><span class="line"></span><br><span class="line"><span class="comment"># visit localhost:8080 in the browser and use the admin account you just</span></span><br><span class="line"><span class="comment"># created to login. Enable the example_bash_operator dag in the home page</span></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>big data</tag>
        <tag>schedule</tag>
      </tags>
  </entry>
  <entry>
    <title>azure storage</title>
    <url>/2018/07/27/asure-storage/</url>
    <content><![CDATA[<p>asure storage 提供四种存储支持（<a href="https://www.youtube.com/watch?v=y6bIUHtdp6Y">asure storage overview (youtube)</a>）：</p>
<ul>
<li><a href="https://azure.microsoft.com/zh-cn/services/storage/blobs/">blob</a> (binary large object)：二进制数据存储。有两种：page blog（只能新增&#x2F;删除&#x2F;向已有数据附加数据，不能修改数据）；block blog（可以更新）</li>
<li><a href="https://azure.microsoft.com/zh-cn/services/storage/tables/">table</a>：存储表格（nosql）</li>
<li><a href="https://azure.microsoft.com/zh-cn/services/storage/queues/">queue</a>：有库，有 rest api</li>
<li><a href="https://azure.microsoft.com/en-us/services/storage/files/">files</a>：好像主要用在文件共享的时候，就是类似于 windows server 上的文件共享（<a href="https://zh.wikipedia.org/wiki/%E4%BC%BA%E6%9C%8D%E5%99%A8%E8%A8%8A%E6%81%AF%E5%8D%80%E5%A1%8A">smb(server message block)</a>），实现和使用方式都和 windows server 的文件共享一样。所以需要支持例如按 &#x2F;servername&#x2F;filename 等方式来 share 和 使用文件。它是构建于 blob 之上的。</li>
</ul>
<h1 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h1><h2 id="Storage-Accout"><a href="#Storage-Accout" class="headerlink" title="Storage Accout"></a>Storage Accout</h2><p>storage 的所有存储都必须在一个 storage account 内发生。这有点类似于一个 database。</p>
<p>安全也是在这里实现：</p>
<ol>
<li><em><strong>key</strong></em>：创建 account 时，就会生成俩 key，primary key 就是你用来登录访问数据的 key。不过这种方式对于有 client 时不太方便，因为可能不能 share key</li>
<li><em><strong>saas token</strong></em>：就是可以登录认证获得 token，然后拿 token 访问数据。</li>
</ol>
<h2 id="数据容器-数据"><a href="#数据容器-数据" class="headerlink" title="数据容器 + 数据"></a>数据容器 + 数据</h2><p>在每个 storage account 里，你可以创建上述四种类型的存储容器，去存放数据。</p>
<ul>
<li>Blob： 在 storage account 里可以创建 <em><strong>blob container</strong></em>，在 <em><strong>blog container</strong></em> 中存放 <em><strong>blob</strong></em></li>
<li>table：在 storage account 里创建 <em><strong>table</strong></em>，在 <em><strong>table</strong></em> 中存放 <em><strong>data entity</strong></em></li>
<li>queue：在 storage account 里创建 <em><strong>queue</strong></em>，在 <em><strong>queue</strong></em> 中存放 <em><strong>message</strong></em></li>
<li>file：在 storage account 里创建 <em><strong>asure files</strong></em> (类似于 <a href="https://zh.wikipedia.org/wiki/%E4%BC%BA%E6%9C%8D%E5%99%A8%E8%A8%8A%E6%81%AF%E5%8D%80%E5%A1%8A">smb(server message block)</a>)??? 感觉应该也是先创建一个 files container，再创建一个个的 asure file（即 smb）</li>
</ul>
]]></content>
      <tags>
        <tag>cloud</tag>
        <tag>azure</tag>
      </tags>
  </entry>
  <entry>
    <title>atlas</title>
    <url>/2020/11/13/atlas/</url>
    <content><![CDATA[<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p><img src="http://atlas.apache.org/public/images/twiki/architecture.png" alt="img"></p>
<h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><p><a href="https://atlas.apache.org/2.0.0/InstallationSteps.html">install steps</a></p>
<p>Access Apache Atlas UI using a browser: <a href="http://localhost:21000/">http://localhost:21000</a> </p>
<p>You can also access the rest api <code>http://localhost:21000/api/atlas/v2</code></p>
<p>默认的用户名密码是 (admin, admin)</p>
<h1 id="Atlas-Features"><a href="#Atlas-Features" class="headerlink" title="Atlas Features"></a>Atlas Features</h1><h2 id="定义元模型，规范元数据"><a href="#定义元模型，规范元数据" class="headerlink" title="定义元模型，规范元数据"></a>定义元模型，规范元数据</h2><p>atlas 可以维护（增删改查） metadata types，支持</p>
<ul>
<li>创建多种类型的 metadata types<ul>
<li>businessmetadatadef：业务元数据的元模型</li>
<li>classificationdef：标签数据的元模型</li>
<li>entitydef：一般元数据的元模型</li>
<li>enumdef</li>
<li>relationshipdef：关系元数据的元模型</li>
<li>structdef</li>
</ul>
</li>
<li>元模型支持定义属性约束、索引、唯一性等</li>
<li>按 id&#x2F;typename&#x2F;query 来检索</li>
</ul>
<blockquote>
<p><a href="http://atlas.apache.org/api/v2/resource_TypesREST.html#resource_TypesREST_createAtlasTypeDefs_POST">相关 API 定义</a></p>
<p><a href="http://atlas.apache.org/api/v2/json_AtlasTypesDef.html">typedef request schema object</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># DELETE/GET/POST/PUT</span><br><span class="line">/v2/types/typedef</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h3><ul>
<li>typename 全局唯一</li>
</ul>
<h2 id="可以维护元数据"><a href="#可以维护元数据" class="headerlink" title="可以维护元数据"></a>可以维护元数据</h2><h3 id="import-metadata"><a href="#import-metadata" class="headerlink" title="import metadata"></a>import metadata</h3><p>atlas 提供以下途径将元数据引入系统：</p>
<ol>
<li>REST API：atlas 提供 api 可以 bulk saveOrUpdate 某个 type 的元数据</li>
<li>文件：atlas 可以上传文件，并 saveOrUpdate 文件中所定义的元模型、元数据等</li>
<li>atlas hook：atlas 通过监听 kafka topic <code>ATLAS_HOOK</code> ，来实时引入数据源中的元数据。目前已提供 Apache Hive&#x2F;Apache HBase&#x2F;Apache Storm&#x2F;Apache Sqoop 的 hook<ol>
<li>hive hook<ol>
<li>可以 import hive databases &amp; tables 元数据</li>
<li>可以监听以下类型的 hive 操作，capture 其中的元数据：<ol>
<li>create database</li>
<li>create table&#x2F;view, create table as select</li>
<li>load, import, export</li>
<li>DMLs (insert)</li>
<li>alter database</li>
<li>alter table (skewed table information, stored as, protection is not supported)</li>
<li>alter view</li>
</ol>
</li>
</ol>
</li>
<li>sqoop<ol>
<li>目前仅支持监听 sqoop 的 hiveimport operation 完成后，capture 其中的元数据。</li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="业务元数据"><a href="#业务元数据" class="headerlink" title="业务元数据"></a>业务元数据</h2><p>atlas 可以:</p>
<ol>
<li>定义业务元数据元模型规范业务元数据</li>
<li>在技术元数据上，添加业务元数据，来实现关联</li>
<li>支持按业务元数据检索</li>
</ol>
<h2 id="血缘"><a href="#血缘" class="headerlink" title="血缘"></a>血缘</h2><p>atlas 可以查询元数据血缘关系。应该是基于关系图实现。</p>
<p>目前 hive 表可以支撑到 column 级别的血缘分析。</p>
<h2 id="可以维护标签"><a href="#可以维护标签" class="headerlink" title="可以维护标签"></a>可以维护标签</h2><p>atlas 中的 classification 即标签，可以打在元数据、术语等地方。</p>
<p>可以基于 classification 检索元数据。</p>
<p>可以做 classification 的传播：</p>
<ul>
<li>基于继承关系链的传播</li>
<li>基于血缘关系链的传播</li>
</ul>
<h3 id="Classification-vs-label"><a href="#Classification-vs-label" class="headerlink" title="Classification vs label"></a>Classification vs label</h3><p>Atlas 中的 classification 和 label 都是标签的概念，label 是轻量级、谁都可以加的简单标签，classification 则有更多的支持。</p>
<p><a href="https://docs.cloudera.com/runtime/7.2.1/atlas-working-with-classifications/topics/atlas-working-with-classifications.html">atlas classification vs label</a></p>
<h2 id="可以维护企业术语表"><a href="#可以维护企业术语表" class="headerlink" title="可以维护企业术语表"></a>可以维护企业术语表</h2><p>atlas 可以维护企业的术语，并将术语与元数据关联，支持按术语检索元数据，通过以下三个概念来实现细粒度的术语管理：</p>
<ol>
<li>glossary：术语表，最高级别，所有的术语都必须属于某个术语表</li>
<li>category：术语分类，必须挂在某个 glossary。可以拥有 childCategories</li>
<li>term：术语。必须挂在某个 glossary。可以挂在某个 category</li>
</ol>
<h2 id="Notifications"><a href="#Notifications" class="headerlink" title="Notifications"></a>Notifications</h2><p>atlas 通过 kafka 实现 hook，引入元数据；也通过 kafka 广播元数据修改，供消费者使用。</p>
<ul>
<li><p>notifications to atlas：<code>ATLAS_HOOK</code>. 目前已提供 Apache Hive&#x2F;Apache HBase&#x2F;Apache Storm&#x2F;Apache Sqoop 的 hook，来监听这些数据源的元数据</p>
</li>
<li><p>notifications from atlas: <code>ATLAS_ENTITIES</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 监听并发布以下事件的通知</span><br><span class="line">ENTITY_CREATE:         sent when an entity instance is created</span><br><span class="line">ENTITY_UPDATE:         sent when an entity instance is updated</span><br><span class="line">ENTITY_DELETE:         sent when an entity instance is deleted</span><br><span class="line">CLASSIFICATION_ADD:    sent when classifications are added to an entity instance</span><br><span class="line">CLASSIFICATION_UPDATE: sent when classifications of an entity instance are updated</span><br><span class="line">CLASSIFICATION_DELETE: sent when classifications are removed from an entity instance</span><br><span class="line"></span><br><span class="line"># notification data</span><br><span class="line">AtlasEntity  entity;</span><br><span class="line">OperationType operationType;</span><br><span class="line">List&lt;AtlasClassification&gt;  classifications</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h2><p>atlas 所有的元数据存储在图数据库 JanusGraph，而索引数据则存储在 index store（solr &#x2F; elasticsearch）来做全文检索</p>
<p>atlas 支持以下检索方式：</p>
<ol>
<li>唯一定位元数据：通过 id</li>
<li>basic 检索：基于 type、attributes、classifciation、terms 等 query parameter 做全文检索</li>
<li>advance 检索：可以使用 dsl 语言做全文检索</li>
</ol>
<h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><ol>
<li>基础设施高可用。<ol>
<li>atlas 使用 JanusGraph 存储元数据，并将 HBase（默认，可采用其他数据库）作为 backing store。HBase 本身的高可用特性支撑了 metadata store 的高可用</li>
<li>atlas 使用 solr &#x2F; elasticsearch 存储元数据索引。这些组件同样支持高可用</li>
</ol>
</li>
<li>Web Service 高可用。<ol>
<li>目前 atlas 的 web service 同一时间只能有一个 active instance 响应，以实现元数据维护、缓存等的一致性问题。高可用模式即有多个备用（passive）instances，当 active instance down 后，可以自动切换某个 passive instance，作为新的 active instance。</li>
</ol>
</li>
</ol>
<h2 id="访问控制"><a href="#访问控制" class="headerlink" title="访问控制"></a>访问控制</h2><p>atlas 支持非常细粒度的访问控制：</p>
<ul>
<li><p>元模型：基于某个元模型或某类元模型的访问控制。典型 example：</p>
<blockquote>
<ul>
<li>Admin users can create&#x2F;update&#x2F;delete types of all categories</li>
<li>Data stewards can create&#x2F;update&#x2F;delete classification types</li>
<li>Healthcare data stewards can create&#x2F;update&#x2F;delete types having names start with “hc”</li>
</ul>
</blockquote>
</li>
<li><p>元数据：基于元模型、标签、元数据 id 的元数据访问控制。典型 example：</p>
<blockquote>
<ul>
<li>Admin users can perform all entity operations on entities of all types</li>
<li>Data stewards can perform all entity operations, except delete, on entities of all types</li>
<li>Data quality admins can add&#x2F;update&#x2F;remove DATA_QUALITY classification</li>
<li>Users in specific groups can read&#x2F;update entities with PII classification or its sub-classification</li>
<li>Finance users can read&#x2F;update entities whose ID start with ‘finance’</li>
</ul>
</blockquote>
</li>
<li><p>admin 操作：可以控制 user&#x2F;group 来 import&#x2F;export entities</p>
</li>
</ul>
<h2 id="UI"><a href="#UI" class="headerlink" title="UI"></a>UI</h2><p>有个 ui 可以管理元数据、标签、术语</p>
<h1 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h1><ol>
<li>web service 只有一个 active instance</li>
<li>Typename 全局唯一</li>
<li>ui 挺慢的</li>
</ol>
<h1 id="基于-atlas-我们可以做什么"><a href="#基于-atlas-我们可以做什么" class="headerlink" title="基于 atlas 我们可以做什么"></a>基于 atlas 我们可以做什么</h1><ol>
<li>数据集发现<ol>
<li>数据字典浏览和检索</li>
</ol>
</li>
<li>数据集导入和导出<ol>
<li>导出数据集，供系统之间交互使用</li>
<li>导入数据集（数据标准、指标口径等）</li>
</ol>
</li>
<li>标签管理：<ol>
<li>维护用户画像标签 (增删改查)</li>
<li>基于标签检索数据集</li>
</ol>
</li>
<li>数据标准维护和浏览：（可以通过术语做？）<ol>
<li>维护数据标准（增删改查）</li>
<li>可以为数据标准加标签</li>
</ol>
</li>
<li>指标和口径维护和浏览<ol>
<li>维护指标口径（增删改查）</li>
<li>可以为指标口径加标签</li>
</ol>
</li>
<li>数据集 staticstics<ol>
<li>数据接入和使用情况统计</li>
</ol>
</li>
<li>辅助数据分析师生成分析：<ol>
<li>通过关联技术元数据和业务元数据，当数据分析师按业务语言定义分析后，可以快速查找相关的表、字段等</li>
</ol>
</li>
</ol>
]]></content>
      <tags>
        <tag>big data</tag>
      </tags>
  </entry>
  <entry>
    <title>automatic drive</title>
    <url>/2019/01/15/automatic-drive/</url>
    <content><![CDATA[<p>reference:</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/29393415">coco</a>: one format for data labelling</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/721960-5e6217ea2a76689a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="auto-drive system"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/721960-6a7eac9f5586b04a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="labelling system"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/721960-5e82ce0148c621a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="training system.png"></p>
]]></content>
      <tags>
        <tag>automatic drive</tag>
      </tags>
  </entry>
  <entry>
    <title>HDP install (offline using ambari)</title>
    <url>/2020/11/23/ambari-install-offline/</url>
    <content><![CDATA[<p><a href="https://wbaseurlww.cnblogs.com/shook/p/12409759.html">reference</a></p>
<p><a href="https://docs.cloudera.com/HDPDocuments/Ambari-latest/bk_ambari-installation/content/set_up_password-less_ssh.html">官方安装指导</a></p>
<h1 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h1><p>除非说明，默认以下操作都是在所有节点上执行</p>
<h2 id="修改-host"><a href="#修改-host" class="headerlink" title="修改 host"></a>修改 host</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@master ~]<span class="comment"># vi /etc/hosts</span></span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1             localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.105.137 master</span><br><span class="line">192.168.105.191 slave1</span><br><span class="line">192.168.105.13 slave2</span><br></pre></td></tr></table></figure>

<h2 id="修改-network-config"><a href="#修改-network-config" class="headerlink" title="修改 network config"></a>修改 network config</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@master ~]<span class="comment"># vi /etc/sysconfig/network</span></span><br><span class="line"><span class="comment"># Created by anaconda</span></span><br><span class="line">NETWORKING=<span class="built_in">yes</span></span><br><span class="line">HOSTNAME=master</span><br><span class="line"></span><br><span class="line">[root@master ~]<span class="comment"># hostnamectl set-hostname master</span></span><br><span class="line">[root@master ~]<span class="comment"># hostname</span></span><br><span class="line">master</span><br><span class="line"></span><br><span class="line"><span class="comment"># ping 各个节点，查看是否可连通</span></span><br><span class="line">[root@master ~]<span class="comment"># ping slave1</span></span><br><span class="line">PING slave1 (192.168.105.191) 56(84) bytes of data.</span><br></pre></td></tr></table></figure>

<h2 id="同步时间-ntp"><a href="#同步时间-ntp" class="headerlink" title="同步时间 ntp"></a>同步时间 ntp</h2><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><h2 id="关闭-Selinux-和-THP"><a href="#关闭-Selinux-和-THP" class="headerlink" title="关闭 Selinux 和 THP"></a>关闭 Selinux 和 THP</h2><h2 id="修改文件打开最大限制"><a href="#修改文件打开最大限制" class="headerlink" title="修改文件打开最大限制"></a><del>修改文件打开最大限制</del></h2><h2 id="SSH-无密码登录（主节点）"><a href="#SSH-无密码登录（主节点）" class="headerlink" title="SSH 无密码登录（主节点）"></a>SSH 无密码登录（主节点）</h2><h2 id="Reboot"><a href="#Reboot" class="headerlink" title="Reboot"></a>Reboot</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ shutdown -r now</span><br></pre></td></tr></table></figure>

<h1 id="制作本地源（离线安装）"><a href="#制作本地源（离线安装）" class="headerlink" title="制作本地源（离线安装）"></a>制作本地源（离线安装）</h1><h2 id="文件目录访问（http-服务方式）"><a href="#文件目录访问（http-服务方式）" class="headerlink" title="文件目录访问（http 服务方式）"></a>文件目录访问（http 服务方式）</h2><h2 id="制作本地源（主节点）"><a href="#制作本地源（主节点）" class="headerlink" title="制作本地源（主节点）"></a>制作本地源（主节点）</h2><h3 id="安装本地源制作相关工具"><a href="#安装本地源制作相关工具" class="headerlink" title="安装本地源制作相关工具"></a>安装本地源制作相关工具</h3><h3 id="修改文件里面的源地址"><a href="#修改文件里面的源地址" class="headerlink" title="修改文件里面的源地址"></a>修改文件里面的源地址</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@master ambari]<span class="comment"># vi ambari/centos7/2.7.4.0-118/ambari.repo</span></span><br><span class="line"><span class="comment">#VERSION_NUMBER=2.7.4.0-118</span></span><br><span class="line">[ambari-2.7.4.0]</span><br><span class="line"><span class="comment">#json.url = http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json</span></span><br><span class="line">name=ambari Version - ambari-2.7.4.0</span><br><span class="line">baseurl=http://192.168.105.137/ambari/ambari/centos7/2.7.4.0-118</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.105.137/ambari/ambari/centos7/2.7.4.0-118/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line">[root@master ambari]<span class="comment"># cp ambari/centos7/2.7.4.0-118/ambari.repo /etc/yum.repos.d/</span></span><br><span class="line">[root@master ambari]<span class="comment"># vi HDP/centos7/3.1.4.0-315/hdp.repo</span></span><br><span class="line"><span class="comment">#VERSION_NUMBER=3.1.4.0-315</span></span><br><span class="line">[HDP-3.1.4.0]</span><br><span class="line">name=HDP Version - HDP-3.1.4.0</span><br><span class="line">baseurl=http://192.168.105.137/ambari/HDP/centos7/3.1.4.0-315</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.105.137/ambari/HDP/centos7/3.1.4.0-315/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[HDP-UTILS-1.1.0.22]</span><br><span class="line">name=HDP-UTILS Version - HDP-UTILS-1.1.0.22</span><br><span class="line">baseurl=http://192.168.105.137/ambari/HDP-UTILS/centos7/1.1.0.22</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.105.137/ambari/HDP-UTILS/centowwws7/1.1.0.22/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line">[root@master ambari]<span class="comment"># cp HDP/centos7/3.1.4.0-315/hdp.repo /etc/yum.repos.d/</span></span><br></pre></td></tr></table></figure>



<h3 id="将创建好的源文件（-repo）拷贝到子节点"><a href="#将创建好的源文件（-repo）拷贝到子节点" class="headerlink" title="将创建好的源文件（.repo）拷贝到子节点"></a>将创建好的源文件（.repo）拷贝到子节点</h3><h1 id="安装-ambari-server"><a href="#安装-ambari-server" class="headerlink" title="安装 ambari-server"></a>安装 ambari-server</h1><h2 id="安装-ambari-server-1"><a href="#安装-ambari-server-1" class="headerlink" title="安装 ambari-server"></a>安装 ambari-server</h2><p>先安装，然后开始配置</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ yum -y install ambari-server</span><br></pre></td></tr></table></figure>

<h2 id="设置并启动-ambari-server（主节点）"><a href="#设置并启动-ambari-server（主节点）" class="headerlink" title="设置并启动 ambari-server（主节点）"></a>设置并启动 ambari-server（主节点）</h2><p><a href="https://www.baeldung.com/find-java-home">how to find JAVA_HOME</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ java -XshowSettings:properties -version 2&gt;&amp;1 &gt; /dev/null | grep <span class="string">&#x27;java.home&#x27;</span> </span><br></pre></td></tr></table></figure>

<h3 id="使用默认-postgresql"><a href="#使用默认-postgresql" class="headerlink" title="使用默认 postgresql"></a>使用默认 postgresql</h3><p>Setup server 时，有几个交互式配置：</p>
<ol>
<li><p>是否自定义用户账户：</p>
<ol>
<li>选 n。即默认设置了 Ambari GUI 的登录用户为 admin&#x2F;admin。并且指定 Ambari Server 的运行用户为 root。</li>
</ol>
<blockquote>
<p>If you want to create a different user to run the Ambari Server, or to assign a previously created user, select <strong><code>y</code></strong> at the <code>Customize user account for ambari-server daemon</code> prompt, then provide a user name.</p>
</blockquote>
</li>
<li><p>JDK：</p>
<ol>
<li>选 2. 因为默认会安装并使用 oracle jdk，但是（1）不能联网下载（2）好像 oracle jdk 不会下载依赖包。所以自己安装好，在这指定 path 即可</li>
</ol>
</li>
<li><p>数据库：</p>
<ol>
<li>按默认配置创建 postgres 数据库</li>
</ol>
</li>
</ol>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@master yum.repos.d]<span class="comment"># ambari-server setup</span></span><br><span class="line">Using python  /usr/bin/python</span><br><span class="line">Setup ambari-server</span><br><span class="line">Checking SELinux...</span><br><span class="line">SELinux status is <span class="string">&#x27;disabled&#x27;</span></span><br><span class="line">Customize user account <span class="keyword">for</span> ambari-server daemon [y/n] (n)? n</span><br><span class="line">Adjusting ambari-server permissions and ownership...</span><br><span class="line">Checking firewall status...</span><br><span class="line">Checking JDK...</span><br><span class="line">[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8</span><br><span class="line">[2] Custom JDK</span><br><span class="line">Enter choice (1): 2</span><br><span class="line">WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts.</span><br><span class="line">WARNING: JCE Policy files are required <span class="keyword">for</span> configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts.</span><br><span class="line">Path to JAVA_HOME: /usr/java/jdk1.8.0_202</span><br><span class="line">Validating JDK on Ambari Server...<span class="keyword">done</span>.</span><br><span class="line">Completing setup...</span><br><span class="line">Configuring database...</span><br><span class="line">Enter advanced database configuration [y/n] (n)? n</span><br><span class="line">Configuring database...</span><br><span class="line">Default properties detected. Using built-in database.</span><br><span class="line">Configuring ambari database...</span><br><span class="line">Checking PostgreSQL...</span><br><span class="line">Running initdb: This may take up to a minute.</span><br><span class="line">Initializing database ... OK</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">About to start PostgreSQL</span><br><span class="line">Configuring <span class="built_in">local</span> database...</span><br><span class="line">Configuring PostgreSQL...</span><br><span class="line">Restarting PostgreSQL</span><br><span class="line">Creating schema and user...</span><br><span class="line"><span class="keyword">done</span>.</span><br><span class="line">Creating tables...</span><br><span class="line"><span class="keyword">done</span>.</span><br><span class="line">Extracting system views...</span><br><span class="line">ambari-admin-2.7.4.0-118.jar</span><br><span class="line">...........</span><br><span class="line">Adjusting ambari-server permissions and ownership...</span><br><span class="line">Ambari Server <span class="string">&#x27;setup&#x27;</span> completed successfully.</span><br></pre></td></tr></table></figure>

<h3 id="使用-mysql"><a href="#使用-mysql" class="headerlink" title="使用 mysql"></a>使用 mysql</h3><p><a href="https://programmer.group/linux-centos-7-mysql-5.7-offline-installation.html">离线安装 mysql</a></p>
<h4 id="离线安装"><a href="#离线安装" class="headerlink" title="离线安装"></a>离线安装</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建用户组</span></span><br><span class="line">$ groupadd hdp</span><br><span class="line"><span class="comment"># 创建用户</span></span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql</span><br><span class="line">$ useradd -g hdp hive -d /home/mysql/hive</span><br><span class="line">$ passwd hive</span><br><span class="line">yourPassword</span><br><span class="line"><span class="comment"># 创建临时目录</span></span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql/hive/3306/data</span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql/hive/3306/log</span><br><span class="line">$ <span class="built_in">mkdir</span> /home/mysql/hive/3306/tmp</span><br><span class="line">$ <span class="built_in">chown</span> -R hive:hdp /home/mysql/hive</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">$ <span class="built_in">mv</span> mysql-5.7.32-linux-glibc2.12-x86_64.tar.gz /usr/local</span><br><span class="line">$ <span class="built_in">cd</span> /usr/local</span><br><span class="line">$ tar -xzvf mysql-5.7.32-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"><span class="comment"># Establish soft links for future upgrades</span></span><br><span class="line">$ <span class="built_in">ln</span> -s mysql-5.7.27-linux-glibc2.12-x86_64 mysql</span><br><span class="line"><span class="comment"># Modify users and user groups of all files under mysql folder</span></span><br><span class="line">$ <span class="built_in">chown</span> -R mysql:mysql mysql/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建配置文件</span></span><br><span class="line">$ <span class="built_in">cd</span> /etc</span><br><span class="line">$ vi my.cnf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 mysql</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/local/mysql/bin</span><br><span class="line">$ ./mysqld --initialize --user=hive</span><br></pre></td></tr></table></figure>

<h4 id="安装-driver-并配置与-ambari-server-的-jdbc-连接"><a href="#安装-driver-并配置与-ambari-server-的-jdbc-连接" class="headerlink" title="安装 driver, 并配置与 ambari-server 的 jdbc 连接"></a>安装 driver, 并配置与 ambari-server 的 jdbc 连接</h4><p><a href="https://dev.mysql.com/downloads/connector/j/">mysql-connector-driver 下载</a> （选 RedHat 8 那个操作系统）</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 解压</span></span><br><span class="line">$ rpm -ivh mysql80-community-release-el7-3.noarch.rpm</span><br><span class="line">$ <span class="built_in">cp</span> /usr/share/java/mysql-connector-java.jar /var/lib/ambari-server/resources/mysql-jdbc-driver.jar</span><br><span class="line"><span class="comment"># 配置 driver path</span></span><br><span class="line">$ vi /etc/ambari-server/conf/ambari.properties</span><br><span class="line">添加server.jdbc.driver.path=/usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure>

<h4 id="配置-mysql"><a href="#配置-mysql" class="headerlink" title="配置 mysql"></a>配置 mysql</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置开机启动，并启动 mysql</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/local/mysql</span><br><span class="line"><span class="comment"># Copy the startup script to the resource directory and modify mysql.server. It&#x27;s better to modify mysqld as well. These two files are best synchronized.</span></span><br><span class="line">$ <span class="built_in">cp</span> ./support-files/mysql.server /etc/rc.d/init.d/mysqld</span><br><span class="line"><span class="comment"># Increase the execution privileges of mysqld service control scripts</span></span><br><span class="line">$ <span class="built_in">chmod</span> +x /etc/rc.d/init.d/mysqld</span><br><span class="line"><span class="comment"># Add mysqld service to system service</span></span><br><span class="line">$ chkconfig --add mysqld</span><br><span class="line"><span class="comment"># Check whether the mysqld service is in effect</span></span><br><span class="line">$ chkconfig --list mysqld </span><br><span class="line"><span class="comment"># mysql start</span></span><br><span class="line">$ service mysqld start</span><br><span class="line"><span class="comment"># View mysql status</span></span><br><span class="line">$ service mysqld status</span><br><span class="line"><span class="comment"># Check mysql related processes</span></span><br><span class="line">$ ps aux|grep mysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line">$ vi /etc/profile</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/local/mysql/bin</span><br><span class="line">$ <span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新 root 密码</span></span><br><span class="line">$ mysql -uroot -p</span><br><span class="line">$ mysql&gt; <span class="built_in">set</span> password <span class="keyword">for</span> root@localhost=password(<span class="string">&quot;root&quot;</span>);</span><br><span class="line"><span class="comment"># 配置 remote access to the mysql</span></span><br><span class="line">$ mysql&gt; use mysql</span><br><span class="line">$ mysql&gt; update user <span class="built_in">set</span> host=<span class="string">&#x27;%&#x27;</span> <span class="built_in">where</span> user=<span class="string">&#x27;root&#x27;</span>;</span><br><span class="line">$ mysql&gt; <span class="keyword">select</span> host,user from user;</span><br><span class="line">$ mysql&gt; grant all privileges on *.* to <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> identified by <span class="string">&#x27;yourPassword&#x27;</span>;</span><br><span class="line">$ mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure>

<h4 id="创建-database"><a href="#创建-database" class="headerlink" title="创建 database"></a>创建 database</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE DATABASE ambari;  </span><br><span class="line">use ambari;  </span><br><span class="line">CREATE USER &#x27;ambari&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;ambari&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;ambari&#x27;@&#x27;%&#x27;;  </span><br><span class="line">CREATE USER &#x27;ambari&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;ambar&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;ambari&#x27;@&#x27;localhost&#x27;;  </span><br><span class="line">CREATE USER &#x27;ambari&#x27;@&#x27;master&#x27; IDENTIFIED BY &#x27;ambari&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;ambari&#x27;@&#x27;master&#x27;;  </span><br><span class="line">FLUSH PRIVILEGES;  </span><br><span class="line">source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql  </span><br><span class="line"></span><br><span class="line">CREATE DATABASE hive;  </span><br><span class="line">use hive;  </span><br><span class="line">CREATE USER &#x27;hive&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;hive&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;hive&#x27;@&#x27;%&#x27;;  </span><br><span class="line">CREATE USER &#x27;hive&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;hive&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;hive&#x27;@&#x27;localhost&#x27;;  </span><br><span class="line">CREATE USER &#x27;hive&#x27;@&#x27;master&#x27; IDENTIFIED BY &#x27;hive&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;hive&#x27;@&#x27;master&#x27;;  </span><br><span class="line">FLUSH PRIVILEGES;  </span><br><span class="line">CREATE DATABASE oozie;  </span><br><span class="line">use oozie;  </span><br><span class="line">CREATE USER &#x27;oozie&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;oozie&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;oozie&#x27;@&#x27;%&#x27;;  </span><br><span class="line">CREATE USER &#x27;oozie&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;oozie&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;oozie&#x27;@&#x27;localhost&#x27;;  </span><br><span class="line">CREATE USER &#x27;oozie&#x27;@&#x27;master&#x27; IDENTIFIED BY &#x27;oozie&#x27;;  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#x27;oozie&#x27;@&#x27;master&#x27;;  </span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>



<h4 id="Mysql-conf"><a href="#Mysql-conf" class="headerlink" title="Mysql conf"></a>Mysql conf</h4><p>上边 cnf 的内容</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[client]                                        # Client settings, the default connection parameters for the client</span><br><span class="line">port = 3306                                    # Default connection port</span><br><span class="line">socket = /home/mysql/hive/3306/tmp/mysql.sock                        # For socket sockets for local connections, the mysqld daemon generates this file</span><br><span class="line"></span><br><span class="line">[mysqld]                                        # Server Basic Settings</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Foundation setup</span></span><br><span class="line">user = hive</span><br><span class="line">bind-address = 0.0.0.0                         # Allow any ip host to access this database</span><br><span class="line">server-id = 1                                  # The unique number of Mysql service Each MySQL service Id needs to be unique</span><br><span class="line">port = 3306                                    # MySQL listening port</span><br><span class="line">basedir = /usr/local/mysql                      # MySQL installation root directory</span><br><span class="line">datadir = /home/mysql/hive/3306/data                      # MySQL Data File Location</span><br><span class="line">tmpdir  = /home/mysql/hive/3306/tmp                                  # Temporary directories, such as load data infile, will be used</span><br><span class="line">socket = /home/mysql/hive/3306/tmp/mysql.sock        # Specify a socket file for local communication between MySQL client program and server</span><br><span class="line">pid-file = /home/mysql/hive/3306/log/mysql.pid      # The directory where the pid file is located</span><br><span class="line">skip_name_resolve = 1                          # Only use IP address to check the client&#x27;s login, not the host name.</span><br><span class="line">character-set-server = utf8mb4                  # Database default character set, mainstream character set support some special emoticons (special emoticons occupy 4 bytes)</span><br><span class="line">transaction_isolation = READ-COMMITTED          # Transaction isolation level, which is repeatable by default. MySQL is repeatable by default.</span><br><span class="line">collation-server = utf8mb4_general_ci          # The character set of database corresponds to some sort rules, etc. Be careful to correspond to character-set-server.</span><br><span class="line">init_connect=&#x27;SET NAMES utf8mb4&#x27;                # Set up the character set when client connects mysql to prevent scrambling</span><br><span class="line">lower_case_table_names = 1                      # Is it case sensitive to sql statements, 1 means insensitive</span><br><span class="line">max_connections = 400                          # maximum connection</span><br><span class="line">max_connect_errors = 1000                      # Maximum number of false connections</span><br><span class="line">explicit_defaults_for_timestamp = true          # TIMESTAMP allows NULL values if no declaration NOT NULL is displayed</span><br><span class="line">max_allowed_packet = 128M                      # The size of the SQL packet sent, if there is a BLOB object suggested to be modified to 1G</span><br><span class="line">interactive_timeout = 1800                      # MySQL connection will be forcibly closed after it has been idle for more than a certain period of time (in seconds)</span><br><span class="line">wait_timeout = 1800                            # The default value of MySQL wait_timeout is 8 hours. The interactive_timeout parameter needs to be configured concurrently to take effect.</span><br><span class="line">tmp_table_size = 16M                            # The maximum value of interior memory temporary table is set to 128M; for example, group by, order by with large amount of data may be used as temporary table; if this value is exceeded, it will be written to disk, and the IO pressure of the system will increase.</span><br><span class="line">max_heap_table_size = 128M                      # Defines the size of memory tables that users can create</span><br><span class="line">query_cache_size = 0                            # Disable mysql&#x27;s cached query result set function; later test to determine whether to turn on or not based on business conditions; in most cases, close the following two items</span><br><span class="line">query_cache_type = 0</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Memory settings allocated by user processes, and each session will allocate memory size <span class="keyword">for</span> parameter settings</span></span><br><span class="line">read_buffer_size = 2M                          # MySQL read buffer size. Requests for sequential table scans allocate a read buffer for which MySQL allocates a memory buffer.</span><br><span class="line">read_rnd_buffer_size = 8M                      # Random Read Buffer Size of MySQL</span><br><span class="line">sort_buffer_size = 8M                          # Buffer size used for MySQL execution sort</span><br><span class="line">binlog_cache_size = 1M                          # A transaction produces a log that is recorded in Cache when it is not committed, and persists the log to disk when it needs to be committed. Default binlog_cache_size 32K</span><br><span class="line"></span><br><span class="line">back_log = 130                                  # How many requests can be stored on the stack in a short time before MySQL temporarily stops responding to new requests; the official recommendation is back_log = 50 + (max_connections/5), with a cap of 900</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">log</span> setting</span></span><br><span class="line">log_error = /home/mysql/hive/3306/log/error.log                          # Database Error Log File</span><br><span class="line">slow_query_log = 1                              # Slow Query sql Log Settings</span><br><span class="line">long_query_time = 1                            # Slow query time; Slow query over 1 second</span><br><span class="line">slow_query_log_file = /home/mysql/hive/3306/log/slow.log                  # Slow Query Log Files</span><br><span class="line">log_queries_not_using_indexes = 1              # Check sql that is not used in the index</span><br><span class="line">log_throttle_queries_not_using_indexes = 5      # Represents the number of SQL statements per minute that are allowed to be logged to a slow log and are not indexed. The default value is 0, indicating that there is no limit.</span><br><span class="line">min_examined_row_limit = 100                    # The number of rows retrieved must reach this value before they can be recorded as slow queries. SQL that returns fewer than the rows specified by this parameter is not recorded in the slow query log.</span><br><span class="line">expire_logs_days = 5                            # MySQL binlog log log file saved expiration time, automatically deleted after expiration</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Master-slave replication settings</span></span><br><span class="line">log-bin = mysql-bin                            # Open mysql binlog function</span><br><span class="line">binlog_format = ROW                            # The way a binlog records content, recording each row being manipulated</span><br><span class="line">binlog_row_image = minimal                      # For binlog_format = ROW mode, reduce the content of the log and record only the affected columns</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Innodb settings</span></span><br><span class="line">innodb_open_files = 500                        # Restrict the data of tables Innodb can open. If there are too many tables in the library, add this. This value defaults to 300</span><br><span class="line">innodb_buffer_pool_size = 64M                  # InnoDB uses a buffer pool to store indexes and raw data, usually 60% to 70% of physical storage; the larger the settings here, the less disk I/O you need to access the data in the table.</span><br><span class="line">innodb_log_buffer_size = 2M                    # This parameter determines the size of memory used to write log files in M. Buffers are larger to improve performance, but unexpected failures can result in data loss. MySQL developers recommend settings between 1 and 8M</span><br><span class="line">innodb_flush_method = O_DIRECT                  # O_DIRECT reduces the conflict between the cache of the operating system level VFS and the buffer cache of Innodb itself.</span><br><span class="line">innodb_write_io_threads = 4                    # CPU multi-core processing capability settings are adjusted according to read-write ratio</span><br><span class="line">innodb_read_io_threads = 4</span><br><span class="line">innodb_lock_wait_timeout = 120                  # InnoDB transactions can wait for a locked timeout second before being rolled back. InnoDB automatically detects transaction deadlocks and rolls back transactions in its own lock table. InnoDB notices the lock settings with the LOCK TABLES statement. The default value is 50 seconds.</span><br><span class="line">innodb_log_file_size = 32M                      # This parameter determines the size of the data log file. Larger settings can improve performance, but also increase the time required to recover the failed database.</span><br></pre></td></tr></table></figure>



<h2 id="停止-ambari-server"><a href="#停止-ambari-server" class="headerlink" title="停止 ambari-server"></a>停止 ambari-server</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[root@master ~] ambari-server stop    <span class="comment">#停止命令</span></span><br><span class="line"></span><br><span class="line">[root@master ~]<span class="comment"># # ambari-server reset   #重置命令</span></span><br><span class="line">[root@master ~]<span class="comment"># # ambari-server setup   #重新设置 </span></span><br><span class="line">[root@master ~]<span class="comment"># # ambari-server start   #启动命令</span></span><br></pre></td></tr></table></figure>

<h1 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h1><h2 id="基本信息"><a href="#基本信息" class="headerlink" title="基本信息"></a>基本信息</h2><p>集群名字：ftms_hdp_qat</p>
<p>选择版本：</p>
<ul>
<li>hdp 3.1</li>
<li>redhat7</li>
</ul>
<h2 id="配置服务"><a href="#配置服务" class="headerlink" title="配置服务"></a>配置服务</h2><p>选择服务</p>
<p>选择 master&#x2F;slave for 各服务</p>
<p><img src="/images/ambari-20201125154733621.png" alt="image-20201125154733621"></p>
<h3 id="配置-hive-x2F-ozzie-x2F-ranger-database"><a href="#配置-hive-x2F-ozzie-x2F-ranger-database" class="headerlink" title="配置 hive&#x2F;ozzie&#x2F;ranger database"></a>配置 hive&#x2F;ozzie&#x2F;ranger database</h3><h3 id="使用-postgresql"><a href="#使用-postgresql" class="headerlink" title="使用 postgresql"></a>使用 postgresql</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 先执行下边这句话，再继续配置</span></span><br><span class="line">$ ambari-server setup --jdbc-db=postgres --jdbc-driver=/usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure>

<h3 id="使用-mysql-1"><a href="#使用-mysql-1" class="headerlink" title="使用 mysql"></a>使用 mysql</h3><p>使用 mysql（生产环境推荐使用），且 mysql 在其他地方也在用，而 postgresql 和 mysql 的语法是有区别的。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先执行下边这句话，再继续配置</span></span><br><span class="line">$ ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar</span><br></pre></td></tr></table></figure>

<h3 id="配置-directories"><a href="#配置-directories" class="headerlink" title="配置 directories"></a>配置 directories</h3><p>采用默认的</p>
<h3 id="configurations"><a href="#configurations" class="headerlink" title="configurations"></a>configurations</h3><p>采用默认的</p>
<h1 id="异常调试"><a href="#异常调试" class="headerlink" title="异常调试"></a>异常调试</h1><h2 id="查看-ambari-的配置"><a href="#查看-ambari-的配置" class="headerlink" title="查看 ambari 的配置"></a>查看 ambari 的配置</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 ambari-server 的配置</span></span><br><span class="line">$ vi /etc/ambari-server/conf/ambari.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 hdp 各服务的配置</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/hdp/3.1.4.0-315/hbase/conf</span><br><span class="line"><span class="comment"># 运行服务</span></span><br><span class="line">$ /usr/hdp/3.1.4.0-315/hbase/bin/hbase shell</span><br></pre></td></tr></table></figure>

<h2 id="查看错误日志"><a href="#查看错误日志" class="headerlink" title="查看错误日志"></a>查看错误日志</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看 ambari-server 启动的错误日志</span></span><br><span class="line">$ <span class="built_in">tail</span> /var/log/ambari-server/ambari-server.log -n 10 -f | less</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 hdp 各服务的日志</span></span><br><span class="line">$ <span class="built_in">cd</span> /usr/hdp/3.1.4.0-315/hbase/logs/hbase/hbase-hbase-regionserver-slave2.<span class="built_in">log</span></span><br><span class="line"><span class="comment"># 或者在 var 下看也一样，不知道是放了软 link 还是什么，日志好像是一样的</span></span><br><span class="line">$ <span class="built_in">cd</span> /var/log/hbase/hbase-hbase-regionserver-slave2.<span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 ranger service 的配置</span></span><br><span class="line">$ /etc/ranger/</span><br></pre></td></tr></table></figure>

<h2 id="重新安装"><a href="#重新安装" class="headerlink" title="重新安装"></a>重新安装</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ ambari-server stop</span><br><span class="line">$ ambari-server reset</span><br><span class="line">$ ambari-server setup</span><br></pre></td></tr></table></figure>

<h2 id="安装找不到包"><a href="#安装找不到包" class="headerlink" title="安装找不到包"></a>安装找不到包</h2><h3 id="找不到-hdp-repo"><a href="#找不到-hdp-repo" class="headerlink" title="找不到 hdp.repo"></a>找不到 hdp.repo</h3><p>在实际安装时，ambari 会生成一个新的 ambari-hdp-1.repo，其中也定义了 hdp 的 baseurl 之类，这里对 hdp 定义的 name 可能是 <code>[HDP-3.1-repo-1]</code> , 而前边准备本地库时，定义的 hdp 的 name 是 <code>[HDP-3.1.4.0]</code>，这两个名字必须保持一致，否则 ambari 就找不到包（这是 ambari 的一个 bug）。</p>
<blockquote>
<p>解决方案：</p>
<p>将 <code>hdp.repo</code> 中的 [HDP-3.1.4.0] 改为 [HDP-3.1-repo-1]，并重新 scp 到各个节点</p>
</blockquote>
<h3 id="postfix找不到libmysqlclient-so-18"><a href="#postfix找不到libmysqlclient-so-18" class="headerlink" title="postfix找不到libmysqlclient.so.18"></a>postfix找不到libmysqlclient.so.18</h3><blockquote>
<p>还有一种简单的方法（没试过）：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">&gt;$ yum reinstall mysql-libs -y</span><br></pre></td></tr></table></figure>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先删除现在安装的 postfix</span></span><br><span class="line">$ systemctl <span class="built_in">disable</span> postfix</span><br><span class="line">$ systemctl stop postfix</span><br><span class="line">$ yum remove postfix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给 libmysqlclient.so.18 加上软链</span></span><br><span class="line">$ find / -name <span class="string">&#x27;*libmysqlclient.so.18*&#x27;</span></span><br><span class="line">/usr/lib64/mysql/libmysqlclient.so.18</span><br><span class="line">$ <span class="built_in">ln</span> -s /usr/lib64/mysql/libmysqlclient.so.18 /usr/lib/libmysqlclient.so.18</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新安装 postfix 并启动</span></span><br><span class="line">$ yum install postfix</span><br><span class="line">$ systemctl <span class="built_in">enable</span> postfix</span><br><span class="line">$ systemctl start postfix</span><br><span class="line">$ systemctl status postfix.service</span><br></pre></td></tr></table></figure>

<h3 id="找不到-libtirpc-devel"><a href="#找不到-libtirpc-devel" class="headerlink" title="找不到 libtirpc-devel"></a>找不到 libtirpc-devel</h3><p>如果出错，可能各个节点都需要做这件事</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 不能联网</span></span><br><span class="line"><span class="comment"># 先下载 https://centos.pkgs.org/7/centos-x86_64/libtirpc-devel-0.2.4-0.16.el7.x86_64.rpm.html 包</span></span><br><span class="line">$ yum-config-manager --<span class="built_in">enable</span> rhui-REGION-rhel-server-optional</span><br><span class="line">$ yum install libtirpc-devel-0.2.4-0.16.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果可以联网。这个可以从 CentOs-Base.repo 里下，但不能联网就没办法了</span></span><br><span class="line">$ <span class="built_in">cd</span> /etc/yum.repos.d</span><br><span class="line">$ <span class="built_in">cp</span> backup/CentOs-Base.repo .</span><br></pre></td></tr></table></figure>

<h2 id="ranger-admin-start-fail"><a href="#ranger-admin-start-fail" class="headerlink" title="ranger-admin start fail"></a>ranger-admin start fail</h2><p>start ranger-admin fail.</p>
<blockquote>
<p>error detail:<br>This function has none of DETERMINISTIC, NO SQL, or READS SQL DATA in its declaration and binary logging is enabled (you <em>might</em> want to use the less safe log_bin_trust_function_creators variable)</p>
</blockquote>
<p>Solution (<a href="https://stackoverflow.com/questions/26015160/deterministic-no-sql-or-reads-sql-data-in-its-declaration-and-binary-logging-i">stackflow</a>):</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Execute the following in the MySQL console:</span></span><br><span class="line">SET GLOBAL log_bin_trust_function_creators = 1;</span><br></pre></td></tr></table></figure>

<h2 id="atlas-server-启动失败"><a href="#atlas-server-启动失败" class="headerlink" title="atlas server 启动失败"></a>atlas server 启动失败</h2><h3 id="Ranger-authorization-失败"><a href="#Ranger-authorization-失败" class="headerlink" title="Ranger authorization 失败"></a>Ranger authorization 失败</h3><blockquote>
<p>执行 <code>cat /var/lib/ambari-agent/tmp/atlas_hbase_setup.rb | hbase shell -n</code> 命令时，失败报 404</p>
<p>Error detail:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ERROR Java::OrgApacheHadoopHbaseIpc::RemoteWithExtrasException: org.apache.hadoop.hbase.coprocessor.CoprocessorException: HTTP 404 Error: HTTP 404</span><br><span class="line">	at org.apache.ranger.authorization.hbase.RangerAuthorizationCoprocessor.grant(RangerAuthorizationCoprocessor.java:1261)</span><br><span class="line">	at org.apache.ranger.authorization.hbase.RangerAuthorizationCoprocessor.grant(RangerAuthorizationCoprocessor.java:1072)</span><br><span class="line">	at org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos$AccessControlService<span class="variable">$1</span>.grant(AccessControlProtos.java:10023)</span><br><span class="line">	at org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos<span class="variable">$AccessControlService</span>.callMethod(AccessControlProtos.java:10187)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.HRegion.execService(HRegion.java:8135)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execServiceOnRegion(RSRpcServices.java:2426)</span><br><span class="line">	at org.apache.hadoop.hbase.regionserver.RSRpcServices.execService(RSRpcServices.java:2408)</span><br><span class="line">	at org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos$ClientService<span class="variable">$2</span>.callBlockingMethod(ClientProtos.java:42010)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:413)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:131)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor<span class="variable">$Handler</span>.run(RpcExecutor.java:324)</span><br><span class="line">	at org.apache.hadoop.hbase.ipc.RpcExecutor<span class="variable">$Handler</span>.run(RpcExecutor.java:304)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</blockquote>
<p>这个原因是 atlas 通过 ranger 访问 hbase 的时候没有权限。可能是由于安装先后顺序的原因，也有 atlas + ranger 本身需要手动配置的原因，导致 ranger 中没有配置 atlas 对 hbase、kafka 的访问权限。因此需要做做几件事：</p>
<ol>
<li><p>在 ambari 的 ranger config 中，启动 hbase ranger plugin，并重启相关服务</p>
</li>
<li><p>在 ambari 的 ranger config 中，启动 kafka ranger  plugin，并重启相关服务 &#x3D;&#x3D;&#x3D;&gt; 暂时没做</p>
</li>
<li><p>在 ranger 添加 hbase 的 service（参照 <a href="https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.5/authorization-ranger/content/resource_service_configure_an_hbase_service.html">Configure a Resource-based Service: HBase</a>)</p>
<ol>
<li>这里 service 的名称必须和 <code>/usr/hdp/3.1.4.0-315/ranger-hbase-plugin/install.properties</code> 里配置 <code>REPOSITORY_NAME</code> 保持一致（但是似乎并不需要？）</li>
<li>username，password 说是 The end system username that can be used for connection.（目前来看，我现在是随便写的 admin 的账号）</li>
<li>Zookeeper 和 hbase.authentication 的配置是和  <code>/usr/hdp/3.1.4.0-315/hbase/conf/hbase-site.xml</code> 中的配置保持一致</li>
</ol>
<p><img src="/images/ambari-20201130112641591.png" alt="image-20201130112641591"></p>
<p><img src="/images/ambari-20201130112704671.png" alt="image-20201130112704671"></p>
</li>
<li><p>添加 atlas 对 hbase tables、kafka topic 的访问 policies（可参看：<a href="https://github.com/emaxwell-hw/Atlas-Ranger-Tag-Security/blob/master/README.md">tag-based security with atlas + ranger</a>）&#x3D;&#x3D;&#x3D;》 暂时没做 kafka</p>
<ol>
<li><strong>创建 hbase 的 policies 时，必须给 all - table, column-family, column 加上 <code>hbase</code> 这个 user</strong>，否则可能会遇到 403。这个原因是启动 metadata server 时，会执行 <code>cat /var/lib/ambari-agent/tmp/atlas_hbase_setup.rb | hbase shell -n</code> 这么一条命令，执行时，会切换到 <code>hbase</code> 这个用户，如果这里不加权限，这条命令就会执行失败</li>
</ol>
<p><img src="/images/ambari-20201130112445208.png" alt="image-20201130112445208"></p>
</li>
</ol>
<p>ranger 的访问链接: <a href="http://ranger-server-host:6080/index.html">http://ranger-server-host:6080/index.html</a> (可以从 ambari ranger config 中看到)</p>
<h3 id="生成-jar-包失败（报-no-such-file-or-directory"><a href="#生成-jar-包失败（报-no-such-file-or-directory" class="headerlink" title="生成 jar 包失败（报 no such file or directory)"></a>生成 jar 包失败（报 no such file or directory)</h3><blockquote>
<p>在执行 <code>source /usr/hdp/current/atlas-server/conf/atlas-env.sh ; /usr/hdp/current/atlas-server/bin/atlas_start.py</code> 时报错，</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">  File <span class="string">&quot;/usr/hdp/current/atlas-server/bin/atlas_start.py&quot;</span>, line 163, <span class="keyword">in</span> </span><br><span class="line">    returncode = main()</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/current/atlas-server/bin/atlas_start.py&quot;</span>, line 73, <span class="keyword">in</span> main</span><br><span class="line">    mc.expandWebApp(atlas_home)</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/3.1.4.0-315/atlas/bin/atlas_config.py&quot;</span>, line 160, <span class="keyword">in</span> expandWebApp</span><br><span class="line">    jar(atlasWarPath)</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/3.1.4.0-315/atlas/bin/atlas_config.py&quot;</span>, line 213, <span class="keyword">in</span> jar</span><br><span class="line">    process = runProcess(commandline)</span><br><span class="line">  File <span class="string">&quot;/usr/hdp/3.1.4.0-315/atlas/bin/atlas_config.py&quot;</span>, line 249, <span class="keyword">in</span> runProcess</span><br><span class="line">    p = subprocess.Popen(commandline, stdout=stdoutFile, stderr=stderrFile, shell=shell)</span><br><span class="line">  File <span class="string">&quot;/usr/lib64/python2.7/subprocess.py&quot;</span>, line 711, <span class="keyword">in</span> __init__</span><br><span class="line">    errread, errwrite)</span><br><span class="line">  File <span class="string">&quot;/usr/lib64/python2.7/subprocess.py&quot;</span>, line 1327, <span class="keyword">in</span> _execute_child</span><br><span class="line">    raise child_exception</span><br><span class="line">OSError: [Errno 2] No such file or directory</span><br></pre></td></tr></table></figure>
</blockquote>
<p>通过在 <code>atlas_config.py</code> 中添加 log，发现最后是在执行 <code>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b03-1.el7.x86_64/jre/bin/jar -xf /usr/hdp/3.1.4.0-315/atlas/server/webapp/atlas.war</code> 时报错，找不到的是 jar 命令. 原因是 jar 是 jdk 中的命令，而使用的默认 openjdk 其实只安装了 jre.</p>
<blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看所有的 openjdk 列表</span></span><br><span class="line">$ yum list | grep jdk</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 jdk</span></span><br><span class="line">$ yum install java-1.8.0-openjdk.x86_64</span><br><span class="line"></span><br><span class="line"><span class="comment"># copy jar 到指定目录</span></span><br><span class="line">$ <span class="built_in">cp</span> /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b03-1.el7.x86_64/bin/jar /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b03-1.el7.x86_64/jre/bin/</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="Host-Disk-Usage-alert"><a href="#Host-Disk-Usage-alert" class="headerlink" title="Host Disk Usage alert"></a>Host Disk Usage alert</h2><p>安装过程下载了挺多乱七八糟的东西，导致硬盘报警了</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看目前各文件系统的硬盘使用情况，如果设置的 80% 报警，则只要有某个文件系统的使用哪个超了，就会报警</span></span><br><span class="line">$ <span class="built_in">df</span> -h</span><br><span class="line">文件系统                       容量  已用  可用 已用% 挂载点</span><br><span class="line">devtmpfs                        32G     0   32G    0% /dev</span><br><span class="line">tmpfs                           32G     0   32G    0% /dev/shm</span><br><span class="line">tmpfs                           32G  824M   31G    3% /run</span><br><span class="line">tmpfs                           32G     0   32G    0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/centos-root         50G   31G   20G   61% /</span><br><span class="line">/dev/sda1                     1014M  154M  861M   16% /boot</span><br><span class="line">/dev/mapper/vg_data2-lv_data2  200G   55M  200G    1% /data02</span><br><span class="line">/dev/mapper/centos-home         47G  444M   47G    1% /home</span><br><span class="line">/dev/mapper/vg_data1-lv_data1  200G  4.9G  196G    3% /data01</span><br><span class="line">tmpfs                          6.3G     0  6.3G    0% /run/user/0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看现在系统中的文件占用情况，找大文件去清</span></span><br><span class="line">$ <span class="built_in">du</span> -hs /*</span><br><span class="line">$ <span class="built_in">du</span> -hs /root/*</span><br><span class="line">$ <span class="built_in">du</span> -hs /var/log/*</span><br><span class="line">$ <span class="built_in">du</span> -h /var/* -d 1 | <span class="built_in">sort</span> -n -r</span><br></pre></td></tr></table></figure>



<h1 id="验证各服务可用"><a href="#验证各服务可用" class="headerlink" title="验证各服务可用"></a>验证各服务可用</h1><h2 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h2><h3 id="创建文件夹（可选？？？）"><a href="#创建文件夹（可选？？？）" class="headerlink" title="创建文件夹（可选？？？）"></a>创建文件夹（可选？？？）</h3><p><a href="https://www.tutorialspoint.com/hive/hive_quick_guide.htm">hive 验证可用</a></p>
<h3 id="配置-ranger-service-amp-policies"><a href="#配置-ranger-service-amp-policies" class="headerlink" title="配置 ranger service &amp; policies"></a>配置 ranger service &amp; policies</h3><p><a href="https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.1.5/authorization-ranger/content/resource_service_configure_a_hive_service.html">ranger-hive-service</a></p>
<p>service 命名</p>
<p>url: get from ambari-hive, or when you connect hive, it will show the whole connect string</p>
<p>policy 中 <code>all-database,table,column</code> 加上 <code>hive</code> user </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 重启 spark 服务</span><br><span class="line">Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br></pre></td></tr></table></figure>

<p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ManagedandExternalTables">hive managed &amp; external tables</a></p>
<p>acid table not supported now （acid new feature in hive，many others does not support it)</p>
<p><a href="https://github.com/Gowthamsb12/BigData-Blogs/blob/master/Spark_ACID">spark-acids thoughts</a></p>
<p><img src="/images/ambari-table-create-in-hive.png" alt="image-20201211154708672"></p>
<p><img src="/images/ambari-table-create-in-spark.png" alt="image-20201211154728273"></p>
<p>I figured it out. Just set: <code>mapred.input.dir.recursive</code> and <code>hive.mapred.supports.subdirectories</code> to <code>true</code>. (Hive-site.xml)</p>
<p> &#x2F;warehouse&#x2F;tablespace&#x2F;managed&#x2F;hive&#x2F;ftms_ods.db&#x2F;test_user6&#x2F;delta_0000001_0000001_0000</p>
<p>&#x2F;warehouse&#x2F;tablespace&#x2F;managed&#x2F;hive&#x2F;ftms_ods.db&#x2F;test_user7&#x2F;part-00000-2a86feec-be9a-413d-a696-8ff115d14075-c000.snappy.orc</p>
<h2 id="包冲突"><a href="#包冲突" class="headerlink" title="包冲突"></a>包冲突</h2><p>xbean-asm5-shaded-4.4.jar</p>
<p>xmlbeans-3.1.0.jar</p>
<p>xercesImpl-2.9.1.jar</p>
<p>xerces2-xsd11-2.11.1.jar</p>
<p>Xmlapis.jar</p>
<h2 id="Xml"><a href="#Xml" class="headerlink" title="Xml"></a>Xml</h2><p>删除 &#x2F;user&#x2F;ftms&#x2F;lib&#x2F;xercesImpl-2.9.1.jar 和 &#x2F;user&#x2F;ftms&#x2F;lib&#x2F;xml-apis-1.3.04.jar</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: User class threw exception: javax.xml.parsers.FactoryConfigurationError: Provider for class javax.xml.parsers.DocumentBuilderFactory cannot be created</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.findServiceProvider(FactoryFinder.java:311)</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.find(FactoryFinder.java:267)</span><br><span class="line">	at javax.xml.parsers.DocumentBuilderFactory.newInstance(DocumentBuilderFactory.java:120)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.asXmlDocument(Configuration.java:3442)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3417)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3388)</span><br><span class="line">	at org.apache.hadoop.conf.Configuration.writeXml(Configuration.java:3384)</span><br><span class="line">	at org.apache.hadoop.hive.conf.HiveConf.getConfVarInputStream(HiveConf.java:2410)</span><br><span class="line">	at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:2703)</span><br><span class="line">	at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:2657)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.hiveConf(HiveMetaStoreUtil.scala:18)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.createHiveMetaStoreClient(HiveMetaStoreUtil.scala:23)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.getHiveMetaStoreClient(HiveMetaStoreUtil.scala:34)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.getHiveTablePartitionCols(HiveMetaStoreUtil.scala:78)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveMetaStoreUtil$.getHiveTablePartitionColNames(HiveMetaStoreUtil.scala:73)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveDataSource$.buildInsertSql(HiveDataSource.scala:7)</span><br><span class="line">	at com.ftms.datapipeline.common.HiveDataSource$.save(HiveDataSource.scala:42)</span><br><span class="line">	at com.ftms.datapipeline.tasks.dwd.DCompany$.main(DCompany.scala:197)</span><br><span class="line">	at com.ftms.datapipeline.tasks.dwd.DCompany.main(DCompany.scala)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721)</span><br><span class="line">Caused by: java.lang.RuntimeException: Provider for class javax.xml.parsers.DocumentBuilderFactory cannot be created</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.findServiceProvider(FactoryFinder.java:308)</span><br><span class="line">	... 23 more</span><br><span class="line">Caused by: java.util.ServiceConfigurationError: javax.xml.parsers.DocumentBuilderFactory: Provider org.apache.xerces.jaxp.DocumentBuilderFactoryImpl not found</span><br><span class="line">	at java.util.ServiceLoader.fail(ServiceLoader.java:239)</span><br><span class="line">	at java.util.ServiceLoader.access$300(ServiceLoader.java:185)</span><br><span class="line">	at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:372)</span><br><span class="line">	at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)</span><br><span class="line">	at java.util.ServiceLoader$1.next(ServiceLoader.java:480)</span><br><span class="line">	at javax.xml.parsers.FactoryFinder$1.run(FactoryFinder.java:294)</span><br><span class="line">	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">	at javax.xml.parsers.FactoryFinder.findServiceProvider(FactoryFinder.java:289)</span><br><span class="line">	... 23 more</span><br></pre></td></tr></table></figure>



<h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><h3 id="在-yarn-client-模式下运行-spark"><a href="#在-yarn-client-模式下运行-spark" class="headerlink" title="在 yarn-client 模式下运行 spark"></a>在 yarn-client 模式下运行 spark</h3><p>会出现 <code>Library directory &#39;...\assembly\target\scala-2.11\jars&#39; does not exist; make sure Spark is built.</code>，这个大致原因是 yarn-client 模式下</p>
<p><a href="https://www.jianshu.com/p/016fbd2a421b"><code>spark.yarn.jar</code>和<code>spark.yarn.archive</code>的使用</a></p>
<blockquote>
<p>Running Spark on YARN requires a binary distribution of Spark which is built with YARN support. Binary distributions can be downloaded from the <a href="https://spark.apache.org/downloads.html">downloads page</a> of the project website. To build Spark yourself, refer to <a href="https://spark.apache.org/docs/latest/building-spark.html">Building Spark</a>.<br> To make Spark runtime jars accessible from YARN side, you can specify <code>spark.yarn.archive</code> or <code>spark.yarn.jars</code>. For details please refer to <a href="https://spark.apache.org/docs/latest/running-on-yarn.html#spark-properties">Spark Properties</a>. If neither <code>spark.yarn.archive</code> nor <code>spark.yarn.jars</code> is specified, Spark will create a zip file with all jars under <code>$SPARK_HOME/jars</code> and upload it to the distributed cache</p>
</blockquote>
<h1 id="Install-ClickHouse"><a href="#Install-ClickHouse" class="headerlink" title="Install ClickHouse"></a>Install ClickHouse</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装 clickhouse</span></span><br><span class="line">$ rpm -ivh clickhouse-server-common-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line">$ rpm -ivh clickhouse-common-static-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line">$ rpm -ivh clickhouse-server-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line">$ rpm -ivh clickhouse-client-19.4.3.11-1.el6.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务</span></span><br><span class="line">$ service clickhouse-server start</span><br><span class="line">Start clickhouse-server service: Path to data directory <span class="keyword">in</span> /etc/clickhouse-server/config.xml: /var/lib/clickhouse/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 client 验证运行成功</span></span><br><span class="line">$ clickhouse-client</span><br><span class="line">ClickHouse client version 19.4.3.11.</span><br><span class="line">Connecting to localhost:9000 as user default.</span><br><span class="line">Connected to ClickHouse server version 19.4.3 revision 54416.</span><br><span class="line"></span><br><span class="line">master :) <span class="keyword">select</span> 1</span><br><span class="line"></span><br><span class="line">SELECT 1</span><br><span class="line"></span><br><span class="line">┌─1─┐</span><br><span class="line">│ 1 │</span><br><span class="line">└───┘</span><br><span class="line"></span><br><span class="line">1 rows <span class="keyword">in</span> <span class="built_in">set</span>. Elapsed: 0.001 sec.</span><br></pre></td></tr></table></figure>

<h2 id="client-启动失败"><a href="#client-启动失败" class="headerlink" title="client 启动失败"></a>client 启动失败</h2><blockquote>
<p>error detail:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ClickHouse client version 20.8.3.18.</span><br><span class="line">Connecting to localhost:9000 as user default.</span><br><span class="line">Code: 102. DB::NetException: Unexpected packet from server localhost:9000 (expected Hello or Exception, got Unknown packet)</span><br></pre></td></tr></table></figure>
</blockquote>
<p>这个错表示，clickhouse-client 收到返回了，但是返回的结果是非预期错误。这个错一般是由于端口占用。可以通过 <code>netstat -antp|grep LIST|grep 9000</code> 查询。</p>
<h3 id="Solution："><a href="#Solution：" class="headerlink" title="Solution："></a>Solution：</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 更新 clickHouse 的端口为 9011</span></span><br><span class="line">$ vi /etc/clickhouse-server/config.xml</span><br><span class="line">:%s/9000/9011</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动时带上端口号</span></span><br><span class="line">$ clickhouse-client --port 9011</span><br></pre></td></tr></table></figure>

<h1 id="安装-python3"><a href="#安装-python3" class="headerlink" title="安装 python3"></a>安装 python3</h1><p><a href="https://www.python.org/downloads/release/python-361/">https://www.python.org/downloads/release/python-361/</a></p>
<p><a href="https://www.jianshu.com/p/758b592387d1">reference doc</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 解压并安装 python3</span></span><br><span class="line">$ tar -xf Python-3.?.?.tar.xz</span><br><span class="line">$ <span class="built_in">cd</span> Python-3.?.?</span><br><span class="line">$ ./configure</span><br><span class="line">$ make altinstall</span><br><span class="line">$ python3.x -V</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建软链</span></span><br><span class="line">$ <span class="built_in">which</span> python3.6</span><br><span class="line">$ <span class="built_in">ln</span> -s /usr/local/bin/python3.6.1 /usr/bin/python3</span><br><span class="line">$ python3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 pip</span></span><br><span class="line">$ python3 -m ensurepip</span><br><span class="line">$ pip3</span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果安装 pip 时报错 zlib not found：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装 zlib 相关依赖包</span></span><br><span class="line">$ yum -y install zlib*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入 python安装包,修改Module路径的setup文件，Modules/Setup.dist （或者 Modules/Setup） 文件</span></span><br><span class="line">$ vi Module/Setup</span><br><span class="line"><span class="comment">#zlib zlibmodule.c -I$(prefix)/include -L$(exec_prefix)/lib -lz</span></span><br><span class="line">去掉注释</span><br><span class="line">     zlib zlibmodule.c -I$(prefix)/include -L$(exec_prefix)/lib -lz</span><br></pre></td></tr></table></figure>
</blockquote>
<h1 id="安装-airflow"><a href="#安装-airflow" class="headerlink" title="安装 airflow"></a>安装 airflow</h1><p>为了方便管理，可以安装个 mpack，然后就可以从 ambari 安装、管理、监控 airflow</p>
<ul>
<li><a href="https://miho120.medium.com/integrating-apache-airflow-with-apache-ambari-ccab2c90173">install airflow from ambari</a></li>
<li><a href="https://github.com/miho120/ambari-airflow-mpack">git</a></li>
</ul>
<p>这个插件在安装&#x2F;启动时，其实就是执行了 <code>/var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts/airflow_scheduler_control.py</code> ，脚本中提供了安装、启动、停止。安装时，本质是执行了以下内容：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ pip install apache-airflow[all]==1.9.0 apache-airflow[celery]==1.9.0</span><br></pre></td></tr></table></figure>

<blockquote>
<p>相关的安装、启动等脚本都在 <code>/var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts</code> 目录下</p>
</blockquote>
<p>但上述过程只能在有线环境执行，离线环境还是得自己下。</p>
<h2 id="install-airflow-offline"><a href="#install-airflow-offline" class="headerlink" title="install airflow offline"></a>install airflow offline</h2><p><a href="https://airflow.apache.org/docs/stable/installation.html">airflow installation 官方</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先下载相关包</span></span><br><span class="line">$ <span class="built_in">mkdir</span> airflow-install</span><br><span class="line">$ <span class="built_in">cd</span> airflow-install</span><br><span class="line">$ pip download <span class="string">&#x27;apache-airflow[all]==1.10.12&#x27;</span> \</span><br><span class="line">--constraint  <span class="string">&#x27;https://raw.githubusercontent.com/apache/airflow/constraints-1.10.12/constraints-3.6.txt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来更新上述 `airflow_scheduler_control.py` 中的安装脚本，选择从本地文件安装即可</span></span><br><span class="line">$ vi /var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts/airflow_scheduler_control.py</span><br><span class="line">$ vi /var/lib/ambari-agent/cache/common-services/AIRFLOW/1.10.0/package/scripts/airflow_webserver_control.py</span><br><span class="line"><span class="comment"># 下边这个命令是上述脚本的内容，这里只是介绍一下执行的命令</span></span><br><span class="line">$ pip install apache-airflow==1.10.12 --no-index -f ./</span><br><span class="line"></span><br><span class="line"><span class="comment"># 过程中可能会有些包缺，例如 docutils、pytest-runner 等，从 https://pypi.org/ 下载相应的 .whl 文件，放到该目录下</span></span><br><span class="line"><span class="comment"># 然后通过 --no-index -f ./ 或者 --no-index -f ./xxx.whl 来安装即可</span></span><br><span class="line">$ pip install pytest-runner --no-index -f ./</span><br></pre></td></tr></table></figure>

<p>实际操作时，下载完 airflow 后，就更新 airflow_scheduler_control.py 和 airflow_webserver_control.py （两个文件的 install method 是一模一样的，按同样的方式修改就行）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">################# 源文件</span></span><br><span class="line">     <span class="number">11</span>         <span class="keyword">def</span> <span class="title function_">install</span>(<span class="params">self, env</span>):</span><br><span class="line">     <span class="number">12</span>                 <span class="keyword">import</span> params</span><br><span class="line">     <span class="number">13</span>                 env.set_params(params)</span><br><span class="line">     <span class="number">14</span>                 <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">30</span>)</span><br><span class="line">     <span class="number">15</span>                 <span class="built_in">print</span>(env)</span><br><span class="line">     <span class="number">16</span>                 <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span> * <span class="number">30</span>)</span><br><span class="line">     <span class="number">17</span>                 self.install_packages(env)</span><br><span class="line">     <span class="number">18</span>                 Logger.info(<span class="built_in">format</span>(<span class="string">&quot;Installing Airflow Service&quot;</span>))</span><br><span class="line">     <span class="number">19</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; pip&quot;</span>))</span><br><span class="line">     <span class="number">20</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; setuptools&quot;</span>))</span><br><span class="line">     <span class="number">21</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; docutils pytest-runner Cython==0.28&quot;</span>))</span><br><span class="line">     <span class="number">22</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-        installed apache-airflow[all]==1.10.0&quot;</span>))</span><br><span class="line">     <span class="number">23</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-        installed apache-airflow[celery]==1.10.0&quot;</span>))</span><br><span class="line">     <span class="number">24</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chmod 755 /bin/airflow /usr/bin/airflow&quot;</span>))</span><br><span class="line">     <span class="number">25</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;useradd &#123;airflow_user&#125;&quot;</span>), ignore_failures=<span class="literal">True</span>)</span><br><span class="line">     <span class="number">26</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;mkdir -p &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">27</span>                 airflow_make_startup_script(env)</span><br><span class="line">     <span class="number">28</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chown -R &#123;airflow_user&#125;:&#123;airflow_group&#125; &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">29</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export AIRFLOW_HOME=&#123;airflow_home&#125; &amp;&amp; airflow initdb&quot;</span>),</span><br><span class="line">     <span class="number">30</span>                         user=params.airflow_user</span><br><span class="line">     <span class="number">31</span>                 )</span><br><span class="line"></span><br><span class="line"><span class="comment">################### 修改后的</span></span><br><span class="line">     <span class="number">11</span>         <span class="keyword">def</span> <span class="title function_">install</span>(<span class="params">self, env</span>):</span><br><span class="line">     <span class="number">12</span>                 <span class="keyword">import</span> params</span><br><span class="line">     <span class="number">13</span>                 env.set_params(params)</span><br><span class="line">    <span class="comment"># 这里是去安装 pip，已经装好了，就不装了</span></span><br><span class="line">     <span class="number">14</span> <span class="comment">#               self.install_packages(env)</span></span><br><span class="line">     <span class="number">15</span>                 Logger.info(<span class="built_in">format</span>(<span class="string">&quot;Installing Airflow Service&quot;</span>))</span><br><span class="line">     <span class="number">16</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; pip&quot;</span>))</span><br><span class="line">     <span class="number">17</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; setuptools&quot;</span>))</span><br><span class="line">    <span class="comment"># 从指定目录找安装包 --no-index -f ./xxx</span></span><br><span class="line">     <span class="number">18</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;pip install --upgrade &#123;airflow_pip_params&#125; docutils pytest-runner Cython --no-index -f /install/python_install/airflow-install/&quot;</span>))</span><br><span class="line">    <span class="comment"># 从指定目录找安装包 --no-index -f ./xxx，并更新版本为 1.10.12，且仅安装 minimal packages</span></span><br><span class="line">     <span class="number">19</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-installed apache-airflow==1.10.12 --no-index -f /install/python_install/airflow-install/&quot;</span>))</span><br><span class="line">    <span class="comment"># 从指定目录找安装包 --no-index -f ./xxx，并更新版本为 1.10.12</span></span><br><span class="line">     <span class="number">20</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export SLUGIFY_USES_TEXT_UNIDECODE=yes &amp;&amp; pip install --upgrade &#123;airflow_pip_params&#125; --ignore-installed apache-airflow[celery]==1.10.12 --no-index -f /install/python_install/airflow-install/&quot;</span>))</span><br><span class="line">    <span class="comment"># 目前系统中默认是安装在 /usr/local/bin/airflow</span></span><br><span class="line">     <span class="number">21</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chmod 755 /usr/local/bin/airflow&quot;</span>))</span><br><span class="line">     <span class="number">22</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;useradd &#123;airflow_user&#125;&quot;</span>), ignore_failures=<span class="literal">True</span>)</span><br><span class="line">     <span class="number">23</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;mkdir -p &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">24</span>                 airflow_make_startup_script(env)</span><br><span class="line">     <span class="number">25</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;chown -R &#123;airflow_user&#125;:&#123;airflow_group&#125; &#123;airflow_home&#125;&quot;</span>))</span><br><span class="line">     <span class="number">26</span>                 Execute(<span class="built_in">format</span>(<span class="string">&quot;export AIRFLOW_HOME=&#123;airflow_home&#125; &amp;&amp; airflow initdb&quot;</span>),</span><br><span class="line">     <span class="number">27</span>                         user=params.airflow_user</span><br><span class="line">     <span class="number">28</span>                 )</span><br></pre></td></tr></table></figure>

<h1 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h1><p><strong>Admin Name</strong> : admin </p>
<p><strong>Cluster Name</strong> : ftms_hdp_qat </p>
<p><strong>Total Hosts</strong> : 3 (3 new) </p>
<p><strong>Repositories</strong>:</p>
<p>redhat7 (HDP-3.1):<br> <a href="http://10.66.18.11/ambari/HDP/centos7/3.1.4.0-315/">http://10.66.18.11/ambari/HDP/centos7/3.1.4.0-315/</a></p>
<p>redhat7 (HDP-3.1-GPL):<br> <a href="http://10.66.18.11/ambari/HDP-GPL/centos7/3.1.4.0-315/">http://10.66.18.11/ambari/HDP-GPL/centos7/3.1.4.0-315/</a></p>
<p>redhat7 (HDP-UTILS-1.1.0.22):<br> <a href="http://10.66.18.11/ambari/HDP-UTILS/centos7/1.1.0.22/">http://10.66.18.11/ambari/HDP-UTILS/centos7/1.1.0.22/</a></p>
<p><strong>Services:</strong></p>
<p><em>HDFS</em> </p>
<p>DataNode : 2 hosts </p>
<p>NameNode : master </p>
<p>NFSGateway : 0 host </p>
<p>SNameNode : slave1 </p>
<p><em>YARN + MapReduce2</em> </p>
<p>Timeline Service V1.5 : slave1 </p>
<p>NodeManager : 1 host </p>
<p>ResourceManager : master </p>
<p>Timeline Service V2.0 Reader : master </p>
<p>Registry DNS : master </p>
<p><em>Tez</em> </p>
<p>Clients : 1 host </p>
<p><em>Hive</em> </p>
<p>Metastore : slave1 </p>
<p>HiveServer2 : slave1 </p>
<p>Database : Existing MySQL &#x2F; MariaDB Database </p>
<p><em>HBase</em> </p>
<p>Master : master </p>
<p>RegionServer : 1 host </p>
<p>Phoenix Query Server : 0 host </p>
<p><em>Sqoop</em> </p>
<p>Clients : 1 host </p>
<p><em>Oozie</em> </p>
<p>Server : master </p>
<p>Database : Existing MySQL &#x2F; MariaDB Database </p>
<p><em>ZooKeeper</em> </p>
<p>Server : 3 hosts </p>
<p><em>Infra Solr</em> </p>
<p>Infra Solr Instance : master </p>
<p><em>Ambari Metrics</em> </p>
<p>Metrics Collector : slave2 </p>
<p>Grafana : master </p>
<p><em>Atlas</em> </p>
<p>Metadata Server : slave1 </p>
<p><em>Kafka</em> </p>
<p>Broker : master </p>
<p><em>Ranger</em> </p>
<p>Admin : slave1 </p>
<p>Tagsync : 1 host </p>
<p>Usersync : slave1 </p>
<p><em>SmartSense</em> </p>
<p>Activity Analyzer : master </p>
<p>Activity Explorer : master </p>
<p>HST Server : master </p>
<p><em>Spark2</em> </p>
<p>Livy for Spark2 Server : 0 host </p>
<p>History Server : master </p>
<p>Thrift Server : 0 host </p>
]]></content>
      <tags>
        <tag>big data</tag>
      </tags>
  </entry>
  <entry>
    <title>在 aws lambda 中应用 jersey</title>
    <url>/2018/06/27/aws-lambda-jersey/</url>
    <content><![CDATA[<p>使用 <a href="https://github.com/awslabs/aws-serverless-java-container">aws serverless java container</a> 实现。</p>
<h1 id="使用-aws-cli"><a href="#使用-aws-cli" class="headerlink" title="使用 aws cli"></a>使用 <a href="https://aws.amazon.com/cn/cli/">aws cli</a></h1><h2 id="创建项目，配置-aws-cli"><a href="#创建项目，配置-aws-cli" class="headerlink" title="创建项目，配置 aws cli"></a>创建项目，配置 aws cli</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用原型创建项目</span></span><br><span class="line">$ mvn archetype:generate -DgroupId=my.service -DartifactId=my-service -Dversion=1.0-SNAPSHOT \</span><br><span class="line">       -DarchetypeGroupId=com.amazonaws.serverless.archetypes \</span><br><span class="line">       -DarchetypeArtifactId=aws-serverless-jersey-archetype \</span><br><span class="line">       -DarchetypeVersion=1.1.3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 aws cli</span></span><br><span class="line">$ pip install awscli</span><br><span class="line"><span class="comment"># 配置 credentials</span></span><br><span class="line">$ aws configure</span><br><span class="line">AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE</span><br><span class="line">AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</span><br><span class="line">Default region name [None]: us-west-2</span><br><span class="line">Default output format [None]: json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 写代码，测试……</span></span><br></pre></td></tr></table></figure>

<p>aws 安装之后一般要配置 credentials，详情可参见 <a href="https://docs.aws.amazon.com/zh_cn/cli/latest/userguide/cli-chap-getting-started.html">aws cli 配置</a></p>
<h2 id="打包部署"><a href="#打包部署" class="headerlink" title="打包部署"></a>打包部署</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># package</span></span><br><span class="line">$ mvn clean package</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传 package 到 s3（需要先创建 s3 bucket）</span></span><br><span class="line">$ aws s3 mb s3://BUCKET_NAME</span><br><span class="line">$ aws cloudformation package --template-file sam.yaml --output-template-file output-sam.yaml --s3-bucket &lt;YOUR S3 BUCKET NAME&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署到 aws lambda</span></span><br><span class="line">$ aws cloudformation deploy --template-file output-sam.yaml --stack-name your-stack-name --capabilities CAPABILITY_IAM</span><br></pre></td></tr></table></figure>

<h2 id="查看部署结果"><a href="#查看部署结果" class="headerlink" title="查看部署结果"></a>查看部署结果</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可查看 stack 详情</span></span><br><span class="line">$ aws cloudformation describe-stacks --stack-name your-stack-name</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;Stacks&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;StackId&quot;</span>: <span class="string">&quot;arn:aws:cloudformation:us-west-2:xxxxxxxx:stack/ServerlessJerseyApi/xxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxx&quot;</span>, </span><br><span class="line">            <span class="string">&quot;Description&quot;</span>: <span class="string">&quot;AWS Serverless Jersey API - learning.aws::aws-lambda-jersey&quot;</span>, </span><br><span class="line">            <span class="string">&quot;Tags&quot;</span>: [], </span><br><span class="line">            <span class="string">&quot;Outputs&quot;</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">&quot;Description&quot;</span>: <span class="string">&quot;URL for application&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;ExportName&quot;</span>: <span class="string">&quot;AwsLambdaJerseyApi&quot;</span>,  </span><br><span class="line">                    <span class="string">&quot;OutputKey&quot;</span>: <span class="string">&quot;AwsLambdaJerseyApi&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;OutputValue&quot;</span>: <span class="string">&quot;https://xxxxxxx.execute-api.us-west-2.amazonaws.com/Prod/ping&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">            ], </span><br><span class="line">            <span class="string">&quot;CreationTime&quot;</span>: <span class="string">&quot;2016-12-13T22:59:31.552Z&quot;</span>, </span><br><span class="line">            <span class="string">&quot;Capabilities&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;CAPABILITY_IAM&quot;</span></span><br><span class="line">            ], </span><br><span class="line">            <span class="string">&quot;StackName&quot;</span>: <span class="string">&quot;ServerlessJerseyApi&quot;</span>, </span><br><span class="line">            <span class="string">&quot;NotificationARNs&quot;</span>: [], </span><br><span class="line">            <span class="string">&quot;StackStatus&quot;</span>: <span class="string">&quot;UPDATE_COMPLETE&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据生成的链接访问 api</span></span><br><span class="line">$ curl https://xxxxxxx.execute-api.us-west-2.amazonaws.com/Prod/ping</span><br></pre></td></tr></table></figure>

<h1 id="使用-sam-cli"><a href="#使用-sam-cli" class="headerlink" title="使用 sam-cli"></a>使用 <a href="https://github.com/awslabs/aws-sam-cli">sam-cli</a></h1><p>aws-cli 只能部署到远端去查看运行效果。而 sam-cli 则可以本地 simulate 一个 lambda 环境，从而实现本地调试。</p>
<h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><p>aws-sam-cli 有个 <code>sam init --runtime java</code>，可以创建一个 sample 项目，但是目前支持的 template 并不包含 jersey 的。所以要创建项目还是通过 mvn archetype。</p>
<p>（所有支持的 runtime 可以查看 <a href="https://github.com/awslabs/aws-sam-cli#project-status">project status</a>）</p>
<p>但是 <code>sam init</code> 创建了一个 <code>template.yaml</code>，这是之后所有 sam 命令的依据。这个文件会被翻译为 <code>mvn archetype</code> 创建的 <code>sam.yaml</code>。因为其后台是利用 <code>aws cli</code> 运行的。</p>
<p>所以我们需要在 <code>mvn archetype</code> 创建了原型之后，手动依据 <code>sam.yaml</code> 创建 <code>template.yaml</code></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用原型创建项目，配置 aws-cli，同上</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 template.yaml</span></span><br><span class="line">$ <span class="built_in">cp</span> sam.yaml template.yaml</span><br></pre></td></tr></table></figure>

<h2 id="部署项目"><a href="#部署项目" class="headerlink" title="部署项目"></a>部署项目</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># package</span></span><br><span class="line">$ mvn clean package</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地测试运行</span></span><br><span class="line">$ sam <span class="built_in">local</span> start-api</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传 package 到 s3（需要先创建 s3 bucket）</span></span><br><span class="line">$ aws s3 mb s3://BUCKET_NAME</span><br><span class="line">$ sam package \</span><br><span class="line">    --template-file template.yaml \</span><br><span class="line">    --output-template-file packaged.yaml \</span><br><span class="line">    --s3-bucket YOUR_S3_BUCKET_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署到 aws lambda</span></span><br><span class="line">$ sam deploy \</span><br><span class="line">    --template-file packaged.yaml \</span><br><span class="line">    --stack-name your-stack-name \</span><br><span class="line">    --capabilities CAPABILITY_IAM \</span><br><span class="line">    --parameter-overrides MyParameterSample=MySampleValue</span><br></pre></td></tr></table></figure>

<p>如果在本地运行时，报错 <code>No class found....</code>，一般是因为 docker 的原因，我最后是通过重装 docker 解决的。由于 aws-sam-cli 使用 docker 去起一个 lambda 容器环境，所以可能是由于 credentials 等获取不到的原因？，总之可能会挂掉。可参见 <a href="https://github.com/docker/for-mac/issues/488">stackoverflow ticket</a>，</p>
<h2 id="查看部署结果-1"><a href="#查看部署结果-1" class="headerlink" title="查看部署结果"></a>查看部署结果</h2><p>这里跟上边是一样的，我们可以只看一部分</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可查看 stack 详情</span></span><br><span class="line">$ aws cloudformation describe-stacks \</span><br><span class="line">    --stack-name your-stack-name \</span><br><span class="line">    --query <span class="string">&#x27;Stacks[].Outputs&#x27;</span></span><br><span class="line">[</span><br><span class="line">    [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;Description&quot;</span>: <span class="string">&quot;URL for application&quot;</span>,</span><br><span class="line">            <span class="string">&quot;ExportName&quot;</span>: <span class="string">&quot;AwsLambdaJerseyApi&quot;</span>,  </span><br><span class="line">            <span class="string">&quot;OutputKey&quot;</span>: <span class="string">&quot;AwsLambdaJerseyApi&quot;</span>,</span><br><span class="line">            <span class="string">&quot;OutputValue&quot;</span>: <span class="string">&quot;https://xxxxxxx.execute-api.us-west-2.amazonaws.com/Prod/ping&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据生成的链接访问 api</span></span><br><span class="line">$ curl https://xxxxxxx.execute-api.us-west-2.amazonaws.com/Prod/ping¡</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>cloud</tag>
        <tag>aws</tag>
      </tags>
  </entry>
  <entry>
    <title>az data engineer certificate</title>
    <url>/2020/10/10/az-data-engineer-certificate/</url>
    <content><![CDATA[<p><a href="https://docs.microsoft.com/zh-cn/learn/certifications/azure-data-engineer?tab=tab-learning-paths">learning paths</a></p>
<h2 id="On-premises-Env-vs-Cloud"><a href="#On-premises-Env-vs-Cloud" class="headerlink" title="On-premises Env vs Cloud"></a>On-premises Env vs Cloud</h2><p><a href="https://docs.microsoft.com/en-us/learn/modules/evolving-world-of-data/3-systems-on-premise-vs-cloud">link</a></p>
<p>The term <em>total cost of ownership</em> (TCO) describes the final cost of owning a given technology. In <strong>on-premises systems</strong>, TCO includes the following costs:</p>
<ul>
<li>Hardware</li>
<li>Software licensing</li>
<li>Labor (installation, upgrades, maintenance)</li>
<li>Datacenter overhead (power, telecommunications, building, heating and cooling)</li>
</ul>
<p><strong>Cloud systems</strong> like Azure track costs by subscriptions. A subscription can be based on usage that’s measured in compute units, hours, or transactions. The cost includes hardware, software, disk storage, and labor. Because of economies of scale, an on-premises system can rarely compete with the cloud in terms of the measurement of the service usage.</p>
<p>The cost of operating an on-premises server system rarely aligns with the actual usage of the system. In cloud systems, the cost usually aligns more closely with the actual usage.</p>
<h4 id="Comment"><a href="#Comment" class="headerlink" title="Comment"></a>Comment</h4><blockquote>
<p>However, many companies use the cloud still in a wasting way. The cost in cloud systems in fact rarely aligns with the actual usage, too.</p>
<p>The main advantage of Cloud is that it can <strong>be charged on usage</strong>. Thus, this advantage only works when using the cloud by need. Otherwise, the cloud advantage evaporates, especially from the aspect of cost.</p>
<p>The advantages of cloud:</p>
<ol>
<li>charge on usage</li>
<li>enjoy the high quality and compresensive services of big company.</li>
</ol>
</blockquote>
<h2 id="Data-types"><a href="#Data-types" class="headerlink" title="Data types"></a>Data types</h2><p><a href="https://docs.microsoft.com/en-us/learn/modules/survey-the-azure-data-platform/2-structured-vs-non-structured">link</a></p>
<p>For nonstructured Data, the data <strong>structure is defined only when the data is read</strong>. The difference in the definition point gives you flexibility to use the same source data for different outputs.</p>
<blockquote>
<p>JSON is in fact semistructured data.</p>
</blockquote>
<p>Examples of nonstructured data include binary, audio, and image files. </p>
<p>NoSQL is in fact semistructured data. The open-source world offers four types of NoSQL databases:</p>
<ol>
<li><strong>Key-value store</strong>: Stores key-value pairs of data in a table structure.</li>
<li><strong>Document database</strong>: Stores documents that are <strong>tagged with metadata</strong> to aid document searches.</li>
<li><strong>Graph database</strong>: Finds relationships between data points by using a structure that’s composed of vertices and edges.</li>
<li><strong>Column database</strong>: Stores data based on columns rather than rows. Columns can be defined at the query’s runtime, allowing flexibility in the data that’s returned performantly.</li>
</ol>
<h3 id="Azure-Storage"><a href="#Azure-Storage" class="headerlink" title="Azure Storage"></a>Azure Storage</h3><p><a href="https://docs.microsoft.com/en-us/learn/modules/survey-the-azure-data-platform/3-store-data-using-azure-store-account">Azure Storage account</a> is the base storage type. It’s mainly used to store data but with poor or no query ability.</p>
<p>Azure Storage offers four configuration options:</p>
<ul>
<li><strong>Azure Blob</strong>: A scalable object store for text and binary data. The cheapst choice to store bot not query data.</li>
<li><strong>Azure Files</strong>: Managed file shares for cloud or on-premises deployments</li>
<li><strong>Azure Queue</strong>: A messaging store for reliable messaging between application components</li>
<li><strong>Azure Table</strong>: A NoSQL store for no-schema storage of structured data</li>
</ul>
<h2 id="Tasks-of-an-Azure-data-engineer"><a href="#Tasks-of-an-Azure-data-engineer" class="headerlink" title="Tasks of an Azure data engineer:"></a>Tasks of an Azure data engineer:</h2><p> <a href="https://docs.microsoft.com/en-us/learn/modules/data-engineering-processes/3-data-engineering-practices">link</a></p>
<p><a href="https://docs.microsoft.com/zh-cn/learn/modules/data-engineering-processes/4-architecturing-project">example</a></p>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/data-engineering-processes/2-roles-and-responsibilities">Data Engineer vs Data Scientist vs AI engineer</a>: Data engineer decide how to organized the data and pre-process the data. Data scientist use the result of Data engineer to create analysis model, and extract value. AI engineer use the existed model &amp; tools to process the data. AI engineer may need the help of Data engineer to store the result, and the help of Data analysis to generate new model.</p>
<p>Here are some of the tasks of an Azure data engineer:</p>
<ul>
<li>Design and develop data storage and data processing solutions for the enterprise.</li>
<li>Set up and deploy cloud-based data services such as blob services, databases, and analytics.</li>
<li>Secure the platform and the stored data. Make sure only the necessary users can access the data.</li>
<li>Ensure business continuity in uncommon conditions by using techniques for high availability and disaster recovery.</li>
<li>Monitor to ensure that the systems run properly and are cost-effective.</li>
</ul>
<h2 id="Plan-the-data-storage-solution"><a href="#Plan-the-data-storage-solution" class="headerlink" title="Plan the data storage solution"></a>Plan the data storage solution</h2><p><a href="https://docs.microsoft.com/en-us/learn/modules/choose-storage-approach-in-azure/3-operations-and-latency">Determine operational needs</a></p>
<p>What are the main operations you’ll be completing on each data type, and what are the performance requirements?</p>
<p>Ask yourself these questions:</p>
<ul>
<li>Will you be doing simple lookups using an ID?</li>
<li>Do you need to query the database for one or more fields?</li>
<li>How many create, update, and delete operations do you expect?</li>
<li>Do you need to run complex analytical queries?</li>
<li>How quickly do these operations need to complete?</li>
</ul>
<p><a href="https://docs.microsoft.com/en-us/learn/modules/choose-storage-approach-in-azure/5-choose-the-right-azure-service-for-your-data">a storage solution example on the e-commerce system</a>: </p>
<ul>
<li><p>Product catalog data: cosmosDB</p>
<ul>
<li><p><strong>Data classification:</strong> Semi-structured because of the need to extend or modify the schema for new products</p>
<p><strong>Operations:</strong></p>
<ul>
<li>Customers require a high number of read operations, with the ability to query on many fields within the database.</li>
<li>The business requires a high number of write operations to track the constantly changing inventory.</li>
</ul>
<p><strong>Latency &amp; throughput:</strong> High throughput and low latency</p>
<p><strong>Transactional support:</strong> Required</p>
</li>
</ul>
</li>
<li><p>Photos &amp; videos: azure blob (with azure CDN)</p>
<ul>
<li><p><strong>Data classification:</strong> Unstructured</p>
<p><strong>Operations:</strong></p>
<ul>
<li>Only need to be retrieved by ID.</li>
<li>Customers require a high number of read operations with low latency.</li>
<li>Creates and updates will be somewhat infrequent and can have higher latency than read operations.</li>
</ul>
<p><strong>Latency &amp; throughput:</strong> Retrievals by ID need to support low latency and high throughput. Creates and updates can have higher latency than read operations.</p>
<p><strong>Transactional support:</strong> Not required</p>
</li>
</ul>
</li>
<li><p>Buisiness Data: azure sql (with azure analysis services)</p>
<ul>
<li><p><strong>Data classification:</strong> Structured</p>
<p><strong>Operations:</strong> Read-only, complex analytical queries across multiple databases</p>
<p><strong>Latency &amp; throughput:</strong> Some latency in the results is expected based on the complex nature of the queries.</p>
<p><strong>Transactional support:</strong> Required</p>
</li>
</ul>
</li>
</ul>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><h2 id="Private-cloud-vs-Public-Cloud-vs-Specific-Cloud"><a href="#Private-cloud-vs-Public-Cloud-vs-Specific-Cloud" class="headerlink" title="Private cloud vs Public Cloud vs Specific Cloud"></a>Private cloud vs Public Cloud vs Specific Cloud</h2><ul>
<li><p><input checked="" disabled="" type="checkbox"> 
Are there still private cloud and public cloud??    &#x3D;&#x3D;&#x3D;&gt; yes</p>
</li>
<li><p><input disabled="" type="checkbox"> 
What’s the difference? The private cloud will have higher quality cloud? The so-called SLA of public cloud is in fact not assured??</p>
</li>
<li><p><input checked="" disabled="" type="checkbox"> 
Maybe there’re also specific cloud, like financial cloud (maybe more secure and fast) &#x3D;&#x3D;&#x3D;&gt; yes</p>
</li>
</ul>
<h4 id="Points"><a href="#Points" class="headerlink" title="Points:"></a>Points:</h4><blockquote>
<ol>
<li>There is specific cloud. Mayi has financial cloud.</li>
<li>There are both public cloud &amp; private cloud, but they’re closely related. That is, they use the same cloud technology (images), but with different clusters &amp; differnt tariff.</li>
</ol>
</blockquote>
<h2 id="Azure-storage-account"><a href="#Azure-storage-account" class="headerlink" title="Azure storage account"></a>Azure storage account</h2><ol>
<li>how to configure to use different type?</li>
<li>Why they’re all in storage account instead of as independant service??</li>
<li>azure blob vs azure file storage</li>
</ol>
<h2 id="Column-database"><a href="#Column-database" class="headerlink" title="Column database"></a>Column database</h2><ol>
<li>How the data is organized in the hardware?</li>
<li>How should we save the data into column database?</li>
<li>Wide Column Stores</li>
<li>BigTable</li>
</ol>
<p>Cosmosdb(Cassendra) vs HBase: infrastructure, load-balance???</p>
<p>Cassendra: Wide Column Stores</p>
<h2 id="ELT-vs-ELTL"><a href="#ELT-vs-ELTL" class="headerlink" title="ELT vs ELTL"></a>ELT vs ELTL</h2><ul>
<li><input disabled="" type="checkbox"> In fact, often ELTL???</li>
<li><input disabled="" type="checkbox"> How is the data stored in T(transform)???</li>
</ul>
<h2 id="Data-Types"><a href="#Data-Types" class="headerlink" title="Data Types"></a>Data Types</h2><ul>
<li><input disabled="" type="checkbox"> what’s markup language???</li>
<li><input disabled="" type="checkbox"> why yaml is not markup language but json is???</li>
</ul>
<h2 id="Azure-SQL"><a href="#Azure-SQL" class="headerlink" title="Azure SQL"></a>Azure SQL</h2><ul>
<li><input disabled="" type="checkbox"> how azure sql support queries across multiple databases??</li>
<li><input disabled="" type="checkbox"> Why does azure sql data warehouse not support???</li>
</ul>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>cloud</tag>
        <tag>certificate</tag>
      </tags>
  </entry>
  <entry>
    <title>bean validator</title>
    <url>/2018/07/18/bean-validator/</url>
    <content><![CDATA[<p>bean validator 主要是验证一个 bean 的各字段是否满足一些约束，例如 <code>@NotNull</code></p>
<p>bean validation 有个规范 <a href="https://beanvalidation.org/2.0/">jsr 380</a>，里边定义了一堆 api。有很多规范的实现，最常用的是 <a href="http://hibernate.org/validator/">hibernate validator</a>，jersey 出的 <a href="https://jersey.github.io/documentation/latest/bean-validation.html">jersey-bean-validation</a> 也是基于 hibernate validator 做的。</p>
<p>bean validator 一般是应用在 web 框架（如 spring、jersey）上，框架在反序列化 rest 请求到 bean 对象时，框架会调用 validator 根据 bean 对象的 annotation 对 bean 进行验证。</p>
<p>这个过程也可以手动进行。可参考 <a href="http://hibernate.org/validator/documentation/getting-started/">hibernate validator: get started</a>。</p>
<h1 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h1><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="comment">// jsr 380 api</span></span><br><span class="line">compile <span class="string">&quot;javax.validation:validation-api:2.0.1.Final&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// hibernate vaidator 实现</span></span><br><span class="line">testCompile <span class="string">&quot;org.hibernate.validator:hibernate-validator:6.0.10.Final&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// hibernate validator 依赖的 JSR 341 实现</span></span><br><span class="line">testCompile <span class="string">&quot;org.glassfish:javax.el:3.0.0&quot;</span></span><br></pre></td></tr></table></figure>

<h1 id="创建-bean，标明约束"><a href="#创建-bean，标明约束" class="headerlink" title="创建 bean，标明约束"></a>创建 bean，标明约束</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.hibernate.validator.referenceguide.chapter01;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.validation.constraints.Min;</span><br><span class="line"><span class="keyword">import</span> javax.validation.constraints.NotNull;</span><br><span class="line"><span class="keyword">import</span> javax.validation.constraints.Size;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Car</span> &#123;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@NotNull</span></span><br><span class="line">   <span class="keyword">private</span> String manufacturer;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@NotNull</span></span><br><span class="line">   <span class="meta">@Size(min = 2, max = 14)</span></span><br><span class="line">   <span class="keyword">private</span> String licensePlate;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Min(2)</span></span><br><span class="line">   <span class="keyword">private</span> <span class="type">int</span> seatCount;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">public</span> <span class="title function_">Car</span><span class="params">(String manufacturer, String licencePlate, <span class="type">int</span> seatCount)</span>&#123;</span><br><span class="line">      <span class="built_in">this</span>.manufacturer = manufacturer;</span><br><span class="line">      <span class="built_in">this</span>.licensePlate = licencePlate;</span><br><span class="line">      <span class="built_in">this</span>.seatCount = seatCount;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><ol>
<li>利用 <code>Validation</code> 获取默认的 <code>ValidatorFactory</code>：<code>Validation.buildDefaultValidatorFactory()</code>；</li>
<li>从 <code>ValidatorFacotry</code> 获取 <code>Validator</code>：<code>factory.getValidator()</code></li>
<li>利用 <code>Validator</code> 验证 bean</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.hibernate.validator.referenceguide.chapter01;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> javax.validation.ConstraintViolation;</span><br><span class="line"><span class="keyword">import</span> javax.validation.Validation;</span><br><span class="line"><span class="keyword">import</span> javax.validation.Validator;</span><br><span class="line"><span class="keyword">import</span> javax.validation.ValidatorFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.junit.BeforeClass;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.assertEquals;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CarTest</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Validator validator;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@BeforeClass</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">setUp</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="type">ValidatorFactory</span> <span class="variable">factory</span> <span class="operator">=</span> Validation.buildDefaultValidatorFactory();</span><br><span class="line">      validator = factory.getValidator();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">manufacturerIsNull</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="type">Car</span> <span class="variable">car</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Car</span>( <span class="literal">null</span>, <span class="string">&quot;DD-AB-123&quot;</span>, <span class="number">4</span> );</span><br><span class="line"></span><br><span class="line">      Set&lt;ConstraintViolation&lt;Car&gt;&gt; constraintViolations =</span><br><span class="line">      validator.validate( car );</span><br><span class="line"></span><br><span class="line">      assertEquals( <span class="number">1</span>, constraintViolations.size() );</span><br><span class="line">      assertEquals(</span><br><span class="line">         <span class="string">&quot;may not be null&quot;</span>,</span><br><span class="line">         constraintViolations.iterator().next().getMessage()</span><br><span class="line">      );</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">licensePlateTooShort</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="type">Car</span> <span class="variable">car</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Car</span>( <span class="string">&quot;Morris&quot;</span>, <span class="string">&quot;D&quot;</span>, <span class="number">4</span> );</span><br><span class="line"></span><br><span class="line">      Set&lt;ConstraintViolation&lt;Car&gt;&gt; constraintViolations =</span><br><span class="line">      validator.validate( car );</span><br><span class="line"></span><br><span class="line">      assertEquals( <span class="number">1</span>, constraintViolations.size() );</span><br><span class="line">      assertEquals(</span><br><span class="line">         <span class="string">&quot;size must be between 2 and 14&quot;</span>,</span><br><span class="line">         constraintViolations.iterator().next().getMessage()</span><br><span class="line">      );</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">seatCountTooLow</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="type">Car</span> <span class="variable">car</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Car</span>( <span class="string">&quot;Morris&quot;</span>, <span class="string">&quot;DD-AB-123&quot;</span>, <span class="number">1</span> );</span><br><span class="line"></span><br><span class="line">      Set&lt;ConstraintViolation&lt;Car&gt;&gt; constraintViolations =</span><br><span class="line">      validator.validate( car );</span><br><span class="line"></span><br><span class="line">      assertEquals( <span class="number">1</span>, constraintViolations.size() );</span><br><span class="line">      assertEquals(</span><br><span class="line">         <span class="string">&quot;must be greater than or equal to 2&quot;</span>,</span><br><span class="line">         constraintViolations.iterator().next().getMessage()</span><br><span class="line">      );</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Test</span></span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">carIsValid</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="type">Car</span> <span class="variable">car</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Car</span>( <span class="string">&quot;Morris&quot;</span>, <span class="string">&quot;DD-AB-123&quot;</span>, <span class="number">2</span> );</span><br><span class="line"></span><br><span class="line">      Set&lt;ConstraintViolation&lt;Car&gt;&gt; constraintViolations =</span><br><span class="line">      validator.validate( car );</span><br><span class="line"></span><br><span class="line">      assertEquals( <span class="number">0</span>, constraintViolations.size() );</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>rest</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 hexo + github 部署博客</title>
    <url>/2018/05/14/build-blog-using-hexo/</url>
    <content><![CDATA[<h1 id="安装部署-hexo"><a href="#安装部署-hexo" class="headerlink" title="安装部署 hexo"></a>安装部署 <a href="https://hexo.io/zh-cn/docs/index.html">hexo</a></h1><p>参考这个<a href="https://zhuanlan.zhihu.com/p/26625249">知乎文章安装</a></p>
<h2 id="1-准备-node、git"><a href="#1-准备-node、git" class="headerlink" title="1. 准备 node、git"></a>1. 准备 node、git</h2><h2 id="2-安装-hexo-cli"><a href="#2-安装-hexo-cli" class="headerlink" title="2. 安装 hexo-cli"></a>2. 安装 hexo-cli</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ npm i -g hexo-cli</span><br></pre></td></tr></table></figure>

<h2 id="3-创建一个网站"><a href="#3-创建一个网站" class="headerlink" title="3. 创建一个网站"></a>3. 创建一个网站</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo init xxx.github.io</span><br></pre></td></tr></table></figure>

<h2 id="4-部署服务器"><a href="#4-部署服务器" class="headerlink" title="4. 部署服务器"></a>4. <a href="https://hexo.io/zh-cn/docs/deployment.html">部署服务器</a></h2><p>这里选择部署到 git 上。</p>
<ol>
<li>首先安装 git deployer</li>
<li>然后修改配置文件，选择部署方式为 git 并配置 repo。</li>
<li>hexo 部署</li>
<li>访问 <code>xxx.github.io</code> 即可</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-deployer-git --save</span><br><span class="line">$ vi _config.yml</span><br><span class="line"></span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: &lt;repository url&gt;</span><br><span class="line">  branch: [branch]</span><br><span class="line">  message: [message]</span><br><span class="line"></span><br><span class="line">$ npm d</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<blockquote>
<ol>
<li>可以选择同时部署到多个服务器。多写几个 ‘deploy’ 配置即可</li>
<li>git 用户名、网站用户名（<code>xxx.github.io</code> 中的 <code>xxx</code>）必须相同。因为它相当于使用 github 服务器</li>
</ol>
</blockquote>
<h1 id="设置-theme"><a href="#设置-theme" class="headerlink" title="设置 theme"></a>设置 theme</h1><p>在 <a href="https://hexo.io/themes/index.html">官方 themes</a> 里挑。我比较喜欢以下几款：</p>
<ol>
<li>带目录结构的：<ol start="2">
<li><a href="https://github.com/probberechts/hexo-theme-cactus/blob/master/README.md">cactus</a>：英文的，有几种颜色可以选，带目录，可以配置搜索，简洁，这是<a href="https://probberechts.github.io/hexo-theme-cactus/cactus-white/public/archives/">white 版本的</a></li>
<li><a href="https://github.com/aircloud/hexo-theme-aircloud">aircloud</a>：英文中文都 ok，有目录，还可以搜索</li>
<li><a href="https://github.com/theme-next/hexo-theme-next">next</a>：有目录，也有集成搜索的文档，这是一个 <a href="http://www.itfanr.cc/about/">example</a>，参照 <a href="https://theme-next.iissnan.com/third-party-services.html">第三方集成</a> 集成搜索等功能. next 优化配置可参考 <a href="http://www.vitah.net/posts/20f300cc/">这篇文章</a></li>
<li><a href="https://github.com/litten/hexo-theme-yilia">yilia</a>：有目录，有搜索，<a href="http://litten.me/2017/12/29/diary-2017-1222-1229/">owner 博客</a></li>
</ol>
</li>
<li>没有目录，没有 tag<ol start="3">
<li><a href="https://github.com/pinggod/hexo-theme-apollo">apollo</a>：<a href="http://pinggod.com/archives/">blog</a> 是中文的，比较简单，颜色也好看</li>
</ol>
</li>
</ol>
<p>配置很简单，以 <a href="https://github.com/litten/hexo-theme-yilia">yilia</a> 为例：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 找到 theme git，download 到 `themes` 文件夹下</span></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/litten/hexo-theme-yilia.git themes/yilia</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 修改 hexo 根目录下的配置文件，指定使用该主题</span></span><br><span class="line">$ vi _config.yml</span><br><span class="line">theme: yilia</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. customize 主题配置. 可以修改 themes 中的 config，也可以直接在 hexo config 中修改</span></span><br><span class="line"><span class="comment">## 修改 themes 中的 _config.yml</span></span><br><span class="line">$ vi themes/yilia/_config.yml</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="comment">## 修改 hexo config</span></span><br><span class="line">$ vi _config.yml</span><br><span class="line">theme_config:</span><br><span class="line">	...</span><br><span class="line">	...</span><br><span class="line">	...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="发表博客"><a href="#发表博客" class="headerlink" title="发表博客"></a>发表博客</h1><h2 id="1-创建博客"><a href="#1-创建博客" class="headerlink" title="1. 创建博客"></a>1. <a href="https://hexo.io/zh-cn/docs/commands.html#new">创建博客</a></h2><p>利用命令创建一个博客，存放在 <code>source/_posts/</code> 下。然后可以编辑这个文件。刷新页面就可以看到博客有更新了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo new titlename</span><br></pre></td></tr></table></figure>

<p>也可以直接把 md 文件 copy 到 <code>source/_posts/</code> 下，可以添加 <a href="https://hexo.io/zh-cn/docs/front-matter.html"><code>frong-matter</code></a> 指定 category、tag 等。</p>
<h2 id="2-生成静态文件"><a href="#2-生成静态文件" class="headerlink" title="2. 生成静态文件"></a>2. <a href="https://hexo.io/zh-cn/docs/generating.html">生成静态文件</a></h2><p><code>hexo g</code> 会根据 md 生成 html、css 等静态文件。文章写完后，利用这个命令生成静态文件，然后再 <code>hexo d</code> 部署即可。</p>
<p>也可以使用下述命令（两个命令等价），指同时 <code>generate</code> + <code>deploy</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo g -d</span><br><span class="line">$ hexo d -g</span><br></pre></td></tr></table></figure>

<h3 id="hexo-clean"><a href="#hexo-clean" class="headerlink" title="hexo clean"></a>hexo clean</h3><p>有时可能需要使用 <a href="https://hexo.io/zh-cn/docs/commands.html#clean"><code>hexo clean</code></a> 清除缓存文件 <code>db.json</code> 和已生成的静态文件 <code>public</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo clean</span><br></pre></td></tr></table></figure>

<h3 id="启动本地服务器（调试用）"><a href="#启动本地服务器（调试用）" class="headerlink" title="启动本地服务器（调试用）"></a><a href="https://hexo.io/zh-cn/docs/commands.html#server">启动本地服务器（调试用）</a></h3><p>博客编辑完成后，可以先本地启动 server，看一下效果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo s</span><br></pre></td></tr></table></figure>

<p><code>-s</code> 参数指定仅仅启动静态模式，即创建博客后，必须要 <code>hexo g</code> 去生成 <code>index.html</code> 等（相当于发布），网站才会真正的更新。否则网站不会更新。这一般用于 <code>production mode</code></p>
<p>一般编辑完文章后，可以先本地启动服务器，调试一下样式可不可以，然后再部署到服务器上</p>
]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>c# basic</title>
    <url>/2019/06/05/c-sharp-basic/</url>
    <content><![CDATA[<h1 id="net-asp-net-c"><a href="#net-asp-net-c" class="headerlink" title=".net, asp.net, c#"></a>.net, asp.net, c#</h1><p>c# is like java language specification;</p>
<p>.net is like jdk&#x2F;javase&#x2F;javaee</p>
<p><a href="https://dotnet.microsoft.com/apps/aspnet">asp.net</a>: is like springboot</p>
<ol>
<li><a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/default-value-expressions">default</a>, as, is</li>
<li>sln: solution ——&gt; csproj: c sharp project ——&gt; files <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/default-value-expressions">.sln vs .csproj</a></li>
</ol>
<h1 id="Key-concepts"><a href="#Key-concepts" class="headerlink" title="Key concepts"></a>Key concepts</h1><p>ref: <a href="https://blog.csdn.net/baidu_32134295/article/details/51285603">c# concepts</a></p>
<ul>
<li><strong>solution</strong>: a complete application, similar to maven project. It contains several c# project like frontend, backend, library to compose a complete application.</li>
<li><strong>project</strong>: similar to maven module. It can be a web project, a library, a windows program, etc.</li>
<li><strong>assembly</strong>: similar to maven jar. A c# project is corresponding to an assembly. An assembly can be a <code>dll</code>, <code>exe</code>, etc.</li>
<li><strong>namespace</strong>: similar to java package. It’s a logical concept to avoid naming conflicts while assembly is a physical concept. A namespace can be in different assemblies and an assembly can contains multiple namespaces.</li>
</ul>
<h1 id="Accessibility-levels"><a href="#Accessibility-levels" class="headerlink" title="Accessibility levels"></a>Accessibility levels</h1><p>ref: <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/accessibility-levels">accessibility levels</a></p>
<ul>
<li><strong>public</strong>: access is not restricted. (all)</li>
<li><strong>private</strong>: limited to containing type (only self)</li>
<li><strong>protected</strong>: limited to the containing class and types derived from the containing class. (sub-classes)</li>
<li><strong>internal</strong>: limited to the current assembly (only the same assembly)</li>
<li><strong>protected internal</strong>: limited to the current assembly or types derived from the containing class (same assembly &amp; sub-classes)</li>
<li><strong>protected private</strong>: limited to the containing class and types derived from the containing class in the current assembly (sub-classes in same assembly)</li>
</ul>
<h1 id="data-types"><a href="#data-types" class="headerlink" title="data types"></a>data types</h1><h2 id="Nullable"><a href="#Nullable" class="headerlink" title="Nullable"></a>Nullable</h2><p><a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/nullable-types/">Nullable<T></a> (T?): similar to Optional in java, but the T can only be <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/introduction#types-and-variables">value type</a>, which are simple types, enum types, struct types, and nullable types. Because value type has no null value (not alike reference type — — object), and there’re situations when their values are undefined, nullable is born.</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="built_in">int</span>? x = <span class="literal">null</span>    <span class="comment">// int? is the shorthand for Nullable&lt;int&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="Delegate"><a href="#Delegate" class="headerlink" title="Delegate"></a>Delegate</h2><p><a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/introduction#delegates">delegate</a> is like <code>@FunctionalInterface</code> in java.</p>
<blockquote>
<p>A <em><strong>delegate type</strong></em> represents references to methods with a particular parameter list and return type. Delegates make it possible to treat methods as entities that can be assigned to variables and passed as parameters. </p>
</blockquote>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="built_in">delegate</span> <span class="built_in">double</span> <span class="title">Function</span>(<span class="params"><span class="built_in">double</span> x</span>)</span>;    <span class="comment">// functional interface definition</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="built_in">double</span>[] <span class="title">Apply</span>(<span class="params"><span class="built_in">double</span>[] a, Function f</span>)</span> &#123;&#125;  <span class="comment">// use delegate as a method param</span></span><br><span class="line"></span><br><span class="line">Apply(&#123;<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">1.0</span>&#125;, (<span class="built_in">double</span> x) -&gt; x*x);   <span class="comment">// define an anoymous function</span></span><br></pre></td></tr></table></figure>

<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><p><a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/introduction#methods">Method</a> contains parameters &amp; return type &amp; body &amp; modifier &amp; type parameters.</p>
<h2 id="parameters"><a href="#parameters" class="headerlink" title="parameters"></a>parameters</h2><p>Argument is where the initial value is from, and parameter is used to pass value&#x2F;references to methods. </p>
<p>Parameter has modifier (e.g. out, final, this, params) and type</p>
<p>Argument are passed as parameter in 4 ways:</p>
<h3 id="value-parameter"><a href="#value-parameter" class="headerlink" title="value parameter:"></a>value parameter:</h3><p>parameter change won’t affect the argument</p>
<ol>
<li>only for input parameter passing</li>
<li>optional by specify default value</li>
</ol>
<h3 id="reference-parameter"><a href="#reference-parameter" class="headerlink" title="reference parameter"></a>reference parameter</h3><p>parameter change will affect the argument</p>
<ol>
<li>for input&#x2F;output parameter passing</li>
</ol>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">swap</span>(<span class="params"><span class="keyword">ref</span> <span class="built_in">int</span> x, <span class="keyword">ref</span> <span class="built_in">int</span> y</span>)</span></span><br></pre></td></tr></table></figure>

<h3 id="output-parameter"><a href="#output-parameter" class="headerlink" title="output parameter"></a>output parameter</h3><p>similar to reference parameter except for that the initial value is unimportant.</p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">divide</span>(<span class="params"><span class="built_in">int</span> x, <span class="built_in">int</span> y, <span class="keyword">out</span> <span class="built_in">int</span> res, <span class="keyword">out</span> <span class="built_in">int</span> remainder</span>)</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">divide(<span class="number">1</span>,<span class="number">2</span>,<span class="keyword">out</span> <span class="keyword">var</span> res, <span class="keyword">out</span> <span class="keyword">var</span> remainder);</span><br></pre></td></tr></table></figure>

<h3 id="parameter-arrays"><a href="#parameter-arrays" class="headerlink" title="parameter arrays"></a>parameter arrays</h3><p>similar to java <code>…</code></p>
<h2 id="extension-methods"><a href="#extension-methods" class="headerlink" title="extension methods"></a>extension methods</h2><p><a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/extension-methods">extension method</a> is a mechanism that you can “add method” to a class without extending from it.</p>
<p>This method:</p>
<ol>
<li>must be static</li>
<li>works in scope when you explictly import the namespace into you source code with a <code>using</code> directive.</li>
<li>must be the first param of method.</li>
<li>when used, it’s same as the normal instance method.</li>
</ol>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">namespace</span> <span class="title">ExtensionMethods</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title">MyExtensions</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="built_in">int</span> <span class="title">WordCount</span>(<span class="params"><span class="keyword">this</span> String str</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> str.Split(<span class="keyword">new</span> <span class="built_in">char</span>[] &#123; <span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;?&#x27;</span> &#125;, </span><br><span class="line">                             StringSplitOptions.RemoveEmptyEntries).Length;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>c#</tag>
      </tags>
  </entry>
  <entry>
    <title>clean mac other storage</title>
    <url>/2021/02/24/clean-mac-other-storage/</url>
    <content><![CDATA[<p>other storage 主要是存的系统的一些缓存、日志等数据。有时会占特别大空间，可以按下列步骤清理</p>
<h2 id="1-暂时关闭-SIP，以能查看和删除系统文件（解决-not-permitted-问题）"><a href="#1-暂时关闭-SIP，以能查看和删除系统文件（解决-not-permitted-问题）" class="headerlink" title="1. 暂时关闭 SIP，以能查看和删除系统文件（解决 not permitted 问题）"></a>1. 暂时关闭 SIP，以能查看和删除系统文件（解决 not permitted 问题）</h2><ol>
<li>以 recover mode 重启电脑：启动时，按 command + R 即可</li>
<li>选择 Utilities -&gt; Terminal</li>
<li>在 Terminal 中输入 <code>csrutil disable</code> 关闭 SIP</li>
<li>重启电脑</li>
</ol>
<p>在完成 clean 后，应该重复 1、2，并在 terminal 中输入 <code>csrutil enable</code> 来启动 SIP</p>
<p>重启电脑后，可以通过 <code>csrutil status</code> 来查看 SIP 服务是否启动（清理完成后应该启动）</p>
<h2 id="2-按-size-查找大文件"><a href="#2-按-size-查找大文件" class="headerlink" title="2. 按 size 查找大文件"></a>2. 按 size 查找大文件</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /</span><br><span class="line">$ sudo <span class="built_in">du</span> -sh  -- *| <span class="built_in">sort</span> -hr</span><br></pre></td></tr></table></figure>

<h2 id="3-常见的大文件"><a href="#3-常见的大文件" class="headerlink" title="3.  常见的大文件"></a>3.  常见的大文件</h2><h3 id="x2F-Libraray-x2F-Caches-和-x2F-Library-x2F-Caches"><a href="#x2F-Libraray-x2F-Caches-和-x2F-Library-x2F-Caches" class="headerlink" title="~&#x2F;Libraray&#x2F;Caches 和  &#x2F;Library&#x2F;Caches"></a>~&#x2F;Libraray&#x2F;Caches 和  &#x2F;Library&#x2F;Caches</h3><p><code>~/Libraray</code> 和  <code>/Library</code> 下的 <code>Caches</code> 和 <code>logs</code> 等都是可以安全删除的。可以查看一下大小，把自己不用的 cache 删掉。</p>
<p>当然也可以查看 <code>Library</code> 下的所有大文件，确认是否可以删除</p>
<h3 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h3><p>Docker 的 images、volumes 等可能占很大空间，可以查看到 <code>~/Library/Containers/com.docker.docker</code> 文件夹的大小</p>
<p><a href="https://docs.docker.com/docker-for-mac/space/">docker space for mac</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/Library/Containers</span><br><span class="line">$ sudo <span class="built_in">du</span> -sh  -- *| <span class="built_in">sort</span> -hr</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 docker 的系统占用，这是清理后了，占用很小</span></span><br><span class="line">$ docker system <span class="built_in">df</span></span><br><span class="line">TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE</span><br><span class="line">Images              1                   1                   100.8kB             0B (0%)</span><br><span class="line">Containers          1                   0                   0B                  0B</span><br><span class="line">Local Volumes       0                   0                   0B                  0B</span><br><span class="line">Build Cache         0                   0                   0B                  0B</span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理磁盘，删除关闭的容器、无用的数据卷和网络，以及 dangling 镜像(即无 tag 的镜像)</span></span><br><span class="line">$ docker system prune</span><br><span class="line"><span class="comment"># 清理得更加彻底，可以将没有容器使用 Docker 镜像都删掉</span></span><br><span class="line">$ docker system prune -a</span><br><span class="line"><span class="comment"># 如果需要同时删除未被任何容器引用的数据卷需要显式的指定 --volumns 参数</span></span><br><span class="line">$ docker system prune --all --force --volumes</span><br><span class="line"><span class="comment"># 删除所有 dangling 数据卷(即无用的 volume)</span></span><br><span class="line">$ docker volume <span class="built_in">rm</span> $(docker volume <span class="built_in">ls</span> -qf dangling=<span class="literal">true</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 有时删完后，需要一段时间 reclaim space，可以使用以下命令，手动 trigger relamation</span></span><br><span class="line">$ docker run --privileged --pid=host docker/desktop-reclaim-space</span><br></pre></td></tr></table></figure>

<h3 id="x2F-Library-x2F-Updates"><a href="#x2F-Library-x2F-Updates" class="headerlink" title="&#x2F;Library&#x2F;Updates"></a>&#x2F;Library&#x2F;Updates</h3><p>这里可能会有很多文件，都可以删。这里正常应该在执行 App Store 里的 Update 时，才会有文件，但不知道为啥，即使 App Store 没有 Update 也会有。</p>
<p>如果这里有大文件，那么：</p>
<ol>
<li>先尝试去执行 App Store 里的 Update</li>
<li>如果还有文件，可以删除文件夹里的所有文件（建议不要删那几个 <code>.plist</code> 文件），不要删除 <code>/Library/Updates</code> 文件夹本身，删除里边的内容</li>
</ol>
<h3 id="x2F-private-x2F-var-x2F-tmp-x2F-WiFiDiagnostics"><a href="#x2F-private-x2F-var-x2F-tmp-x2F-WiFiDiagnostics" class="headerlink" title="&#x2F;private&#x2F;var&#x2F;tmp&#x2F;WiFiDiagnostics*"></a>&#x2F;private&#x2F;var&#x2F;tmp&#x2F;WiFiDiagnostics*</h3><p><code>/private/var/tmp/</code> 里的文件删除的时候要小心些。</p>
<p><code>WiFiDiagnostics</code> 是 wifi log，这些文件<strong>可以安全删除</strong></p>
<p>但它可以用  <code>command+control+option+shift+w</code> 或 <code>command+control+option+shift+&gt;</code> 触发。如果你正好使用 karabiner 并且 remap 了 <code>command+control+option+shift</code>，在使用过程中可能正好和 +w 或 +&gt; 冲突了，那么每次都会启动 logging。所以需要修改配置。</p>
<ol>
<li>karabiner -&gt; Misc -&gt; Open config folder</li>
<li>open karabiner.json，在其中加入下面的配置</li>
</ol>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;rules&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Disabling command+control+option+shift+w. This triggers wifi logging.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;manipulators&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;w&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;mandatory&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;command&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;control&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;option&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;shift&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;escape&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;basic&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Disabling command+control+option+shift+&gt;. This triggers wifi logging also.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;manipulators&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&gt;&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;mandatory&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;command&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;control&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;option&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;shift&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;escape&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;basic&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Change caps_lock key to command+control+option+shift. (Post escape key when pressed alone)&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;manipulators&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;caps_lock&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;optional&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;any&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;left_shift&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;modifiers&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;left_command&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;left_control&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;left_option&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;to_if_alone&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                    <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;key_code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;escape&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;basic&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>/private/var/tmp</code> 文件夹下可能还有很多 <code>sysdiagnose</code> 文件，这个应该是可以删，是系统诊断结果。但不太确定，我没删。</p>
<p>Sysdiagnose 可以通过 <code>command+control+option+shift+.</code> 来启动一次，所以也要注意</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>code license</title>
    <url>/2018/07/26/code-license/</url>
    <content><![CDATA[<p>license 是软件的授权许可。</p>
<p>对于开源软件来说，虽然别人可以用，但是用的时候希望别人遵循一些要求，比如，使用时必须标明原作者是谁、可以做怎样的修改、软件被用作不正规用途原作者是否要负责……这些其实就是一个协议。</p>
<p>对于作者来说，自己为开源代码写符合法律条规的繁冗的 license 太麻烦，所以就可以采用广为流传的开源协议（eg. MIT, CC…），在 license 文件中标明 “Licnse under the MIT license”</p>
<h1 id="快速选择"><a href="#快速选择" class="headerlink" title="快速选择"></a>快速选择</h1><p>详细的协议选择可以从 github <a href="https://choosealicense.com/">choose license</a> 项目中选。下边列些常用的（参见 <a href="https://www.cnblogs.com/Wayou/p/how_to_choose_a_license.html">如何为你的代码选择一个开源协议</a>）</p>
<h2 id="MIT-协议"><a href="#MIT-协议" class="headerlink" title="MIT 协议"></a>MIT 协议</h2><p>宽松但覆盖一般要点。此协议允许别人以任何方式使用你的代码同时署名原作者，但原作者不承担代码使用后的风险，当然也没有技术支持的义务。jQuery和Rails就是MIT协议</p>
<h2 id="apache-协议"><a href="#apache-协议" class="headerlink" title="apache 协议"></a>apache 协议</h2><p>作品涉及到专利，可以考虑这个。也比较宽松，但考虑了专利，简单指明了作品归属者对用户专利上的一些授权（我的理解是软件作品中含有专利，但它授权你可以免费使用）。Apache服务器，SVN还有NuGet等是使用的Apache协议。</p>
<h2 id="GPL"><a href="#GPL" class="headerlink" title="GPL"></a>GPL</h2><p>对作品的传播和修改有约束的，可以使用这个。GPL（<a href="http://choosealicense.com/licenses/gpl-v2">V2</a>或<a href="http://choosealicense.com/licenses/gpl-v3">V3</a>）是一种版本自由的协议（可以参照copy right来理解，后者是版本保留，那copyleft便是版权自由，或者无版权，但无版权不代表你可以不遵守软件中声明的协议）。此协议要求代码分发者或者以此代码为基础开发出来的衍生作品需要以同样的协议来发布。此协议的版本3与版本2相近，只是多3中加了条对于不支持修改后代码运行的硬件的限制（没太明白此句话的内涵）。</p>
]]></content>
  </entry>
  <entry>
    <title>data lake</title>
    <url>/2020/11/09/data-lake/</url>
    <content><![CDATA[<h1 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h1><p><a href="https://zhuanlan.zhihu.com/p/91165577">数据湖</a></p>
<p>数据湖是：</p>
<ol>
<li>装有一些便于提取、分析、搜索、挖掘的设备（本身不具备分析能力，是其他分析工具可以方便的在湖上运行，而不需要把湖的数据挪出去再分析）</li>
<li>存放各种数据（格式不统一，原始数据）：结构、半结构、非结构化</li>
<li>来源各种各样，能很方便的导入到数据湖</li>
</ol>
<p><strong>数据湖就是原始数据保存区</strong>. 虽然这个概念国内谈的少，但<strong>绝大部分互联网公司都已经有了</strong>。国内一般把整个HDFS叫做数据仓库（广义），<strong>即存放所有数据的地方</strong>，而国外一般叫数据湖（data lake）。把需要的数据导入到数据湖，如果你想结合来自数据湖的信息和客户关系管理系统（CRM）里面的信息，我们就进行连接，<strong>只有需要时才执行这番数据结合</strong>。</p>
<p>数据湖是多结构数据的系统或存储库，它们以原始格式和模式存储，通常作为对象“blob”或文件存储。数据湖的主要思想是对企业中的所有数据进行统一存储，从原始数据（源系统数据的精确副本）转换为用于报告、可视化、分析和机器学习等各种任务的目标数据。数据湖中的数据包括结构化数据（关系数据库数据），半结构化数据（CSV、XML、JSON等），非结构化数据（电子邮件，文档，PDF）和二进制数据（图像、音频、视频），从而形成一个容纳所有形式数据的集中式数据存储。</p>
<p>数据湖从本质上来讲，是一种企业数据架构方法，物理实现上则是一个数据存储平台，用来集中化存储企业内海量的、多来源，多种类的数据，<strong>并支持对数据进行快速加工和分析</strong> (支持直接在数据湖上运行分析，而无需将数据移至单独的分析系统）。从实现方式来看，目前Hadoop是最常用的部署数据湖的技术，但并不意味着数据湖就是指Hadoop集群。为了应对不同业务需求的特点，MPP数据库+Hadoop集群+传统数据仓库这种“混搭”架构的数据湖也越来越多出现在企业信息化建设规划中。</p>
<blockquote>
<p><code>Data Lake</code>： 数据湖<br><code>Data Swamp</code>： 数据沼泽<br><code>Data Mart</code>： 数据集市<br><code>Data Warehouse</code>： 数据仓库<br><code>Data Cube</code>：数据立方体<br><code>Data Stream</code>：数据流<br><code>Data Virtualization</code>：数据虚拟化</p>
</blockquote>
<h2 id="错误认知"><a href="#错误认知" class="headerlink" title="错误认知"></a>错误认知</h2><ul>
<li>错误认知1： 数据湖仅用于“存储”数据<ul>
<li>支持对数据进行快速加工和分析。支持直接在数据湖上运行分析，而无需将数据移至单独的分析系统</li>
</ul>
</li>
<li>错误认知2：数据湖仅存储“原始”数据<ul>
<li>需要有定义的机制来编目和保护数据。这些元素并非原始数据，而是对数据湖的管理数据。</li>
</ul>
</li>
</ul>
<h2 id="数据和和分析解决方案的基本要素"><a href="#数据和和分析解决方案的基本要素" class="headerlink" title="数据和和分析解决方案的基本要素"></a>数据和和分析解决方案的基本要素</h2><p>组织构建数据湖和分析平台时，他们需要考虑许多关键功能，包括：</p>
<h4 id="数据移动（支持大规模的数据以原始形式导入）"><a href="#数据移动（支持大规模的数据以原始形式导入）" class="headerlink" title="数据移动（支持大规模的数据以原始形式导入）"></a>数据移动（支持大规模的数据以原始形式导入）</h4><p>数据湖允许您导入任何数量的实时获得的数据。您可以从多个来源收集数据，并以其原始形式将其移入到数据湖中。此过程允许您扩展到任何规模的数据，同时节省定义数据结构、Schema 和转换的时间。</p>
<h4 id="安全地存储和编目数据（编目使得数据是被监督的，可用的）"><a href="#安全地存储和编目数据（编目使得数据是被监督的，可用的）" class="headerlink" title="安全地存储和编目数据（编目使得数据是被监督的，可用的）"></a>安全地存储和编目数据（编目使得数据是被监督的，可用的）</h4><p>数据湖允许您存储关系数据（例如，来自业务线应用程序的运营数据库和数据）和非关系数据（例如，来自移动应用程序、IoT 设备和社交媒体的运营数据库和数据）。它们还使您能够通过<strong>对数据进行爬网、编目和建立索引</strong>来了解湖中的数据。最后，必须保护数据以确保您的数据资产受到保护。</p>
<blockquote>
<p>是数据湖里的数据本身有索引吗？还是基于数据湖做catalog、元数据管理等？catalog 即是对数据湖数据的索引？？？</p>
</blockquote>
<h4 id="分析（可以直接在数据湖上，运行快速加工和分析）"><a href="#分析（可以直接在数据湖上，运行快速加工和分析）" class="headerlink" title="分析（可以直接在数据湖上，运行快速加工和分析）"></a>分析（可以直接在数据湖上，运行快速加工和分析）</h4><p>数据湖允许组织中的各种角色（如数据科学家、数据开发人员和业务分析师）通过各自选择的分析工具和框架来访问数据。这包括 Apache Hadoop、Presto 和 Apache Spark 等开源框架，以及数据仓库和商业智能供应商提供的商业产品。<strong>数据湖允许您运行分析，而无需将数据移至单独的分析系统</strong>。</p>
<h4 id="机器学习（在数据湖上进行机器学习）"><a href="#机器学习（在数据湖上进行机器学习）" class="headerlink" title="机器学习（在数据湖上进行机器学习）"></a>机器学习（在数据湖上进行机器学习）</h4><p>数据湖将允许组织生成不同类型的见解，包括报告历史数据以及进行机器学习（构建模型以预测可能的结果），并建议一系列规定的行动以实现最佳结果。</p>
<h1 id="Data-swamp"><a href="#Data-swamp" class="headerlink" title="Data swamp"></a>Data swamp</h1><p>搭建数据湖容易，但是让数据湖发挥价值是很难。如果只是一直往里面灌数据，而应用场景极少，没有输出或者极少输出，形成<strong>单向湖</strong>。</p>
<p>企业的业务是实时在变化的，这代表着沉积在数据湖中的数据定义、数据格式实时都在发生的转变，企业的大型数据湖对企业数据治理（Data Governance）提升了更高的要求。大部分使用数据湖的企业在数据真的需要使用的时候，往往因为数据湖中的数据质量太差而无法最终使用。数据湖，被企业当成一个大数据的垃圾桶，最终数据湖成为臭气熏天，存储在Hadoop当中的数据成为无人可以清理的数据沼泽.</p>
<p>数据湖架构的主要挑战是存储原始数据而不监督内容。对于使数据可用的数据湖，它需要有定义的机制来编目和保护数据。没有这些元素，就无法找到或信任数据，从而导致出现“<a href="https://www.gartner.com/newsroom/id/2809117">数据沼泽</a>”。 满足更广泛受众的需求需要数据湖具有管理、语义一致性和访问控制。</p>
<p><img src="https://pic2.zhimg.com/80/v2-7f3ec7c14c46b4e7328f74e44529ad21_720w.jpg" alt="img"></p>
<h1 id="Data-Lake-v-s-Data-Warehouse"><a href="#Data-Lake-v-s-Data-Warehouse" class="headerlink" title="Data Lake v.s. Data Warehouse"></a>Data Lake v.s. Data Warehouse</h1><p><a href="https://aws.amazon.com/cn/big-data/datalakes-and-analytics/what-is-a-data-lake/">aws 什么是数据湖</a></p>
<p><a href="https://dbaplus.cn/news-141-2924-1.html">数据仓库、数据湖 -&gt; 数据中台</a></p>
<p>数据仓库里的数据都满足特定的 schema，而数据湖则没有。仓库里的数据是简单整理过的，湖里的则是原始的（但不全是原始的）。仓库里的来源也都是规范的关系数据，而湖里则什么都有。</p>
<p>数据仓库是一个优化的数据库，用于分析来自事务系统和业务线应用程序的关系数据。事先定义数据结构和 Schema 以优化快速 SQL 查询，其中结果通常用于操作报告和分析。数据经过了清理、丰富和转换，因此可以充当用户可信任的“单一信息源”。</p>
<p>数据湖有所不同，因为它存储来自业务线应用程序的关系数据，以及来自移动应用程序、IoT 设备和社交媒体的非关系数据。捕获数据时，未定义数据结构或 Schema。这意味着您可以存储所有数据，而不需要精心设计也无需知道将来您可能需要哪些问题的答案。您可以对数据使用不同类型的分析（如 SQL 查询、大数据分析、全文搜索、实时分析和机器学习）来获得见解。</p>
<p>随着使用数据仓库的组织看到数据湖的优势，他们正在改进其仓库以包括数据湖，并启用各种查询功能、数据科学使用案例和用于发现新信息模型的高级功能。Gartner 将此演变称为“分析型数据管理解决方案”或“<a href="https://www.gartner.com/doc/3614317/magic-quadrant-data-management-solutions">DMSA</a>”。</p>
<table>
<thead>
<tr>
<th align="center">特性</th>
<th align="center">数据仓库</th>
<th align="center">数据湖</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>数据</strong></td>
<td align="center">来自事务系统、运营数据库和业务线应用程序的<strong>关系数据</strong></td>
<td align="center">来自 IoT 设备、网站、移动应用程序、社交媒体和企业应用程序的<strong>非关系和关系数据</strong></td>
</tr>
<tr>
<td align="center"><strong>Schema</strong></td>
<td align="center">设计在数据仓库实施之前（写入型 Schema）</td>
<td align="center">写入在分析时（读取型 Schema）</td>
</tr>
<tr>
<td align="center"><strong>性价比</strong></td>
<td align="center">更快查询结果会带来较高存储成本</td>
<td align="center">更快查询结果只需较低存储成本</td>
</tr>
<tr>
<td align="center">**数据质量 **</td>
<td align="center">可作为重要事实依据的高度监管数据</td>
<td align="center">任何可以或无法进行监管的数据（例如原始数据）</td>
</tr>
<tr>
<td align="center"><strong>用户</strong></td>
<td align="center">业务分析师</td>
<td align="center">数据科学家、数据开发人员和业务分析师（使用监管数据）</td>
</tr>
<tr>
<td align="center"><strong>分析</strong></td>
<td align="center">批处理报告、BI 和可视化</td>
<td align="center">机器学习、预测分析、数据发现和分析</td>
</tr>
</tbody></table>
<p><img src="https://pic2.zhimg.com/80/v2-9eb32acb557b22322749f775c17b0079_720w.jpg" alt="img"></p>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>duplicate rows in postgresql</title>
    <url>/2018/11/06/duplicate-rows-in-postgresql/</url>
    <content><![CDATA[<p>参见 <a href="https://blog.theodo.fr/2018/01/search-destroy-duplicate-rows-postgresql/">Search and destroy duplicate rows in PostgreSQL</a></p>
<h1 id="Find-duplicates"><a href="#Find-duplicates" class="headerlink" title="Find duplicates"></a>Find duplicates</h1><h2 id="using-group"><a href="#using-group" class="headerlink" title="using group"></a>using group</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  firstname,</span><br><span class="line">  lastname,</span><br><span class="line">  <span class="built_in">count</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> people</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span></span><br><span class="line">  firstname,</span><br><span class="line">  lastname</span><br><span class="line"><span class="keyword">HAVING</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="operator">&gt;</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<h2 id="using-partition"><a href="#using-partition" class="headerlink" title="using partition"></a>using partition</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span></span><br><span class="line">  (<span class="keyword">SELECT</span> <span class="operator">*</span>, <span class="built_in">count</span>(<span class="operator">*</span>)</span><br><span class="line">  <span class="keyword">OVER</span></span><br><span class="line">    (<span class="keyword">PARTITION</span> <span class="keyword">BY</span></span><br><span class="line">      firstname,</span><br><span class="line">      lastname</span><br><span class="line">    ) <span class="keyword">AS</span> count</span><br><span class="line">  <span class="keyword">FROM</span> people) tableWithCount</span><br><span class="line">  <span class="keyword">WHERE</span> tableWithCount.count <span class="operator">&gt;</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<h2 id="Using-not-strict-distinct"><a href="#Using-not-strict-distinct" class="headerlink" title="Using not strict distinct"></a>Using not strict distinct</h2><p>利用 not strict distinct <code>DISTINCT ON</code> 找到唯一的那些条，剩余的就是重复的，可以修改或删除</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> people <span class="keyword">WHERE</span> people.id <span class="keyword">NOT</span> <span class="keyword">IN</span> </span><br><span class="line">(<span class="keyword">SELECT</span> id <span class="keyword">FROM</span> (</span><br><span class="line">    <span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> <span class="keyword">ON</span> (firstname, lastname) <span class="operator">*</span></span><br><span class="line">  <span class="keyword">FROM</span> people));</span><br><span class="line"></span><br><span class="line"><span class="operator">/</span><span class="operator">/</span> more readable code</span><br><span class="line"><span class="keyword">WITH</span> <span class="keyword">unique</span> <span class="keyword">AS</span></span><br><span class="line">    (<span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> <span class="keyword">ON</span> (firstname, lastname) <span class="operator">*</span> <span class="keyword">FROM</span> people)</span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> people <span class="keyword">WHERE</span> people.id <span class="keyword">NOT</span> <span class="keyword">IN</span> (<span class="keyword">SELECT</span> id <span class="keyword">FROM</span> <span class="keyword">unique</span>);</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title>fantastic tools</title>
    <url>/2022/10/22/fantastic-tools/</url>
    <content><![CDATA[<h1 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h1><p>收集一些在设计时可能会用到的比较好的网站</p>
<ul>
<li><a href="https://fontawesome.com/v4.7.0/icons/">icons from the fontawesome</a>: 各种各样的图标，很漂亮</li>
<li><a href="https://ant.design/docs/spec/introduce-cn">ant design</a>：里边有 UI 设计价值观及图标资源等，还有前端组件库</li>
</ul>
<h2 id="前端组件库"><a href="#前端组件库" class="headerlink" title="前端组件库"></a>前端组件库</h2><p><a href="https://zhuanlan.zhihu.com/p/24650288">组件库大合集</a></p>
<p><a href="https://github.com/JingwenTian/awesome-frontend">组件库大合集2</a></p>
<h1 id="mac"><a href="#mac" class="headerlink" title="mac"></a>mac</h1><p><a href="https://insights.thoughtworks.cn/ocds-guide-to-setting-up-mac/">强迫症的Mac设置指南</a></p>
<h2 id="terminal"><a href="#terminal" class="headerlink" title="terminal"></a>terminal</h2><p>[10 Must know terminal commands and tips for productivity](10 Must know terminal commands and tips for productivity) 介绍了一些，简单罗列下：</p>
<ol>
<li><code>iterm2</code>：是一种 terminal，将其作为默认 terminal，可以方便的分屏等</li>
<li><code>oh my zsh</code>：管理 zsh 配置的，使用 <code>~/.zshrc</code>，利用 <code>source ~/.zshrc</code> 可以是配置立马生效<ol>
<li><a href="https://hustyichi.github.io/2018/09/19/oh-my-zsh/">oh my zsh 插件</a></li>
</ol>
</li>
<li><code>cat</code>：不打开文件的情况下查看内容</li>
<li><code>imgcat</code>：同上，不过查看的是图片</li>
<li><code>less [filename]</code>：同 <code>cat</code>，不过如果长文件，可以用这个，仅显示一部分</li>
<li><code>pbcopy &lt; [filename]</code>：复制文件内容到 clipboard</li>
<li><code>touch</code>：创建各种各样的文件，可以同时创建多个。eg. <code>touch index.html readme.md index.php</code></li>
<li><code>lsof -i :[port]</code>：查看端口占用</li>
<li><code>&amp;&amp;</code>：实现 command chaining，即同时写多个命令，依次执行。eg. <code>npm i &amp;&amp; npm start</code></li>
<li><code>open .</code>：打开当前目录</li>
</ol>
<h3 id="iterm2-oh-my-zsh-theme-配置"><a href="#iterm2-oh-my-zsh-theme-配置" class="headerlink" title="iterm2 + oh my zsh + theme 配置"></a>iterm2 + oh my zsh + theme 配置</h3><ol>
<li><a href="https://www.iterm2.com/">download iterm2</a>，解压安装</li>
<li>设置 iterm2 为默认 terminal：iterm2 -&gt; make iterm2 default Term</li>
<li>安装 <a href="https://github.com/robbyrussell/oh-my-zsh">oh my zsh</a>: <ul>
<li><code>sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; </code></li>
</ul>
</li>
<li>配置主题和颜色<ol start="4">
<li>主题，我选用默认的 robbyrussell。其他下载主题然后在 <code>~/.zshrc</code> 中配置 <code>ZSH_THEME</code></li>
<li>颜色，下载 <a href="https://github.com/mbadolato/iTerm2-Color-Schemes">iterm2 color schemes</a>，然后在 iterm2 perferences -&gt; profiles -&gt; colors -&gt; color presets -&gt; import -&gt; 从前边下载的库中选择自己喜欢的 scheme</li>
</ol>
</li>
<li>配置高亮<ul>
<li><code>brew install zsh-syntax-highlighting</code></li>
<li>在 <code>~/.zshrc</code> 中添加：<code>source /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh</code></li>
<li>刷新配置使其生效：<code>source ~/.zshrc</code></li>
</ul>
</li>
<li>显示快捷键配置<ul>
<li>preferences -&gt; keys -&gt; hotKey -&gt; Show&#x2F;Hide all… -&gt; 设置为 <code>⌘.</code></li>
</ul>
</li>
<li>常用的配置：<ol>
<li>配置新开重开使用之前的目录：preferences -&gt; profiles -&gt; general -&gt; working directory -&gt; reuse previous session’s directory</li>
<li>配置快速切换 iterm 的快捷键：preferences -&gt; keys -&gt; hot key -&gt; show&#x2F;hide all windows with a system-wide hotkey</li>
<li>配置窗口透明度和默认启动大小：preferences -&gt; profiles -&gt; window</li>
<li>配置 command line move-by-word, delete-by-word: preferences -&gt; profiles -&gt; keys (<a href="https://apple.stackexchange.com/questions/154292/iterm-going-one-word-backwards-and-forwards">stackoverflow</a>)<ol>
<li>向左移动 by word (⌥b)，向右移动 by word (⌥f)，删除右边 by word (⌥d)<ol>
<li>Under Profile Shortcut Keys, click the + sign.</li>
<li>Type your key shortcut (option-b, option-f, option-d, option-left, etc.)</li>
<li>For Action, choose Send Escape Sequence.</li>
<li>Write b, d or f in the input field.</li>
</ol>
</li>
<li>删除左边 by word (⌥⌫)<ol>
<li>preferences -&gt; profiles -&gt; keys -&gt; left option (⌥) key : Esc+</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="iterm2-常用快捷键"><a href="#iterm2-常用快捷键" class="headerlink" title="iterm2 常用快捷键"></a>iterm2 常用快捷键</h3><ul>
<li><code>⌘d</code>：横分屏</li>
<li><code>⌘⇧d</code>：竖分屏</li>
<li><code>⌘⌥ + direction</code>：navigate between panes</li>
<li><code>⌘.</code>：show&#x2F;hide iterm2</li>
<li><code>⌘⇧↩︎</code>: 最大化当前 pane &#x2F; 回复当前 pane</li>
</ul>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><ul>
<li><a href="https://github.com/newren/git-filter-repo">git-fitler-repo</a></li>
<li>常用的 git config 配置</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在 ~/.zshrc 中添加 alias</span></span><br><span class="line">$ vi ~/.zshrc</span><br><span class="line"><span class="built_in">alias</span> g=<span class="string">&quot;/usr/bin/git&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 .gitconfig 中添加 alias 配置</span></span><br><span class="line">$ vi ~/.gitconfig</span><br><span class="line">[user]</span><br><span class="line">        name = xxx</span><br><span class="line">        email = xxx@some.com</span><br><span class="line"></span><br><span class="line">[<span class="built_in">alias</span>]</span><br><span class="line">        a = add</span><br><span class="line">        aa = add .</span><br><span class="line">        b = branch</span><br><span class="line">        c = commit</span><br><span class="line">        cm = commit -m</span><br><span class="line">        ca = commit --amend</span><br><span class="line">        d = diff</span><br><span class="line">        l = <span class="built_in">log</span> --graph --pretty=format:<span class="string">&#x27;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr)%Creset | %C(bold)%an&#x27;</span> --abbrev-commit --<span class="built_in">date</span>=relative</span><br><span class="line">        o = checkout</span><br><span class="line">        pl = pull</span><br><span class="line">        pb = pull --rebase</span><br><span class="line">        ps = push</span><br><span class="line">        r = reset</span><br><span class="line">        st = status</span><br></pre></td></tr></table></figure>



<h1 id="reading"><a href="#reading" class="headerlink" title="reading"></a>reading</h1><ul>
<li><a href="http://www.shuwu.mobi/">我的小书屋</a></li>
<li><a href="http://readfree.me/">readfree</a>：可以直接推送到 kindle，很方便</li>
<li><a href="http://bulaoge.cn/">不老歌</a>：写日记</li>
<li><a href="https://www.baoshuu.com/">宝书网</a></li>
</ul>
<h1 id="music"><a href="#music" class="headerlink" title="music"></a>music</h1><ul>
<li><a href="https://www.sq688.com/">超高无损音乐下载</a></li>
</ul>
<h1 id="json"><a href="#json" class="headerlink" title="json"></a>json</h1><ul>
<li><a href="https://jsonformatter.org/xml-viewer">json formatter</a>: json、xml 等都支持，可以格式化，有 json tree，统计了节点数</li>
<li><a href="https://jsoneditoronline.org/">json editor online</a>: 界面简单，有 json tree，统计了 tree 节点数</li>
<li><a href="http://jsonviewer.stack.hu/">json viewer</a>: 功能精简，格式化 json，没有 tree</li>
<li><a href="https://codebeautify.org/yaml-to-json-xml-csv">yaml to json</a>: yaml 和 json 之间的转化</li>
</ul>
<h1 id="Editing"><a href="#Editing" class="headerlink" title="Editing"></a>Editing</h1><ul>
<li>typora: markdown tool</li>
<li><a href="https://github.com/Clipy/Clipy">clipy</a>: free tool for pasting</li>
</ul>
<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><ul>
<li><a href="https://karabiner-elements.pqrs.org/">karabiner</a>: 定义快捷键。可以将 caps 键重新映射，在自定义快捷键时避免冲突</li>
<li><a href="https://github.com/fikovnik/ShiftIt">shiftit</a>: 窗口 size &amp; location 定义。用 brew 安装 <code>brew cask install shiftit</code></li>
<li>Eudic: 好用的词典，可以有一个简单悬浮窗口</li>
<li>Alfred: easy used spotlight substitute to search in Mac</li>
<li><a href="https://mediaatelier.com/CheatSheet/?lang=en">cheatsheet</a>: 显示当前应用的快捷键。Just hold the ⌘-Key a bit longer to get a list of all active short cuts of the current application.</li>
</ul>
<h1 id="给图片加水印"><a href="#给图片加水印" class="headerlink" title="给图片加水印"></a>给图片加水印</h1><ul>
<li>美图秀秀：批量添加水印，编辑水印位置、大小、透明度</li>
<li><a href="https://jingyan.baidu.com/article/0eb457e555170643f1a90592.html">Photoshop 批量添加水印</a></li>
<li>免费软件：<ul>
<li><a href="https://www.xnview.com/en/xnconvert/#downloads">XnConvert</a>：<a href="https://uiiiuiii.com/software/202192.html">使用 XnConvert 批量添加水印</a></li>
<li><a href="https://imagemagick.org/index.php">imagemagick</a>: 基于命令行的图形处理库（现有的图像处理软件大多都用到此库）</li>
</ul>
</li>
<li><a href="https://sspai.com/post/53079">6 个小工具，打造图片批处理工作流</a></li>
</ul>
<h2 id="ImageMagick"><a href="#ImageMagick" class="headerlink" title="ImageMagick"></a>ImageMagick</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">$ brew install imagemagick</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /images</span><br><span class="line"><span class="comment"># 获取图片基本信息</span></span><br><span class="line">$ identify a.jpg</span><br><span class="line"><span class="comment"># 转换图片格式</span></span><br><span class="line">$ magick a.jpg a.png</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量为图片添加水印</span></span><br><span class="line">  1 <span class="comment">#!/bin/bash</span></span><br><span class="line">  2</span><br><span class="line">  3 <span class="built_in">dir</span>=<span class="variable">$1</span></span><br><span class="line">  4 mark=<span class="variable">$2</span></span><br><span class="line">  5</span><br><span class="line">  6 <span class="built_in">echo</span> <span class="string">&quot;the images dir to process: <span class="variable">$dir</span>&quot;</span></span><br><span class="line">  7 <span class="built_in">echo</span> <span class="string">&quot;the mark location: <span class="variable">$mark</span>&quot;</span></span><br><span class="line">  8</span><br><span class="line">  9 <span class="built_in">shopt</span> -s nullglob <span class="comment"># 如果不添加这个，当目录中没有 .png 类型的文件时，他会产生 &quot;$dir&quot;/*.png，那么后边就会报错</span></span><br><span class="line"> 10 <span class="keyword">for</span> each <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$dir</span>&quot;</span>/&#123;*.jpg,*.jpeg,*.png&#125;</span><br><span class="line"> 11 <span class="keyword">do</span></span><br><span class="line"> 12         <span class="built_in">echo</span> <span class="string">&quot;each is: <span class="variable">$each</span>&quot;</span></span><br><span class="line"> 13         convert <span class="variable">$each</span> <span class="variable">$mark</span> -gravity southeast -geometry +5+20 -composite <span class="variable">$each</span></span><br><span class="line"> 14         convert <span class="variable">$each</span> <span class="variable">$mark</span> -gravity center -composite <span class="variable">$each</span></span><br><span class="line"> 15         convert <span class="variable">$each</span> <span class="variable">$mark</span> -gravity northwest -geometry +5+20 -composite <span class="variable">$each</span></span><br><span class="line"> 16         <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$each</span>: done&quot;</span></span><br><span class="line"> 17 <span class="keyword">done</span></span><br><span class="line"> 18 <span class="built_in">shopt</span> -u nullglob</span><br><span class="line"> 19 <span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>

<h1 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h1><h2 id="terminal-1"><a href="#terminal-1" class="headerlink" title="terminal"></a>terminal</h2><p><a href="https://p3terx.com/archives/the-strongest-terminal-solution-under-windows-10.html">打造 Windows 10 下最强终端方案：WSL + Terminus + Oh My Zsh + The Fuck</a></p>
<blockquote>
<p>注意这里装的是 wsl1，可以改成 wsl2，参见<a href="https://docs.microsoft.com/en-us/windows/wsl/install">install wsl</a></p>
</blockquote>
<h2 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h2><p>mac 下有免费的 clipy 来实现 copy history，windows 下有 <a href="https://copyq.readthedocs.io/en/latest/basic-usage.html">copyq</a>（也可以用于 mac）</p>
<p>copyq 在它的窗口里可以配置各种命令的快捷键（全局或程序内），包括显示和隐藏 copyq 窗口的</p>
<h2 id="search"><a href="#search" class="headerlink" title="search"></a>search</h2><p>mac 下有 alfred 来搜索文件，windows 有一些替代的：</p>
<ol>
<li>listary：有免费版</li>
<li>wox：开源</li>
</ol>
]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>构建</title>
    <url>/2018/08/16/gradle-build/</url>
    <content><![CDATA[<h1 id="Problems"><a href="#Problems" class="headerlink" title="Problems?"></a>Problems?</h1><ol>
<li>manifest 是干什么用的？</li>
<li>代码运行时，如何找到 dependency 的包</li>
<li>java -jar 时，classpath 指定？</li>
</ol>
<h1 id="classpath"><a href="#classpath" class="headerlink" title="classpath"></a>classpath</h1><p>classpath 指定的是 java 类所在的目录（包括当前项目的类、依赖的类等）。应该是当打 jar 包的时候，默认会加上当前目录(.)到 classpath，这样就包含了 jar 内部的类？</p>
<h1 id="Thin-jar"><a href="#Thin-jar" class="headerlink" title="Thin jar"></a>Thin jar</h1><p><a href="https://github.com/cuzfrog/gradle-lean">gradle lean</a></p>
<p>This plugin depends on <code>JavaPlugin</code> and <code>ApplicationPlugin</code>.</p>
<ul>
<li>for <code>installDist</code>, jars under <code>install/$PROJECT_NAME$/lib/</code></li>
<li>for <code>distZip</code>, jars under <code>/lib/</code> inside package</li>
</ul>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">plugins &#123;</span><br><span class="line">    id <span class="string">&#x27;java&#x27;</span></span><br><span class="line">    <span class="comment">// Apply the application plugin to add support for building a CLI application.</span></span><br><span class="line">    id <span class="string">&#x27;application&#x27;</span></span><br><span class="line"></span><br><span class="line">    id <span class="string">&#x27;scala&#x27;</span></span><br><span class="line"></span><br><span class="line">    id <span class="string">&#x27;com.github.maiflai.scalatest&#x27;</span> version <span class="string">&#x27;0.26&#x27;</span></span><br><span class="line"></span><br><span class="line">    id <span class="string">&quot;com.github.gradle-lean&quot;</span> version <span class="string">&quot;0.1.2&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="implementation-vs-compile-vs-api"><a href="#implementation-vs-compile-vs-api" class="headerlink" title="implementation vs compile vs api"></a>implementation vs compile vs api</h1><p><a href="https://stackoverflow.com/questions/44493378/whats-the-difference-between-implementation-and-compile-in-gradle">stackoverflow</a></p>
<h1 id="Dependency-Conflict"><a href="#Dependency-Conflict" class="headerlink" title="Dependency Conflict"></a>Dependency Conflict</h1><h2 id="force-some-edition"><a href="#force-some-edition" class="headerlink" title="force some edition"></a>force some edition</h2><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">configurations.all &#123;</span><br><span class="line">    resolutionStrategy &#123;</span><br><span class="line">        force <span class="string">&#x27;com.fasterxml.jackson.module:jackson-module-scala_2.11:2.10.3&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>gradle</tag>
        <tag>build</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>gradle test performance</title>
    <url>/2018/10/12/gradle-test-performance/</url>
    <content><![CDATA[<p><a href="https://docs.gradle.org/current/dsl/org.gradle.api.tasks.testing.Test.html#org.gradle.api.tasks.testing.Test:forkEvery">gradle test configurations</a></p>
<p><a href="https://discuss.gradle.org/t/parallel-test-execution-with-gradle-maxparallelforks-property/15136">one sample config</a></p>
<p><a href="https://guides.gradle.org/performance/">ways to improve performance of gradle build</a></p>
<p>common used properties:</p>
<ul>
<li><code>jvmArgs</code>: jvm 参数。通常会配置堆栈大小，保证测试对内存的要求。<ul>
<li><code>&#39;-Xms128m&#39;, &#39;-Xmx1024m&#39;, &#39;-XX:MaxMetaspaceSize=128m&#39;</code>。<code>-Xms</code> 是初始堆大小，<code>-Xmx</code> 是最大堆大小，<code>-XX:MaxMetaspaceSize</code> 是 class metadata 可占用的最大本地内存（默认是 unlimited）。具体 jvm 参数参考 <a href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html">java doc</a>.</li>
</ul>
</li>
<li><code>forkEvery</code>: 每个 test process 里跑的 test classes 的最大个数。当次数达到限制后，会自动重启。这定义了一个测试线程什么时候回重启，与并发无关。默认是 0，即无最大限制，就是可以一直跑</li>
<li><code>maxParalleForks</code>: 能并发跑的最大 test processes 数目</li>
<li><code>systemProperty</code>: 系统属性</li>
<li><code>environment</code>：系统环境变量</li>
<li><code>include</code>: 具体执行的测试。可以通过这个配置不同的测试级别（单元测试、集成测试、functional 测试……）</li>
</ul>
]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>guice</title>
    <url>/2018/08/17/guice/</url>
    <content><![CDATA[<p><a href="https://gist.github.com/virasak/3798194">TEST with GUICE</a></p>
]]></content>
  </entry>
  <entry>
    <title>hadoop</title>
    <url>/2019/01/07/hadoop/</url>
    <content><![CDATA[<p>Hadoop is a framework of distributed storage &amp; computing.</p>
<ul>
<li><strong>distributed storage</strong>: hadoop use <strong>HDFS</strong> to save large amount of data in cluster.</li>
<li><strong>distributed computing</strong>: hadoop use <strong>map-reduce</strong> framework to conduct fast data analysis (query &amp; writing) over data in HDFS.</li>
<li><strong>resource manager &amp; job schedular</strong>: hadoop use <strong>yarn</strong> to manage&#x2F;allocate cluster resources (memory, cpu, etc.) and to schedule  and moniter job executing.</li>
</ul>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><h2 id="cluster-architecture"><a href="#cluster-architecture" class="headerlink" title="cluster architecture"></a>cluster architecture</h2><p><img src="/../images/hadoop-20201026164010368.png" alt="image-20201026164010368"></p>
<p><img src="/../images/hadoop-20201026164402103.png" alt="image-20201026164402103"></p>
<h2 id="request-processing"><a href="#request-processing" class="headerlink" title="request processing"></a>request processing</h2><p><img src="/../images/hadoop-20201026164147039.png" alt="image-20201026164147039"></p>
<h2 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h2><p>Use <strong>rack aware</strong> so that your replicas will be saved into different racks, which can solve the rack failure issue.</p>
<p>Each data node will send heartbeat and block report to the namenode. Thus when data node fails, the name node knows it and will re-replicated to 3.</p>
<p><img src="/../images/hadoop-20201026164613209.png" alt="image-20201026164613209"></p>
<h2 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h2><p><strong>High Availability: Percentage of Uptime of the system</strong>. Fault Tolerance, on the other hand, mainly focus on the data loss &#x2F; system un-recovered damage tolerance. For example, a name-node failure can be processed by reboot from the aspect of fault-tolerance, while there must be a <strong>quick</strong> working solution from the aspect of high availability.</p>
<h3 id="Name-Node-Failure"><a href="#Name-Node-Failure" class="headerlink" title="Name Node Failure"></a>Name Node Failure</h3><p>For a name node failure, we want to switch to a standby name node with all the informations quickly. How?</p>
<p>A name node saves the file namespaces in memory, besides, it also saved editlog for each change into the disk. A name node failure will lose the in-memory fsImage, but we can reproduce the fsImage from the editlogs</p>
<p><img src="/../images/hadoop-20201026165814244.png" alt="y"></p>
<p>A common solution is to use QJM to save the editlogs. And the standby name node will read from the editlogs to rebuild the fsImage. Besides, there’s  two failover controllers on each name node and a zookeeper. ZooKeeper keeps a lock, and both name nodes are requesting the lock. When the active name node fails, it lost the lock, and the standby nn will acquire the lock.</p>
<p><img src="/../images/hadoop-20201026170521244.png" alt="image-20201026170521244"></p>
<h3 id="Name-Node-Reboot"><a href="#Name-Node-Reboot" class="headerlink" title="Name Node Reboot"></a>Name Node Reboot</h3><p>What if you just want to reboot the name node, and since the fsImage is in memory, it will be gone at once and it takes a long time to rebuild from the editlogs?</p>
<p>The main issue here is that the fsImage is in memory. Thus to reboot quickly, we need to save the fsImage into disk. The secondary name node is for this. It periodically merge the old fsImage with the editlogs, and replace the old fsImage in the disk, and then truncate the logs.</p>
<p>Secondary Name Node is not necessary. If needed, you can build it on the standby nn.</p>
<p><img src="/../images/hadoop-20201026171217319.png" alt="image-20201026171217319"></p>
<h3 id="install-hadoop-on-mac"><a href="#install-hadoop-on-mac" class="headerlink" title="install hadoop on mac"></a><a href="http://www.cnblogs.com/micrari/p/5716851.html">install hadoop on mac</a></h3><p>see <a href="http://kontext.tech/docs/DataAndBusinessIntelligence/p/default-ports-used-by-hadoop-services-hdfs-mapreduce-yarn">default ports used by hadoop services 3.1.0</a></p>
<blockquote>
<p>when config password-free login by ssh, it may only work when generate key into id_rsa&#x2F;id_dsa. The other user defind key file name won’t work.</p>
</blockquote>
<ul>
<li><strong>access hdfs</strong></li>
</ul>
<p><a href="https://ambari.apache.org/1.2.3/installing-hadoop-using-ambari/content/reference_chap2_1.html">hdfs default ports</a> are changed. see <a href="https://issues.apache.org/jira/browse/HDFS-9427">hdfs issue</a>, or check the <code>dfs.namenode.http-address</code> property in <a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml">hdfs-default.xml</a> for the newest setting.</p>
<blockquote>
<p>Namenode ports: 50470 –&gt; 9871, 50070 –&gt; 9870, 8020 –&gt; 9820<br>Secondary NN ports: 50091 –&gt; 9869, 50090 –&gt; 9868<br>Datanode ports: 50020 –&gt; 9867, 50010 –&gt; 9866, 50475 –&gt; 9865, 50075 – &gt;9864</p>
</blockquote>
<p>When running the example, it seems that jar can only search files. Thus you need to ensure there’s no sub-dirs in search dir.</p>
<ul>
<li><strong>access yarn</strong></li>
</ul>
<p>Access resource manager through <code>localhost:8088</code>. Or check the property <code>yarn.resourcemanager.webapp.address</code> in  <a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-yarn/hadoop-yarn-common/yarn-default.xml">yarn-default.xml</a> for the newest configuration</p>
<h4 id="start-hadoop-locally"><a href="#start-hadoop-locally" class="headerlink" title="start hadoop locally"></a>start hadoop locally</h4><p><a href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">map reduce</a> is a framework to write applications which process vast amounts of data in-parallel on large clusters. </p>
<p>A map-reduce job usually splits the input data into independent chunks, and <strong>map</strong> in a parallel manner. Then the frameworks sorts the output and then <strong>reduce</strong> to the integrate output.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># initialize the namenode</span></span><br><span class="line">$ hdfs namenode -format</span><br><span class="line"><span class="comment"># start namenode and datanode daemon (access namenode at localhost:9870)</span></span><br><span class="line">$ start-dfs.sh</span><br><span class="line"><span class="comment"># start ResourceManager &amp; NodeManager daemon (access yarn at localhost:8088)</span></span><br><span class="line">$ start-yarn.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># stop namenode and datanode daemon</span></span><br><span class="line">$ stop-dfs.sh</span><br><span class="line"><span class="comment"># stop ResourceManager &amp; NodeManager daemon</span></span><br><span class="line">$ stop-yarn.sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Note:</p>
<p>The <code>hdfs namenode -format</code> command must be executed everytime you restarted your computer. And it’s initialized again. Need to figure out other ways to avoid this.</p>
</blockquote>
<p>There are other commands used to start these daemon:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># deprecated to use the above</span></span><br><span class="line">$ start-all.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># used on specific node (eg. when a new node is added into the cluster, execute on that node)</span></span><br><span class="line">$ hadoop-daemon.sh start datanode/namenode</span><br><span class="line">$ yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>storage</tag>
        <tag>hadoop</tag>
        <tag>distributed computing</tag>
      </tags>
  </entry>
  <entry>
    <title>hdfs</title>
    <url>/2019/01/07/hdfs/</url>
    <content><![CDATA[<h1 id="hdfs-architecture"><a href="#hdfs-architecture" class="headerlink" title="hdfs architecture"></a><a href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html#The+File+System+Namespace">hdfs architecture</a></h1><p>HDFS 集群以 master-slave 模型运行。其中有两种节点：</p>
<ul>
<li>namenode: master node. know where the files are to find in hdfs</li>
<li>datanode: slave node: have the data of the files</li>
</ul>
<p><img src="https://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif" alt="architecture"></p>
<h1 id="namenode"><a href="#namenode" class="headerlink" title="namenode"></a>namenode</h1><p>参见 <a href="https://www.cnblogs.com/shitouer/archive/2013/01/07/2837683.html">namenode and datanode</a></p>
<p>Namenode 管理着文件系统的Namespace。它维护着文件系统树(filesystem tree)以及文件树中所有的文件和文件夹的元数据(metadata)。管理这些信息的文件有两个，分别是Namespace 镜像文件(Namespace image)和操作日志文件(edit log)，这些信息被Cache在RAM中，当然，这两个文件也会被持久化存储在本地硬盘。Namenode记录着每个文件中各个块 (block) 所在的数据节点的位置信息，但是他并不持久化存储这些信息，因为这些信息会在系统启动时从数据节点重建。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/721960-5d86c88472cd002a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="namenode.png"></p>
<p>每个 file 有多个 block 构成，这些 block 分散的存储在各个 datanode 上（并且根据 replication factor，有冗余副本），而 namenode 知道如何一个 file 有哪些 block (file 的元数据信息)，根据 datanode 发送给它的 block 列表，namenode 就可以构建每个文件中各个 block 的位置信息。即根据文件元数据 + datanode block 列表，可以重建文件 block 位置信息，因此不需要持久化。</p>
<h2 id="容错机制"><a href="#容错机制" class="headerlink" title="容错机制"></a>容错机制</h2><p>由于 datanode 只是分布式地存储 block，不知道这些 block 是怎么组织成文件，以及文件是怎么组织成文件树的。因此 namenode 一旦当掉，整个文件系统就挂了（没办法写和查文件）。因此 namenode 的容错机制很重要。常见的方式：</p>
<ol>
<li>同步备份。即 namenode 中需要持久化存储的镜像文件和log，同步地持久化存储到其他文件系统中。</li>
<li>secondary namenode (异步)。secondary namenode 一般定期地去同步本地 namenode 的镜像和 log。但除此之外，secondary namenode 还有其他用途，比如合并镜像和log（避免文件过大），这个合并过程很占用 cpu 和内存，所以正好在 secondary namenode 上做。合并完后，在 secondary namenode 上也保存一份。不过这种备份恢复会丢掉一部分数据。</li>
</ol>
<h1 id="datanode"><a href="#datanode" class="headerlink" title="datanode"></a>datanode</h1><p>datanode 根据客户端或者 namenode 调度存储&#x2F;检索数据，并定期向 namenode 发送它们所存储的 block 列表。</p>
<h1 id="commands"><a href="#commands" class="headerlink" title="commands"></a>commands</h1><h2 id="hdfs-namenode-format"><a href="#hdfs-namenode-format" class="headerlink" title="hdfs namenode -format"></a>hdfs namenode -format</h2><p><a href="https://stackoverflow.com/questions/27143409/what-the-command-hadoop-namenode-format-will-do">stackoverflow</a></p>
<p>Remove all metadata in namenode. Initialize the namenode. However, the data in datanode is not removed.</p>
<h2 id="hdfs-dfs-mkdir-xxx"><a href="#hdfs-dfs-mkdir-xxx" class="headerlink" title="hdfs dfs -mkdir xxx"></a>hdfs dfs -mkdir xxx</h2><p>Create a directory. To see the data location, see <code>local storage</code></p>
<h2 id="hdfs-dfs-put-source-dest"><a href="#hdfs-dfs-put-source-dest" class="headerlink" title="hdfs dfs -put source dest"></a>hdfs dfs -put source dest</h2><p>copy content in source to dest</p>
<h2 id="hdfs-dfs-get"><a href="#hdfs-dfs-get" class="headerlink" title="hdfs dfs -get"></a>hdfs dfs -get</h2><h2 id="hdfs-dfs-du-h-v"><a href="#hdfs-dfs-du-h-v" class="headerlink" title="hdfs dfs -du -h -v"></a>hdfs dfs -du -h -v</h2><p>It displays sizes of files and directories contained in the given directory or the length of a file in case it’s just a file.</p>
<ul>
<li>The <strong>-s</strong> option will result in an <strong>aggregate summary of file lengths</strong> being displayed, rather than the individual files. Without the -s option, the calculation is done by going 1-level deep from the given path.</li>
<li>The <strong>-h</strong> option will format file sizes in a <strong>human-readable</strong> fashion (e.g 64.0m instead of 67108864)</li>
<li>The <strong>-v</strong> option will display <strong>the names of columns</strong> as a header line.</li>
<li>The <strong>-x</strong> option will <strong>exclude snapshots</strong> from the result calculation. Without the -x option (default), the result is always calculated from all INodes, including all snapshots under the given path.</li>
</ul>
<h2 id="hadoop-fs-count-h-x2F-dir-x2F"><a href="#hadoop-fs-count-h-x2F-dir-x2F" class="headerlink" title="hadoop fs -count -h &#x2F;dir&#x2F;*"></a>hadoop fs -count -h &#x2F;dir&#x2F;*</h2><p>显示文件夹下的所有文件数、大小</p>
<h1 id="web-ui"><a href="#web-ui" class="headerlink" title="web ui"></a>web ui</h1><p><a href="https://ambari.apache.org/1.2.3/installing-hadoop-using-ambari/content/reference_chap2_1.html">hdfs default ports</a> are changed. see <a href="https://issues.apache.org/jira/browse/HDFS-9427">here</a></p>
<blockquote>
<p>Namenode ports: 50470 –&gt; 9871, 50070 –&gt; 9870, 8020 –&gt; 9820<br>Secondary NN ports: 50091 –&gt; 9869, 50090 –&gt; 9868<br>Datanode ports: 50020 –&gt; 9867, 50010 –&gt; 9866, 50475 –&gt; 9865, 50075 –&gt; 9864</p>
</blockquote>
<h2 id="local-storage"><a href="#local-storage" class="headerlink" title="local storage"></a>local storage</h2><p>From localhost:9870, you can get the namenode information. To see the data you created locally:</p>
<ol>
<li>Login localhost:9870, <strong>get the ‘<em>configuration</em>‘ from the ‘<em>utilities</em>‘</strong></li>
<li>Find <code>dfs.datanode.data.dir</code>  to get the data location</li>
</ol>
<h2 id="Issue-Permission-denied-user-x3D-dr-who"><a href="#Issue-Permission-denied-user-x3D-dr-who" class="headerlink" title="Issue: Permission denied: user&#x3D;dr.who"></a>Issue: Permission denied: user&#x3D;dr.who</h2><p>When ‘<em>browse the file system</em>‘ from ‘<em>utilities</em>‘, there are some dirs (e.g. <code>/tmp</code>) you have no permission to access. It may show:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Permission denied: user=dr.who, access=READ_EXECUTE, inode=&quot;/tmp&quot;:cherish:supergroup:drwx------</span><br></pre></td></tr></table></figure>

<p>The ‘<em>dr.who</em>‘ is just a configured static user in <code>core-default.xml</code>:</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">hadoop.http.staticuser.user</span>=<span class="string">dr.who</span></span><br></pre></td></tr></table></figure>

<p>And there is permission check because it’s set to check by default in <code>hdfs-default.xml</code>:</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">dfs.permissions.enabled</span>=<span class="string">true </span></span><br></pre></td></tr></table></figure>

<p>There are three ways to solve it:</p>
<h3 id="solutions"><a href="#solutions" class="headerlink" title="solutions"></a>solutions</h3><h4 id="disable-the-permission-check"><a href="#disable-the-permission-check" class="headerlink" title="disable the permission check"></a>disable the permission check</h4><blockquote>
<p>This is not recommended in the prod mode.</p>
</blockquote>
<p>Add the following property in <code>hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="change-the-staticuser"><a href="#change-the-staticuser" class="headerlink" title="change the staticuser"></a>change the staticuser</h4><p>Add the following property in <code>core-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>cherish<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="modify-the-file-permission"><a href="#modify-the-file-permission" class="headerlink" title="modify the file permission"></a>modify the file permission</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ hdfs dfs -<span class="built_in">chmod</span> -R 755 /tmp</span><br></pre></td></tr></table></figure>

<h1 id="Replica"><a href="#Replica" class="headerlink" title="Replica"></a>Replica</h1>]]></content>
      <tags>
        <tag>big data</tag>
        <tag>storage</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo+next 设置</title>
    <url>/2018/06/14/hexo-next/</url>
    <content><![CDATA[<p><a href="https://hfcherish.github.io/2018/05/23/build-blog-using-hexo/">使用 hexo + github 部署博客</a> 介绍了怎么部署自己的博客，然后就开始无休止的调整主题。</p>
<p>我选定的主题是 <a href="https://github.com/theme-next/hexo-theme-next">next</a>：有目录，也有集成搜索的文档，这是一个 <a href="http://www.itfanr.cc/about/">example</a>，参照 <a href="https://theme-next.iissnan.com/third-party-services.html">第三方集成</a> 集成搜索等功能. next 优化配置可参考 <a href="http://www.vitah.net/posts/20f300cc/">这篇文章</a></p>
<h1 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h1><p>我是采用两个配置文件的写法，即在 <code>source/_data/next.yml</code> 中写 next 相关的配置。</p>
<h1 id="code-highlight-配置"><a href="#code-highlight-配置" class="headerlink" title="code highlight 配置"></a>code highlight 配置</h1><p>按照<a href="https://theme-next.iissnan.com/getting-started.html#theme-settings">主题设定教程</a>，我设置的是 <code>scheme: Mist</code>。默认的代码 highlight 是用 <a href="https://github.com/chriskempson/tomorrow-theme">tomorrow theme</a>，按照 <a href="https://theme-next.iissnan.com/theme-settings.html#syntax-highlight-scheme">代码高亮设置教程</a>，可以有五种选项。但是很多 code grammar 高亮显示无效，比如 jsx。所以想换一个 highlight 主题。</p>
<p>找了个 <a href="https://vxhly.github.io/2017/10/hexo-next-advanced-settings/">code highlight theme 配置教程</a> ，开始动手。</p>
]]></content>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title>hikariCP configuration</title>
    <url>/2018/07/19/hikariCP-configuration/</url>
    <content><![CDATA[<p><a href="https://github.com/brettwooldridge/HikariCP">hikariCP</a> 是一个轻量级的数据库连接池。引用 <a href="https://github.com/brettwooldridge/HikariCP">数据库连接池性能对比</a> 的说法（我并没有测试过）：</p>
<blockquote>
<ol>
<li>性能方面 hikariCP&gt;druid&gt;tomcat-jdbc&gt;dbcp&gt;c3p0 。hikariCP的高性能得益于最大限度的避免锁竞争。</li>
<li>druid功能最为全面，sql拦截等功能，统计数据较为全面，具有良好的扩展性。</li>
<li>综合性能，扩展性等方面，可考虑使用druid或者hikariCP连接池。</li>
<li>可开启prepareStatement缓存，对性能会有大概20%的提升。</li>
</ol>
</blockquote>
<p>在使用 spring jpa 时，默认使用的连接池是 hikariCP，所以最终采用了这个连接池。</p>
<p>使用过程中出现了一些坑，总结一下。</p>
<h1 id="java-sql-SQLTransientConnectionException"><a href="#java-sql-SQLTransientConnectionException" class="headerlink" title="java.sql.SQLTransientConnectionException"></a>java.sql.SQLTransientConnectionException</h1><p>仅使用默认配置，在运行所有测试时，会出现如下异常信息：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/721960-3c58b4722a0f8ab5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="sql exception.png"></p>
<p>这是因为默认的连接池数量是 10，而并行运行测试时，连接池数量不够了。通过设置 <a href="https://github.com/brettwooldridge/HikariCP#frequently-used"><code>maximumPoolSize</code></a> 解决。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">spring.datasource.hikari.maximum-pool-size:1000</span></span><br></pre></td></tr></table></figure>

<h1 id="too-many-connections"><a href="#too-many-connections" class="headerlink" title="too many connections"></a>too many connections</h1><p>在进行上述设置后，启动应用，连接数据库，发现数据库无法连接，报 <code>too many connections</code>。</p>
<h2 id="fixed-size-pool"><a href="#fixed-size-pool" class="headerlink" title="fixed-size pool"></a>fixed-size pool</h2><p>按 <a href="https://github.com/brettwooldridge/HikariCP/issues/657">hikariCP owner 的解释</a>，这可能是因为当设置 <code>maximumPoolSize</code> 后，这就变成了 fix-size 的连接池了，即总是会占有 1000（上边的设置）个连接池。idle 连接不会被释放，因为释放了也要创建新的 idle 连接池来保证 fix-size。从而新的连接就无法建立了。</p>
<blockquote>
<p>When running as a fixed-size pool (default) the <code>idleTimeout</code> has no effect. Your example is a fixed-size pool – when <code>minimumIdle</code> is not defined it defaults to <code>maximumPoolSize</code>.</p>
<p><code>idleTimeout</code> is meant to shrink the pool from <code>maximumPoolSize</code> down toward <code>minimumIdle</code> when connections are unused in the pool. However, when <code>minimumIdle</code> &#x3D;&#x3D; <code>maximumPoolSize</code> then closing an “idle” connection makes no sense as it will be replaced immediately in the pool.</p>
</blockquote>
<p>所以配置 <code>minimumIdle</code> 可以解决上述问题。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">spring.datasource.hikari.maximum-pool-size:1000</span></span><br><span class="line"><span class="string">spring.datasource.hikari.miniumIdle:10</span></span><br></pre></td></tr></table></figure>

<h2 id="wait-timeout-too-long"><a href="#wait-timeout-too-long" class="headerlink" title="wait-timeout too long"></a>wait-timeout too long</h2><p>有时就是因为 connection 一直没被释放，这可能是这是的 connection wait_timeout 太长了。参照 <a href="https://support.rackspace.com/how-to/how-to-change-the-mysql-timeout-on-a-server/">change the mysql timeout on a server</a> 来了解 ‘wait_timeout’ 的设置。</p>
<p>引用原文：</p>
<blockquote>
<p>Choose a reasonable <code>wait_timeout</code> value. Stateless PHP environments do well with a 60 second timeout or less. Stateful applications that use a connection pool (Java, .NET, etc.) will need to adjust <code>wait_timeout</code> to match their connection pool settings. The default 8 hours (<code>wait_timeout = 28800</code>) works well with properly configured connection pools.</p>
<p>Configure the <code>wait_timeout</code> to be slightly longer than the application connection pool’s expected connection lifetime. This is a good safety check.</p>
</blockquote>
<p>在设置了合理的 mysql <code>wait_timeout</code> 后，同样也设置 hikariCP 的连接池空闲时间，参考<a href="https://github.com/brettwooldridge/HikariCP/wiki/FAQ#q-i-am-getting-a-commysqljdbcexceptionsjdbc4communicationsexception-communications-link-failure-exception-logged-in-the-isconnectionalive-method-of-hikaripool-in-my-logs-what-is-happening">FAQ</a></p>
<blockquote>
<p>If you set the MySQL <code>wait_timeout = 28800</code> (seconds &#x3D; 8 hours), you should set HikariCP <code>idleTimeout</code> and <code>maxLifetime</code> to the slightly shorter 28000000 (milliseconds &#x3D; 7 hours 46 minutes).</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">spring.datasource.hikari.maximum-pool-size:1000</span></span><br><span class="line"><span class="string">spring.datasource.hikari.miniumIdle:10</span></span><br><span class="line"><span class="string">spring.datasource.hikari.idleTimeout:28000000</span></span><br><span class="line"><span class="string">spring.datasource.hikari.maxLifetime:28000000</span></span><br></pre></td></tr></table></figure>

<h1 id="性能优化配置"><a href="#性能优化配置" class="headerlink" title="性能优化配置"></a>性能优化配置</h1><p>按照前边的说法，合理启用 prepareStatement 缓存，可以大幅提升性能。官方推荐的配置可参考 <a href="https://github.com/brettwooldridge/HikariCP/wiki/MySQL-Configuration">mysql configuration</a></p>
<p>一个典型配置如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">jdbcUrl=jdbc:mysql://localhost:3306/simpsons</span></span><br><span class="line"><span class="string">user=test</span></span><br><span class="line"><span class="string">password=test</span></span><br><span class="line"><span class="string">dataSource.cachePrepStmts=true</span></span><br><span class="line"><span class="string">dataSource.prepStmtCacheSize=250</span></span><br><span class="line"><span class="string">dataSource.prepStmtCacheSqlLimit=2048</span></span><br><span class="line"><span class="string">dataSource.useServerPrepStmts=true</span></span><br><span class="line"><span class="string">dataSource.useLocalSessionState=true</span></span><br><span class="line"><span class="string">dataSource.rewriteBatchedStatements=true</span></span><br><span class="line"><span class="string">dataSource.cacheResultSetMetadata=true</span></span><br><span class="line"><span class="string">dataSource.cacheServerConfiguration=true</span></span><br><span class="line"><span class="string">dataSource.elideSetAutoCommits=true</span></span><br><span class="line"><span class="string">dataSource.maintainTimeStats=false</span></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title>hive introduction</title>
    <url>/2019/01/03/hive-introduction/</url>
    <content><![CDATA[<p><a href="https://cwiki.apache.org/confluence/display/Hive/Home#Home-HiveDocumentation">apache hive</a> 是一个 data warehouse 应用。支持分布式存储的大数据读、写和管理，并且支持使用标准的 SQL 语法查询。Hive is not a database.  This is to make use of SQL capabilities by defining a metadata to the files in HDFS.  Long story short, it brings the possibility to query the hdfs file.</p>
<p>hive 并没有固定的数据存储方式。自带的是 csv（comma-separated value）和 tsv (tab-separated values) connectors，也可以使用 connector for other formats。</p>
<h2 id="database-v-s-warehouse"><a href="#database-v-s-warehouse" class="headerlink" title="database v.s. warehouse"></a>database v.s. warehouse</h2><p>参见 <a href="https://panoply.io/data-warehouse-guide/the-difference-between-a-database-and-a-data-warehouse/">the difference between database and data warehouse</a></p>
<h3 id="database："><a href="#database：" class="headerlink" title="database："></a>database：</h3><p>存储具体的业务数据，完善支持 concurrent transaction 操作（CRUD）。</p>
<p>database contains highly detailed data as well as a detailed relational views. Tables are normalized to achieve efficient storage, concurrent transaction processing, as well as return quick query results.</p>
<ul>
<li>**主要用于 OLTP (online trancaction processing)**。</li>
<li><strong>use a normalized structure</strong>. 即通常会组织成 table、row、column，冗余信息很少（比如三张表 product、color、product-color），所以节省空间。在查询时就需要通过复杂的 join 来实现，所以分析性的查询会比较耗时</li>
<li><strong>no historical data</strong>. 主要处理 transaction 数据，只保存现在的数据，进行的查询和分析也是基于现有数据。即它的分析是 static one-time reports</li>
<li><strong>optimization 主要是优化写速度、读速度</strong>。复杂分析因为涉及很多 join，其性能提升也是一个主要的问题。</li>
<li><strong>经常需要满足关系型数据库的 ACID 原则</strong>（atomicity, consistency, isolation, and durability）。所以它需要支持并发操作下的数据完整性。对 concurrent transaction 的支持要求比较高。</li>
</ul>
<h3 id="data-warehouse"><a href="#data-warehouse" class="headerlink" title="data warehouse"></a>data warehouse</h3><p>将企业中的各种数据收集起来，重新组织，对这些数据做高效 <em><strong>分析</strong></em></p>
<blockquote>
<p>A <a href="https://panoply.io/data-warehouse-guide">data warehouse</a> is a system that pulls together data from many different sources within an organization for reporting and analysis. The reports created from complex queries within a data warehouse are used to make business decisions.</p>
<p>The primary focus of a data warehouse is to provide a correlation between data from existing systems, i.e., product inventory stored in one system, purchase orders for a specific customer, stored in another system. Data warehouses are used for online analytical processing (OLAP), which uses complex queries to analyze rather than process transactions.</p>
</blockquote>
<ul>
<li><strong>主要用于 OLAP (online analysis processing)</strong>. 它收集企业内各个数据源的数据，建立数据关联，对这些数据做复杂的查询分析，以辅佐业务决策。</li>
<li><strong>use a denormalized structure</strong>. 它收集多个相关数据源的数据，将这些 table <a href="https://searchdatamanagement.techtarget.com/definition/denormalization">denormailize</a>、transform，获得 summarized data、multidimentional views，并基于这些数据实现快速分析和查询。它不在乎冗余，相反，很多时候正是通过冗余重新组织数据，使得查询更方便。</li>
<li><strong>store historical data</strong>. data warehouse 主要是用于分析的，所以通常会存储历史数据，以实现对历史数据和现有数据的对比分析。</li>
<li><strong>optimization 主要是查询响应速度</strong>。它对大数据做分析，响应速度是主要的衡量标准。</li>
<li><strong>一般不支持高并发操作</strong>。支持一定并发，但支持程度远不如 database</li>
</ul>
<h1 id="installation"><a href="#installation" class="headerlink" title="installation"></a>installation</h1><p>See <a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html">hadoop: setting up a single-node cluster</a>, <a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">GettingStarted</a></p>
<p>Hive relies on hadoop. And we need a db (eg. mysql) to store hive metadata. So the prerequisites are:</p>
<ul>
<li><strong>hadoop installed</strong></li>
<li><strong>mysql installed</strong>: to store hive metadata</li>
<li><strong>java installed</strong>: ??</li>
<li><strong>ssh installed and sshd running</strong>: when running hadoop scripts and managing remote hadoop daemons, it use ssh to authenticate.</li>
</ul>
<h3 id="install-hadoop-on-mac"><a href="#install-hadoop-on-mac" class="headerlink" title="install hadoop on mac"></a><a href="https://hfcherish.github.io/2019/01/07/hadoop/">install hadoop on mac</a></h3><h3 id="install-hive-on-mac"><a href="#install-hive-on-mac" class="headerlink" title="install hive on mac"></a><a href="https://www.cnblogs.com/micrari/p/7067968.html">install hive on mac</a></h3><blockquote>
<p>After init mysql, you may find that you can’t connect mysql using ‘-uhive -pxxx’. Then try to grant privileges to <code>&#39;hive&#39;@&#39;%&#39;</code> instead of <code>&#39;hive&#39;@&#39;localhost&#39;</code>. Use wildcard <code>%</code> to match all hosts.</p>
</blockquote>
<p>After installation, can try the <a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-SimpleExampleUseCases">simple example</a> to see how to conduct analysis on hive.</p>
<h3 id="set-env"><a href="#set-env" class="headerlink" title="set env"></a>set env</h3><p>To use hadoop and hive conveniently, set the bin in Path. Just add the follow config into <code>~/.zshrc</code>, and then source it <code>source ~/.zshrc</code>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/local/Cellar/hadoop/3.1.1/libexec</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/local/Cellar/hive/3.1.1/libexec</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure>

<h3 id="running-using-beeline"><a href="#running-using-beeline" class="headerlink" title="running using beeline"></a><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-RunningHiveServer2andBeeline.1">running using beeline</a></h3><p>beeline is a new hive client to replace the deprecated HiveCli. With beeline, you can execute write, load, query, etc. on hive.</p>
<p>To connect simply, type the following:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hiveserver2</span><br><span class="line">$ beeline -u jdbc:hive2://</span><br></pre></td></tr></table></figure>

<p>To create, alter database&#x2F;table&#x2F;column&#x2F;etc. on hive, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL">Hive Data Definition Language</a>.</p>
<p>To get the query commands, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select">LanguageManual Select</a></p>
<p>To load data from file, insert, delete, merge, update data, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML">DML (data manipulation language)</a></p>
<p>Other non-sql commands to use in HiveQL or beeline, see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Commands">LanguageManual Commands</a>. The <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Cli#LanguageManualCli-HiveResources">Hive Resources</a> related commands are non-sql commands.</p>
<h1 id="Configure-Hive"><a href="#Configure-Hive" class="headerlink" title="Configure Hive"></a>Configure Hive</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+Configuration#AdminManualConfiguration-ConfiguringHive">how to configure hive properties</a></p>
<p>To show hive config in hive cli: (<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ShowConf">show conf</a>)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># to show current: `set confName`</span></span><br><span class="line">0: jdbc:hive2://slave1:2181,slave2:2181,maste&gt; <span class="built_in">set</span> hive.fetch.task.conversion;</span><br></pre></td></tr></table></figure>

<p>There are two hive-site.xml files. See <a href="https://community.cloudera.com/t5/Support-Questions/Why-do-I-have-two-hive-site-xml-config-files-on-my-HDP-host/td-p/209500">two hive-site.xml config files on HDP</a></p>
<ul>
<li><p>&#x2F;etc&#x2F;hive&#x2F;conf&#x2F;hive-site.xml is the config for Hive service itself and is managed via Ambari through the Hive service config page.</p>
</li>
<li><p>&#x2F;usr&#x2F;hdp&#x2F;current&#x2F;spark-client&#x2F;conf&#x2F;hive-site.xml actually points to &#x2F;etc&#x2F;spark&#x2F;conf&#x2F;hive-site.xml . This is the minimal hive config that Spark needs to access Hive. This is managed via Ambari through the Spark service config page. Ambari correctly configures this hive site for Kerberos. Depending upon your version of HDP you may not have the correct support in Ambari for configuring Livy.  The hive-site.xml in Spark doesn’t have the same template as Hive’s. Ambari will notice the hive-site.xml and overwrite it in the Spark directory whenever Spark is restarted.</p>
</li>
</ul>
<h1 id="analysis-on-hive"><a href="#analysis-on-hive" class="headerlink" title="analysis on hive"></a>analysis on hive</h1><p>When you start a sql function (eg. <code>select count(*) from xxx</code>), it in fact  starts an map-reduce job based on hadoop to search among all datanodes. Such functions are simple analysis implemented by hive.</p>
<blockquote>
<p>Hive compiler generates map-reduce jobs for most queries. These jobs are then submitted to the Map-Reduce cluster indicated by the variable:</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mapred.job.tracker</span><br></pre></td></tr></table></figure>

<p>For complex analysis, you may need to write custom mappers (map data) &amp; reducers (collect data) scripts. Use<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Transform"><code>TRANSFORM</code></a> keyword in hive to achieve this.</p>
<p>For example, the <code>weekday_mapper.py</code> to convert <code>unixtime</code> to <code>weekday</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">  line = line.strip()</span><br><span class="line">  userid, movieid, rating, unixtime = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">  weekday = datetime.datetime.fromtimestamp(<span class="built_in">float</span>(unixtime)).isoweekday()</span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;\t&#x27;</span>.join([userid, movieid, rating, <span class="built_in">str</span>(weekday)])</span><br></pre></td></tr></table></figure>

<p>And then use the script:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> u_data_new (</span><br><span class="line">  userid <span class="type">INT</span>,</span><br><span class="line">  movieid <span class="type">INT</span>,</span><br><span class="line">  rating <span class="type">INT</span>,</span><br><span class="line">  weekday <span class="type">INT</span>)</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">add</span> FILE weekday_mapper.py;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> u_data_new</span><br><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">  TRANSFORM (userid, movieid, rating, unixtime)</span><br><span class="line">  <span class="keyword">USING</span> <span class="string">&#x27;python weekday_mapper.py&#x27;</span></span><br><span class="line">  <span class="keyword">AS</span> (userid, movieid, rating, weekday)</span><br><span class="line"><span class="keyword">FROM</span> u_data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> weekday, <span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> u_data_new</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> weekday;</span><br></pre></td></tr></table></figure>

<h1 id="storage-on-hive"><a href="#storage-on-hive" class="headerlink" title="storage on hive"></a>storage on hive</h1><p>Hive relies on Hadoop. The data in hive is saved in hdfs in fact. And the metadata is saved in mysql (the db can be configured). When check <code>localhost:9870</code>, you can see a new folder <code>/user/hive/warehouse</code>. All tables in hive are dirs in <code>/user/hive/warehouse</code>.</p>
<h2 id="Hive-Partition"><a href="#Hive-Partition" class="headerlink" title="Hive Partition"></a>Hive Partition</h2><p><a href="https://blog.csdn.net/helloxiaozhe/article/details/78445276">hive中简单介绍分区表(partition table)，含动态分区(dynamic partition)与静态分区(static partition)</a></p>
<blockquote>
<p>Hive organizes tables into partitions. It is a way of dividing a table into related parts based on the values of partitioned columns such as date, city, and department. Using partition, it is easy to query a portion of the data.<br>Tables or partitions are sub-divided into <strong>buckets,</strong> to provide extra structure to the data that may be used for more efficient querying. Bucketing works based on the value of hash function of some column of a table.<br>For example, a table named <strong>Tab1</strong> contains employee data such as id, name, dept, and yoj (i.e., year of joining). Suppose you need to retrieve the details of all employees who joined in 2012. A query searches the whole table for the required information. However, if you partition the employee data with the year and store it in a separate file, it reduces the query processing time. The following example shows how to partition a file and its data:</p>
</blockquote>
<h2 id="Hive-bucket"><a href="#Hive-bucket" class="headerlink" title="Hive bucket"></a>Hive bucket</h2><p><a href="https://sparkbyexamples.com/apache-hive/hive-partitioning-vs-bucketing-with-examples/">hive partitioning vs bucket with examples</a></p>
<p><a href="https://sparkbyexamples.com/apache-hive/hive-partitioning-vs-bucketing-with-examples/">stack-overflow: hive partition vs bucket</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> zipcodes(</span><br><span class="line">RecordNumber <span class="type">int</span>,</span><br><span class="line">Country string,</span><br><span class="line">City string,</span><br><span class="line">Zipcode <span class="type">int</span>)</span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(state string)</span><br><span class="line">CLUSTERED <span class="keyword">BY</span> Zipcode <span class="keyword">INTO</span> <span class="number">10</span> BUCKETS</span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED</span><br><span class="line">FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span>;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">PARTITIONING</th>
<th align="left">BUCKETING</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Directory is created on HDFS for each partition.</td>
<td align="left">File is created on HDFS for each bucket.</td>
</tr>
<tr>
<td align="left">You can have one or more Partition columns</td>
<td align="left">You can have only one Bucketing column</td>
</tr>
<tr>
<td align="left">You can’t manage the number of partitions to create</td>
<td align="left">You can manage the number of buckets to create by specifying the count</td>
</tr>
<tr>
<td align="left">NA</td>
<td align="left">Bucketing can be created on a partitioned table</td>
</tr>
<tr>
<td align="left">Uses PARTITIONED BY</td>
<td align="left">Uses CLUSTERED BY</td>
</tr>
</tbody></table>
<p>partition  和 bucket 都是将大数据集拆成更小的数据集，加速查询处理的方式。比如按日期拆分区，很多分析只拿当天的分区，处理的数据量、读取的 hdfs 文件很少，就快。</p>
<p>最大的区别是 partition 拆数据就是按 column 值拆，bucket 拆数据是按 column hash 值拆，所以 bucket 最终的桶的数目是固定的，同时一个桶里可能有多个 column 值（parition 每个分区只会存一种 column 的值）</p>
<p>相对来讲，bucket 粒度可能更细。比如一个场景，我们将 order 按 date 分区，分区后每天的数据量还是特别大，如果我们很多查询&#x2F;join是基于 employee，此时可以基于 employe_id 再分成更多的小集合，即按 employe_id 字段 hash 到 n 个桶里，这种拆桶方式特别有利于宏宇今天说的 map-side join，而且相比 partition，可以控制文件数量（有时想用的 partition 字段可能会分成特别特别多小分区，这个时候 bucket 就更合适些）</p>
<p>上边那个例子，假如 order 按 date+employee_id partition，分区就会特别多（对 hdfs namenode 造成大压力，hive metadata 也有压力），所以按 date partition, 按 employee_id bucket 就比较合适</p>
<h2 id="ORC-vs-Parquet"><a href="#ORC-vs-Parquet" class="headerlink" title="ORC vs Parquet"></a>ORC vs Parquet</h2><p><a href="https://community.cloudera.com/t5/Support-Questions/ORC-vs-Parquet-When-to-use-one-over-the-other/td-p/95942">orc vs Parquet</a></p>
<p><a href="https://blog.cloudera.com/orcfile-in-hdp-2-better-compression-better-performance/">ORCFile in HDP 2: Better Compression, Better Performance</a></p>
<h1 id="Hive-Transactional"><a href="#Hive-Transactional" class="headerlink" title="Hive Transactional"></a>Hive Transactional</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+Transactions#HiveTransactions-NewConfigurationParametersforTransactions">hive transaction</a></p>
<p>Close:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set hive.support.concurrency = false;</span><br><span class="line">set hive.optimize.index.filter = false;</span><br><span class="line">set hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager;</span><br><span class="line">set hive.compactor.initiator.on = false;</span><br><span class="line">set hive.compactor.worker.threads = 0;</span><br><span class="line">set hive.strict.managed.tables = false;</span><br><span class="line"></span><br><span class="line">TBLPROPERTIES (&#x27;transactional&#x27;=&#x27;false&#x27;)</span><br></pre></td></tr></table></figure>

<h1 id="architecture"><a href="#architecture" class="headerlink" title="architecture"></a><a href="https://cwiki.apache.org/confluence/display/Hive/Design">architecture</a></h1><p><img src="https://cwiki.apache.org/confluence/download/attachments/27362072/system_architecture.png?version=1&modificationDate=1414560669000&api=v2" alt="hive architecture"></p>
<h1 id="Hive-Data-Types"><a href="#Hive-Data-Types" class="headerlink" title="Hive Data Types"></a>Hive Data Types</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-decimal">hive data types</a></p>
<h1 id="Common-used-commands"><a href="#Common-used-commands" class="headerlink" title="Common used commands"></a>Common used commands</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">0: jdbc:hive2://slave1:2181&gt; use dbname;</span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; show tables;</span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; describe formatted tablename;</span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; describe extended tableName</span><br></pre></td></tr></table></figure>

<h2 id="auto-increment-id"><a href="#auto-increment-id" class="headerlink" title="auto increment id"></a>auto increment id</h2><p><a href="https://cloud.tencent.com/developer/article/1433240">two ways hive auto increment id</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">## use row_number</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl_dim  </span><br><span class="line"><span class="keyword">select</span> <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> tbl_stg.id) <span class="operator">+</span> t2.sk_max, tbl_stg.<span class="operator">*</span>  </span><br><span class="line"><span class="keyword">from</span> tbl_stg </span><br><span class="line"><span class="keyword">cross</span> <span class="keyword">join</span> (<span class="keyword">select</span> <span class="built_in">coalesce</span>(<span class="built_in">max</span>(sk),<span class="number">0</span>) sk_max <span class="keyword">from</span> tbl_dim) t2; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## use UDFRowSequence</span><br><span class="line"><span class="keyword">add</span> jar hdfs:<span class="operator">/</span><span class="operator">/</span><span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">-</span>contrib<span class="number">-2.0</span><span class="number">.0</span>.jar;  </span><br><span class="line"><span class="keyword">create</span> temporary <span class="keyword">function</span> row_sequence <span class="keyword">as</span> <span class="string">&#x27;org.apache.hadoop.hive.contrib.udf.udfrowsequence&#x27;</span>; </span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> tbl_dim  </span><br><span class="line"><span class="keyword">select</span> row_sequence() <span class="operator">+</span> t2.sk_max, tbl_stg.<span class="operator">*</span>  </span><br><span class="line"><span class="keyword">from</span> tbl_stg </span><br><span class="line"><span class="keyword">cross</span> <span class="keyword">join</span> (<span class="keyword">select</span> <span class="built_in">coalesce</span>(<span class="built_in">max</span>(sk),<span class="number">0</span>) sk_max <span class="keyword">from</span> tbl_dim) t2;</span><br></pre></td></tr></table></figure>

<h2 id="get-latest-partition"><a href="#get-latest-partition" class="headerlink" title="get latest partition"></a>get latest partition</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">## will <span class="keyword">only</span> scan <span class="number">2</span><span class="number">-3</span> partitions</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">max</span>(ingest_date) <span class="keyword">from</span> db.table_name</span><br><span class="line"><span class="keyword">where</span> ingest_date<span class="operator">&gt;</span>date_add(<span class="built_in">current_date</span>,<span class="number">-3</span>)</span><br></pre></td></tr></table></figure>

<h2 id="create-table-from-another-table"><a href="#create-table-from-another-table" class="headerlink" title="create table from another table"></a>create table from another table</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> new_test </span><br><span class="line">    <span class="type">row</span> format delimited </span><br><span class="line">    fields terminated <span class="keyword">by</span> <span class="string">&#x27;|&#x27;</span> </span><br><span class="line">    STORED <span class="keyword">AS</span> RCFile </span><br><span class="line"><span class="keyword">AS</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> source <span class="keyword">where</span> col<span class="operator">=</span><span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="select-all-without-some-columns"><a href="#select-all-without-some-columns" class="headerlink" title="select all without some columns"></a>select all without some columns</h2><p><a href="https://blog.csdn.net/Kikitious_Du/article/details/84754240">blog</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.support.quoted.identifiers<span class="operator">=</span><span class="keyword">none</span>;</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">`(num<span class="operator">|</span>uid)?<span class="operator">+</span>.<span class="operator">+</span>`</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    (<span class="keyword">select</span> </span><br><span class="line">    <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> uid <span class="keyword">order</span> <span class="keyword">by</span> pay_time <span class="keyword">asc</span>) <span class="keyword">as</span> num</span><br><span class="line">    ,<span class="operator">*</span></span><br><span class="line">    <span class="keyword">from</span> <span class="keyword">order</span>) first_order</span><br><span class="line"><span class="keyword">where</span> num <span class="operator">=</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h2 id="select-latest-in-group"><a href="#select-latest-in-group" class="headerlink" title="select latest in group"></a>select latest in group</h2><p><a href="https://stackoverflow.com/questions/35520193/how-to-find-most-recent-records-for-every-group-in-hive">link</a></p>
<p>use rank</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> (</span><br><span class="line">  <span class="keyword">select</span> id, name, starttime, <span class="built_in">rank</span>() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> name <span class="keyword">order</span> <span class="keyword">by</span> unix_timestamp(starttime, <span class="string">&#x27;EEE, dd MMM yyyy hh:mm:ss z&#x27;</span>) <span class="keyword">desc</span>) <span class="keyword">as</span> rnk <span class="keyword">from</span> hive_table) a </span><br><span class="line"> <span class="keyword">where</span> a.rnk<span class="operator">=</span><span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<h2 id="hive-cli-pretty"><a href="#hive-cli-pretty" class="headerlink" title="hive cli pretty"></a>hive cli pretty</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.cli.print.header<span class="operator">=</span><span class="literal">true</span>; <span class="operator">/</span><span class="operator">/</span> 打印列名</span><br><span class="line"><span class="keyword">set</span> hive.cli.print.row.to.vertical<span class="operator">=</span><span class="literal">true</span>; <span class="operator">/</span><span class="operator">/</span> 开启行转列功能, 前提必须开启打印列名功能</span><br><span class="line"><span class="keyword">set</span> hive.cli.print.row.to.vertical.num<span class="operator">=</span><span class="number">1</span>; <span class="operator">/</span><span class="operator">/</span> 设置每行显示的列数</span><br></pre></td></tr></table></figure>

<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><h2 id="小文件问题"><a href="#小文件问题" class="headerlink" title="小文件问题"></a>小文件问题</h2><p>和 spark 的小文件问题一样，hive 的运算引擎（mapreduce 或 Tez），为了提高性能，最后都会采用多个 reducer 来写数据，这个时候就会有小文件。不同于 Spark，Hive 本身提供了多种措施来优化小文件存储，我们只需要设置就行</p>
<h3 id="1-使用-concatenate"><a href="#1-使用-concatenate" class="headerlink" title="1. 使用 concatenate"></a>1. 使用 concatenate</h3><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-AlterTable/PartitionConcatenate">hive concatenate</a> 主要针对 orc 和 rcfile 文件格式存储的文件，特别是 orc ，可以直接执行 stripe level 的 merge，省掉 deserialize 和 decode 的开销，很高效。（concatenate 可以执行多次，最终文件数量不会变化）</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name [<span class="keyword">PARTITION</span> (partition_key <span class="operator">=</span> <span class="string">&#x27;partition_value&#x27;</span> [, ...])] CONCATENATE;</span><br></pre></td></tr></table></figure>

<h3 id="2-使用一些配置，在写文件时，自动-merge"><a href="#2-使用一些配置，在写文件时，自动-merge" class="headerlink" title="2. 使用一些配置，在写文件时，自动 merge"></a>2. 使用一些配置，在写文件时，自动 merge</h3><p>输入时合并：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--  每个Map最大输入大小，决定合并后的文件数</span></span><br><span class="line"><span class="keyword">set</span>  mapred. max .split.size<span class="operator">=</span><span class="number">256000000</span>;</span><br><span class="line"><span class="comment">-- 一个节点上split的至少的大小 ，决定了多个data node上的文件是否需要合并</span></span><br><span class="line"><span class="keyword">set</span>  mapred. min .split.size.per.node<span class="operator">=</span><span class="number">100000000</span>;</span><br><span class="line"><span class="comment">-- 一个交换机下split的至少的大小，决定了多个交换机上的文件是否需要合并</span></span><br><span class="line"><span class="keyword">set</span>  mapred. min .split.size.per.rack<span class="operator">=</span><span class="number">100000000</span>;</span><br><span class="line"><span class="comment">-- 执行Map前进行小文件合并</span></span><br><span class="line"><span class="keyword">set</span>  hive.input.format<span class="operator">=</span>org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; </span><br></pre></td></tr></table></figure>

<p>输出时合并：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- hive 输出时合并的配置参数</span></span><br><span class="line"><span class="comment">-- 在Map-only的任务结束时合并小文件</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.mapfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 在Map-Reduce的任务结束时合并小文件, 默认 false</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.tezfiles<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.merge.mapredfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 合并文件的大小, 默认 256000000</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.size.per.task<span class="operator">=</span><span class="number">256000000</span>;</span><br><span class="line"><span class="comment">-- 当输出文件的平均大小小于该值时, 启动一个独立的map-reduce任务进行文件merge， 默认 16000000</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.smallfiles.avgsize<span class="operator">=</span><span class="number">256000000</span>;</span><br><span class="line"><span class="comment">-- 当这个参数设置为true,orc文件进行stripe Level级别的合并,当设置为false,orc文件进行文件级别的合并。默认 true</span></span><br><span class="line"><span class="keyword">set</span> hive.merge.orcfile.stripe.level<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure>

<p>Hive在对结果文件进行合并时会执行一个额外的map-only脚本，mapper的数量是文件总大小除以size.per.task参数所得的值，触发合并的条件是：</p>
<p>根据查询类型不同，相应的mapfiles&#x2F;mapredfiles参数需要打开；</p>
<p>结果文件的平均大小需要大于avgsize参数的值。</p>
<h1 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h1><h2 id="count-return-0"><a href="#count-return-0" class="headerlink" title="count(*) return 0"></a>count(*) return 0</h2><p><a href="https://community.cloudera.com/t5/Support-Questions/hive-count-not-working/td-p/216889">hive count(*) not working</a></p>
<p><a href="https://cwiki.apache.org/confluence/display/Hive/StatsDev#StatsDev-ExistingTables%E2%80%93ANALYZE">hive analyze</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可以设，但不好</span></span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; <span class="built_in">set</span> hive.fetch.task.conversion=none;</span><br><span class="line"><span class="comment"># 或者设</span></span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; <span class="built_in">set</span> hive.compute.query.using.stats=<span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 推荐</span></span><br><span class="line">0: jdbc:hive2://slave1:2181&gt; analyze table t [partition p] compute statistics <span class="keyword">for</span> [columns c,...];</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Its better not to disturb the properties on the statistics usage like hive.compute.query.using.stats. It impacts the way the statistics are used in your query for performance optimization and execution plans. It has tremendous influence on execution plans, the statistics stored depends on the file format as well. Therefore definitely not a solution to change any property with regards to statistics.<br>The real reason for count not working correctly is the statistics not updated in the hive due to which it returns 0. When a table is created first, the statistics is written with no data rows. Thereafter any data append&#x2F;change happens hive requires to update this statistics in the metadata. Depending on the circumstances hive might not be updating this real time.<br>Therefore running the ANALYZE command recomputes this statistics to make this work correctly.</p>
</blockquote>
<h2 id="hive-not-recognizing-alias-names-in-select-part"><a href="#hive-not-recognizing-alias-names-in-select-part" class="headerlink" title="hive not recognizing alias names in select part"></a>hive not recognizing alias names in select part</h2><p>The where clause is evaluated before the select clause, which is why you can’t refer to select aliases in your where clause.</p>
<p>You can however refer to aliases from a derived table.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * from (</span><br><span class="line">  <span class="keyword">select</span> user as u1, url as u2 from rank_test</span><br><span class="line">) t1 <span class="built_in">where</span> u1 &lt;&gt; <span class="string">&quot;&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * from (</span><br><span class="line">  <span class="keyword">select</span> user, count(*) as cnt from rank_test group by user</span><br><span class="line">) t1 <span class="built_in">where</span> cnt &gt;= 2;</span><br></pre></td></tr></table></figure>

<p>Side note: a more efficient way to write the last query would be</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> user, count(*) as cnt from rank_test group by user</span><br><span class="line">having count(*) &gt;= 2</span><br></pre></td></tr></table></figure>

<h2 id="In-not-in-substitution"><a href="#In-not-in-substitution" class="headerlink" title="In, not in substitution"></a>In, not in substitution</h2><p>Hive supports sub-query in <code>in</code> , <code>not in</code> only after 0.13. And <code>in</code> may be slow, so we can replace it with join.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- in</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">where</span> id <span class="keyword">in</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b)</span><br><span class="line"><span class="comment">-- in substitutionn</span></span><br><span class="line"><span class="keyword">select</span> a.<span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">join</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b) b1 <span class="keyword">on</span> a.id <span class="operator">=</span> b1.id</span><br></pre></td></tr></table></figure>

<h2 id="VERTEX-FAILURE"><a href="#VERTEX-FAILURE" class="headerlink" title="VERTEX_FAILURE"></a>VERTEX_FAILURE</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.partitions=8000;</span><br><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.partitions.pernode=8000;</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> hive.tez.log.level=DEBUG;</span><br></pre></td></tr></table></figure>

<h2 id="explain"><a href="#explain" class="headerlink" title="explain"></a>explain</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">explain <span class="keyword">select</span> <span class="built_in">sum</span>(id) <span class="keyword">from</span> my;</span><br></pre></td></tr></table></figure>

<h2 id="xa0"><a href="#xa0" class="headerlink" title="\xa0"></a>\xa0</h2><p>(<code>SPACE_SEPARATOR</code>, <code>LINE_SEPARATOR</code>, or <code>PARAGRAPH_SEPARATOR</code>) but is not also a non-breaking space (<code>&#39;\u00A0&#39;</code>, <code>&#39;\u2007&#39;</code>, <code>&#39;\u202F&#39;</code>).</p>
<p><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Character.html#isWhitespace-char-">java isWhiteSpace()</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">print(res.selectExpr(&quot;trim(translate(mobile1, &#x27;\u00A0&#x27;, &#x27; &#x27;))&quot;).collect())</span><br><span class="line">print(res.selectExpr(&quot;trim(regexp_replace(mobile1, &#x27;\u00A0|\u2007|\u202F&#x27;, &#x27; &#x27;))&quot;).collect())</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>storage</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>数据导入 hive</title>
    <url>/2020/11/11/import-data-to-hive/</url>
    <content><![CDATA[<h1 id="ftp-csv-文件导入"><a href="#ftp-csv-文件导入" class="headerlink" title="ftp .csv 文件导入"></a>ftp .csv 文件导入</h1><p>可以先将文件弄到 HDFS，然后创建&#x2F;更新 hive 表来关联到 HDFS 文件。</p>
<p>将文件弄到 HDFS有以下一些方法：</p>
<ol>
<li><strong>ftp -&gt; local -&gt; hdfs:</strong> 将文件先下载到本地，再通过 hdfs 命令拷贝到 hdfs 中</li>
<li><strong>ftp -&gt; hdfs</strong>: 直接连接 FTP，将文件拷到 hdfs 中，省却本地拷贝</li>
<li><strong>已有的数据采集工具</strong>：使用实时数据流处理系统，来实现不同系统之间的流通</li>
</ol>
<h2 id="一、ftp-gt-local-gt-hdfs"><a href="#一、ftp-gt-local-gt-hdfs" class="headerlink" title="一、ftp -&gt; local -&gt;hdfs"></a>一、ftp -&gt; local -&gt;hdfs</h2><p>几种方案：</p>
<ol>
<li><p><code>hadoop fs -get ftp://uid:password@server_url/file_path temp_file | hadoop fs -moveFromLocal tmp_file hadoop_path/dest_file</code> </p>
</li>
<li><p>参照<a href="https://community.cloudera.com/t5/Support-Questions/How-read-ftp-server-files-and-load-into-hdfs-in-incremental/m-p/223519/highlight/true#M185384">这个实现</a>用 python 包从 ftp 中读，然后用 hdfs 命令写到 hdfs</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> hdfs <span class="keyword">import</span> InsecureClient</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can also use KerberosClient or custom client</span></span><br><span class="line">namenode_address = <span class="string">&#x27;your namenode address&#x27;</span></span><br><span class="line">webhdfs_port = <span class="string">&#x27;your webhdfs port&#x27;</span> <span class="comment"># default for Hadoop 2: 50070, Hadoop 3: 9870</span></span><br><span class="line">user = <span class="string">&#x27;your user name&#x27;</span></span><br><span class="line">client = InsecureClient(<span class="string">&#x27;http://&#x27;</span> + namenode_address + <span class="string">&#x27;:&#x27;</span> + webhdfs_port, user=user)</span><br><span class="line"></span><br><span class="line">ftp_address = <span class="string">&#x27;your ftp address&#x27;</span></span><br><span class="line">hdfs_path = <span class="string">&#x27;where you want to write&#x27;</span></span><br><span class="line"><span class="keyword">with</span> urlopen(ftp_address) <span class="keyword">as</span> response:</span><br><span class="line">    content = response.read()</span><br><span class="line">    <span class="comment"># You can also use append=True</span></span><br><span class="line">    <span class="comment"># Further reference: https://hdfscli.readthedocs.io/en/latest/api.html#hdfs.client.Client.write</span></span><br><span class="line">    <span class="keyword">with</span> client.write(hdfs_path) <span class="keyword">as</span> writer:</span><br><span class="line">        writer.write(content</span><br></pre></td></tr></table></figure>
</li>
<li><p>参考 <a href="https://blog.csdn.net/yiluohan0307/article/details/79364525">ftp 提取文件到 hdfs</a></p>
</li>
</ol>
<h2 id="二、ftp-gt-hdfs"><a href="#二、ftp-gt-hdfs" class="headerlink" title="二、ftp -&gt; hdfs"></a>二、ftp -&gt; hdfs</h2><p>几种方案：(参考 <a href="https://blog.csdn.net/yiluohan0307/article/details/79364525">ftp 提取文件到 hdfs</a>)</p>
<ol>
<li><p>用 <a href="http://hadoop101.blogspot.com/?view=classic">FTP To HDFS</a> 连接 ftp，把文件直接放到 hdfs</p>
</li>
<li><p>HDFS dfs -cp: 简单快速，但不显示进度，适用于小文件</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ hdfs dfs –<span class="built_in">cp</span> [ftp://username:password@hostname/ftp_path] [hdfs:///hdfs_path]</span><br></pre></td></tr></table></figure>
</li>
<li><p>Hadoop distcp: 分布式提取，快，能显示拷贝进度，不支持流式写入（即拷贝的文件不能有其他程序在写入），适合大量文件或大文件的拷贝</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ hadoop distcp [ftp://username:password@hostname/ftp_path] [hdfs:///hdfs_path]</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="三、已有的数据采集工具"><a href="#三、已有的数据采集工具" class="headerlink" title="三、已有的数据采集工具"></a>三、已有的数据采集工具</h2><h3 id="文件导入"><a href="#文件导入" class="headerlink" title="文件导入"></a>文件导入</h3><ol>
<li><p><a href="https://nifichina.github.io/general/GettingStarted.html#%E6%9C%89%E5%93%AA%E4%BA%9B%E7%B1%BB%E5%88%AB%E7%9A%84%E5%A4%84%E7%90%86%E5%99%A8">apache NiFi</a> 来实现不同系统之间的流通，似乎拷贝完，会直接删除 ftp 上的文件</p>
</li>
<li><p>Apache Flume是一个分布式、可靠、高可用的日志收集系统，支持各种各样的数据来源。基于流式数据，适用于日志和事件类型的数据收集，重构后的Flume-NG版本中一个agent（数据传输流程）中的source（源）和sink（目标）之间通过channel进行链接，同一个源可以配置多个channel。多个agent还可以进行链接组合共同完成数据收集任务，使用起来非常灵活。</p>
<p><a href="https://blog.csdn.net/qq_39160721/article/details/80255588">flume 采集 ftp 文件 上传到 hadoop</a> 使用 <a href="https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html#spooling-directory-source">spooldir source</a>（不确定是不是能用）, 也可以使用第三方 source 组件 <a href="https://github.com/keedio/flume-ftp-source">flume-ftp-source</a></p>
<blockquote>
<p>Flume 也支持 sql source 的流式导入（使用 <a href="https://github.com/keedio/flume-ng-sql-source">flume-ng-sql-source</a> 插件），并提供对数据进行简单处理，并写到各数据接收方的能力。因此它的实时性更好。</p>
</blockquote>
</li>
<li><p>DataX：阿里的开源框架，本身社区不太活跃，但有很多 fork 再改的，似乎架构不错</p>
</li>
<li><p>Gobllin: Gobblin是用来整合各种数据源的通用型ETL框架，Gobblin的接口封装和概念抽象做的很好，作为一个ETL框架使用者，我们只需要实现我们自己的Source，Extractor，Conventer类，再加上一些数据源和目的地址之类的配置文件提交给Gobblin就行了。Gobblin相对于其他解决方案具有普遍性、高度可扩展性、可操作性。</p>
</li>
<li><p>kettle：一款开源的ETL工具</p>
</li>
</ol>
<h3 id="其他数据源（非-FTP-文件）"><a href="#其他数据源（非-FTP-文件）" class="headerlink" title="其他数据源（非 FTP 文件）"></a>其他数据源（非 FTP 文件）</h3><ol>
<li>Apache Sqoop：RDBMS &lt;–&gt; HDFS</li>
<li>Aegisthus：针对 Cassandra 数据源</li>
<li>mongo-hadoop：针对 mongodb 数据源</li>
</ol>
<h1 id="数据导入需要关注的问题"><a href="#数据导入需要关注的问题" class="headerlink" title="数据导入需要关注的问题"></a>数据导入需要关注的问题</h1><ol>
<li><strong>数据源都有哪些？</strong><ol>
<li>结构化（sql）、半结构化（json, xml…)、非结构化（video、image、file…)</li>
<li>日志数据（csv)、业务数据</li>
</ol>
</li>
<li><strong>是否可以直接连接数据库？</strong><ol>
<li>针对关系型数据，如果可连接数据库，可以通过 sqoop 导入数据到 hive<ol>
<li>增量式导入？？</li>
</ol>
</li>
<li>针对关系型数据，如果不能连接数据库：<ol>
<li><strong>是否可以默认周期性导出符合特定标准的 .csv 文件？</strong><ol>
<li>如果数据库导出 dump 文件，再将 dump 文件导入到 hadoop，则比较麻烦，以 oracle 为例，可能需要使用 COPYToBDA 来创建 hive table <a href="https://weidongzhou.wordpress.com/2016/11/12/data-query-between-bda-and-exadata-part-4-query-oracle-dump-file-on-bda-using-copy2bda/">Query Oracle Dump File on BDA Using Copy2BDA</a> ，或者将 dump 文件先导入到一个 temp oracle 数据库中，再用 sqoop 导入到 hive</li>
<li>如果数据库周期性导出 .csv 文件，将这些 .csv 文件使用上述工具（flume 等）导入到 hive，需要关注增量式导出和导入<ol>
<li>增量式导出：文件的组织结构、命名规范 ，.csv 内 record 要求包含 modified date, delete date（在增量式导入时，需要基于这些时间来合并表）</li>
<li>增量式导入：将新增的 .csv 文件作为 hive external table，然后通过中间 view 来合并基表和incremental 表，并更新基表、清空 incremental 表。<a href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.5/bk_data-access/content/incrementally-updating-hive-table-with-sqoop-and-ext-table.html">Incrementally Updating a Table</a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>导入周期和实时性需求<ol>
<li><strong>哪些需要每天批量导入、哪些需要流式实时导入</strong></li>
<li><strong>哪些需要全量导入、哪些需要增量式导入？</strong></li>
</ol>
</li>
<li><strong>如何实现增量式导入？删除的数据是否有删除标识（软删除）？</strong><ol>
<li>如果用 sqoop，参考 <a href="https://hfcherish.github.io/2020/11/10/sqoop/">sqoop 增量导入</a>，不支持对删除数据的处理</li>
<li>如果用 flume<ol>
<li>如果是 sql source，使用 <a href="https://github.com/keedio/flume-ng-sql-source">flume-ng-sql-source</a>, 对于 mysql 可以通过 query <code>agent.sources.sqlSource.custom.query</code> 来获取增量 source</li>
<li>如果是文件导入，则需要通过 <a href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.5/bk_data-access/content/incrementally-updating-hive-table-with-sqoop-and-ext-table.html">Incrementally Updating a Table</a> 来合并表</li>
</ol>
</li>
<li>Spark SQL</li>
</ol>
</li>
</ol>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>java api lib for excel</title>
    <url>/2018/07/25/java-api-for-excel/</url>
    <content><![CDATA[<h1 id="可选-lib"><a href="#可选-lib" class="headerlink" title="可选 lib"></a>可选 lib</h1><ul>
<li><a href="http://poi.apache.org/components/document/index.html">apache POI</a>：java 中最大众的 ，支持 <code>xls</code>、<code>xlsx</code>，提供接口来创建、读写 excel文件。</li>
<li><a href="http://www.openoffice.org/download/sdk/">apache openOffice uno</a>：</li>
<li><del><a href="http://www.openoffice.org/download/sdk/">JExcel app</a></del>：这个功能强大，什么都可以做，但是可能收费，而且仅基于 windows + installed excel</li>
<li><del><a href="http://jexcelapi.sourceforge.net/">JExcelAPI</a></del>：轻量更易用，但似乎仅支持 <code>xls</code>，而且不支持复杂的 range、formular 计算操作。</li>
<li><a href="https://www.teamdev.com/jexcel">javascript 版本的 JExcel</a></li>
<li><del><a href="https://www.docx4java.org/trac/docx4j">docx4j</a></del>：其中 <a href="https://github.com/plutext/docx4j/tree/master/src/samples/xlsx4j/org/xlsx4j/samples">xlsx4j</a> 是处理 excel 的，不过看起来功能比较简单。</li>
<li><a href="https://msdn.microsoft.com/zh-cn/vba/vba-excel">microsoft excel VBA</a>：vba 是微软写的操作 office 软件的语言。所以可以利用这个 vba 写代码……</li>
</ul>
<p>ref doc:</p>
<ul>
<li><a href="http://www.baeldung.com/java-microsoft-excel">baeldung example for apache POI &amp; JExcelAPI</a></li>
<li><a href="https://www.mkyong.com/java/jexcel-api-reading-and-writing-excel-file-in-java/">Mkyong example for JExcelAPI</a></li>
</ul>
<h1 id="核心操作支持"><a href="#核心操作支持" class="headerlink" title="核心操作支持"></a>核心操作支持</h1><table>
<thead>
<tr>
<th>lib</th>
<th>apache poi</th>
<th>apache openoffice</th>
<th>JExcelAPI</th>
</tr>
</thead>
<tbody><tr>
<td>read&#x2F;create excel file</td>
<td>✔️</td>
<td>可以</td>
<td>✔️</td>
</tr>
<tr>
<td>read&#x2F;write excel cells</td>
<td>1. 获取 sheet，遍历 row，遍历 row cells；</td>
<td>可以</td>
<td>1. 获取 sheet，可以根据 cell 行列数获取（<code>getCell(rowIndex, columnIndex)</code>）</td>
</tr>
<tr>
<td>compute formula for cells</td>
<td>可以（用 formular evaluator，参见<a href="https://stackoverflow.com/questions/5937373/using-apache-poi-hssf-how-can-i-refresh-all-formula-cells-at-once">stackoverflow</a>）</td>
<td>可以(calculateAll())</td>
<td>可能可以</td>
</tr>
<tr>
<td>write&#x2F;read named cells of file</td>
<td>可以（<code>workBook.getNamedAt(&quot;name&quot;)</code>，参见 <a href="https://stackoverflow.com/questions/33183144/apache-poi-update-cells-in-a-named-range">stackoverflow</a>, <a href="https://poi.apache.org/components/spreadsheet/quick-guide.html#NamedRanges">官方文档</a>）</td>
<td>可以（<code>namedRange</code>)</td>
<td>NO</td>
</tr>
<tr>
<td>pros</td>
<td>1. 使用广泛；2. 文档清晰；3. 支持很多复杂需求</td>
<td>1. 似乎功能比 poi 更简易，也更丰富些；2. 可以同时操作 openoffice 和 microoffice；3. 语言支持多，只要使用相应语言的 binding 就可以</td>
<td>1. 简单轻量；2. 接口友好</td>
</tr>
<tr>
<td>cons</td>
<td>接口不是很友好，访问起来比较麻烦</td>
<td>1. 文档乱七八糟；2. 采用 uno，领域对象不太一致；3. 必须要安装 openoffice</td>
<td>1. 功能太简单，复杂需求实现不了</td>
</tr>
</tbody></table>
<h1 id="核心操作-example（POI）"><a href="#核心操作-example（POI）" class="headerlink" title="核心操作 example（POI）"></a>核心操作 example（POI）</h1><p><a href="https://poi.apache.org/components/spreadsheet/quick-guide.html#NamedRanges">quick guide</a></p>
<p><a href="https://github.com/HFCherish/learning-common/blob/master/common-excel/src/test/java/learning/common/excel/utils/XLSXTest.java">源代码</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//        load excel</span></span><br><span class="line"><span class="type">XSSFWorkbook</span> <span class="variable">workbook</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">XSSFWorkbook</span>(getFile(<span class="string">&quot;test.xlsx&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//        get sheet by name</span></span><br><span class="line"><span class="type">String</span> <span class="variable">sheetName</span> <span class="operator">=</span> <span class="string">&quot;Product Mix&quot;</span>;</span><br><span class="line"><span class="type">XSSFSheet</span> <span class="variable">sheet</span> <span class="operator">=</span> workbook.getSheet(sheetName);</span><br><span class="line">assertThat(sheet.getSheetName(), is(sheetName));</span><br><span class="line"></span><br><span class="line"><span class="comment">//        get cell by coordinate</span></span><br><span class="line"><span class="type">XSSFCell</span> <span class="variable">tvsetNumber</span> <span class="operator">=</span> getCell(sheet, <span class="string">&quot;D4&quot;</span>);</span><br><span class="line">assertThat(tvsetNumber.getNumericCellValue(), closeTo(<span class="number">100</span>, <span class="number">0.1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//        get formula cell by coordinate</span></span><br><span class="line"><span class="type">XSSFCell</span> <span class="variable">total</span> <span class="operator">=</span> getCell(sheet, <span class="string">&quot;D13&quot;</span>);</span><br><span class="line">assertThat(total.getNumericCellValue(), closeTo(<span class="number">16000</span>, <span class="number">0.1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//        change cell value</span></span><br><span class="line">tvsetNumber.setCellValue(<span class="number">200</span>);</span><br><span class="line">assertThat(tvsetNumber.getNumericCellValue(), closeTo(<span class="number">200</span>, <span class="number">0.1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//        refresh formulas</span></span><br><span class="line">XSSFFormulaEvaluator.evaluateAllFormulaCells(workbook);</span><br><span class="line">assertThat(total.getNumericCellValue(), closeTo(<span class="number">23500</span>, <span class="number">0.1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//        write back to file</span></span><br><span class="line">workbook.write(<span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(getFile(<span class="string">&quot;update.xlsx&quot;</span>)));</span><br><span class="line"></span><br><span class="line"><span class="comment">//        check data updated</span></span><br><span class="line"><span class="type">XSSFWorkbook</span> <span class="variable">updateWorkBook</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">XSSFWorkbook</span>(getFile(<span class="string">&quot;update.xlsx&quot;</span>));</span><br><span class="line">assertThat(getCell(updateWorkBook.getSheet(sheetName), <span class="string">&quot;D4&quot;</span>).getNumericCellValue(), closeTo(<span class="number">200</span>, <span class="number">0.1</span>));</span><br><span class="line">assertThat(getCell(updateWorkBook.getSheet(sheetName), <span class="string">&quot;D13&quot;</span>).getNumericCellValue(), closeTo(<span class="number">23500</span>, <span class="number">0.1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//		  get cell by name</span></span><br><span class="line"><span class="type">XSSFName</span> <span class="variable">test_name</span> <span class="operator">=</span> workbook.getName(<span class="string">&quot;test_cell_name&quot;</span>);</span><br><span class="line"><span class="type">AreaReference</span> <span class="variable">areaReference</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AreaReference</span>(test_name.getRefersToFormula(), SpreadsheetVersion.EXCEL2007);</span><br><span class="line"></span><br><span class="line"><span class="type">CellReference</span> <span class="variable">firstCell</span> <span class="operator">=</span> areaReference.getFirstCell();</span><br><span class="line"><span class="type">XSSFSheet</span> <span class="variable">sheet</span> <span class="operator">=</span> workbook.getSheet(firstCell.getSheetName());</span><br><span class="line"><span class="type">XSSFRow</span> <span class="variable">row</span> <span class="operator">=</span> sheet.getRow(firstCell.getRow());</span><br><span class="line"><span class="type">XSSFCell</span> <span class="variable">cell</span> <span class="operator">=</span> row.getCell(firstCell.getCol());</span><br><span class="line"></span><br><span class="line"><span class="comment">// get cell function</span></span><br><span class="line"><span class="keyword">private</span> XSSFCell <span class="title function_">getCell</span><span class="params">(XSSFSheet sheet, String cellCoordinate)</span> &#123;</span><br><span class="line">    <span class="type">CellReference</span> <span class="variable">d4</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CellReference</span>(cellCoordinate);</span><br><span class="line">    <span class="type">XSSFRow</span> <span class="variable">row</span> <span class="operator">=</span> sheet.getRow(d4.getRow());</span><br><span class="line">    <span class="keyword">return</span> row.getCell(d4.getCol());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="其他操作（POI）"><a href="#其他操作（POI）" class="headerlink" title="其他操作（POI）"></a>其他操作（POI）</h1><h2 id="copy-sheet"><a href="#copy-sheet" class="headerlink" title="copy sheet"></a>copy sheet</h2><h2 id="xlsm-to-xlsx"><a href="#xlsm-to-xlsx" class="headerlink" title="xlsm to xlsx"></a>xlsm to xlsx</h2>]]></content>
      <tags>
        <tag>java</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title>java.lang.UnsatisfiedLinkError: no xxx in java.library.path</title>
    <url>/2018/08/14/java-application-using-third-party-lib/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><ol>
<li>项目需要引入 local 第三方包</li>
<li>该第三方包只有 window&#x2F;linux license，而开发在 macos</li>
<li>开发时，通过 gradle dependency <code>compile files(&#39;path/to/thejar.jar&#39;)</code> 来引入包</li>
</ol>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>运行时，报错误 <code>java.lang.UnsatisfiedLinkError: no thejar in java.library.path</code></p>
<h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>引入 <code>.dll</code> 或 <code>.so</code> 失败造成。</p>
<h1 id="solution"><a href="#solution" class="headerlink" title="solution"></a>solution</h1><ol>
<li>把 thejar 加入到 path 中 ————— not work</li>
<li>加入 path，并 loadLibrary ——————— not work</li>
<li>should work（配置 .dll 或 .so 路径）：<ol>
<li>配置 PATH</li>
<li>或 jar 包启动时，设置 ‘-Djava.library.path’</li>
</ol>
</li>
</ol>
<p>有关 <code>PATH</code>, <code>-classpath</code>, <code>java.library.path</code> 的区别，再 google。java 在使用这三个 path 时：</p>
<ol>
<li><code>PATH</code>：用来寻找 <code>java</code>, <code>javac</code> 等 command 并执行</li>
<li><code>classpath</code>：jvm 在执行时用来寻找 java class。classpath 一般指向 jar 包的位置，即 jdk 的 lib 目录</li>
<li><code>java.library.path</code>: 指向非 java 类包的位置，如 .dll, .so 等。在 java <code>System.loadLibrary()</code> 时从这找</li>
</ol>
<p><code>java.library.path</code> 的设定可参照 <a href="https://stackoverflow.com/questions/1403788/java-lang-unsatisfiedlinkerror-no-dll-in-java-library-path">stackoverflow</a></p>
<ul>
<li><code>java -jar xxx.jar -Djava.library.path=xxx</code></li>
<li>Set PATH</li>
<li>Set programmatically (NOT RECOMMENDED, may cause unpredictable result):</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">System.setProperty(<span class="string">&quot;java.library.path&quot;</span>, path);</span><br><span class="line"><span class="comment">//set sys_paths to null</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">Field</span> <span class="variable">sysPathsField</span> <span class="operator">=</span> ClassLoader.class.getDeclaredField(<span class="string">&quot;sys_paths&quot;</span>);</span><br><span class="line">sysPathsField.setAccessible(<span class="literal">true</span>);</span><br><span class="line">sysPathsField.set(<span class="literal">null</span>, <span class="literal">null</span>);</span><br></pre></td></tr></table></figure>

<p>linux 下可通过 <code>LD_LIBRARY_PATH</code> 设置 <code>java.library.path</code>。windows 下似乎是通过 <code>PATH</code> 设定（待确定）</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java reflection</title>
    <url>/2018/07/14/java-reflection/</url>
    <content><![CDATA[<h1 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h1><p>java 泛型存在类型擦除（参见 <a href="https://blog.csdn.net/briblue/article/details/76736356">java 泛型</a>）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; l1 = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;String&gt;();</span><br><span class="line">List&lt;Integer&gt; l2 = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;Integer&gt;();</span><br><span class="line"></span><br><span class="line">System.out.println(l1.getClass() == l2.getClass());	<span class="comment">// return true, 两个都是 List.class</span></span><br></pre></td></tr></table></figure>

<h2 id="获取运行时泛型类型"><a href="#获取运行时泛型类型" class="headerlink" title="获取运行时泛型类型"></a>获取运行时泛型类型</h2><p>类型擦除使得根据类定义获取 runtime 泛型类型是不可能的，一般有几种方法(参见 <a href="https://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime">stackoverflow</a>)：</p>
<ol>
<li>根据类对象实例获取，可参见 <a href="http://qussay.com/2013/09/28/handling-java-generic-types-with-reflection/#has_default_constructor">handle java generic types with reflection</a><ul>
<li>eg. <code>Class&lt;T&gt; tClass = (Class&lt;T&gt;) ReflectionUtil.getClass(ReflectionUtil.getParameterizedTypes(this)[0]);</code></li>
</ul>
</li>
<li>从父类中获取（要求父类有相同的泛型参数）<ul>
<li>eg. <code>Class&lt;T&gt; tClass = (Class&lt;T&gt;) ((ParameterizedType) getClass().getGenericSuperclass()).getActualTypeArguments()[0]</code></li>
</ul>
</li>
<li>通过方法存储泛型类型为 field。但这意味着所有的 client 都必须要通过相应方法设置该 field</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 通过方法（constructor）存储泛型类型</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GenericClass</span>&lt;T&gt; &#123;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">final</span> Class&lt;T&gt; type;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">public</span> <span class="title function_">GenericClass</span><span class="params">(Class&lt;T&gt; type)</span> &#123;</span><br><span class="line">          <span class="built_in">this</span>.type = type;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">public</span> Class&lt;T&gt; <span class="title function_">getMyType</span><span class="params">()</span> &#123;</span><br><span class="line">         <span class="keyword">return</span> <span class="built_in">this</span>.type;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="获取一个带泛型信息的-class-变量"><a href="#获取一个带泛型信息的-class-变量" class="headerlink" title="获取一个带泛型信息的 class 变量"></a>获取一个带泛型信息的 class 变量</h2><p>例如当使用 <code>new ObjectMapper().readValue(string, someClass)</code>，而 someClass 是包含泛型参数的类型（eg. List<Integer>），如何获取这样的 class 变量？</p>
<p>参见 <a href="https://stackoverflow.com/a/6349488/10003123">stackOverflow</a>，总结如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.databind.ObjectMapper;</span><br><span class="line"><span class="type">ObjectMapper</span> <span class="variable">mapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// as Array</span></span><br><span class="line">MyClass[] myObjects = mapper.readValue(json, MyClass[].class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// as List</span></span><br><span class="line">List&lt;MyClass&gt; myObjects = mapper.readValue(jsonInput, <span class="keyword">new</span> <span class="title class_">TypeReference</span>&lt;List&lt;MyClass&gt;&gt;()&#123;&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// as List (another more generic way)</span></span><br><span class="line">List&lt;MyClass&gt; myObjects = mapper.readValue(jsonInput, mapper.getTypeFactory().constructCollectionType(List.class, MyClass.class));</span><br><span class="line"></span><br><span class="line"><span class="comment">// as List (using TypeToken in Gson)</span></span><br><span class="line">Class&lt;List&lt;MyClass&gt;&gt; tClass = <span class="keyword">new</span> <span class="title class_">TypeToken</span>&lt;List&lt;MyClass&gt;() &#123;</span><br><span class="line">        &#125;.getRawType();</span><br><span class="line">        </span><br><span class="line"><span class="comment">// use c</span></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java stream parallel 有时比 sequential 还慢？</title>
    <url>/2022/10/22/java-stream-parallel/</url>
    <content><![CDATA[<h1 id="为什么-java-stream-parallel-有时比-sequential-执行还慢？"><a href="#为什么-java-stream-parallel-有时比-sequential-执行还慢？" class="headerlink" title="为什么 java stream parallel 有时比 sequential 执行还慢？"></a>为什么 java stream parallel 有时比 sequential 执行还慢？</h1><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>考虑下边的代码，并行执行不一定比顺序执行快，甚至很多时候都是更慢的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_not_sure_if_without_warm_up</span><span class="params">()</span> &#123;</span><br><span class="line">        String[] array = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">1000000</span>];</span><br><span class="line">        Arrays.fill(array, <span class="string">&quot;AbabagalamagA&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Benchmark...&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i) &#123;</span><br><span class="line">            System.out.printf(<span class="string">&quot;Run %d:  sequential %s  -  parallel %s\n&quot;</span>,</span><br><span class="line">                    i,</span><br><span class="line">                    test(() -&gt; sequential(array)),</span><br><span class="line">                    test(() -&gt; parallel(array)));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">sequential</span><span class="params">(String[] array)</span> &#123;</span><br><span class="line">        Arrays.stream(array).map(String::toLowerCase).collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">parallel</span><span class="params">(String[] array)</span> &#123;</span><br><span class="line">        Arrays.stream(array).parallel().map(String::toLowerCase).collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String <span class="title function_">test</span><span class="params">(Runnable runnable)</span> &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">        runnable.run();</span><br><span class="line">        <span class="type">long</span> <span class="variable">elapsed</span> <span class="operator">=</span> System.currentTimeMillis() - start;</span><br><span class="line">        <span class="keyword">return</span> String.format(<span class="string">&quot;%4.2fs&quot;</span>, elapsed / <span class="number">1000.0</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="为什么？"><a href="#为什么？" class="headerlink" title="为什么？"></a>为什么？</h2><p>有几个原因（<a href="http://www.theserverside.com/definition/just-in-time-compiler-JIT">stackoverflow</a>）：</p>
<ol>
<li><strong>stream 的并行执行比串行执行要做更多的事</strong>。并行执行需要拆分程序，使得程序可以并行执行，最后要合并结果。例如，上述并行执行涉及到 new 线程池、分配线程执行特定的 string 操作并加到一个 list、最终合并 list。这个程序本身已经执行很快，此时，这些额外开销比本身执行的时间可能还要长，就影响了它最终带来的性能。</li>
<li><strong>编译器、jvm、GC 等会影响代码执行效率，因此对 java 做这些基准测试很微妙</strong>。例如 <a href="http://www.theserverside.com/definition/just-in-time-compiler-JIT">JIT compiler</a>、GC 等就会很大程度的影响测试结果。<ol start="3">
<li>测试很大程度受 JIT compiler 执行的影响<ol start="4">
<li>在 JIT compiler 完成之前，可能测试已经跑完了。此时顺序执行和并行执行哪个 JIT compiler 先跑完，可能测试就会跑的更快一些</li>
<li>而且 JIT compiler 什么时候开始跑也不确定。</li>
<li>并且 JIT compiler 会做一些运行时优化，比如有些代码，其输出没有在任何地方被使用，JIT compiler 会直接消除这些代码的执行。这种情况还是非常容易发生的。此时，你这些测试衡量就更微妙了，因为可能最终执行的测试并不是你所写的测试，而是优化之后的。</li>
<li>如果在测试执行之前，加上一些预热，就可以保证程序都已经再编译完成，此时评估的就是同等条件下的程序执行效率了（参见下边的 code）。</li>
</ol>
</li>
<li>GC 会影响执行效率，不同的代码会产生不同的 eliminated objects<ol start="5">
<li>stream、并行运行等会涉及到很多中间变量的构建、copy 等，比如中间 string、list 等，这时 GC 执行工作量就比较大，会影响最终的测试执行时间，使得测试结果也不可信。</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>对 java 做这些基准测试，有时结果会比较 confusing，所以建议采用专门的 benchmark 框架来做基准测试，比如 <a href="http://openjdk.java.net/projects/code-tools/jmh/">JMH</a>，这框架执行过程中，可以看到很多 java 额外执行的一些操作时间等，就可以更好的观察测试结果了。        </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* 更改测试，加上预热，保证 JIT 编译已完成，此时基本是在同等条件下测试，测试结果相对更可信一些</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_parallel_faster_if_has_warm_up</span><span class="params">()</span> &#123;</span><br><span class="line">    String[] array = <span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">1000000</span>];</span><br><span class="line">    Arrays.fill(array, <span class="string">&quot;AbabagalamagA&quot;</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;Warmup...&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">        sequential(array);</span><br><span class="line">        parallel(array);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(<span class="string">&quot;Benchmark...&quot;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i) &#123;</span><br><span class="line">        System.out.printf(<span class="string">&quot;Run %d:  sequential %s  -  parallel %s\n&quot;</span>,</span><br><span class="line">                i,</span><br><span class="line">                test(() -&gt; sequential(array)),</span><br><span class="line">                test(() -&gt; parallel(array)));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="什么是-JIT-compiler"><a href="#什么是-JIT-compiler" class="headerlink" title="什么是 JIT compiler"></a>什么是 <a href="http://www.theserverside.com/definition/just-in-time-compiler-JIT">JIT compiler</a></h3><p>JIT (just-in-time) compiler 指在运行时执行的编译器。</p>
<p>(1) java 是编译成字节码，然后在运行时解释执行的</p>
<p>c、C++ 等编程语言都是直接编译成机器码，可以在机器上直接执行的。但是不同平台处理器有差异，导致用户可能需要为不同平台写多套程序。</p>
<p>java 就提出了 JVM，将代码一次编译成字节码，然后提供不同的 JVM，JVM 会将字节码解释执行为可运行的机器码。</p>
<p>但是解释执行是一行一行做的，就影响了执行效率。这也是为啥 c++ 等会诟病 java 很慢的原因。</p>
<p>(2) 为了提高解释执行的效率，使用了 JIT compiler</p>
<p>正如上文所说，因为解释执行慢，所以在程序运行起来后，同时会执行 JIT compiler，将字节码编译成可执行代码（相当于二次编译）。这就可以一定程度的加快解释执行的效率。而且 JIT compiler 因为可以获取运行时环境、参数等，所以可以做更多的优化</p>
<h1 id="parallel-慎用？？？"><a href="#parallel-慎用？？？" class="headerlink" title="parallel 慎用？？？"></a>parallel 慎用？？？</h1><p><a href="https://dzone.com/articles/think-twice-using-java-8">DZone: parallel 慎用</a> 说因为 stream 公用线程池，一个 broken thread 会影响所有 healthy 线程的执行，所以要慎用。</p>
<p>简单看了一些，比如这个 <a href="https://stackoverflow.com/questions/20375176/should-i-always-use-a-parallel-stream-when-possible">stackoverflow</a>，应该是说 stream 提供了方便的形式去写 function、可读性高、promote 大家写出 side-effects-free 的代码，但是 stream 本身还是有很多缺陷的。</p>
<p>公用线程池的测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">should_be_influenced_by_long_tasks</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="comment">/** Simulating multiple threads in the system</span></span><br><span class="line"><span class="comment">    * if one of them is executing a long-running task.</span></span><br><span class="line"><span class="comment">    * Some of the other threads/tasks are waiting</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">MAX</span> <span class="operator">=</span> <span class="number">12</span>;</span><br><span class="line">    <span class="type">ExecutorService</span> <span class="variable">es</span> <span class="operator">=</span> Executors.newCachedThreadPool();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这个线程执行很慢，但是因为共享线程池，因此会影响其他线程的执行。极端情况，这里是一个 broken tread，其他 healthy thread 都会受影响</span></span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">1000</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 执行结果不确定，因为有上边的长线程。如果注释掉上边线程，下边这个可以很快执行</span></span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.execute(() -&gt; countPrimes(MAX, <span class="number">0</span>));</span><br><span class="line">    es.shutdown();</span><br><span class="line">    es.awaitTermination(<span class="number">60</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">countPrimes</span><span class="params">(<span class="type">int</span> max, <span class="type">int</span> delay)</span> &#123;</span><br><span class="line">    System.out.println(Thread.currentThread().getId() + <span class="string">&quot;: &quot;</span> + range(<span class="number">1</span>, max).parallel().filter(<span class="built_in">this</span>::isPrime).peek(i -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            sleep(delay);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;).count());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">isPrime</span><span class="params">(<span class="type">long</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> n &gt; <span class="number">1</span> &amp;&amp; rangeClosed(<span class="number">2</span>, (<span class="type">long</span>) sqrt(n)).noneMatch(divisor -&gt; n % divisor == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="ForkJoinPool"><a href="#ForkJoinPool" class="headerlink" title="ForkJoinPool"></a><a href="http://tutorials.jenkov.com/java-util-concurrent/java-fork-and-join-forkjoinpool.html">ForkJoinPool</a></h2><p><a href="https://www.jianshu.com/p/bd825cb89e00">这个文章</a> 介绍了 ForkJoinPool，说是 parallel stream 实现的主要原理和背后手段</p>
<p>stream 的并发执行现在基本上都是采用分治法，先拆分用多线程逐个处理，然后再合并结果。最后的合并操作必须在前边某几个线程执行完之后才做。</p>
<p>而普通的线程池 <a href="">ThreadPoolExecutor</a> 就是构建一个线程池，并发执行，但是它没办法决定线程执行的父子关系。</p>
<p>ForkJoinPool 就是为了解决上述问题而存在，它可以让子任务并发执行完成之后，才开始执行父任务。除此以外，和 ThreadPoolExecutor 一样，都是用一个无限队列来保存待执行的任务。</p>
<p>ForkJoinPool 采用了一个通用线程池，实现了 **<a href="http://ifeve.com/talk-concurrency-forkjoin/">工作窃取</a>**。工作窃取指某个线程从其他队列里窃取任务来执行。ForkJoinPool 就可以？？？？？</p>
<h1 id="什么时候用-parallel"><a href="#什么时候用-parallel" class="headerlink" title="什么时候用 parallel"></a>什么时候用 parallel</h1><p>目前来说，在 java 中：</p>
<ol>
<li>如果是数据量很大的操作，可以考虑用 parallel</li>
<li>如果有性能问题，再考虑用 parallel</li>
<li>如果确实有多核，再考虑用</li>
<li>如果确实是无 side effect 的函数，才可以考虑用</li>
<li>如果已经有其他并行措施，可以不用 parallel</li>
<li>如果数据操作很慢，慎用（可能 block 其他 thread）</li>
<li>如果数据操作很快，也慎用（可能这个时候用并行的额外开销会超过它所能带来的优势）</li>
</ol>
<p><a href="https://blog.oio.de/2016/01/22/parallel-stream-processing-in-java-8-performance-of-sequential-vs-parallel-stream-processing/">这篇文章</a>也对比了并行和串行 stream，然后画了个决策象限图，如下图所示：</p>
<p><img src="https://blog.oio.de/wp-content/uploads/2016/01/stream_performance_image3.png" alt="parallel 决策象限图"></p>
<p>跟上边类似，关注下边四个方面：</p>
<ol>
<li><code>number_of_elements * cost_per_element</code> 比较大。这可以比较好的解决这种状况：每个元素运行很快时，如果数据量大就可以用；如果每个元素运行稍费时些，即使数据量不那么大，也 ok。但是应该要避免过于费时的那些场景，见上边的分析。</li>
<li>source collection 可以很高效的被拆分（这样才方便拆线程处理）</li>
<li>每个元素的函数执行是独立的（这才可以并行处理，即并行首先要求 side effect free）</li>
<li>多核</li>
</ol>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java multithread programming</title>
    <url>/2023/05/09/java-thread/</url>
    <content><![CDATA[<p><a href="https://www.digitalocean.com/community/tutorials/core-java-tutorial">Core Java Tutorial | DigitalOcean</a></p>
<h1 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h1><p>Process: A process is a self contained execution environment and it can be seen as a program or application.</p>
<p>Thread: lightweight.</p>
<ul>
<li><p>a process can have multiple threads running, and at least one main thread.</p>
</li>
<li><p>all thread share parent process code and data</p>
</li>
<li><p>thread creation, context switching, and intercommunication are less expensive</p>
</li>
<li><p>Multithreading: In multi-core system, more than one thread can run at the exactly same time. In single-core system, more than one thread can run parallel using OS feature time slicing to share the processor time.</p>
</li>
</ul>
<h2 id="example"><a href="#example" class="headerlink" title="example"></a>example</h2><ul>
<li><p>implement <code>Runnable</code>: recommended (interface-oriented programming). Support to be more functional class.</p>
</li>
<li><p>extends <code>Thread</code></p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// anonymous way</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">r</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Runnable</span>()&#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;My Runnable&quot;</span>);</span><br><span class="line">            &#125;&#125;;</span><br><span class="line"><span class="comment">// lambda way, since Runnable is a functional interface</span></span><br><span class="line"><span class="type">Runnable</span> <span class="variable">r1</span> <span class="operator">=</span> () -&gt; System.out.println(<span class="string">&quot;My Runnable&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// verbose way, especially when the class is complicated, e.g. a publisher/consumer</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HeavyWorkRunnable</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Doing heavy processing - START &quot;</span>+Thread.currentThread().getName());</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            <span class="comment">//Get database connection, delete unused data from DB</span></span><br><span class="line">            doDBProcessing();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;Doing heavy processing - END &quot;</span>+Thread.currentThread().getName());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">doDBProcessing</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyThread</span> <span class="keyword">extends</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyThread</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;MyThread - START &quot;</span>+Thread.currentThread().getName());</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            doDBProcessing();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;MyThread - END &quot;</span>+Thread.currentThread().getName());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">doDBProcessing</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadRunExample</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">HeavyWorkRunnable</span>(), <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">HeavyWorkRunnable</span>(), <span class="string">&quot;t2&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Starting Runnable threads&quot;</span>);</span><br><span class="line">        t1.start();</span><br><span class="line">        t2.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;Runnable Threads has been started&quot;</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyThread</span>(<span class="string">&quot;t3&quot;</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t4</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyThread</span>(<span class="string">&quot;t4&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Starting MyThreads&quot;</span>);</span><br><span class="line">        t3.start();</span><br><span class="line">        t4.start();</span><br><span class="line">        System.out.println(<span class="string">&quot;MyThreads has been started&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="daemon-threads-amp-non-daemon-threads"><a href="#daemon-threads-amp-non-daemon-threads" class="headerlink" title="daemon threads &amp; non-daemon threads"></a>daemon threads &amp; non-daemon threads</h2><p>In Java, a daemon thread is a low-priority thread that runs in the background to perform tasks such as garbage collection and memory management. Daemon threads are usually used to perform tasks that do not require user interaction or direct communication with the user. In Java, you can create a daemon thread by calling the <code>setDaemon(true)</code> method on the Thread object.</p>
<p>When the main thread finishes in a Java program, the JVM will only wait for non-daemon threads to complete before terminating. Daemon threads, on the other hand, will be abruptly terminated when the JVM exits, regardless of their state.</p>
<h3 id="garbage-collector-daemon-thread"><a href="#garbage-collector-daemon-thread" class="headerlink" title="garbage collector daemon thread"></a>garbage collector daemon thread</h3><p>If the garbage collector daemon thread is terminated abruptly during the JVM shutdown, it may leave some unreclaimed objects in the heap. The unreclaimed objects will eventually be reclaimed by the operating system when the process terminates.</p>
<p>Calling <code>System.gc()</code> does not start a new thread. Instead, it is a request to the JVM to run the garbage collector. Whether or not the JVM actually runs the garbage collector in response to this request is up to the JVM implementation and cannot be guaranteed. </p>
<p>In general, it is not recommended to call <code>System.gc()</code> explicitly. </p>
<p>In some rare cases, calling <code>System.gc()</code> may be necessary. For example, if your application is generating a large amount of garbage and you want to force garbage collection before a critical section of code, you can call <code>System.gc()</code> to encourage the JVM to collect the garbage. But note that this is generally not recommended unless you have a specific need for it and have thoroughly tested its impact on performance.</p>
<p>Therefore, it’s generally recommended to manage memory explicitly by properly releasing objects when they are no longer needed, rather than relying on the JVM to reclaim them at the end of the process.</p>
<h2 id="blocked-thread-wait-notify…"><a href="#blocked-thread-wait-notify…" class="headerlink" title="blocked thread (wait, notify…)"></a>blocked thread (wait, notify…)</h2><p><img src="/../images/Thread-Lifecycle-States.png" alt="thread-life-cycle.png"></p>
<p>Object class contains 3 final methods <code>wait</code>, <code>notify</code>, <code>notifyall</code> which allows thread to communicate about the lock status.</p>
<p><code>wait</code>: block the current thread, until some thread calls <code>notify</code>&#x2F;<code>notifyall</code> on this object, or after some specified time.</p>
<p><code>notify</code>: unlock one thread that’s waiting for the object</p>
<p><code>notifyAll</code>: unlock all threads that’re waiting for the object.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// producer consumer issue</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WaitNotifyTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(<span class="string">&quot;process it&quot;</span>);</span><br><span class="line">        <span class="type">Waiter</span> <span class="variable">waiter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Waiter</span>(msg);</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(waiter,<span class="string">&quot;waiter&quot;</span>).start();</span><br><span class="line"></span><br><span class="line">        <span class="type">Waiter</span> <span class="variable">waiter1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Waiter</span>(msg);</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(waiter1, <span class="string">&quot;waiter1&quot;</span>).start();</span><br><span class="line"></span><br><span class="line">        <span class="type">Notifier</span> <span class="variable">notifier</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Notifier</span>(msg);</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">Thread</span>(notifier, <span class="string">&quot;notifier&quot;</span>).start();</span><br><span class="line"><span class="comment">// here the line will be printed quickly and the main thread is finished </span></span><br><span class="line"><span class="comment">// while all the other threads are still running. See thread.join below</span></span><br><span class="line">        System.out.println(<span class="string">&quot;All the threads are started&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String msg;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Message</span><span class="params">(String str)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.msg=str;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getMsg</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> msg;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setMsg</span><span class="params">(String str)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.msg=str;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Waiter</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Message msg;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Waiter</span><span class="params">(Message m)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.msg=m;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Thread.currentThread().getName();</span><br><span class="line">        <span class="keyword">synchronized</span> (msg) &#123;</span><br><span class="line">            <span class="keyword">try</span>&#123;</span><br><span class="line">                System.out.println(name+<span class="string">&quot; waiting to get notified at time:&quot;</span>+System.currentTimeMillis());</span><br><span class="line">                msg.wait();</span><br><span class="line">            &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(name+<span class="string">&quot; waiter thread got notified at time:&quot;</span>+System.currentTimeMillis());</span><br><span class="line">            <span class="comment">//process the message now</span></span><br><span class="line">            System.out.println(name+<span class="string">&quot; processed: &quot;</span>+msg.getMsg());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Notifier</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Message msg;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Notifier</span><span class="params">(Message msg)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.msg = msg;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Thread.currentThread().getName();</span><br><span class="line">        System.out.println(name+<span class="string">&quot; started&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            <span class="keyword">synchronized</span> (msg) &#123;</span><br><span class="line">                msg.setMsg(name+<span class="string">&quot; Notifier work done&quot;</span>);</span><br><span class="line">                msg.notify();</span><br><span class="line">                <span class="comment">// msg.notifyAll();</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="thread-join"><a href="#thread-join" class="headerlink" title="thread.join"></a>thread.join</h3><p>If there are any non-daemon threads still running, they will continue to run even after the <code>main()</code> function has completed. The JVM will keep running until all non-daemon threads have finished executing. Once all non-daemon threads have completed, the JVM will exit.</p>
<p>If you want the main process to wait for all threads to complete before exiting, you can call the <code>join()</code> method on each thread. The <code>join()</code> method will block the calling thread (in this case, the main thread) until the thread being joined completes its execution.</p>
<p><strong>public final void join()</strong>: This java thread join method puts the current thread on wait until the thread on which it’s called is dead. If the thread is interrupted, it throws InterruptedException. <strong>public final synchronized void join(long millis)</strong>: This java thread join method is used to wait for the thread on which it’s called to be dead or wait for specified milliseconds. Since thread execution depends on OS implementation, it doesn’t guarantee that the current thread will wait only for given time. <strong>public final synchronized void join(long millis, int nanos)</strong>: This java thread join method is used to wait for thread to die for given milliseconds plus nanoseconds.</p>
<p>Using join with maximum time can avoid some dead lock issues.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadJoinExample</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">MyRunnable</span>(), <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">MyRunnable</span>(), <span class="string">&quot;t2&quot;</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">MyRunnable</span>(), <span class="string">&quot;t3&quot;</span>);</span><br><span class="line"></span><br><span class="line">        t1.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//start second thread after waiting for 2 seconds or if it&#x27;s dead</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            t1.join(<span class="number">2000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        t2.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//start third thread only when first thread is dead</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            t1.join();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        t3.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//let all threads finish execution before finishing main thread</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            t1.join();</span><br><span class="line">            t2.join();</span><br><span class="line">            t3.join();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            <span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;All threads are dead, exiting main thread&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRunnable</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Thread started:::&quot;</span>+Thread.currentThread().getName());</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">4000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;Thread ended:::&quot;</span>+Thread.currentThread().getName());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Thread-safety-synchronized"><a href="#Thread-safety-synchronized" class="headerlink" title="Thread safety (synchronized)"></a>Thread safety (synchronized)</h2><p>Multiple threads create from the same object share the object variables, which may cause issues. To avoid parallel update issues, we can</p>
<ol>
<li><p>Do not update in the parallel thread</p>
</li>
<li><p>Synchronization is the easiest and most widely used tool for thread safety in java.</p>
</li>
<li><p>Use of Atomic Wrapper classes from <em>java.util.concurrent.atomic</em> package. For example AtomicInteger</p>
</li>
<li><p>Use of locks from <em>java.util.concurrent.locks</em> package.</p>
</li>
<li><p>Using thread safe collection classes, check this post for usage of <a href="https://www.digitalocean.com/community/tutorials/concurrenthashmap-in-java">ConcurrentHashMap</a> for thread safety.</p>
</li>
<li><p>Using volatile keyword with variables to make every thread read the data from memory, not read from thread cache.</p>
</li>
</ol>
<p><code>synchronized</code> internally uses locks on Object or Class to make sure only one thread is executing the synchronized code. A monitor in Java is a synchronization mechanism that allows multiple threads to safely access shared resources. A monitor is associated with an object, and when a thread enters a synchronized block on that object, it acquires the monitor lock.</p>
<p>When use synchronization,</p>
<ol>
<li><p>use in 2 ways: on entire method or on a code block. Cannot use <code>synchronized</code> on construction code or variables.</p>
</li>
<li><p>Best practice:</p>
<ol>
<li><p>use the lowest level of lock. Better lock the required code block instead of the whole method. Lock the instance method in fact use the current Object as the lock, and lock the static method in fact use the current Class as the lock.</p>
</li>
<li><p>Use a private dummy object as the lock. Do not make the lock public or provide public setter, because when the object is changed, multiple threads on this variable maybe parallel running for they in fact locked different object reference.</p>
<ol>
<li><p>Better not use the current Object as a lock. It will lock all the fields on the Object, which may block all the synchronized code on this class when there’re many synchronized blocks.</p>
</li>
<li><p>Better not use any object maintained in a constant pool, e.g. String. It may block some completely unrelated synchronized code on the same String.</p>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadSafety</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">ProcessingThread</span> <span class="variable">pt</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProcessingThread</span>();</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(pt, <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        t1.start();</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(pt, <span class="string">&quot;t2&quot;</span>);</span><br><span class="line">        t2.start();</span><br><span class="line">        <span class="comment">//wait for threads to finish processing</span></span><br><span class="line">        t1.join();</span><br><span class="line">        t2.join();</span><br><span class="line">        System.out.println(<span class="string">&quot;Processing count=&quot;</span>+pt.getCount());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProcessingThread</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> count;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i &lt; <span class="number">5</span>; i++)&#123;</span><br><span class="line">            processSomething(i);</span><br><span class="line">            <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getCount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.count;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">processSomething</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">        <span class="comment">// processing some job</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(i*<span class="number">1000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Dead-lock"><a href="#Dead-lock" class="headerlink" title="Dead lock"></a>Dead lock</h2><p>To avoid dead lock,</p>
<ol>
<li><p><strong>Avoid Nested Locks</strong>: This is the most common reason for deadlocks, avoid locking another resource if you already hold one. It’s almost impossible to get deadlock situation if you are working with only one object lock.</p>
</li>
<li><p><strong>Lock Only What is Required</strong></p>
</li>
<li><p><strong>Avoid waiting indefinitely</strong>: You can get deadlock if two threads are waiting for each other to finish indefinitely using <a href="https://www.digitalocean.com/community/tutorials/java-thread-join-example" title="Java Thread Join Example with Explanation">thread join</a>. If your thread has to wait for another thread to finish, it’s always best to use join with maximum time you want to wait for thread to finish.</p>
</li>
</ol>
<h3 id="thread-dump"><a href="#thread-dump" class="headerlink" title="thread dump"></a>thread dump</h3><p>To detect dead lock, we can use thread dump.</p>
<p>Java thread dump is list of all the thread active in JVM. Each entry is in the following format:</p>
<ol>
<li><strong>Thread Name</strong>: Name of the Thread</li>
<li><strong>Thread Priority</strong>: Priority of the thread</li>
<li><strong>Thread ID</strong>: Represents the unique ID of the Thread</li>
<li><strong>Thread Status</strong>: Provides the current <a href="https://www.digitalocean.com/community/tutorials/thread-life-cycle-in-java-thread-states-in-java" title="Life Cycle of Thread – Understanding Thread States in Java">thread state</a>, for example RUNNABLE, WAITING, BLOCKED. While analyzing deadlock look for the blocked threads and resources on which they are trying to acquire lock.</li>
<li><strong>Thread callstack</strong>: Provides the vital stack information for the thread. This is the place where we can see the locks obtained by Thread and if it’s waiting for any lock.</li>
</ol>
<p>To get thread dump:</p>
<ol>
<li><p><strong>VisualVM Profiler</strong>: If you are analyzing application for slowness, you must use a profiler. We can generate thread dump for any process using VisualVM profiler very easily. You just need to right click on the running process and click on “Thread Dump” option to generate it.</p>
</li>
<li><p><strong>jstack</strong>: Java comes with <strong>jstack</strong> tool through which we can generate thread dump for a java process. This is a two step process.</p>
<ol>
<li>Find out the PID of the java process using <code>ps -eaf | grep java</code> command</li>
<li>Run jstack tool as <code>jstack PID</code> to generate the thread dump output to console, you can append thread dump output to file using command “<code>jstack PID &gt;&gt; mydumps.tdump</code>”</li>
</ol>
</li>
<li><p>We can use <code>kill -3 PID</code> command to generate the thread dump. This is slightly different from other ways to generate thread dump. When kill command is issued, thread dump is generated to the System out of the program. So if it’s a java program with console as system out, the thread dump will get printed on the console. If the java program is a Tomcat server with system out as <code>catalina.out</code>, then thread dump will be generated in the file.</p>
</li>
<li><p>Java 8 has introduced <code>jcmd</code> utility. You should use this instead of jstack if you are on Java 8 or higher. Command to generate thread dump using jcmd is <code>jcmd PID Thread.print</code>.</p>
</li>
</ol>
<h3 id="nested-dead-lock-example"><a href="#nested-dead-lock-example" class="headerlink" title="nested dead lock example"></a>nested dead lock example</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadDeadlock</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">Object</span> <span class="variable">obj1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">        <span class="type">Object</span> <span class="variable">obj2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">        <span class="type">Object</span> <span class="variable">obj3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line"></span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">SyncThread</span>(obj1, obj2), <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">SyncThread</span>(obj2, obj3), <span class="string">&quot;t2&quot;</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(<span class="keyword">new</span> <span class="title class_">SyncThread</span>(obj3, obj1), <span class="string">&quot;t3&quot;</span>);</span><br><span class="line"></span><br><span class="line">        t1.start();</span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">        t2.start();</span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">        t3.start();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SyncThread</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Object obj1;</span><br><span class="line">    <span class="keyword">private</span> Object obj2;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SyncThread</span><span class="params">(Object o1, Object o2)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.obj1=o1;</span><br><span class="line">        <span class="built_in">this</span>.obj2=o2;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> Thread.currentThread().getName();</span><br><span class="line">        System.out.println(name + <span class="string">&quot; acquiring lock on &quot;</span>+obj1);</span><br><span class="line">        <span class="keyword">synchronized</span> (obj1) &#123;</span><br><span class="line">         System.out.println(name + <span class="string">&quot; acquired lock on &quot;</span>+obj1);</span><br><span class="line">         work();</span><br><span class="line">         System.out.println(name + <span class="string">&quot; acquiring lock on &quot;</span>+obj2);</span><br><span class="line">         <span class="keyword">synchronized</span> (obj2) &#123;</span><br><span class="line">            System.out.println(name + <span class="string">&quot; acquired lock on &quot;</span>+obj2);</span><br><span class="line">            work();</span><br><span class="line">        &#125;</span><br><span class="line">         System.out.println(name + <span class="string">&quot; released lock on &quot;</span>+obj2);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(name + <span class="string">&quot; released lock on &quot;</span>+obj1);</span><br><span class="line">        System.out.println(name + <span class="string">&quot; finished execution.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">work</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">30000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="thread-dump-1"><a href="#thread-dump-1" class="headerlink" title="thread dump"></a>thread dump</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2012-12-27 19:08:34</span><br><span class="line">Full thread dump Java HotSpot(TM) 64-Bit Server VM (23.5-b02 mixed mode):</span><br><span class="line"></span><br><span class="line">&quot;Attach Listener&quot; daemon prio=5 tid=0x00007fb0a2814000 nid=0x4007 waiting on condition [0x0000000000000000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">&quot;DestroyJavaVM&quot; prio=5 tid=0x00007fb0a2801000 nid=0x1703 waiting on condition [0x0000000000000000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">&quot;t3&quot; prio=5 tid=0x00007fb0a204b000 nid=0x4d07 waiting for monitor entry [0x000000015d971000]</span><br><span class="line">   java.lang.Thread.State: BLOCKED (on object monitor)</span><br><span class="line">    at com.journaldev.threads.SyncThread.run(ThreadDeadlock.java:41)</span><br><span class="line">    - waiting to lock &lt;0x000000013df2f658&gt; (a java.lang.Object)</span><br><span class="line">    - locked &lt;0x000000013df2f678&gt; (a java.lang.Object)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:722)</span><br><span class="line"></span><br><span class="line">&quot;t2&quot; prio=5 tid=0x00007fb0a1073000 nid=0x4207 waiting for monitor entry [0x000000015d209000]</span><br><span class="line">   java.lang.Thread.State: BLOCKED (on object monitor)</span><br><span class="line">    at com.journaldev.threads.SyncThread.run(ThreadDeadlock.java:41)</span><br><span class="line">    - waiting to lock &lt;0x000000013df2f678&gt; (a java.lang.Object)</span><br><span class="line">    - locked &lt;0x000000013df2f668&gt; (a java.lang.Object)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:722)</span><br><span class="line"></span><br><span class="line">&quot;t1&quot; prio=5 tid=0x00007fb0a1072000 nid=0x5503 waiting for monitor entry [0x000000015d86e000]</span><br><span class="line">   java.lang.Thread.State: BLOCKED (on object monitor)</span><br><span class="line">    at com.journaldev.threads.SyncThread.run(ThreadDeadlock.java:41)</span><br><span class="line">    - waiting to lock &lt;0x000000013df2f668&gt; (a java.lang.Object)</span><br><span class="line">    - locked &lt;0x000000013df2f658&gt; (a java.lang.Object)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:722)</span><br><span class="line"></span><br><span class="line">&quot;Service Thread&quot; daemon prio=5 tid=0x00007fb0a1038000 nid=0x5303 runnable [0x0000000000000000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">&quot;C2 CompilerThread1&quot; daemon prio=5 tid=0x00007fb0a1037000 nid=0x5203 waiting on condition [0x0000000000000000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">&quot;C2 CompilerThread0&quot; daemon prio=5 tid=0x00007fb0a1016000 nid=0x5103 waiting on condition [0x0000000000000000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">&quot;Signal Dispatcher&quot; daemon prio=5 tid=0x00007fb0a4003000 nid=0x5003 runnable [0x0000000000000000]</span><br><span class="line">   java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line">&quot;Finalizer&quot; daemon prio=5 tid=0x00007fb0a4800000 nid=0x3f03 in Object.wait() [0x000000015d0c0000]</span><br><span class="line">   java.lang.Thread.State: WAITING (on object monitor)</span><br><span class="line">    at java.lang.Object.wait(Native Method)</span><br><span class="line">    - waiting on &lt;0x000000013de75798&gt; (a java.lang.ref.ReferenceQueue$Lock)</span><br><span class="line">    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)</span><br><span class="line">    - locked &lt;0x000000013de75798&gt; (a java.lang.ref.ReferenceQueue$Lock)</span><br><span class="line">    at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)</span><br><span class="line">    at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:177)</span><br><span class="line"></span><br><span class="line">&quot;Reference Handler&quot; daemon prio=5 tid=0x00007fb0a4002000 nid=0x3e03 in Object.wait() [0x000000015cfbd000]</span><br><span class="line">   java.lang.Thread.State: WAITING (on object monitor)</span><br><span class="line">    at java.lang.Object.wait(Native Method)</span><br><span class="line">    - waiting on &lt;0x000000013de75320&gt; (a java.lang.ref.Reference$Lock)</span><br><span class="line">    at java.lang.Object.wait(Object.java:503)</span><br><span class="line">    at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)</span><br><span class="line">    - locked &lt;0x000000013de75320&gt; (a java.lang.ref.Reference$Lock)</span><br><span class="line"></span><br><span class="line">&quot;VM Thread&quot; prio=5 tid=0x00007fb0a2049800 nid=0x3d03 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#0 (ParallelGC)&quot; prio=5 tid=0x00007fb0a300d800 nid=0x3503 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#1 (ParallelGC)&quot; prio=5 tid=0x00007fb0a2001800 nid=0x3603 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#2 (ParallelGC)&quot; prio=5 tid=0x00007fb0a2003800 nid=0x3703 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#3 (ParallelGC)&quot; prio=5 tid=0x00007fb0a2004000 nid=0x3803 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#4 (ParallelGC)&quot; prio=5 tid=0x00007fb0a2005000 nid=0x3903 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#5 (ParallelGC)&quot; prio=5 tid=0x00007fb0a2005800 nid=0x3a03 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#6 (ParallelGC)&quot; prio=5 tid=0x00007fb0a2006000 nid=0x3b03 runnable </span><br><span class="line"></span><br><span class="line">&quot;GC task thread#7 (ParallelGC)&quot; prio=5 tid=0x00007fb0a2006800 nid=0x3c03 runnable </span><br><span class="line"></span><br><span class="line">&quot;VM Periodic Task Thread&quot; prio=5 tid=0x00007fb0a1015000 nid=0x5403 waiting on condition </span><br><span class="line"></span><br><span class="line">JNI global references: 114</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Found one Java-level deadlock:</span><br><span class="line">=============================</span><br><span class="line">&quot;t3&quot;:</span><br><span class="line">  waiting to lock monitor 0x00007fb0a1074b08 (object 0x000000013df2f658, a java.lang.Object),</span><br><span class="line">  which is held by &quot;t1&quot;</span><br><span class="line">&quot;t1&quot;:</span><br><span class="line">  waiting to lock monitor 0x00007fb0a1010f08 (object 0x000000013df2f668, a java.lang.Object),</span><br><span class="line">  which is held by &quot;t2&quot;</span><br><span class="line">&quot;t2&quot;:</span><br><span class="line">  waiting to lock monitor 0x00007fb0a1012360 (object 0x000000013df2f678, a java.lang.Object),</span><br><span class="line">  which is held by &quot;t3&quot;</span><br><span class="line"></span><br><span class="line">Java stack information for the threads listed above:</span><br><span class="line">===================================================</span><br><span class="line">&quot;t3&quot;:</span><br><span class="line">    at com.journaldev.threads.SyncThread.run(ThreadDeadlock.java:41)</span><br><span class="line">    - waiting to lock &lt;0x000000013df2f658&gt; (a java.lang.Object)</span><br><span class="line">    - locked &lt;0x000000013df2f678&gt; (a java.lang.Object)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:722)</span><br><span class="line">&quot;t1&quot;:</span><br><span class="line">    at com.journaldev.threads.SyncThread.run(ThreadDeadlock.java:41)</span><br><span class="line">    - waiting to lock &lt;0x000000013df2f668&gt; (a java.lang.Object)</span><br><span class="line">    - locked &lt;0x000000013df2f658&gt; (a java.lang.Object)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:722)</span><br><span class="line">&quot;t2&quot;:</span><br><span class="line">    at com.journaldev.threads.SyncThread.run(ThreadDeadlock.java:41)</span><br><span class="line">    - waiting to lock &lt;0x000000013df2f678&gt; (a java.lang.Object)</span><br><span class="line">    - locked &lt;0x000000013df2f668&gt; (a java.lang.Object)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:722)</span><br><span class="line"></span><br><span class="line">Found 1 deadlock.</span><br></pre></td></tr></table></figure>

<h1 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h1><p>Java ThreadLocal is used to create thread local variables.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadLocalExample</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// SimpleDateFormat is not thread-safe, so give one to each thread</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;SimpleDateFormat&gt; formatter = </span><br><span class="line">    ThreadLocal.&lt;SimpleDateFormat&gt;withInitial</span><br><span class="line">    (() -&gt; &#123;<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SimpleDateFormat</span>(<span class="string">&quot;yyyyMMdd HHmm&quot;</span>);&#125;);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">ThreadLocalExample</span> <span class="variable">obj</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadLocalExample</span>();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span> ; i&lt;<span class="number">10</span>; i++)&#123;</span><br><span class="line">            <span class="type">Thread</span> <span class="variable">t</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(obj, <span class="string">&quot;&quot;</span>+i);</span><br><span class="line">            Thread.sleep(<span class="keyword">new</span> <span class="title class_">Random</span>().nextInt(<span class="number">1000</span>));</span><br><span class="line">            t.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Thread Name= &quot;</span>+Thread.currentThread().getName()+<span class="string">&quot; default Formatter = &quot;</span>+formatter.get().toPattern());</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="keyword">new</span> <span class="title class_">Random</span>().nextInt(<span class="number">1000</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//formatter pattern is changed here by thread, but it won&#x27;t reflect to other threads</span></span><br><span class="line">        formatter.set(<span class="keyword">new</span> <span class="title class_">SimpleDateFormat</span>());</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;Thread Name= &quot;</span>+Thread.currentThread().getName()+<span class="string">&quot; formatter = &quot;</span>+formatter.get().toPattern());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Callable"><a href="#Callable" class="headerlink" title="Callable"></a>Callable</h1><p>Callable is thread that can return things.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyCallable</span> <span class="keyword">implements</span> <span class="title class_">Callable</span>&lt;String&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        <span class="keyword">return</span> Thread.currentThread().getName();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span>&#123;</span><br><span class="line">        <span class="comment">//Get ExecutorService from Executors utility class, thread pool size is 10</span></span><br><span class="line">        <span class="type">ExecutorService</span> <span class="variable">executor</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">        <span class="comment">//create a list to hold the Future object associated with Callable</span></span><br><span class="line">        List&lt;Future&lt;String&gt;&gt; list = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;Future&lt;String&gt;&gt;();</span><br><span class="line">        <span class="comment">//Create MyCallable instance</span></span><br><span class="line">        Callable&lt;String&gt; callable = <span class="keyword">new</span> <span class="title class_">MyCallable</span>();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt; <span class="number">100</span>; i++)&#123;</span><br><span class="line">            <span class="comment">//submit Callable tasks to be executed by thread pool</span></span><br><span class="line">            Future&lt;String&gt; future = executor.submit(callable);</span><br><span class="line">            <span class="comment">//add Future to the list, we can get return value using Future</span></span><br><span class="line">            list.add(future);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(Future&lt;String&gt; fut : list)&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">//print the return value of Future, notice the output delay in console</span></span><br><span class="line">                <span class="comment">// because Future.get() waits for task to get completed</span></span><br><span class="line">                System.out.println(<span class="keyword">new</span> <span class="title class_">Date</span>()+ <span class="string">&quot;::&quot;</span>+fut.get());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//shut down the executor service now</span></span><br><span class="line">        executor.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Thread-Pool-Framework"><a href="#Thread-Pool-Framework" class="headerlink" title="Thread Pool Framework"></a>Thread Pool Framework</h1><p>Tread pool is a way to manage the pool of worker threads. It contains a queue that keeps tasks waiting to get executed. There’re 3 main classes:</p>
<ol>
<li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html">ExecutorService </a>: the interface of thread pool.</p>
</li>
<li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html">ThreadPoolExecutor </a>: the implemented thread pool, with complex functions.</p>
</li>
<li><p><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html">Executors </a>: factory class to create all kinds of thread pool</p>
</li>
</ol>
<h2 id="some-executor-pools"><a href="#some-executor-pools" class="headerlink" title="some executor pools"></a>some executor pools</h2><p>The work queue size of an <code>ExecutorService</code> in Java depends on the type of the work queue implementation used.</p>
<p>If the <code>ExecutorService</code> is created using the <code>Executors.newFixedThreadPool(int nThreads)</code> method, which creates a fixed-size thread pool, then the work queue size is unbounded. This means that tasks submitted to the thread pool will wait in an unbounded queue until a thread is available to execute them.</p>
<p>If the <code>ExecutorService</code> is created using the <code>Executors.newCachedThreadPool()</code> method, which creates a thread pool that creates new threads as needed, then the work queue size is also unbounded.</p>
<p>If the <code>ExecutorService</code> is created using the <code>Executors.newSingleThreadExecutor()</code> method, which creates a single thread executor that executes tasks sequentially in the order they are submitted, and the work queue size is also unbounded. The main difference between <code>newSingleThreadExecutor()</code> and <code>newFixedThreadPool(1)</code> is the order of execution of submitted tasks. If you need to ensure that tasks are executed in the order they are submitted, you should use <code>newSingleThreadExecutor()</code>. If you need to limit the number of concurrent tasks to one but do not care about the order of execution, you can use <code>newFixedThreadPool(1)</code>.</p>
<p><strong>Unbounded work queue size can potentially cause memory issues if the queue grows too large.</strong></p>
<p>If you want to create an <code>ExecutorService</code> with a bounded work queue size, you can use the <code>ThreadPoolExecutor</code> class and specify the maximum size of the work queue when creating the thread pool. In the following example, the ThreadPoolExecutor has the initial pool size as 2, maximum pool size to 4 and work queue size as 2. So if there are 4 running tasks and more tasks are submitted, the work queue will hold only 2 of them and the rest of them will be handled by <code>RejectedExecutionHandlerImpl</code>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.ExecutorService;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.Executors;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ThreadPoolExecutor;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.RejectedExecutionHandler;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ArrayBlockingQueue;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.ThreadFactory;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WorkerPool</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> InterruptedException&#123;</span><br><span class="line">        <span class="comment">//RejectedExecutionHandler implementation</span></span><br><span class="line">        <span class="type">RejectedExecutionHandlerImpl</span> <span class="variable">rejectionHandler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RejectedExecutionHandlerImpl</span>();</span><br><span class="line">        <span class="comment">//Get the ThreadFactory implementation to use</span></span><br><span class="line">        <span class="type">ThreadFactory</span> <span class="variable">threadFactory</span> <span class="operator">=</span> Executors.defaultThreadFactory();</span><br><span class="line">        <span class="comment">//creating the ThreadPoolExecutor with initial pool size as 2, maximum pool size to 4 and work queue size as 2</span></span><br><span class="line">        <span class="type">ThreadPoolExecutor</span> <span class="variable">executorPool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">10</span>, TimeUnit.SECONDS, <span class="keyword">new</span> <span class="title class_">ArrayBlockingQueue</span>&lt;Runnable&gt;(<span class="number">2</span>), threadFactory, rejectionHandler);</span><br><span class="line">        <span class="comment">//start the monitoring thread</span></span><br><span class="line">        <span class="type">MyMonitorThread</span> <span class="variable">monitor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyMonitorThread</span>(executorPool, <span class="number">3</span>);</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">monitorThread</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(monitor);</span><br><span class="line">        monitorThread.start();</span><br><span class="line">        <span class="comment">//submit work to the thread pool</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">10</span>; i++)&#123;</span><br><span class="line">            executorPool.execute(<span class="keyword">new</span> <span class="title class_">WorkerThread</span>(<span class="string">&quot;cmd&quot;</span>+i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">30000</span>);</span><br><span class="line">        <span class="comment">//shut down the pool</span></span><br><span class="line">        executorPool.shutdown();</span><br><span class="line">        <span class="comment">//shut down the monitor thread</span></span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">        monitor.shutdown();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WorkerThread</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String command;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">WorkerThread</span><span class="params">(String s)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.command=s;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">&quot; Start. Command = &quot;</span>+command);</span><br><span class="line">        processCommand();</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">&quot; End.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">processCommand</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.command;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RejectedExecutionHandlerImpl</span> <span class="keyword">implements</span> <span class="title class_">RejectedExecutionHandler</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor executor)</span> &#123;</span><br><span class="line">        System.out.println(r.toString() + <span class="string">&quot; is rejected&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyMonitorThread</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">private</span> ThreadPoolExecutor executor;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> seconds;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> run=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">MyMonitorThread</span><span class="params">(ThreadPoolExecutor executor, <span class="type">int</span> delay)</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">this</span>.executor = executor;</span><br><span class="line">        <span class="built_in">this</span>.seconds=delay;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">shutdown</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.run=<span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span>(run)&#123;</span><br><span class="line">                System.out.println(</span><br><span class="line">                    String.format(<span class="string">&quot;[monitor] [%d/%d] Active: %d, Completed: %d, Task: %d, isShutdown: %s, isTerminated: %s&quot;</span>,</span><br><span class="line">                        <span class="built_in">this</span>.executor.getPoolSize(),</span><br><span class="line">                        <span class="built_in">this</span>.executor.getCorePoolSize(),</span><br><span class="line">                        <span class="built_in">this</span>.executor.getActiveCount(),</span><br><span class="line">                        <span class="built_in">this</span>.executor.getCompletedTaskCount(),</span><br><span class="line">                        <span class="built_in">this</span>.executor.getTaskCount(),</span><br><span class="line">                        <span class="built_in">this</span>.executor.isShutdown(),</span><br><span class="line">                        <span class="built_in">this</span>.executor.isTerminated()));</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(seconds*<span class="number">1000</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Timer-amp-TimerTask"><a href="#Timer-amp-TimerTask" class="headerlink" title="Timer &amp; TimerTask"></a>Timer &amp; TimerTask</h1><p><strong>java.util.TimerTask</strong> is an <strong><a href="https://www.digitalocean.com/community/tutorials/abstract-class-in-java">abstract class</a></strong> that implements Runnable interface and we need to extend this class to create our own <strong>TimerTask</strong> that can be scheduled using <em>java Timer</em> class.</p>
<p>While scheduling tasks using Timer, you should make sure that time interval is more than normal thread execution, otherwise tasks queue size will keep growing and eventually task will be executing always.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"><span class="keyword">import</span> java.util.Timer;</span><br><span class="line"><span class="keyword">import</span> java.util.TimerTask;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MyTimerTask</span> <span class="keyword">extends</span> <span class="title class_">TimerTask</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Timer task started at:&quot;</span>+<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">        completeTask();</span><br><span class="line">        System.out.println(<span class="string">&quot;Timer task finished at:&quot;</span>+<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">completeTask</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//assuming it takes 20 secs to complete the task</span></span><br><span class="line">            Thread.sleep(<span class="number">20000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span>&#123;</span><br><span class="line">        <span class="type">TimerTask</span> <span class="variable">timerTask</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyTimerTask</span>();</span><br><span class="line">        <span class="comment">//running timer task as daemon thread</span></span><br><span class="line">        <span class="type">Timer</span> <span class="variable">timer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Timer</span>(<span class="literal">true</span>);</span><br><span class="line">        <span class="comment">//schedule the task every 10 seconds </span></span><br><span class="line">        timer.scheduleAtFixedRate(timerTask, <span class="number">0</span>, <span class="number">10</span>*<span class="number">1000</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;TimerTask started&quot;</span>);</span><br><span class="line">        <span class="comment">//cancel after sometime</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">120000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        timer.cancel();</span><br><span class="line">        System.out.println(<span class="string">&quot;TimerTask cancelled&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">30000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h1><p>Java 1.5 Concurrency API came up with <code>java.util.concurrent.locks</code> package with <code>Lock</code> interface and some implementation classes to improve the Object locking mechanism. Some important interfaces and classes in Java Lock API are:</p>
<ol>
<li><p><strong>Lock</strong>: This is the base interface for Lock API. It provides all the features of synchronized keyword with additional ways to create different Conditions for locking, providing timeout for thread to wait for lock. Some of the important methods are lock() to acquire the lock, unlock() to release the lock, tryLock() to wait for lock for a certain period of time, newCondition() to create the Condition etc.</p>
</li>
<li><p><strong>Condition</strong>: Condition objects are similar to <a href="https://www.digitalocean.com/community/tutorials/java-thread-wait-notify-and-notifyall-example">Object wait-notify</a> model with additional feature to create different sets of wait. A Condition object is always created by Lock object. Some of the important methods are await() that is similar to wait() and signal(), signalAll() that is similar to notify() and notifyAll() methods.</p>
</li>
<li><p><strong>ReadWriteLock</strong>: It contains a pair of associated locks, one for read-only operations and another one for writing. The read lock may be held simultaneously by multiple reader threads as long as there are no writer threads. The write lock is exclusive.</p>
</li>
<li><p><strong>ReentrantLock</strong>: This is the most widely used implementation class of Lock interface. This class implements the Lock interface in similar way as synchronized keyword. Apart from Lock interface implementation, ReentrantLock contains some utility methods to get the thread holding the lock, threads waiting to acquire the lock etc. synchronized block are reentrant in nature i.e if a thread has lock on the monitor object and if another synchronized block requires to have the lock on the same monitor object then thread can enter that code block. I think this is the reason for the class name to be ReentrantLock.</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.Lock;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.locks.ReentrantLock;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ConcurrencyLockExample</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Resource resource;</span><br><span class="line">    <span class="keyword">private</span> Lock lock;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ConcurrencyLockExample</span><span class="params">(Resource r)</span>&#123;</span><br><span class="line">        <span class="built_in">this</span>.resource = r;</span><br><span class="line">        <span class="built_in">this</span>.lock = <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            lockAcquired = lock.tryLock(<span class="number">10</span>, TimeUnit.SECONDS)</span><br><span class="line">            <span class="keyword">if</span>(lockAcquired)&#123;</span><br><span class="line">                resource.doSomething();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">            <span class="comment">//release lock</span></span><br><span class="line">            <span class="keyword">if</span>(lockAcquired) &#123;</span><br><span class="line">                lock.unlock();    </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        resource.doLogging();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Resource</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doSomething</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">//do some operation, DB read, write etc</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doLogging</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="comment">//logging, no need for thread safety</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="lock-vs-synchronized"><a href="#lock-vs-synchronized" class="headerlink" title="lock vs synchronized"></a>lock vs synchronized</h2><ol>
<li><p>Use <code>synchronized</code> if the code section you want to lock is simple and doesn’t need to perform any complex operations. <code>synchronized</code> is simpler and more readable than <code>Lock</code>.</p>
</li>
<li><p>Use <code>Lock</code> if you need more advanced features, such as fairness, re-entrancy, and the ability to try acquiring a lock without blocking. <code>Lock</code> is more flexible and can provide better performance than <code>synchronized</code> in some situations.</p>
</li>
<li><p>Always use the <code>try-finally</code> pattern when using <code>Lock</code> to ensure that the lock is released even if an exception is thrown.</p>
</li>
</ol>
<p>In summary, <code>synchronized</code> is easier to use and sufficient for most cases, while <code>Lock</code> provides more advanced features and better performance in certain situations. <code>Lock</code> provides more control and flexibility, but requires more code and is more error-prone, while <code>synchronized</code> is simpler and easier to use, but may have more contention issues in high concurrency scenarios.</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript 解构语法</title>
    <url>/2018/05/31/javascript-destructuring-assignment/</url>
    <content><![CDATA[<p>具体可参见 <a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment">mdn javascript 解构语法</a>. 这里简单总结一下。</p>
<h1 id="解构是做什么的"><a href="#解构是做什么的" class="headerlink" title="解构是做什么的"></a>解构是做什么的</h1><p>解构就是一种方便变量赋值的语法，由编译器完成真正的变量赋值</p>
<h1 id="数组解构"><a href="#数组解构" class="headerlink" title="数组解构"></a>数组解构</h1><ul>
<li><strong>将数组元素赋值给变量</strong></li>
<li><strong>赋值依据是元素顺序</strong></li>
<li>指定变量名时，可以提供默认值，以避免 <code>undefined</code> 赋值</li>
<li>支持忽略一些元素（添加 <code>,</code> ，但不提供变量名）</li>
<li>支持 	<code>rest</code> 数组赋值</li>
</ul>
<p>eg.</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 基本赋值</span></span><br><span class="line"><span class="keyword">var</span> a, b, rest;</span><br><span class="line">[a, b] = [<span class="number">10</span>, <span class="number">20</span>];</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// 10</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// 20</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认值</span></span><br><span class="line"><span class="keyword">var</span> a, b;</span><br><span class="line"></span><br><span class="line">[a=<span class="number">5</span>, b=<span class="number">7</span>] = [<span class="number">1</span>];</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// 1</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// 7</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 忽略某些元素</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">f</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> [a, , b] = <span class="title function_">f</span>();</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// 1</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// 3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// rest 赋值</span></span><br><span class="line">[a, b, ...rest] = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>];</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// 10</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// 20</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(rest); <span class="comment">// [30, 40, 50]</span></span><br></pre></td></tr></table></figure>

<h1 id="对象解构"><a href="#对象解构" class="headerlink" title="对象解构"></a>对象解构</h1><p>和数组解构差不多：</p>
<ul>
<li><strong>将对象属性赋值给变量</strong></li>
<li><strong>赋值依据是属性名称</strong></li>
<li>指定属性名时，可以给默认值，避免 <code>undefined</code> 赋值</li>
<li>变量名称默认是属性名，也可以自定义，通过 <code>propertyName: customName</code> 方式定义</li>
<li>支持 <code>rest</code> 对象赋值（在 proposal 中）</li>
</ul>
<p>eg.</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 基本赋值</span></span><br><span class="line">(&#123; a, b &#125; = &#123; <span class="attr">a</span>: <span class="number">10</span>, <span class="attr">b</span>: <span class="number">20</span> &#125;);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// 10</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// 20</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认值</span></span><br><span class="line"><span class="keyword">var</span> &#123;a = <span class="number">10</span>, b = <span class="number">5</span>&#125; = &#123;<span class="attr">a</span>: <span class="number">3</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// 3</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// 5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义变量名 + 默认值</span></span><br><span class="line"><span class="keyword">var</span> o = &#123;<span class="attr">p</span>: <span class="number">42</span>, <span class="attr">q</span>: <span class="literal">true</span>&#125;;</span><br><span class="line"><span class="keyword">var</span> &#123;<span class="attr">p</span>: foo, <span class="attr">q</span>: bar, <span class="attr">m</span>: other=<span class="string">&#x27;haha&#x27;</span>&#125; = o;</span><br><span class="line"> </span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(foo); <span class="comment">// 42 </span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(bar); <span class="comment">// true</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(other); <span class="comment">// haha</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// rest 赋值</span></span><br><span class="line"><span class="comment">// Stage 3 proposal</span></span><br><span class="line">(&#123;a, b, ...rest&#125; = &#123;<span class="attr">a</span>: <span class="number">10</span>, <span class="attr">b</span>: <span class="number">20</span>, <span class="attr">c</span>: <span class="number">30</span>, <span class="attr">d</span>: <span class="number">40</span>&#125;);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// 10</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// 20</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(rest); <span class="comment">//&#123;c: 30, d: 40&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 无声明赋值</span></span><br><span class="line"><span class="comment">// 相当于 var &#123;a,b&#125; = &#123;a:1, b:2&#125;;</span></span><br><span class="line"><span class="comment">// 括号去掉， &#123;a,b&#125; 是块代码，不是对象，所以不能去掉</span></span><br><span class="line"><span class="keyword">var</span> a, b;</span><br><span class="line"></span><br><span class="line">(&#123;a, b&#125; = &#123;<span class="attr">a</span>: <span class="number">1</span>, <span class="attr">b</span>: <span class="number">2</span>&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript 表达式和操作符</title>
    <url>/2018/05/31/javascript-spread-operator/</url>
    <content><![CDATA[<h1 id="扩展运算符"><a href="#扩展运算符" class="headerlink" title="... 扩展运算符"></a><code>...</code> 扩展运算符</h1><p><code>...obj</code> 是 js 的扩展运算符，可以将一个可迭代的对象在函数调用的位置展开成为多个参数,或者在数组字面量中展开成多个数组元素。(其他可参见<a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Guide/Expressions_and_Operators#Relational_operators">运算符介绍</a>，<a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Operators">运算符和表达式清单 reference</a>)</p>
<p>eg.</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在数组字面量中展开</span></span><br><span class="line"><span class="comment">// 利用扩展运算符，实现了数组合并</span></span><br><span class="line"><span class="keyword">var</span> parts = [<span class="string">&#x27;shoulder&#x27;</span>, <span class="string">&#x27;knees&#x27;</span>];</span><br><span class="line"><span class="keyword">var</span> lyrics = [<span class="string">&#x27;head&#x27;</span>, ...parts, <span class="string">&#x27;and&#x27;</span>, <span class="string">&#x27;toes&#x27;</span>];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 在函数调用处展开</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">f</span>(<span class="params">x, y, z</span>) &#123; &#125;</span><br><span class="line"><span class="keyword">var</span> args = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>];</span><br><span class="line"><span class="title function_">f</span>(...args);</span><br></pre></td></tr></table></figure>

<h1 id="96-96-template-literals"><a href="#96-96-template-literals" class="headerlink" title="&#96;&#96; template literals"></a>&#96;&#96; template literals</h1><p><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals">template literals</a></p>
<p><a href="https://www.npmjs.com/package/sql-template-strings">sql template strings</a></p>
]]></content>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>jave core(advanced topics)</title>
    <url>/2023/05/12/java-core-advanced/</url>
    <content><![CDATA[<p>JVM is the heart of Java programming language. When we execute a Java program, JVM is responsible for converting the byte code to the machine-specific code. JVM is also platform-dependent and provides core java functions such as memory management, garbage collection, security, etc.</p>
<h1 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h1><p>In Java, a developer does not need to explicitly allocate and deallocate memory – the JVM and more specifically the Garbage Collector – has the duty of handling memory allocation so that the developer doesn’t have to.</p>
<p>For most collectors GC related pauses are proportional to size of their heaps which is approximately 1 second for each gigabyte of live objects. So, a larger heap (which can be advantageous for most apps) means a longer pause.</p>
<h2 id="JVM-Memory-Model"><a href="#JVM-Memory-Model" class="headerlink" title="JVM Memory Model"></a>JVM Memory Model</h2><p>Firstly, we need to understand the memory model.</p>
<p><img src="/../images/java_memory_model.png" alt="java memory model"></p>
<p>There are 3 kinds of memory jvm used:</p>
<h3 id="1-thread-stack"><a href="#1-thread-stack" class="headerlink" title="1. thread stack"></a>1. thread stack</h3><p>Java Stack memory is used for the execution of a thread. It contains information about nested method calls down to the current position in the program. It also contains all local variables and references to objects on the heap defined in currently executing methods.</p>
<p>Stack memory is always referenced in LIFO (Last-In-First-Out) order. Whenever a method is invoked, a new block is created in the stack memory for the method to hold local primitive values and reference to other objects in the method. As soon as the method ends, the block becomes unused and becomes available for the next method. Stack memory size is very less compared to Heap memory.</p>
<h3 id="2-heap-memory"><a href="#2-heap-memory" class="headerlink" title="2. heap memory"></a>2. heap memory</h3><p>Java Heap space is used by java runtime to allocate memory to Objects and JRE classes. Whenever we create an object, it’s always created in the Heap space. Garbage Collection runs on the heap memory to free the memory used by objects that don’t have any reference. Any object created in the heap space has global access and can be referenced from anywhere of the application.</p>
<p>Different Garbage Collectors have different implementation. Heap can be a single area as single-generation. Or it can be divided into two generations by the object age, which is the mostly used way currenly.</p>
<p>At broad level, JVM Heap memory is physically divided into two parts - <strong>Young Generation</strong> and <strong>Old Generation</strong>. </p>
<p>The young generation is the place where all the new objects are created. When the young generation is filled, garbage collection is performed. This garbage collection is called <strong>Minor GC</strong>. Young Generation is divided into three parts - <strong>Eden Memory</strong> and two <strong>Survivor Memory</strong> spaces.</p>
<p>Old Generation memory contains the objects that are long-lived and survived after many rounds of Minor GC. Usually, garbage collection is performed in Old Generation memory when it’s full. Old Generation Garbage Collection is called <strong>Major GC</strong> and usually takes a longer time.</p>
<p>By dividing memory into the young and old generations, the JVM can quickly identify and collect short-lived objects, while allowing long-lived objects to reside in the old generation. This helps to minimize the overhead of garbage collection and improve the performance of Java programs.</p>
<p>For more about the garbage collecting process, see below <a href="#Object-Allocation">Object Allocation</a> and <a href="#Garbage-Collection">Garbage Collection</a>.</p>
<h3 id="3-permanent-generation-x2F-Metaspace"><a href="#3-permanent-generation-x2F-Metaspace" class="headerlink" title="3. permanent generation &#x2F; Metaspace"></a>3. permanent generation &#x2F; Metaspace</h3><p><strong>Permanent Generation</strong>: This was a memory region in earlier versions of Java that was used to store metadata related to the Java classes and the Java Virtual Machine itself, such as the bytecode, class objects, method objects, and constant pools. </p>
<p>However, in Java 8 and later versions, the Permanent Generation has been removed and replaced with the Metaspace.</p>
<p><strong>Metaspace</strong>: It is a memory region that stores metadata related to the Java classes and the Java Virtual Machine itself. Unlike the Permanent Generation, the size of the Metaspace is not fixed and can be dynamically adjusted by the JVM at runtime.</p>
<p>The following types of metadata are typically stored in the Metaspace:</p>
<ol>
<li><p>Class metadata: Metaspace stores information about classes, including class names, superclass and interfaces, modifiers (such as public, private, abstract, etc.), annotations, and method information (names, signatures, return types, parameter types, etc.).</p>
</li>
<li><p>Method metadata: Metaspace holds metadata about methods, such as method names, signatures, return types, parameter types, annotations, access modifiers, and bytecode instructions.</p>
</li>
<li><p>Field metadata: Metaspace stores information about class fields, including field names, types, modifiers, annotations, and access control information.</p>
</li>
<li><p>Constant pool: The constant pool is a table maintained by Metaspace that contains symbolic references, literal values, and other constant data used by the class. It includes items such as class names, method and field names, string literals, numeric constants, and method references.</p>
</li>
<li><p>Annotations: Metaspace stores metadata related to annotations, which are used to provide additional information about classes, methods, fields, and other program elements.</p>
</li>
<li><p>Reflection-related information: Metaspace holds information required for Java reflection, which allows runtime inspection and modification of classes, methods, and fields.</p>
</li>
</ol>
<p>The Metaspace is designed to be dynamically expandable to accommodate the growing number of loaded classes and their associated metadata. It allows for efficient memory allocation and management of class-related information at runtime.</p>
<h2 id="Object-Allocation"><a href="#Object-Allocation" class="headerlink" title="Object Allocation"></a>Object Allocation</h2><p>The method primitive local variables are allocated in thread stacks.</p>
<p>Class static primitive variables are allocatted in constant pool of Metaspace. However the class static complex objects are allocated in the heap, and the constant pool only save the reference to the objects.</p>
<p>Almost all other objects are allocated in the heap. Heap is for object allocation. In generational heap, the objects are almost always allocated into the young generation, or more specifically, the eden space, except for large objects, which are allocated directly to the old generation to avoid copying overhead.</p>
<h3 id="where’s-string-pool"><a href="#where’s-string-pool" class="headerlink" title="where’s string pool"></a>where’s string pool</h3><p>The string pool can belong to Heap or Perm Gen, depending on the JVM memory manager implementation.</p>
<p>In Java, the string pool is a special area of memory that resides in the Java heap. The string pool is a storage area where Java stores a pool of unique string literals, i.e., string objects that are explicitly written as literals in the source code (e.g., “Hello”, “World”).</p>
<p>When you create a string literal in Java, such as assigning a value to a string variable using double quotes, the Java compiler checks if the same string already exists in the string pool. If it does, the existing string object is reused; otherwise, a new string object is created and added to the string pool.</p>
<p>The string pool provides several benefits, including memory efficiency and improved performance for string comparisons. By reusing string literals, Java avoids unnecessary duplication of string objects, saving memory. Additionally, string comparisons using the <code>equals()</code> method can be optimized by comparing references directly when the strings are interned in the string pool.</p>
<p>It’s important to note that not all string objects reside in the string pool. Strings that are dynamically created using the <code>new</code> keyword (e.g., <code>new String(&quot;Dynamic&quot;)</code>) or through string concatenation operations (<code>&quot;Hello&quot; + &quot;World&quot;</code>) are not added to the string pool unless explicitly interned using the <code>intern()</code> method. Interning a string using the <code>intern()</code> method allows you to place it in the string pool manually.</p>
<p>Overall, the string pool in Java is a specialized area of the heap memory where unique string literals are stored, promoting memory efficiency and improving string comparison performance.</p>
<h2 id="Garbage-Collection-1"><a href="#Garbage-Collection-1" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h2><p>The <strong>young generation hosts most of the newly created objects</strong>. An empirical study of most applications shows that majority of objects are quickly short lived and therefore, soon become eligible for collection. Therefore, new objects start their journey here and are only “promoted” to the old generation space after they have attained a certain “age”.</p>
<p>On young Generation, minor GC is executed. Minor GC can clean most of the short-lived objects by scanning only small limited area (the eden space and one of the survivor space), which is a lot more quick than scanning the big heap. And it also use different algorithm which is swift to collect objects.</p>
<h3 id="Young-Generation-GC"><a href="#Young-Generation-GC" class="headerlink" title="Young Generation GC"></a>Young Generation GC</h3><h4 id="workflow"><a href="#workflow" class="headerlink" title="workflow"></a>workflow</h4><p>Young Generation are further divided into Eden space and 2 survivor spaces. The detail steps for the minor GC workflow:</p>
<ol>
<li><p> <strong>Any new objects are allocated to the Eden space</strong>. Both survivor spaces start out empty. When the Eden space fills up, a minor garbage collection is triggered. Referenced objects are moved to the first survivor space. Unreferenced objects are deleted.</p>
</li>
<li><p>During the next minor GC, the same thing happens to the Eden space. Unreferenced objects are deleted and referenced objects are moved to a survivor space. However, in this case, they are moved to the second survivor space (S2). In addition, objects from the last minor GC in the first survivor space (S1) have their age incremented and are moved to S2. Once all surviving objects have been moved to S2, both S1 and Eden space are cleared. At this point, S2 contains objects with different ages.</p>
</li>
<li><p>At the next minor GC, the same process is repeated. However this time the survivor spaces switch. Referenced objects are moved to S1 from both Eden and S2. Surviving objects are aged. Eden and S2 are cleared.</p>
</li>
<li><p>After every minor garbage collection cycle, the age of each object is checked. Those that have reached a certain arbitrary age, for example, 8, are promoted from the young generation to the old or tenured generation. For all subsequent minor GC cycles, objects will continue to be promoted to the old generation space.</p>
</li>
</ol>
<p>The primary algorithm used for Minor GC is called the <strong>copying or scavenging</strong> algorithm, not the mark-and-sweep algorithm in Major GC.</p>
<ol>
<li><p>The collector identifies live objects in the young generation by tracing object references starting from the root set (such as static variables, local variables, etc.). This process is known as “tracing” or “marking,” where live objects are marked as reachable.</p>
</li>
<li><p>The live objects are then copied from the Eden space and one of the Survivor spaces to the other empty Survivor space. This step is called “compacting” or “copying.”</p>
</li>
<li><p>The memory space occupied by the non-live objects (garbage) is completely reclaimed and made available for future allocations.</p>
</li>
<li><p>After the copying process, the roles of the Survivor spaces are swapped. The Survivor space that was just used becomes empty and ready to receive live objects during the next minor GC.</p>
</li>
</ol>
<p>Deciding when to promote objects can dramatically improve efficiency. Keeping objects in the young generation a little longer may allow many of them to die and save collection time. If you keep them too long the young generation can run out of space or ruin the generational assumption altogether. Waiting too long to promote can also dramatically increase the work needed to copy the live objects and therefore the time it takes to do GC.</p>
<p>Minor GC is swift, also because there’s <strong>remembered set</strong>.</p>
<p>Generational collectors use a ‘remembered set’ to track all references into the young generation from the outside, so the collector doesn’t have to scan for them. This set is also used as part of the ‘roots’ for the garbage collector. A common technique is ‘card marking’, which uses a bit (or byte) indicating that a word or region in the old generation is suspect. These ‘marks’ can be precise or imprecise, meaning it may record the exact location or just a region in memory. Write barriers are used to track references from the young generation into the old generation and keep the remembered set up to date. Oracle’s HotSpot uses what’s called a ‘blind store’. Every time you store a reference it marks a card. This works well, because checking the reference takes more CPU time, so the system saves time by just marking the card.</p>
<h4 id="when-to-trigger"><a href="#when-to-trigger" class="headerlink" title="when to trigger"></a>when to trigger</h4><ol>
<li><p>Eden Space Exhaustion: When the Eden space becomes full, a minor GC is triggered.</p>
</li>
<li><p>Survivor Space Threshold: When the survivor space, which is the survivor space currently being used for object survivorship after minor GC, reaches a certain threshold (often configurable), a minor GC is triggered.</p>
</li>
</ol>
<h4 id="Why-eden-and-2-survivor-spaces"><a href="#Why-eden-and-2-survivor-spaces" class="headerlink" title="Why eden and 2 survivor spaces?"></a>Why eden and 2 survivor spaces?</h4><p>There’re always an empty survivor space. It is important because it provides a clean area for live objects and allows efficient copying of live objects during each minor GC.</p>
<p>By keeping the Eden space separate from the Survivor spaces, the generational garbage collector can treat them as distinct regions representing the young generation and survivor generation. This separation aligns with the generational hypothesis, where most objects in the young generation have a shorter lifespan compared to objects in the survivor or tenured generations. It allows the garbage collector to optimize its collection strategies and policies based on the different characteristics of these generations.</p>
<p>Besides, it simplifies the allocation of new objects. Objects are allocated directly into the Eden space, which provides a clean region for new object allocation.</p>
<p>Combining the Eden space and one of the Survivor spaces into a single space is indeed a viable approach that can be taken in some garbage collection algorithms. In fact, certain garbage collectors, such as the Shenandoah garbage collector, employ a design that combines the Eden space and one of the Survivor spaces into a single region called the “forwarding space.”</p>
<h4 id="Age-tracking"><a href="#Age-tracking" class="headerlink" title="Age tracking"></a>Age tracking</h4><p>Objects survive serveral minor GC cycles, are promoted to old generation. The ages of the objects are calcuated as below:</p>
<ol>
<li><p>Age Tracking: Objects that survive a young generation collection are promoted to the Survivor spaces. The garbage collector keeps track of the number of times an object has survived collection cycles. This tracking is often done using a technique called “age bits” or “age counters.”</p>
</li>
<li><p>Age Threshold: The garbage collector has an age threshold or limit that determines when an object is considered mature or aged. This threshold defines the number of collection cycles an object must survive to be promoted to the old generation. The specific age threshold can be configurable or determined by heuristics based on the JVM implementation.</p>
</li>
<li><p>Promotion to Old Generation: When an object’s age surpasses the age threshold, it is considered mature and is promoted to the old generation.</p>
</li>
</ol>
<h4 id="space-size"><a href="#space-size" class="headerlink" title="space size"></a>space size</h4><p>The size of the Eden space and the two Survivor spaces in Java’s generational garbage collection can vary depending on the JVM implementation and configuration settings. The default sizes are typically determined based on the heap size, the garbage collector algorithm being used, and other factors.</p>
<p>In the HotSpot JVM, which is the most widely used JVM implementation, the sizes of the Eden space and Survivor spaces are configurable through JVM options. The options commonly used to control these sizes are:</p>
<ol>
<li><p><code>-Xmn</code> or <code>-XX:NewSize</code>: This option sets the initial and maximum size of the young generation, which includes the Eden space and the two Survivor spaces combined. For example, <code>-Xmn256m</code> sets the young generation size to 256 megabytes.</p>
</li>
<li><p><code>-XX:SurvivorRatio</code>: This option specifies the ratio of Eden space size to each Survivor space size. The default value is often 8, meaning that each Survivor space will be one-eighth the size of the Eden space.</p>
</li>
</ol>
<h4 id="promotion-failure"><a href="#promotion-failure" class="headerlink" title="promotion failure"></a>promotion failure</h4><p>If the available space in the destination Survivor space is not sufficient to accommodate all the live objects being copied from the Eden space and one Survivor space, a condition known as “promotion failure” or “promotion bottleneck” occurs. This situation arises when the objects surviving in the young generation (Eden and Survivor spaces) exceed the capacity of the available Survivor space.</p>
<p>When a promotion failure happens, the garbage collector needs to handle it appropriately. Here are a few common scenarios:</p>
<ol>
<li><p>Resize Survivor space: The garbage collector may dynamically adjust the sizes of the Survivor spaces to provide more space for the promotion. It can either increase the size of the Survivor spaces or allocate additional memory to accommodate the live objects. This resizing approach allows the promotion to proceed successfully by providing sufficient space.</p>
</li>
<li><p>Perform Full GC: If resizing the Survivor space is not possible or does not alleviate the promotion bottleneck, the garbage collector may initiate a Full GC (major garbage collection) instead. During a Full GC, the entire heap, including both the young and old generations, is collected. The goal is to reclaim memory, promote objects to the old generation, and potentially resize memory regions if needed. Full GCs are more time-consuming and can significantly impact application performance.</p>
</li>
<li><p>Trigger Out-of-Memory Error: In some cases, if the JVM determines that there is no feasible way to accommodate the promotion, it may throw an Out-of-Memory Error. This error indicates that the JVM has exhausted all available memory and cannot allocate additional space for the promotion.</p>
</li>
</ol>
<p>To avoid promotion bottlenecks, it’s essential to appropriately size the Survivor spaces based on the application’s memory usage patterns, allocate sufficient memory to the JVM, and optimize the allocation and deallocation of objects to minimize unnecessary promotions.</p>
<h3 id="Old-Generation-GC"><a href="#Old-Generation-GC" class="headerlink" title="Old Generation GC"></a>Old Generation GC</h3><p>Major GC (Full GC) are executed on old generation when it’s full.</p>
<h4 id="when-to-trigger-1"><a href="#when-to-trigger-1" class="headerlink" title="when to trigger"></a>when to trigger</h4><ol>
<li><p>Heap Space Exhaustion: When the available memory in the heap is nearly full or reaches a certain threshold, the JVM may trigger a major GC.</p>
</li>
<li><p>Allocation Failure: If an allocation request for a large object cannot be fulfilled due to insufficient contiguous space in the heap, a major GC may be triggered.</p>
</li>
<li><p>Explicit Invocation: Major GC can also be triggered explicitly by invoking the <code>System.gc()</code> method or using JVM-specific flags. However, it’s important to note that the JVM may choose to ignore explicit GC requests, as it has its own internal mechanisms for determining when to perform garbage collection.</p>
</li>
<li><p>Time-Based Triggers: Some garbage collection algorithms employ time-based triggers where a major GC is initiated after a certain amount of time has elapsed since the last major GC or based on specific time intervals.</p>
</li>
</ol>
<h4 id="workflow-1"><a href="#workflow-1" class="headerlink" title="workflow"></a>workflow</h4><p>The most common used algorithm in major GC is the mark-and-sweep algorithm.</p>
<ol>
<li><p>Marking:</p>
<ul>
<li>The first step is to mark all the live objects in the heap. The process starts from the root objects, such as static variables, local variables in active threads, and other reachable objects.</li>
<li>Each live object is traversed recursively, marking its references to other objects as live as well. This process continues until all reachable objects are marked.</li>
<li>To mark an object, a flag or a bit is typically set in its header or memory structure to indicate that it is live.</li>
<li>To handle cycles in the object graph, the garbage collector typically uses some form of cycle detection mechanism.</li>
<li>After the graph traversal phase, the <code>finalize</code> method is typically called. However, it’s not recommended to use <code>finalize</code>, see <a href="#resurrect-objects">resurrect objects</a></li>
</ul>
</li>
<li><p>Sweeping:</p>
<ul>
<li>This phase iterates over the entire heap, looking for unmarked objects to reclaim the memory occupied by them.</li>
<li>To reclaim, the garbage collector can update its internal data structures, such as the free space or available memory list, to indicate the newly freed memory regions.</li>
</ul>
</li>
</ol>
<h4 id="resurrect-objects"><a href="#resurrect-objects" class="headerlink" title="resurrect objects"></a>resurrect objects</h4><p>Object resurrection occurs via the following process. First, an object becomes <em>garbage</em> when it is no longer reachable from the program, and may be collected (destroyed and deallocated). Then, during object destruction, before the garbage collector deallocates the object, a <a href="https://en.wikipedia.org/wiki/Finalizer" title="Finalizer">finalizer</a> method may be run, which may in turn make that object or another garbage object (reachable from the object with a finalizer) reachable again by creating references to it, as a finalizer may contain arbitrary code. If this happens, the referenced object – which is not necessarily the finalized object – is no longer garbage, and cannot be deallocated, as otherwise the references to it would become <a href="https://en.wikipedia.org/wiki/Dangling_reference" title="Dangling reference">dangling references</a> and cause errors when used, generally program crash or unpredictable behavior. Instead, in order to maintain <a href="https://en.wikipedia.org/wiki/Memory_safety" title="Memory safety">memory safety</a>, the object is returned to life or <em>resurrected.</em></p>
<p>In order to detect this, a garbage collector will generally do <a href="https://en.wikipedia.org/w/index.php?title=Two-phase_collection&action=edit&redlink=1" title="Two-phase collection (page does not exist)">two-phase collection</a> in the presence of finalizers: first finalize any garbage that has a finalizer, and then re-check <em>all</em> garbage (or all garbage reachable from the objects with finalizers), in case the finalizers have resurrected some garbage. Since the <code>finalize</code> method is executed once and only once, regardless of whether the object is actually reclaimed or not, the above policy won’t reclaim the resurrect objects. This adds overhead and delays memory reclamation.</p>
<p>Thus <strong>the <code>finalize</code> method has been deprecated</strong> since Java 9, and the recommended approach for resource cleanup is to use try-with-resources or other explicit resource management techniques (e.g., <code>close()</code>).</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ResurrectExample</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> ResurrectedObject resurrectedObject;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">ResurrectedObject</span> <span class="variable">object</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ResurrectedObject</span>();</span><br><span class="line">        object = <span class="literal">null</span>; <span class="comment">// Object becomes eligible for garbage collection</span></span><br><span class="line">        System.gc();   <span class="comment">// Trigger garbage collection</span></span><br><span class="line">        System.out.println(resurrectedObject.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ResurrectedObject</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> String message;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">ResurrectedObject</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.message = <span class="string">&quot;Initial message&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> String <span class="title function_">getMessage</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> message;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">finalize</span><span class="params">()</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">            <span class="built_in">super</span>.finalize();</span><br><span class="line">            resurrectedObject = <span class="built_in">this</span>; <span class="comment">// Resurrect the object</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>}</p>
<h4 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h4><p>Objects that are allocated next to each other will not necessarily become unreachable (“die”) at the same time. This means that the heap may become fragmented after a garbage collection, so that the free spaces in the heap are many but small, making allocation of large objects hard or even impossible. Free spaces that are smaller than the minimum size can not be used at all, and the garbage collector discards them as <em>dark matter</em>.</p>
<p>To reduce fragmentation, some GC compacts a part of the heap at every garbage collection (old collection). Compaction moves objects closer together and further down in the heap, thus creating larger free areas near the top of the heap. As these objects are moved, the collector must fix all references in the threads to these live objects, called ‘remapping’. Remap has to cover all references that could point to an object, so it usually scans everything. The amount of work done in this phase is generally linear to the size of the live set.</p>
<p>Not all garbage collection algorithms include a separate compaction phase. Some collectors, such as the G1 (Garbage-First) collector, use a region-based approach where memory is divided into fixed-size regions, and free space is managed within those regions without the need for compaction.</p>
<p>Compaction is performed at the beginning of or during the sweep phase and while all Java threads are paused.</p>
<h5 id="Incremental-compaction"><a href="#Incremental-compaction" class="headerlink" title="Incremental compaction"></a>Incremental compaction</h5><p>Incremental compaction is used in a couple of commercial collectors (Oracle G1 and the Balanced Collector from IBM). This technique assumes that some regions of memory are more popular than others, although this is not always the case depending on the application. The GC algorithm tracks cross-region remembered sets (i.e. which region points to which). This allows the collector to compact a single region at a time and only scan regions pointing into it when remapping all potential references. The collector identifies region sets that fit into limited pause times, allowing the maximum time for application interruption to be controlled. Large heaps have fewer non-popular regions; the number of regions pointing into a single region tends to be linear to the size of the heap. Because of this, the work for this type of compaction can grow with the square of the heap size.</p>
<h5 id="External-and-Internal-Compaction"><a href="#External-and-Internal-Compaction" class="headerlink" title="External and Internal Compaction"></a>External and Internal Compaction</h5><p>The JRockit JVM uses two compaction methods called <em>external compaction</em> and <em>internal compaction</em>. External compaction moves (evacuates) the objects within the compaction area to free positions outside the compaction area and as far down in the heap as possible. Internal compaction moves the objects within the compaction area as far down in the compaction area as possible, thus moving them closer together.</p>
<p>The JVM selects a compaction method depending on the current garbage collection mode and the position of the compaction area. External compaction is typically used near the top of the heap, while internal compaction is used near the bottom where the density of objects is higher.</p>
<h5 id="Sliding-Window-Schemes"><a href="#Sliding-Window-Schemes" class="headerlink" title="Sliding Window Schemes"></a>Sliding Window Schemes</h5><p>The position of the compaction area changes at each garbage collection, using one or two sliding windows to determine the next position. Each sliding window moves a notch up or down in the heap at each garbage collection, until it reaches the other end of the heap or meets a sliding window that moves in the opposite direction, and starts over again. Thus the whole heap is eventually traversed by compaction over and over again.</p>
<h5 id="Compaction-Area-Sizing"><a href="#Compaction-Area-Sizing" class="headerlink" title="Compaction Area Sizing"></a>Compaction Area Sizing</h5><p>The size of the compaction area depends on the garbage collection mode used. In throughput mode the compaction area size is static, while all other modes, including the static mode, adjust the compaction area size depending on the compaction area position, aiming at keeping the compaction times equal throughout the run. The compaction time depends on the number of objects moved and the number of references to these objects. Thus the compaction area will be smaller in parts of the heap where the object density is high or where the amount of references to the objects within the area is high. Typically the object density is higher near the bottom of the heap than at the top of the heap, except at the very top where the latest allocated objects are found. Thus the compaction areas are usually smaller near the bottom of the heap than in the top half of the heap.</p>
<h4 id="Strong-Weak-Soft-and-Phantom-References"><a href="#Strong-Weak-Soft-and-Phantom-References" class="headerlink" title="Strong, Weak, Soft and Phantom References"></a>Strong, Weak, Soft and Phantom References</h4><p>In Java, strong, weak, soft, and phantom references are different types of references that provide varying levels of control over object lifecycle and garbage collection. Here’s a brief explanation of each type:</p>
<ol>
<li><p>Strong Reference:</p>
<p>Strong references are the default type of reference in Java. An object with a strong reference remains reachable as long as the reference itself is in scope or actively referenced. The garbage collector does not reclaim objects that have at least one strong reference.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">strongRef</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br></pre></td></tr></table></figure>

<p>In this example, the <code>strongRef</code> is a strong reference to the <code>Object</code> instance. As long as there is an active strong reference to an object, it won’t be eligible for garbage collection.</p>
</li>
<li><p>Weak Reference:</p>
<p>Weak references allow objects to be eligible for garbage collection even if they have weak references pointing to them. Weak references are useful for implementing caches or managing non-essential or optional data. When the garbage collector detects an object with only weak references, it is free to reclaim the object’s memory.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">WeakReference&lt;Object&gt; weakRef = <span class="keyword">new</span> <span class="title class_">WeakReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>());</span><br></pre></td></tr></table></figure>

<p>Here, <code>weakRef</code> is a weak reference to the <code>Object</code> instance. Weak references are cleared and become eligible for garbage collection when there are no strong references to the object.</p>
</li>
<li><p>Soft Reference:</p>
<p>Soft references are similar to weak references but have a stronger guarantee for longer retention. The garbage collector only reclaims objects with soft references if memory becomes scarce. Soft references are commonly used for implementing memory-sensitive caches or data structures that prioritize preserving memory over strong references.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SoftReference&lt;Object&gt; softRef = <span class="keyword">new</span> <span class="title class_">SoftReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>());</span><br></pre></td></tr></table></figure>

<p>The <code>softRef</code> is a soft reference to the <code>Object</code> instance. Soft references are similar to weak references but have a higher tendency to survive garbage collection. They are typically used for implementing caches or other memory-sensitive caches.</p>
</li>
<li><p>Phantom Reference:</p>
<p>Phantom references are the weakest type of reference. They provide a way to get notified when an object is about to be finalized but do not prevent the object from being collected. Phantom references are often used for monitoring or performing post-mortem cleanup actions on objects.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ReferenceQueue&lt;Object&gt; referenceQueue = <span class="keyword">new</span> <span class="title class_">ReferenceQueue</span>&lt;&gt;();</span><br><span class="line">PhantomReference&lt;Object&gt; phantomRef = <span class="keyword">new</span> <span class="title class_">PhantomReference</span>&lt;&gt;(<span class="keyword">new</span> <span class="title class_">Object</span>(), referenceQueue);</span><br></pre></td></tr></table></figure>

<p>In this example, <code>phantomRef</code> is a phantom reference to the <code>Object</code> instance. Phantom references are the weakest type of reference and are enqueued in a <code>ReferenceQueue</code> after the object has been finalized. They are useful for performing post-mortem cleanup actions.</p>
</li>
</ol>
<h3 id="Permanent-Generation-GC"><a href="#Permanent-Generation-GC" class="headerlink" title="Permanent Generation GC"></a>Permanent Generation GC</h3><p>With the introduction of the Metaspace in Java 8 and later versions, the collection of class metadata and interned strings is handled by the native memory management system rather than the traditional garbage collection process used for the Java heap. The Metaspace has its own mechanisms for managing memory, such as native memory allocation and deallocation, which are typically handled by the underlying operating system.</p>
<h3 id="Collection-Strategies"><a href="#Collection-Strategies" class="headerlink" title="Collection Strategies"></a>Collection Strategies</h3><h4 id="Concurrent-collector"><a href="#Concurrent-collector" class="headerlink" title="Concurrent collector"></a>Concurrent collector</h4><p>The <em>mostly concurrent mark and sweep strategy</em> (often simply called <em>concurrent garbage collection</em>) allows the Java threads to continue running during large portions of the garbage collection. The threads must however be stopped a few times for synchronization.</p>
<p>The mostly concurrent mark phase is divided into four parts:</p>
<ul>
<li><em>Initial marking</em>, where the root set of live objects is identified. This is done while the Java threads are paused.</li>
<li><em>Concurrent marking</em>, where the references from the root set are followed in order to find and mark the rest of the live objects in the heap. This is done while the Java threads are running.</li>
<li><em>Precleaning</em>, where changes in the heap during the concurrent mark phase are tracked in card marks and any additional live objects are found and marked. This is done while the Java threads are running.</li>
<li><em>Final marking</em>, where changes during the precleaning phase are identified and any additional live objects are found and marked. This is done while the Java threads are paused.</li>
</ul>
<p>The mostly concurrent sweep phase consists of four parts:</p>
<ul>
<li>Sweeping of one half of the heap. This is done while the Java threads are running and are allowed to allocate objects in the part of the heap that isn’t currently being swept.</li>
<li>A short pause to switch halves.</li>
<li>Sweeping of the other half of the heap. This is done while the Java threads are running and are allowed to allocate objects in the part of the heap that was swept first.</li>
<li>A short pause for synchronization and recording statistics.</li>
</ul>
<h4 id="Parallel-collector"><a href="#Parallel-collector" class="headerlink" title="Parallel collector"></a>Parallel collector</h4><p>The parallel mark and sweep strategy (also called the <em>parallel garbage collector</em>) uses all available CPUs in the system for performing the garbage collection as fast as possible. All Java threads are paused during the entire parallel garbage collection. </p>
<p>A collector can be concurrent but not parallel, and it can be concurrent AND parallel. (Side note – be cautious when researching older literature on garbage collection, since what we used to call parallel is now called concurrent.)</p>
<h4 id="Stop-the-world-STW"><a href="#Stop-the-world-STW" class="headerlink" title="Stop-the-world (STW)"></a>Stop-the-world (STW)</h4><p> It’s the opposite of concurrent. It performs garbage collection while the application is completely stopped.</p>
<h4 id="Incremental"><a href="#Incremental" class="headerlink" title="Incremental"></a>Incremental</h4><p>It performs garbage collection as a series of smaller increments with potentially long gaps in between. The application is stopped during garbage collection but runs in between increments. Moving – the collector moves objects during garbage collection and has to update references to those live objects.</p>
<h4 id="Conservative"><a href="#Conservative" class="headerlink" title="Conservative"></a>Conservative</h4><p> most non-managed runtimes are conservative. In this model, the collector is unsure of whether a field is a reference or not, so it assumes that it is. This is in contrast to a Precise Collector.</p>
<h4 id="Precise"><a href="#Precise" class="headerlink" title="Precise"></a>Precise</h4><p>A precise collector knows exactly where every possible object reference is. A collector cannot be a moving collector without also being precise, because you have to know which references to fix when you move the live objects. Precise collectors identify the live objects in the memory heap, reclaim resources held by dead objects and periodically relocate live objects.</p>
<p>Most of the work the virtual machine does to be precise, is actually in the compiler, not the collector itself. All commercial JVMs today are moving and precise.</p>
<h3 id="Collector-Types"><a href="#Collector-Types" class="headerlink" title="Collector Types"></a>Collector Types</h3><p><strong>1. Mark&#x2F;Sweep&#x2F;Compact Collector</strong></p>
<p>performs the three phases as three separate steps.</p>
<p><strong>2. Mark&#x2F;Compact Collector</strong></p>
<p>skips the sweep and moves live objects to a contiguous area of the heap.</p>
<p><strong>3. Copying Collector</strong></p>
<p>performs all three phases in one pass. A copying collector is pretty aggressive. It uses a ‘from’ and ‘to’ space and moves all the live objects then fixes the references all in one pass. When the ‘from’ space is empty the collection is complete. Work done in a copying collector is linear to the size of the live set.</p>
<p><strong>4. Generational Collectors</strong> </p>
<p>A generational collector is based on the hypothesis that most objects die young. This is the collector introduced above. </p>
<p>Commercial server-side JVMs typically use a copying collector for the young generation that employs a monolithic, stop-the-world collection. In other words, the collector stops application processing and copies the entire live set into a new section of the heap. The old generation usually uses a Mark&#x2F;Sweep&#x2F;Compact collector, which may be stop-the-world, concurrent,mostly concurrent, incremental stop-the-world or mostly incremental stop-the-world.</p>
<p><img src="/../images/comparing_collector_types.png" alt="comparing collector types"></p>
<h3 id="Commercial-Collectors"><a href="#Commercial-Collectors" class="headerlink" title="Commercial Collectors"></a>Commercial Collectors</h3><h4 id="Oracle’s-HotSpot-ParallelGC"><a href="#Oracle’s-HotSpot-ParallelGC" class="headerlink" title="Oracle’s HotSpot ParallelGC"></a>Oracle’s HotSpot ParallelGC</h4><p>This is the default collector for HotSpot. It uses a monolithic, stop-the-world copying collector for the young generation and a monolithic, stop-the-world Mark&#x2F;Sweep&#x2F;Compact algorithm for the old generation.</p>
<h4 id="Oracle’s-HotSpot-CMS"><a href="#Oracle’s-HotSpot-CMS" class="headerlink" title="Oracle’s HotSpot CMS"></a>Oracle’s HotSpot CMS</h4><p>The Concurrent Mark&#x2F;Sweep collector (CMS) is an option in HotSpot. It attempts to reduce the old generation pauses as much as possible by concurrently marking and sweeping the old generation without compacting. Once the old generation becomes too fragmented, it falls back to a monolithic, stop-the-world compaction.</p>
<p>CMS performs mostly concurrent marking for old generation. For young generation, it’s the same as above.</p>
<h4 id="Oracle’s-HotSpot-G1GC-Garbage-First"><a href="#Oracle’s-HotSpot-G1GC-Garbage-First" class="headerlink" title="Oracle’s HotSpot G1GC (Garbage First)"></a>Oracle’s HotSpot G1GC (Garbage First)</h4><p>G1 is an option in HotSpot. Its goal is to avoid, “as much as possible” a full GC. G1 uses a mostly concurrent marker for the old generation. It marks concurrently as much as possible, then uses a stop-theworld pause to catch up on mutations and reference processing. G1 tracks inter-regional relationships in remembered sets and does not use fine-grained free lists. It uses stop-the-world, mostly incremental compaction and delays compaction of popular objects and regions as much as possible. G1 falls back to monolithic, stop-the-world full compaction of these popular areas when needed.</p>
<p>For young generation, it’s the same as above.</p>
<p><img src="/../images/commercial-gc.png" alt="commercial GC"> </p>
<h3 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h3><p>We can use the Java command line as well as UI tools for monitoring garbage collection activities of an application.</p>
<h4 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h4><p>We can use <code>jstat</code> command line tool to monitor the JVM memory and garbage collection activities. It’s shipped with standard JDK.</p>
<p>Firstly, execute the application.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">java -Xmx120m -Xms30m -Xmn10m -XX:PermSize=20m -XX:MaxPermSize=20m -XX:+UseSerialGC -jar Java2Demo.jar</span></span><br></pre></td></tr></table></figure>

<p>To execute <code>jstat</code> you need to know the process id of the application, you can get it easily using <code>ps -eaf | grep java</code> command.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ps -eaf | grep Java2Demo.jar</span></span><br><span class="line">  501 9582  11579   0  9:48PM ttys000    0:21.66 /usr/bin/java -Xmx120m -Xms30m -Xmn10m -XX:PermSize=20m -XX:MaxPermSize=20m -XX:+UseG1GC -jar Java2Demo.jar</span><br><span class="line">  501 14073 14045   0  9:48PM ttys002    0:00.00 grep Java2Demo.jar</span><br></pre></td></tr></table></figure>

<p>So the process id for my java application is 9582. Now we can run <strong>jstat</strong> command as shown below.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">jstat -gc 9582 1000</span></span><br><span class="line"> S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT</span><br><span class="line">1024.0 1024.0  0.0    0.0    8192.0   7933.3   42108.0    23401.3   20480.0 19990.9    157    0.274  40      1.381    1.654</span><br><span class="line">1024.0 1024.0  0.0    0.0    8192.0   8026.5   42108.0    23401.3   20480.0 19990.9    157    0.274  40      1.381    1.654</span><br><span class="line">1024.0 1024.0  0.0    0.0    8192.0   8030.0   42108.0    23401.3   20480.0 19990.9    157    0.274  40      1.381    1.654</span><br><span class="line">1024.0 1024.0  0.0    0.0    8192.0   8122.2   42108.0    23401.3   20480.0 19990.9    157    0.274  40      1.381    1.654</span><br><span class="line">1024.0 1024.0  0.0    0.0    8192.0   8171.2   42108.0    23401.3   20480.0 19990.9    157    0.274  40      1.381    1.654</span><br><span class="line">1024.0 1024.0  48.7   0.0    8192.0   106.7    42108.0    23401.3   20480.0 19990.9    158    0.275  40      1.381    1.656</span><br><span class="line">1024.0 1024.0  48.7   0.0    8192.0   145.8    42108.0    23401.3   20480.0 19990.9    158    0.275  40      1.381    1.656</span><br></pre></td></tr></table></figure>

<p>The last argument for jstat is the time interval between each output, so it will print memory and garbage collection data every 1 second. Let’s go through each of the columns one by one.</p>
<ul>
<li><strong>S0C and S1C</strong>: This column shows the current size of the Survivor0 and Survivor1 areas in KB.</li>
<li><strong>S0U and S1U</strong>: This column shows the current usage of the Survivor0 and Survivor1 areas in KB. Notice that one of the survivor areas are empty all the time.</li>
<li><strong>EC and EU</strong>: These columns show the current size and usage of Eden space in KB. Note that EU size is increasing and as soon as it crosses the EC, Minor GC is called and EU size is decreased.</li>
<li><strong>OC and OU</strong>: These columns show the current size and current usage of Old generation in KB.</li>
<li><strong>PC and PU</strong>: These columns show the current size and current usage of Perm Gen in KB.</li>
<li><strong>YGC and YGCT</strong>: YGC column displays the number of GC event occurred in young generation. YGCT column displays the accumulated time for GC operations for Young generation. Notice that both of them are increased in the same row where EU value is dropped because of minor GC.</li>
<li><strong>FGC and FGCT</strong>: FGC column displays the number of Full GC event occurred. FGCT column displays the accumulated time for Full GC operations. Notice that Full GC time is too high when compared to young generation GC timings.</li>
<li><strong>GCT</strong>: This column displays the total accumulated time for GC operations. Notice that it’s sum of YGCT and FGCT column values.</li>
</ul>
<p>The advantage of <strong>jstat</strong> is that it can be executed in remote servers too where we don’t have GUI. Notice that the sum of S0C, S1C and EC is 10m as specified through <code>-Xmn10m</code> JVM option.</p>
<h4 id="Java-VisualVM-with-Visual-GC"><a href="#Java-VisualVM-with-Visual-GC" class="headerlink" title="Java VisualVM with Visual GC"></a>Java VisualVM with Visual GC</h4><p>If you want to see memory and GC operations in GUI, then you can use <code>jvisualvm</code> tool. Java VisualVM is also part of JDK, so you don’t need to download it separately. Just run <code>jvisualvm</code> command in the terminal to launch the Java VisualVM application. Once launched, you need to install <strong>Visual GC</strong> plugin from Tools -&lt; Plugins option.</p>
<p>After installing <strong>Visual GC</strong>, just open the application from the left side column and head over to <strong>Visual GC</strong> section. You will get an image of JVM memory and garbage collection details.</p>
<h2 id="Tuning-Memory-Management-System"><a href="#Tuning-Memory-Management-System" class="headerlink" title="Tuning Memory Management System"></a>Tuning Memory Management System</h2><p><strong>Java Garbage Collection Tuning</strong> should be the last option you should use for increasing the throughput of your application and only when you see a drop in performance because of longer GC timings causing application timeout.</p>
<h3 id="Choose-collector-types"><a href="#Choose-collector-types" class="headerlink" title="Choose collector types"></a>Choose collector types</h3><ol>
<li><strong>Serial GC (-XX:+UseSerialGC)</strong>: Serial GC uses the simple <strong>mark-sweep-compact</strong> approach for young and old generations garbage collection i.e Minor and Major GC.Serial GC is useful in client machines such as our simple stand-alone applications and machines with smaller CPU. It is good for small applications with low memory footprint.</li>
<li><strong>Parallel GC (-XX:+UseParallelGC)</strong>: Parallel GC is same as Serial GC except that is spawns N threads for young generation garbage collection where N is the number of CPU cores in the system. We can control the number of threads using <code>-XX:ParallelGCThreads=n</code> JVM option.Parallel Garbage Collector is also called throughput collector because it uses multiple CPUs to speed up the GC performance. Parallel GC uses a single thread for Old Generation garbage collection.</li>
<li><strong>Parallel Old GC (-XX:+UseParallelOldGC)</strong>: This is same as Parallel GC except that it uses multiple threads for both Young Generation and Old Generation garbage collection.</li>
<li><strong>Concurrent Mark Sweep (CMS) Collector (-XX:+UseConcMarkSweepGC)</strong>: CMS Collector is also referred as concurrent low pause collector. It does the garbage collection for the Old generation. CMS collector tries to minimize the pauses due to garbage collection by doing most of the garbage collection work concurrently with the application threads.CMS collector on the young generation uses the same algorithm as that of the parallel collector. This garbage collector is suitable for responsive applications where we can’t afford longer pause times. We can limit the number of threads in CMS collector using <code>-XX:ParallelCMSThreads=n</code> JVM option.</li>
<li><strong>G1 Garbage Collector (-XX:+UseG1GC)</strong>: The Garbage First or G1 garbage collector is available from Java 7 and its long term goal is to replace the CMS collector. The G1 collector is a parallel, concurrent, and incrementally compacting low-pause garbage collector.Garbage First Collector doesn’t work like other collectors and there is no concept of Young and Old generation space. It divides the heap space into multiple equal-sized heap regions. When a garbage collection is invoked, it first collects the region with lesser live data, hence “Garbage First”. You can find more details about it at <a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/G1.html">Garbage-First Collector Oracle Documentation</a>.</li>
</ol>
<h3 id="Set-heap-size"><a href="#Set-heap-size" class="headerlink" title="Set heap size"></a>Set heap size</h3><p>A small heap will become full quickly and must be garbage collected more often. It is also prone to more fragmentation, making object allocation slower. A large heap introduces a slight overhead in garbage collection times. A heap that is larger than the available physical memory in the system must be paged out to disk, which leads to long access times or even application freezes, especially during garbage collection.</p>
<ul>
<li><code>-Xms:&lt;size&gt;</code>, which sets the initial and minimum heap size</li>
<li><code>-Xmx:&lt;size&gt;</code>, which sets the maximum heap size</li>
</ul>
<p>On 64-bit systems, a memory address is 64 bits long, which makes it possible to address much more memory than with a 32-bit address; on the other hand, each address reference requires twice as much memory. To reduce the memory usage for address references on 64-bit systems, the JRockit JVM can use <em>compressed references</em>. Compressed references reduce the address references to 32 bits, and can be used as long as the entire heap can be addressed with 32 bits. So on a 64.bit system, you will usually benefit from setting the maximum heap size below 4 GB as long as the amount of live data is less than 3-4 GB. Compressed references are enabled by default whenever applicable.</p>
<p>When you run the JRockit JVM on a 64-bit system with a heap size less than 4 GB, if native OutOfMemory errors occur despite memory being available, try disabling compressed references by using the <code>-XxcompressedRefs=0</code> option.</p>
<h3 id="other"><a href="#other" class="headerlink" title="other"></a>other</h3><p>If you see <code>java.lang.OutOfMemoryError: PermGen space</code> errors in logs, then try to monitor and increase the Perm Gen memory space using <code>-XX:PermGen</code> and <code>-XX:MaxPermGen</code> JVM options. You might also try using <code>-XX:+CMSClassUnloadingEnabled</code> and check how it’s performing with CMS Garbage collector. If you see a lot of Full GC operations, then you should try increasing Old generation memory space.</p>
<h1 id="JIT"><a href="#JIT" class="headerlink" title="JIT"></a>JIT</h1><p>just-in-time compilation. To be continued… </p>
<h1 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h1><h2 id="Serializable"><a href="#Serializable" class="headerlink" title="Serializable"></a>Serializable</h2><p>f you want a class object to be serializable, all you need to do it implement the <code>java.io.Serializable</code> interface. Serializable in java is a marker interface and has no fields or methods to implement. It’s like an Opt-In process through which we make our classes serializable. Serialization in java is implemented by <code>ObjectInputStream</code> and <code>ObjectOutputStream</code>, so all we need is a wrapper over them to either save it to file or send it over the network.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.ObjectInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.ObjectOutputStream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SerializationTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        String fileName=<span class="string">&quot;employee.ser&quot;</span>;</span><br><span class="line">        <span class="type">Employee</span> <span class="variable">emp</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Employee</span>();</span><br><span class="line">        emp.setId(<span class="number">100</span>);</span><br><span class="line">        emp.setName(<span class="string">&quot;Pankaj&quot;</span>);</span><br><span class="line">        emp.setSalary(<span class="number">5000</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//serialize to file</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            SerializationUtil.serialize(emp, fileName);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">Employee</span> <span class="variable">empNew</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            empNew = (Employee) SerializationUtil.deserialize(fileName);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassNotFoundException | IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;emp Object::&quot;</span>+emp);</span><br><span class="line">        System.out.println(<span class="string">&quot;empNew Object::&quot;</span>+empNew);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Employee</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line"><span class="comment">// static variable values are also not serialized since they belongs to class and not object.</span></span><br><span class="line"><span class="comment">//    private static final long serialVersionUID = -6470090944414208496L;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> id;</span><br><span class="line"><span class="comment">// transient field won&#x27;t be serialized</span></span><br><span class="line">    <span class="keyword">transient</span> <span class="keyword">private</span> <span class="type">int</span> salary;</span><br><span class="line"><span class="comment">//    private String password;</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Employee&#123;name=&quot;</span>+name+<span class="string">&quot;,id=&quot;</span>+id+<span class="string">&quot;,salary=&quot;</span>+salary+<span class="string">&quot;&#125;&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//getter and setter methods</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(<span class="type">int</span> id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getSalary</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> salary;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSalary</span><span class="params">(<span class="type">int</span> salary)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.salary = salary;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    public String getPassword() &#123;</span></span><br><span class="line"><span class="comment">//        return password;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    public void setPassword(String password) &#123;</span></span><br><span class="line"><span class="comment">//        this.password = password;</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SerializationUtil</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// deserialize to Object from given file</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title function_">deserialize</span><span class="params">(String fileName)</span> <span class="keyword">throws</span> IOException,</span><br><span class="line">            ClassNotFoundException &#123;</span><br><span class="line">        <span class="type">FileInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(fileName);</span><br><span class="line">        <span class="type">ObjectInputStream</span> <span class="variable">ois</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectInputStream</span>(fis);</span><br><span class="line">        <span class="type">Object</span> <span class="variable">obj</span> <span class="operator">=</span> ois.readObject();</span><br><span class="line">        ois.close();</span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// serialize the given object and save it to file</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">serialize</span><span class="params">(Object obj, String fileName)</span></span><br><span class="line">            <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(fileName);</span><br><span class="line">        <span class="type">ObjectOutputStream</span> <span class="variable">oos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectOutputStream</span>(fos);</span><br><span class="line">        oos.writeObject(obj);</span><br><span class="line"></span><br><span class="line">        fos.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="serialVersionUID"><a href="#serialVersionUID" class="headerlink" title="serialVersionUID"></a>serialVersionUID</h2><p>For the above code, if we uncomment the “password” variable and it’s getter-setter methods from Employee class and run it. You will get below exception;</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.io.InvalidClassException: com.xxx.Employee; local class incompatible: stream classdesc serialVersionUID = -6470090944414208496, local class serialVersionUID = -6234198221249432383</span><br><span class="line">    at java.io.ObjectStreamClass.initNonProxy(ObjectStreamClass.java:604)</span><br><span class="line">    at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1601)</span><br><span class="line">    at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1514)</span><br><span class="line">    at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1750)</span><br><span class="line">    at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1347)</span><br><span class="line">    at java.io.ObjectInputStream.readObject(ObjectInputStream.java:369)</span><br><span class="line">    at com.xxx.SerializationUtil.deserialize(SerializationUtil.java:22)</span><br><span class="line">    at com.xxx.DeserializationTest.main(DeserializationTest.java:13)</span><br><span class="line">empNew Object::null</span><br></pre></td></tr></table></figure>

<p>The reason is clear that serialVersionUID of the previous class and new class are different. Actually if the class doesn’t define serialVersionUID, it’s getting calculated automatically and assigned to the class. Java uses class variables, methods, class name, package etc to generate this unique long number. If you are working with any IDE, you will automatically get a warning that “The serializable class Employee does not declare a static final serialVersionUID field of type long”.</p>
<p>We can assign this value as we want. It just need to be there to let deserialization process know that the new class is the new version of the same class and should be deserialized of possible. For example, uncomment only the serialVersionUID field from the <code>Employee</code> class and run <code>SerializationTest</code> program. Now uncomment the password field from Employee class and run the <code>DeserializationTest</code> program and you will see that the object stream is deserialized successfully because the change in Employee class is compatible with serialization process.</p>
<h2 id="Externalizable"><a href="#Externalizable" class="headerlink" title="Externalizable"></a>Externalizable</h2><p>Sometimes we want to obscure the object data to maintain it’s integrity. We can do this by implementing <code>java.io.Externalizable</code> interface and provide implementation of <em>writeExternal()</em> and <em>readExternal()</em> methods to be used in serialization process.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.Externalizable;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.ObjectInput;</span><br><span class="line"><span class="keyword">import</span> java.io.ObjectOutput;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> <span class="keyword">implements</span> <span class="title class_">Externalizable</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String gender;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeExternal</span><span class="params">(ObjectOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.writeInt(id);</span><br><span class="line">        out.writeObject(name+<span class="string">&quot;xyz&quot;</span>);</span><br><span class="line">        out.writeObject(<span class="string">&quot;abc&quot;</span>+gender);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readExternal</span><span class="params">(ObjectInput in)</span> <span class="keyword">throws</span> IOException,</span><br><span class="line">            ClassNotFoundException &#123;</span><br><span class="line">        id=in.readInt();</span><br><span class="line">        <span class="comment">//read in the same order as written</span></span><br><span class="line">        name=(String) in.readObject();</span><br><span class="line">        <span class="keyword">if</span>(!name.endsWith(<span class="string">&quot;xyz&quot;</span>)) <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IOException</span>(<span class="string">&quot;corrupted data&quot;</span>);</span><br><span class="line">        name=name.substring(<span class="number">0</span>, name.length()-<span class="number">3</span>);</span><br><span class="line">        gender=(String) in.readObject();</span><br><span class="line">        <span class="keyword">if</span>(!gender.startsWith(<span class="string">&quot;abc&quot;</span>)) <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IOException</span>(<span class="string">&quot;corrupted data&quot;</span>);</span><br><span class="line">        gender=gender.substring(<span class="number">3</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Person&#123;id=&quot;</span>+id+<span class="string">&quot;,name=&quot;</span>+name+<span class="string">&quot;,gender=&quot;</span>+gender+<span class="string">&quot;&#125;&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(<span class="type">int</span> id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Serialization-Proxy-Pattern"><a href="#Serialization-Proxy-Pattern" class="headerlink" title="Serialization Proxy Pattern"></a>Serialization Proxy Pattern</h2><h3 id="why"><a href="#why" class="headerlink" title="why"></a>why</h3><p>Serialization in java comes with some serious pitfalls such as;</p>
<ul>
<li>The class structure can’t be changed a lot without breaking the java serialization process. So even though we don’t need some variables later on, we need to keep them just for backward compatibility.</li>
<li>Serialization causes huge security risks, an attacker can change the stream sequence and cause harm to the system. For example, user role is serialized and an attacker change the stream value to make it admin and run malicious code.</li>
</ul>
<p>Java Serialization Proxy pattern is a way to achieve greater security with Serialization. In this pattern, an inner private static class is used as a proxy class for serialization purpose. It’s great because:</p>
<ol>
<li><p>Single responsiblity. The main class doesn’t need to concern about the serialization and it can change happily. </p>
</li>
<li><p>In the proxy class, we can decide which attributes to be serialized and ignore the sensitive information.</p>
</li>
<li><p>In this way, we can always use the constructor (in the <code>readResolve</code>) to create the object, to forbid some deserialization from stream directly, which may break the data integrity. </p>
</li>
<li><p>It can be used in case when information are saved in db, and we can serialize only id, but get the whole object from db.</p>
</li>
</ol>
<h3 id="how"><a href="#how" class="headerlink" title="how"></a>how</h3><p>This pattern is implemented by properly implementing <em>readResolve()</em> and <em>writeReplace()</em> methods.</p>
<ol>
<li><p><strong>readObject(ObjectInputStream ois)</strong>: If this method is present in the class, ObjectInputStream readObject() method will use this method for reading the object from stream.</p>
</li>
<li><p><strong>writeObject(ObjectOutputStream oos)</strong>: If this method is present in the class, ObjectOutputStream writeObject() method will use this method for writing the object to stream. One of the common usage is to obscure the object variables to maintain data integrity.</p>
</li>
<li><p><strong>Object writeReplace()</strong>: If this method is present, then after serialization process this method is called and the object returned is serialized to the stream.</p>
</li>
<li><p><strong>Object readResolve()</strong>: If this method is present, then after deserialization process, this method is called to return the final object to the caller program. One of the usage of this method is to implement Singleton pattern with Serialized classes. Read more at <a href="https://www.digitalocean.com/community/tutorials/java-singleton-design-pattern-best-practices-examples#serialization-and-singleton">Serialization and Singleton</a>.</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Person</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String email;</span><br><span class="line">    <span class="keyword">private</span> String password;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Person</span><span class="params">(String name, String email, String password)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.email = email;</span><br><span class="line">        <span class="built_in">this</span>.password = password;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Object <span class="title function_">writeReplace</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">PersonProxy</span>(<span class="built_in">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">readObject</span><span class="params">(ObjectInputStream ois)</span> <span class="keyword">throws</span> InvalidObjectException&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">InvalidObjectException</span>(<span class="string">&quot;Proxy is not used, something fishy&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">PersonProxy</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> String name;</span><br><span class="line">        <span class="keyword">private</span> String email;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">PersonProxy</span><span class="params">(Person person)</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.name = person.name;</span><br><span class="line">            <span class="built_in">this</span>.email = person.email;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">private</span> Object <span class="title function_">readResolve</span><span class="params">()</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Person</span>(name, email, <span class="literal">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>Both <code>Person</code> and <code>PersonProxy</code> class should implement Serializable interface.</li>
<li><code>PersonProxy</code> is inner private static class, so that other classes can’t access it.</li>
<li><code>Person</code> class should provide <em>writeReplace()</em> method returning <code>PersonProxy</code> instance. So when Person object is serialized, the returned stream is of PersonProxy class. However PersonProxy class is not visible outside, so it can’t be used directly.</li>
<li><code>PersonProxy</code> class should implement <em>readResolve()</em> method returning <code>Person</code> object. So when Person class is deserialized, internally PersonProxy is deserialized and when it’s readResolve() method is called, we get Person object.</li>
<li>Finally implement <em>readObject()</em> method in Person class and throw <code>InvalidObjectException</code> to avoid hackers attack trying to fabricate Data object stream and parse it.</li>
</ul>
<h1 id="ClassLoader"><a href="#ClassLoader" class="headerlink" title="ClassLoader"></a>ClassLoader</h1><p>When we compile a Java Class, JVM creates the bytecode, which is platform and machine-independent. The bytecode is stored in a <strong>.class file</strong>. When we try to use a class, the ClassLoader loads it into the memory.</p>
<p>There are three types of built-in ClassLoader in Java.</p>
<ol>
<li><strong>Bootstrap Class Loader</strong> – It loads JDK internal classes. It loads rt.jar and other core classes for example java.lang.* package classes.</li>
<li><strong>Extensions Class Loader</strong> – It loads classes from the JDK extensions directory, usually $JAVA_HOME&#x2F;lib&#x2F;ext directory.</li>
<li><strong>System Class Loader</strong> – This classloader loads classes from the current classpath. We can set classpath while invoking a program using -cp or -classpath command line option.</li>
</ol>
<p>Whenever a request is raised to load a class, it delegates it to the parent classloader. This is how uniqueness is maintained in the runtime environment. If the parent class loader doesn’t find the class then the class loader itself tries to load the class.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.DataInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStream;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CCRun</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">progClass</span> <span class="operator">=</span> args[<span class="number">0</span>];</span><br><span class="line">        String progArgs[] = <span class="keyword">new</span> <span class="title class_">String</span>[args.length - <span class="number">1</span>];</span><br><span class="line">        System.arraycopy(args, <span class="number">1</span>, progArgs, <span class="number">0</span>, progArgs.length);</span><br><span class="line"></span><br><span class="line">        <span class="type">CCLoader</span> <span class="variable">ccl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CCLoader</span>(CCRun.class.getClassLoader());</span><br><span class="line">        <span class="type">Class</span> <span class="variable">clas</span> <span class="operator">=</span> ccl.loadClass(progClass);</span><br><span class="line">        Class mainArgType[] = &#123; (<span class="keyword">new</span> <span class="title class_">String</span>[<span class="number">0</span>]).getClass() &#125;;</span><br><span class="line">        <span class="type">Method</span> <span class="variable">main</span> <span class="operator">=</span> clas.getMethod(<span class="string">&quot;main&quot;</span>, mainArgType);</span><br><span class="line">        Object argsArray[] = &#123; progArgs &#125;;</span><br><span class="line">        main.invoke(<span class="literal">null</span>, argsArray);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Below method is used to check that the Foo is getting loaded</span></span><br><span class="line">        <span class="comment">// by our custom class loader i.e CCLoader</span></span><br><span class="line">        <span class="type">Method</span> <span class="variable">printCL</span> <span class="operator">=</span> clas.getMethod(<span class="string">&quot;printCL&quot;</span>, <span class="literal">null</span>);</span><br><span class="line">        printCL.invoke(<span class="literal">null</span>, <span class="keyword">new</span> <span class="title class_">Object</span>[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CCLoader</span> <span class="keyword">extends</span> <span class="title class_">ClassLoader</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">CCLoader</span><span class="params">(ClassLoader parent)</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(parent);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Loads the class from the file system. The class file should be located in</span></span><br><span class="line"><span class="comment">     * the file system. The name should be relative to get the file location</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> name</span></span><br><span class="line"><span class="comment">     *            Fully Classified name of the class, for example, com.journaldev.Foo</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Class <span class="title function_">getClass</span><span class="params">(String name)</span> <span class="keyword">throws</span> ClassNotFoundException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">file</span> <span class="operator">=</span> name.replace(<span class="string">&#x27;.&#x27;</span>, File.separatorChar) + <span class="string">&quot;.class&quot;</span>;</span><br><span class="line">        <span class="type">byte</span>[] b = <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// This loads the byte code data from the file</span></span><br><span class="line">            b = loadClassFileData(file);</span><br><span class="line">            <span class="comment">// defineClass is inherited from the ClassLoader class</span></span><br><span class="line">            <span class="comment">// that converts byte array into a Class. defineClass is Final</span></span><br><span class="line">            <span class="comment">// so we cannot override it</span></span><br><span class="line">            <span class="type">Class</span> <span class="variable">c</span> <span class="operator">=</span> defineClass(name, b, <span class="number">0</span>, b.length);</span><br><span class="line">            resolveClass(c);</span><br><span class="line">            <span class="keyword">return</span> c;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Every request for a class passes through this method. </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Class <span class="title function_">loadClass</span><span class="params">(String name)</span> <span class="keyword">throws</span> ClassNotFoundException &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Loading Class &#x27;&quot;</span> + name + <span class="string">&quot;&#x27;&quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (name.startsWith(<span class="string">&quot;com.xxx&quot;</span>)) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;Loading Class using CCLoader&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> getClass(name);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>.loadClass(name);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Reads the file (.class) into a byte array. The file should be</span></span><br><span class="line"><span class="comment">     * accessible as a resource and make sure that it&#x27;s not in Classpath to avoid</span></span><br><span class="line"><span class="comment">     * any confusion.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">byte</span>[] loadClassFileData(String name) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="type">InputStream</span> <span class="variable">stream</span> <span class="operator">=</span> getClass().getClassLoader().getResourceAsStream(</span><br><span class="line">                name);</span><br><span class="line">        <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> stream.available();</span><br><span class="line">        <span class="type">byte</span> buff[] = <span class="keyword">new</span> <span class="title class_">byte</span>[size];</span><br><span class="line">        <span class="type">DataInputStream</span> <span class="variable">in</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DataInputStream</span>(stream);</span><br><span class="line">        in.readFully(buff);</span><br><span class="line">        in.close();</span><br><span class="line">        <span class="keyword">return</span> buff;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span> &#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Foo Constructor &gt;&gt;&gt; &quot;</span> + args[<span class="number">0</span>] + <span class="string">&quot; &quot;</span> + args[<span class="number">1</span>]);</span><br><span class="line">        <span class="type">Bar</span> <span class="variable">bar</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Bar</span>(args[<span class="number">0</span>], args[<span class="number">1</span>]);</span><br><span class="line">        bar.printCL();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">printCL</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Foo ClassLoader: &quot;</span>+Foo.class.getClassLoader());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bar</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Bar</span><span class="params">(String a, String b)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Bar Constructor &gt;&gt;&gt; &quot;</span> + a + <span class="string">&quot; &quot;</span> + b);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">printCL</span><span class="params">()</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;Bar ClassLoader: &quot;</span>+Bar.class.getClassLoader());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">compile all classes</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">javac -<span class="built_in">cp</span> . com/journaldev/cl/Foo.java</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">javac -<span class="built_in">cp</span> . com/journaldev/cl/Bar.java</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">javac CCLoader.java</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">javac CCRun.java</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">run directly</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">java CCRun com.xxx.Foo 1212 1313</span></span><br><span class="line">Loading Class &#x27;com.xxx.Foo&#x27;</span><br><span class="line">Loading Class using CCLoader</span><br><span class="line">Loading Class &#x27;java.lang.Object&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.String&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.Exception&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.System&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.StringBuilder&#x27;</span><br><span class="line">Loading Class &#x27;java.io.PrintStream&#x27;</span><br><span class="line">Foo Constructor &gt;&gt;&gt; 1212 1313</span><br><span class="line">Loading Class &#x27;com.xxx.Bar&#x27;</span><br><span class="line">Loading Class using CCLoader</span><br><span class="line">Bar Constructor &gt;&gt;&gt; 1212 1313</span><br><span class="line">Loading Class &#x27;java.lang.Class&#x27;</span><br><span class="line">Bar ClassLoader: CCLoader@71f6f0bf</span><br><span class="line">Foo ClassLoader: CCLoader@71f6f0bf</span><br></pre></td></tr></table></figure>

<h2 id="Set-as-default-classLoader"><a href="#Set-as-default-classLoader" class="headerlink" title="Set as default classLoader"></a>Set as default classLoader</h2><p>We can make our custom class loader as the default one when JVM starts by using Java Options.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ClassLoaderTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;class loader for HashMap: &quot;</span></span><br><span class="line">                + java.util.HashMap.class.getClassLoader());</span><br><span class="line">        System.out.println(<span class="string">&quot;class loader for DNSNameService: &quot;</span></span><br><span class="line">                + sun.net.spi.nameservice.dns.DNSNameService.class</span><br><span class="line">                        .getClassLoader());</span><br><span class="line">        System.out.println(<span class="string">&quot;class loader for this class: &quot;</span></span><br><span class="line">                + ClassLoaderTest.class.getClassLoader());</span><br><span class="line"></span><br><span class="line">        System.out.println(com.mysql.jdbc.Blob.class.getClassLoader());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">javac -<span class="built_in">cp</span> .:../lib/mysql-connector-java-5.0.7-bin.jar com/xxx/ClassLoaderTest.java</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">java -<span class="built_in">cp</span> .:../lib/mysql-connector-java-5.0.7-bin.jar -Djava.system.class.loader=CCLoader com.xxx.ClassLoaderTest</span></span><br><span class="line">Loading Class &#x27;com.xxx.ClassLoaderTest&#x27;</span><br><span class="line">Loading Class using CCLoader</span><br><span class="line">Loading Class &#x27;java.lang.Object&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.String&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.System&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.StringBuilder&#x27;</span><br><span class="line">Loading Class &#x27;java.util.HashMap&#x27;</span><br><span class="line">Loading Class &#x27;java.lang.Class&#x27;</span><br><span class="line">Loading Class &#x27;java.io.PrintStream&#x27;</span><br><span class="line">class loader for HashMap: null</span><br><span class="line">Loading Class &#x27;sun.net.spi.nameservice.dns.DNSNameService&#x27;</span><br><span class="line">class loader for DNSNameService: sun.misc.Launcher$ExtClassLoader@24480457</span><br><span class="line">class loader for this class: CCLoader@38503429</span><br><span class="line">Loading Class &#x27;com.mysql.jdbc.Blob&#x27;</span><br><span class="line">sun.misc.Launcher$AppClassLoader@2f94ca6c</span><br></pre></td></tr></table></figure>

<h1 id="Object-hashCode"><a href="#Object-hashCode" class="headerlink" title="Object hashCode()"></a>Object hashCode()</h1><p>The <code>Object.hashCode()</code> method in Java calculates the hash code for an object. The default implementation of <code>hashCode()</code> in the <code>Object</code> class is known as the identity hash code. The identity hash code is not based on the memory address of the object, as commonly believed, but rather it is generated using a more complex algorithm.</p>
<p>In the OpenJDK implementation of <code>hashCode()</code>, the identity hash generation involves several steps. First, the <code>ObjectSynchronizer::FastHashCode()</code> function is called. If biased locking is enabled, the function revokes any existing biases and disables biased locking on the object. This is done to ensure the correctness of the identity hash code generation process.</p>
<p>Next, the function retrieves the object’s header, which is stored in the mark word of the object. The mark word contains various information about the object, including the identity hash code. In the simplest case, where no locks are involved, the identity hash is directly stored in the mark word. However, if the object is involved in biased locking or other complex synchronization scenarios, the mark word may point to a lock record or an ObjectMonitor, which is a data structure used for synchronization.</p>
<p>If the identity hash code is present in the mark word, it is returned. Otherwise, the function calls <code>get_next_hash()</code> to generate a new hash code and stores it in the displaced header kept by the ObjectMonitor. This ensures that the identity hash remains consistent even if the object is relocated in memory.</p>
<p>The default algorithm used to generate the identity hash code depends on the version of OpenJDK. In OpenJDK 8 and 9, it uses a combination of thread state and the xorshift algorithm. However, previous versions like OpenJDK 7 and 6 used a randomly generated number as the default method.</p>
<p>In summary, the default <code>hashCode()</code> implementation in Java does not simply rely on the memory address of the object. Instead, it involves complex logic to generate and store the identity hash code in the object’s header, taking into account synchronization scenarios such as biased locking.</p>
<p><a href="https://srvaroa.github.io/jvm/java/openjdk/biased-locking/2017/01/30/hashCode.html">How does the default hashCode() work?</a></p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul>
<li><p><a href="https://www.digitalocean.com/community/tutorials/java-jvm-memory-model-memory-management-in-java">Java (JVM) Memory Model - Memory Management in Java | DigitalOcean</a></p>
</li>
<li><p><a href="https://docs.oracle.com/cd/E13150_01/jrockit_jvm/jrockit/geninfo/diagnos/garbage_collect.html">Understanding Memory Management</a></p>
</li>
<li><p><a href="https://www.baeldung.com/java-memory-management-interview-questions">Memory Management in Java Interview Questions (+Answers) | Baeldung</a></p>
</li>
<li><p><a href="https://docs.oracle.com/javase/specs/jls/se20/html/jls-17.html#jls-17.4">javase 20 memory model</a></p>
</li>
<li><p><a href="https://docs.oracle.com/en/java/javase/20/gctuning/introduction-garbage-collection-tuning.html#GUID-326EB4CF-8C8C-4267-8355-21AB04F0D304">Introduction to Garbage Collection Tuning javase 20</a></p>
</li>
<li><p><a href="https://docs.oracle.com/en/java/javase/20/vm/index.html">Java Platform, Standard Edition Java Virtual Machine Guide, Release 20</a></p>
</li>
<li><p><a href="https://www.azul.com/wp-content/uploads/WP-Understanding-Java-Garbage-Collection.pdf">https://www.azul.com/wp-content/uploads/WP-Understanding-Java-Garbage-Collection.pdf</a></p>
</li>
<li><p><a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/G1.html">Garbage-First Collector</a></p>
</li>
<li><p><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/index.html">Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide, Release 8</a></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>js ecosystem</title>
    <url>/2018/06/21/js-ecosystem-md/</url>
    <content><![CDATA[<p>我在学习 react，一直在使用 <a href="https://github.com/facebook/create-react-app">create-react-app</a> 创建项目。create-react-app 其实包括两个核心：</p>
<ul>
<li><code>create-react-app</code>：主要提供了 command-line 工具，方便用户创建 react 项目</li>
<li><code>react-scripts</code>：这才是核心。它封装了所有开发 react 项目的配置，使得用户可以零配置直接开始开发 react。用户基本不需要更新 <code>create-react-app</code>，因为它总是拉最新的 <code>react-scripts</code>，而 <code>react-scripts</code> 才是简化用户配置的核心。</li>
</ul>
<p>问题来了，我在写测试的时候发现，<code>react-scripts</code> 默认配置使用的是 jest，而且版本较低（可运行 <code>npm ls jest</code> 查看依赖树，结果如下图所示）。而我需要使用的 data-driven-test 依赖包 <code>jest-each</code> 是 jest 23.0.0 以后的版本才有的。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/721960-cc0aae2294d01d0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="react-scripts-dependency.png"></p>
<p>所以我需要在测试的时候不使用默认安装的 jest，</p>
<p>读了一个 <a href="https://medium.com/@francesco.agnoletto/i-didnt-like-create-react-app-so-i-created-my-own-boilerplate-190a7dd5d74">post: 自己写样板，不使用 create-react-app</a>，受它的启发要自己配置 react 项目，那么就有必要了解 js ecosystem 中的一些工程。</p>
<h1 id="webpack"><a href="#webpack" class="headerlink" title="webpack"></a><a href="https://www.webpackjs.com/concepts/">webpack</a></h1><p>一个开源的前端打包工具，支持用户进行模块化开发（即用户开发很多 module，然后不同的 mudule 之间可通过 import, export 进行相互引用）。原本 js 是不支持的，可参见 <a href="https://hfcherish.github.io/2018/06/21/js-global-namespace/">js global namespace</a>。</p>
<h1 id="ESLint"><a href="#ESLint" class="headerlink" title="ESLint"></a><a href="http://eslint.cn/docs/user-guide/configuring">ESLint</a></h1><p>是一个 javascript 的语法检查器。类似于在 IDE 中写 java 时的即时编译检查。它是可以配置的，以完成你所需要的检查。</p>
<h1 id="ECMAScript"><a href="#ECMAScript" class="headerlink" title="ECMAScript"></a><a href="https://zh.wikipedia.org/wiki/ECMAScript">ECMAScript</a></h1><p><a href="https://huangxuan.me/2015/09/22/js-version/">ES5, ES6, ES2016, ES.Next: What’s going on with JavaScript versioning?</a> 翻译的这个文章讲得很好，我直接引用原文：</p>
<blockquote>
<ul>
<li><strong>ECMAScript</strong>：一个由 ECMA International 进行标准化，TC39 委员会进行监督的语言。通常用于指代标准本身。</li>
<li><strong>JavaScript</strong>：ECMAScript 标准的各种实现的最常用称呼。这个术语并不局限于某个特定版本的 ECMAScript 规范，并且可能被用于任何不同程度的任意版本的 ECMAScript 的实现。</li>
<li>**ECMAScript 5 (ES5)**：ECMAScript 的第五版修订，于 2009 年完成标准化。这个规范在所有现代浏览器中都相当完全的实现了。</li>
<li>**ECMAScript 6 (ES6) &#x2F; ECMAScript 2015 (ES2015)**：ECMAScript 的第六版修订，于 2015 年完成标准化。这个标准被部分实现于大部分现代浏览器。可以查阅这张兼容性表来查看不同浏览器和工具的实现情况。</li>
<li><strong>ECMAScript 2016</strong>：预计的第七版 ECMAScript 修订，计划于明年夏季发布。这份规范具体将包含哪些特性还没有最终确定</li>
<li><strong>ECMAScript Proposals</strong>：被考虑加入未来版本 ECMAScript 标准的特性与语法提案，他们需要经历五个阶段：Strawman（稻草人），Proposal（提议），Draft（草案），Candidate（候选）以及 Finished （完成）。</li>
</ul>
</blockquote>
<p>blog 里也讲了 ecmascript 的历史。简答总结一下：</p>
<ol>
<li>很久以前（1996），网景浏览器把他们写的 javascript 交给 ECMA International（欧洲计算机制造协会）进行标准化</li>
<li>ECMA 1，2，3 版本很快发布，而且被各大浏览器厂商支持</li>
<li>ECMA 一直没有变化，各大浏览器厂商自行扩展（所以 javascript 其实是 ECMAScript 的实现和扩展）</li>
<li>某一年，ECMA 4 出来，太激进，被废弃了（只有 Adobe 实现了）</li>
<li>2009 年，ECMA 5（es5） 出来。但直到 2012 年才逐渐被公众接受</li>
<li>2015 年，es6 出来。与此同时，相关委员会决定每年定义一次新标准，避免等待整个草案完成。因此 ES6 也被命名为 ECMAScript 2015</li>
</ol>
<p>一些资源：</p>
<ul>
<li>如果你还不熟悉 ES6，Babel 有一个<a href="https://babeljs.io/docs/learn-es2015/">很不错的特性概览</a></li>
<li>如果你希望深入 ES6，这里有两本很不错的书： Axel Rauschmayer 的 <a href="http://exploringjs.com/">Exploring ES6</a>和 Nicholas Zakas 的 <a href="https://leanpub.com/understandinges6">Understanding ECMAScript 6</a>。Axel 的博客 <a href="http://www.2ality.com/">2ality</a> 也是很不错的 ES6 资源</li>
</ul>
<h1 id="babel"><a href="#babel" class="headerlink" title="babel"></a><a href="https://www.babeljs.cn/">babel</a></h1><p>babel 是一个 javascript 编译器。其核心是一个语法转换器，能将使用 es6、flow、jsx 的代码转换为浏览器兼容的 javascript。所以这些项目 build 后其实是生成了浏览器兼容的 javascript。</p>
<p>为啥会有这个，原因就是上边说的，新版本 js 出来了，但是大家还不支持。</p>
]]></content>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>js export</title>
    <url>/2018/06/15/js-export/</url>
    <content><![CDATA[<p><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Statements/export">export</a> 用于从 module 中导出函数、对象、原始值，在其他地方通过 <code>import</code> 使用这些函数、对象、原始值。</p>
<p>有两种导出方式：命名导出（<code>export</code>），默认导出（<code>export default</code>）</p>
<h1 id="1-命名导出"><a href="#1-命名导出" class="headerlink" title="1. 命名导出"></a>1. 命名导出</h1><p>就是导出 module 中有命名的函数、对象、原始值。相应的，import 时，必须使用相同的命名引入（当然可以使用 <code>import a as b from &#39;./module&#39;</code> 来修改名称）</p>
<p>举例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 定义时导出</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> a = <span class="string">&#x27;a&#x27;</span>, b = <span class="string">&#x27;b&#x27;</span>; <span class="comment">// 适用于 var, let</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">function</span> <span class="title function_">a</span>(<span class="params"></span>)&#123;&#125;;</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">class</span> <span class="title class_">a</span>&#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义后导出</span></span><br><span class="line"><span class="keyword">const</span> a = <span class="string">&#x27;a&#x27;</span>, b = <span class="string">&#x27;b&#x27;</span>;</span><br><span class="line"><span class="keyword">export</span> &#123;a, b <span class="keyword">as</span> newB&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 导出其他模块的导出。</span></span><br><span class="line"><span class="comment">// 此时仅会导出 otherModule 的命名导出，所以这里最终导出的还是有命名的</span></span><br><span class="line"><span class="keyword">export</span> * <span class="keyword">from</span> <span class="string">&#x27;otherModule&#x27;</span>;</span><br><span class="line"><span class="keyword">export</span> &#123;a, b <span class="keyword">as</span> newB&#125; <span class="keyword">from</span> <span class="string">&#x27;otherModule&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果需要导出 otherModule 的默认导出，只能这样写：</span></span><br><span class="line"><span class="keyword">import</span> defaultExport <span class="keyword">from</span> <span class="string">&#x27;otherModule&#x27;</span>;</span><br><span class="line"><span class="keyword">export</span> [<span class="keyword">default</span>] defaultExport;</span><br></pre></td></tr></table></figure>

<h1 id="2-默认导出"><a href="#2-默认导出" class="headerlink" title="2. 默认导出"></a>2. 默认导出</h1><p>默认导出（<code>export default</code>）的函数、类可以认为没有固定名称，即 import 时，可以用任何名称导入</p>
<p>一个 module 中只能有一个默认导出。</p>
<p><code>export default</code> 后不能跟 <code>const</code>, <code>let</code>, <code>var</code></p>
<p>举例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 默认导出函数（定义时）</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span>(<span class="params"></span>)&#123;&#125;</span><br><span class="line"><span class="keyword">import</span> myname <span class="keyword">from</span> <span class="string">&#x27;module&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">funcName</span>(<span class="params"></span>)&#123;&#125;</span><br><span class="line"><span class="keyword">import</span> funcNameMy <span class="keyword">from</span> <span class="string">&#x27;module2&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认导出类（定义时）</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">className</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认导出 expression</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> a = <span class="string">&#x27;a&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认导出（定义后）</span></span><br><span class="line"><span class="keyword">export</span> &#123;a <span class="keyword">as</span> <span class="keyword">default</span>, b, c <span class="keyword">as</span> newC&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>js global namespace</title>
    <url>/2018/06/21/js-global-namespace/</url>
    <content><![CDATA[<ol>
<li>最基本的js写法是：不管是要调用项目内或项目外的其他文件的方法，都是直接在当前文件中调用，然后在web文件（html）中利用 <code>&lt;script&gt;</code> 按依赖顺序引入所有的内部和外部文件。<ul>
<li>即每个js中声明的变量都是全局变量。js采用{}来定义变量生命周期（或者说namespace），除了被｛｝所包围的其余变量都是全局变量。有个god object即window－－－全局对象，所有的变量、函数都是这个god object的member－－－全局变量。</li>
<li>利用 <code>&lt;script&gt;</code> 引入所有js，效果类似于将所有文件的内容组装到一个大文件运行。因此声明顺序受依赖关系约束。</li>
<li>即browser运行每个html时，它始终是将这个html中的所有script作为一个文件来运行。即browser是个解释执行器，它总是执行一个文件。而不同于后端（例如java 的jre）的编译运行，</li>
</ul>
</li>
<li>前后端的区别：<ul>
<li>browser是解释执行器，而js不提供import机制，所以只能人工解决依赖确定关系－－－需要提供一种机制来解决这中依赖确定关系</li>
<li>后端执行是通过server来执行的，服务器会下载所需lib存放到服务器容器中，运行是直接从容器拿。而前端执行是通过browser来执行，每次执行js browser都需要下载依赖的各种js文件，然后将这些文件组合成一个来运行。当然有jquery之类的会利用缓存使得不需要每次执行都下载，然而这依然不是一个最佳解决方案－－－需要提供一种机制来解决依赖下载和组装。</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>前端</th>
<th>后端</th>
</tr>
</thead>
<tbody><tr>
<td>开发生命周期</td>
<td>1. code<br> 2. 简单组合所有文件<br> 3. 解释一行为可执行码－－即时性<br> 4. 执行一行</td>
<td>1. code（提供import）<br> 2. 编译：确定依赖关系，据此依次编译各个文件为汇编码／机器码（其中有预编译、预处理等步骤）<br> 3. 连接：将外部函数代码添加到上述文件中，组合成一个完整可执行文件。<br> 4. 运行整个文件</td>
</tr>
</tbody></table>
]]></content>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s general</title>
    <url>/2019/03/01/k8s/</url>
    <content><![CDATA[<p><a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">k8s</a> is a platform to manage containerized workloads and services.</p>
<h1 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h1><h2 id="kubernetes-Objects"><a href="#kubernetes-Objects" class="headerlink" title="kubernetes Objects"></a>kubernetes Objects</h2><ol>
<li>Kubernetes abstract <strong>a desired state of cluster</strong> as objects.</li>
<li>an object configuration includes:<ol>
<li>spec: describe the desired state<ol>
<li>apiVersion: the api version of kubernetes</li>
<li>metadata: the name &amp; namespace</li>
<li>spec: the desired state definition.</li>
</ol>
</li>
<li>status: describe the actual state of the object</li>
</ol>
</li>
<li>cluster state (<a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/">understanding kubernetes objects</a>):<ol>
<li>what containerized applications are running and where they’re running</li>
<li>how many resources (disk, network, etc.) are attached to the the container</li>
<li>the policies around how the application behaves, such as restart policies, fault-tolerance, etc.</li>
</ol>
</li>
</ol>
<h3 id="Workloads"><a href="#Workloads" class="headerlink" title="Workloads"></a>Workloads</h3><p>Objects that set deployment rules of pods.</p>
<p>All controllers are workloads.</p>
<h3 id="POD"><a href="#POD" class="headerlink" title="POD"></a>POD</h3><p><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">pod</a> is <strong>a minimize runnable object</strong> in k8s object model.</p>
<p>A Pod encapsulates an application <em>container</em> (or, in some cases, multiple containers), <em>storage resources</em>, <em>a unique network IP</em>, and <em>options that govern how the container(s) should run.</em></p>
<p>It represents <strong>a single instances of application</strong>.</p>
<p>There’re two common use cases:</p>
<ul>
<li><strong>Pods that run a single container</strong>, which is the most case. So often pod is a synomynous with container.</li>
<li><strong>Pods that run multiple containers that need to work together.</strong> All the containers in a pod share the storage &amp; network, which means they use the same ip and same storage volume.</li>
</ul>
<h4 id="Pod-lifecycle"><a href="#Pod-lifecycle" class="headerlink" title="Pod lifecycle"></a>Pod lifecycle</h4><p><strong>A pod doesn’t self-heal &amp; self-scale</strong>. It’s just a running instance. It stopped &amp; deleted when the process is finished, or the node is failed, or the resource is exhaused… Controllers (eg. deployment, statefulSet…) instead can create and manage multiple pods.</p>
<p>Pod restarting is different from container restarting. <strong>Pod provides the env for containers: os, storage, network…</strong></p>
<h3 id="Controllers"><a href="#Controllers" class="headerlink" title="Controllers"></a>Controllers</h3><p>Controllers (eg. deployment, statefulSet…) instead can create and manage multiple pods.</p>
<h3 id="StatefulSet"><a href="#StatefulSet" class="headerlink" title="StatefulSet????"></a>StatefulSet????</h3><p>When using a Kubernetes StatefulSet, each pod in the StatefulSet is typically assigned its own unique and stable hostname and ordinal index. This allows each pod to have its own identity and ensures that the pods maintain a predictable and consistent network identity across restarts or rescheduling.</p>
<p>By default, each pod in a StatefulSet is provisioned with its own volume(s), which can be backed by physical storage or cloud-based storage solutions. This ensures data isolation and allows each pod to have its own storage space.</p>
<p>However, it is possible to configure a StatefulSet to use shared storage among its pods. This can be achieved by using a shared network file system (NFS) or a distributed file system (such as CephFS or GlusterFS) as the underlying storage solution. With this configuration, all pods in the StatefulSet can mount the same shared storage, allowing them to access and share data stored within that storage.</p>
<p>To achieve shared storage with StatefulSet, you would need to configure the appropriate volume and volume mount settings in the StatefulSet’s pod template specification. The specific configuration details depend on the storage solution you are using.</p>
<p>It’s important to note that while sharing storage among pods can provide benefits like data sharing and consistency, it may introduce potential performance and scalability considerations. It’s recommended to carefully evaluate your requirements and choose the appropriate storage solution based on your specific use case.</p>
<h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><p>Service is an <strong>abstraction</strong> which defines <strong>a logical set of pods</strong>, and <strong>a policy by which to access the pods</strong>.</p>
<p>It enables <strong>the decoupling of access &amp; the real pods</strong>, which means you can access by service name&#x2F;ip rather than the pod ip, while <strong>pod ip is not stable</strong>.</p>
<blockquote>
<p>Q: How does k8s get all pod endpoints by service?</p>
<p>A: By <code>LabelSelector</code>. You can define labels for each pod. And we define <code>LabelSelector</code> in service, so that k8s can search pod node by label first, and then using the <code>targetPort</code> to locate the pod on node.</p>
</blockquote>
<h3 id="Secrets"><a href="#Secrets" class="headerlink" title="Secrets???"></a>Secrets???</h3><p>In Kubernetes (k8s), a secret is an API object used to store sensitive data such as passwords, API keys, and TLS certificates. Secrets are typically used to securely provide this sensitive information to applications running within Kubernetes pods.</p>
<p>Kubernetes supports different types of secrets, each designed for specific use cases. Here are a few examples:</p>
<ol>
<li>Opaque: The most commonly used secret type in Kubernetes. It stores arbitrary key-value pairs as Base64-encoded strings. These secrets are useful for storing generic sensitive data.</li>
</ol>
<p>Example:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-secret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">dXNlcm5hbWU=</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">cGFzc3dvcmQ=</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>TLS: Specifically used for storing TLS certificates and private keys. This type of secret is often used for securing HTTPS connections.</li>
</ol>
<p>Example:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tls-secret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">kubernetes.io/tls</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">tls.crt:</span> <span class="string">&lt;Base64-encoded</span> <span class="string">TLS</span> <span class="string">certificate&gt;</span></span><br><span class="line">  <span class="attr">tls.key:</span> <span class="string">&lt;Base64-encoded</span> <span class="string">private</span> <span class="string">key&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Docker-registry: Used to store authentication information for private Docker registries.</li>
</ol>
<p>Example:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">reg-cred</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">kubernetes.io/dockerconfigjson</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="string">.dockerconfigjson:</span> <span class="string">&lt;Base64-encoded</span> <span class="string">Docker</span> <span class="string">registry</span> <span class="string">credentials&gt;</span></span><br></pre></td></tr></table></figure>

<p>These are just a few examples of secret types in Kubernetes. Secrets allow you to securely manage sensitive information and provide it to your applications when needed.</p>
<p>By default, <code>echo</code> command adds a newline character at the end of the output. The <code>-n</code> option prevents <code>echo</code> from appending the newline, ensuring that only the encoded string is printed without any additional characters.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo -n &quot;test&quot; | base64</span><br><span class="line">dGVzdA==</span><br></pre></td></tr></table></figure>

<h2 id="kubernetes-control-plane"><a href="#kubernetes-control-plane" class="headerlink" title="kubernetes control plane"></a>kubernetes control plane</h2><ol>
<li>the control plane <strong>manage the cluster state to match the desired state of objects</strong></li>
<li>the control plane consists of a collection of processes for the above intention.<ol>
<li>kubernetes master:<ol>
<li>is responsible for the maintaining the desired state.</li>
<li>“master” in fact refers to three processes: <a href="https://kubernetes.io/docs/admin/kube-apiserver/">kube-apiserver</a>, <a href="https://kubernetes.io/docs/admin/kube-controller-manager/">kube-controller-manager</a> and <a href="https://kubernetes.io/docs/admin/kube-scheduler/">kube-scheduler</a>.</li>
<li>these three processes are typically run on single node in the cluster. This node is called “master”, too. The master can also be replicated for avaibility and redundancy.</li>
</ol>
</li>
<li>kubernetes nodes:<ol>
<li>the nodes to run applications.</li>
<li>there’re two process in each node:<ol>
<li>kubelet: communicate with the master</li>
<li>kube-proxy: a network proxy.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="kubernetes-api"><a href="#kubernetes-api" class="headerlink" title="kubernetes api"></a>kubernetes api</h1><p>The <strong>api</strong> communicates with master to operate on kubernetes objects.</p>
<p><strong>kubectl</strong> is a cli to implement the above intention. It in fact calls the api internally.</p>
<p>All kinds of <strong>sdk</strong> (java, python…) encapsulate the api, too.</p>
<p>There are two kinds of api groups:</p>
<ol>
<li>core groups: the original k8s api</li>
<li>other groups: other api to extend the core group, like you may want to abstract more objects?</li>
</ol>
<h1 id="Access-services-on-cluster"><a href="#Access-services-on-cluster" class="headerlink" title="Access services on cluster"></a>Access services on cluster</h1><p>There are several levels.</p>
<p>ip:</p>
<ul>
<li>pod ip: </li>
<li>cluster ip: the virtual ip for a service</li>
<li>node ip</li>
</ul>
<h2 id="In-pod-access"><a href="#In-pod-access" class="headerlink" title="In-pod access"></a>In-pod access</h2><p><strong>Each pod has a unique IP</strong>.  And all <strong>containers in a pod share the ip</strong>, which means that they can access each other by <code>localhost</code></p>
<h2 id="In-cluster-access"><a href="#In-cluster-access" class="headerlink" title="In-cluster access"></a>In-cluster access</h2><p>By default, a service can be accessed by other pods in the same cluster, through:</p>
<h4 id="cluster-ip-port"><a href="#cluster-ip-port" class="headerlink" title="cluster-ip:port"></a>cluster-ip:port</h4><ul>
<li>cluster ip is the virtual ip of a service</li>
<li>port is is the node port of the service.</li>
</ul>
<p>Every node on k8s has a <code>kube-proxy</code>. It installs iptable rules which keep a simple record of (servicename:clusterip:serviceport).</p>
<p>In some node:</p>
<ol>
<li>call cluster-ip:port————— <strong>In a pod</strong></li>
<li>the kube-proxy search the iptable, and get some info.———— <strong>pod &#x3D;&gt; kube-proxy of node where the pod resides.</strong></li>
<li>the kube-proxy using the info to ask master for the real endpoints.—— <strong>kube-proxy of node &#x3D;&gt; master kube-api</strong></li>
<li>the kube-proxy chooses a endpoint by <code>SessionAffinity</code> defined in service (round-robin by default) —— <strong>in kube-proxy</strong></li>
<li>the kube-proxy redirect request to <code>pod-ip:podPort</code> —— <strong>kube-proxy &#x3D;&gt; pod endpoint</strong></li>
</ol>
<p>kube-proxy: enables the Kubernetes service abstraction by maintaining network rules on the host and performing connection forwarding</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/e351b830334b8622a700a8da6568cb081c464a9b/13020/images/docs/services-userspace-overview.svg" alt="proxy-mode:user space"></p>
<h4 id="servicename-namespacename"><a href="#servicename-namespacename" class="headerlink" title="servicename.namespacename"></a>servicename.namespacename</h4><p>When accessing by service name, there’re two ways:</p>
<h5 id="environement-viaribles"><a href="#environement-viaribles" class="headerlink" title="environement viaribles"></a>environement viaribles</h5><p>when create a service, k8s will create some env for each serivce, e.g. <code>&#123;SVCNAME_CAPTIPAL&#125;_SERVICE_HOST</code>. So the kube-proxy in fact gets the service cluster ip from these envs first. When a pod calls a service, t<strong>he service must be created before the pod</strong> so that the envs are created.</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># the cluster ip</span></span><br><span class="line"><span class="attr">REDIS_MASTER_SERVICE_HOST</span>=<span class="string">10.0.0.11</span></span><br><span class="line"><span class="attr">REDIS_MASTER_SERVICE_PORT</span>=<span class="string">6379</span></span><br><span class="line"><span class="attr">REDIS_MASTER_PORT</span>=<span class="string">tcp://10.0.0.11:6379</span></span><br><span class="line"><span class="attr">REDIS_MASTER_PORT_6379_TCP</span>=<span class="string">tcp://10.0.0.11:6379</span></span><br><span class="line"><span class="attr">REDIS_MASTER_PORT_6379_TCP_PROTO</span>=<span class="string">tcp</span></span><br><span class="line"><span class="attr">REDIS_MASTER_PORT_6379_TCP_PORT</span>=<span class="string">6379</span></span><br><span class="line"><span class="attr">REDIS_MASTER_PORT_6379_TCP_ADDR</span>=<span class="string">10.0.0.11</span></span><br></pre></td></tr></table></figure>

<h5 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h5><p><a href="https://kubernetes.io/docs/concepts/services-networking/service/#dns">DNS</a> is an add-on k8s object, which can be chosed to add to the cluster.</p>
<p>It’s an in-cluster dns, which serves DNS records for Kubernetes services.</p>
<p>It watches the k8s api for new services and create <strong>DNS SVC records</strong> for each.</p>
<p>Containers started by Kubernetes automatically include this DNS server in their DNS searches.</p>
<h2 id="between-cluster-access"><a href="#between-cluster-access" class="headerlink" title="between-cluster access"></a>between-cluster access</h2><ol>
<li>NodePort: expose nodeIP</li>
<li>LoadBalancer: expose loadbalancer ip</li>
<li>Ingress: expose loadbalancer &amp; path</li>
</ol>
<h1 id="Ingress"><a href="#Ingress" class="headerlink" title="Ingress"></a>Ingress</h1><p><a href="https://zhuanlan.zhihu.com/p/618328589">一篇搞懂 ingress</a></p>
<h2 id="what’s-ingress"><a href="#what’s-ingress" class="headerlink" title="what’s ingress"></a>what’s ingress</h2><p>Ingress is a k8s resource to route external traffic into k8x cluster services. From functionality perspective, it provides:</p>
<ol>
<li><p>load balance</p>
</li>
<li><p>routing</p>
</li>
<li><p>reverse proxy</p>
</li>
<li><p>service discovery</p>
</li>
<li><p>…</p>
</li>
</ol>
<p>It can route by http path, host name, http method, etc.</p>
<h2 id="IngressController"><a href="#IngressController" class="headerlink" title="IngressController"></a>IngressController</h2><p>However, Ingress itself is just a definition. IngressController is the one to really routing, load-balancing, and so on. IngressController config the load balancer etc. based on the ingress resource. And it routes based on the rules defined in ingress.</p>
<p>IngressController is an independent component. There’re many implementations. And different controller has different features, i.e. not all IngressControllers have all the above functionalities.</p>
<ul>
<li><p>nginx ingress controller: in this case, it converts the ingress object innto nginx config, and apply this config to nginx server.</p>
</li>
<li><p>traefix ingress controller</p>
</li>
<li><p>istio ingress gateway</p>
</li>
<li><p>contour ingress controller: based on Envoy proxy.</p>
</li>
<li><p>kong ingress controller: a kinds of api gateways</p>
</li>
<li><p>ambassador api gateway: k8s-native api gateway</p>
</li>
</ul>
<h2 id="expose-the-service"><a href="#expose-the-service" class="headerlink" title="expose the service"></a>expose the service</h2><p>When external user wants to access some cluser service, the entrypoint is the address of IngressController. To expose IngressController, several ways:</p>
<h3 id="1-NodePort"><a href="#1-NodePort" class="headerlink" title="1. NodePort"></a>1. NodePort</h3><p>Expose service to all nodes in cluster.</p>
<h3 id="2-HostNetwork-共享主机网络"><a href="#2-HostNetwork-共享主机网络" class="headerlink" title="2. HostNetwork(共享主机网络)"></a>2. HostNetwork(共享主机网络)</h3><p>Expose ingressController to the network namespace of  host node, so that we can access IngressController by the host ip.</p>
<h3 id="3-LoadBalancer"><a href="#3-LoadBalancer" class="headerlink" title="3. LoadBalancer"></a>3. LoadBalancer</h3><p>Expose IngressController to the LB, and then access through LB</p>
<h3 id="4-ExternalIPs"><a href="#4-ExternalIPs" class="headerlink" title="4. ExternalIPs"></a>4. ExternalIPs</h3><p>Designate externalIP for ingressController, and access throught that.</p>
]]></content>
      <tags>
        <tag>container</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2021/05/17/kerberos/</url>
    <content><![CDATA[<p><a href="http://www.nosqlnotes.com/technotes/kerberos-protocol/">图解Kerberos协议原理</a></p>
<p><a href="https://xz.aliyun.com/t/8187">内网渗透之kerberos协议分析</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/96032550">kerberos 协议</a></p>
<p><a href="https://docs.cloudera.com/documentation/enterprise/5-6-x/topics/cm_sg_principal_keytab.html">Kerberos Concepts - Principals, Keytabs and Delegation Tokens</a></p>
<blockquote>
<p>A user in Kerberos is called a principal, which is made up of three distinct components: the primary, instance, and realm. A Kerberos principal is used in a Kerberos-secured system to represent a unique identity. The first component of the principal is called the primary, or sometimes the user component. The primary component is an arbitrary string and may be the operating system username of the user or the name of a service. The primary component is followed by an optional section called the instance, which is used to create principals that are used by users in special roles or to define the host on which a service runs, for example. An instance, if it exists, is separated from the primary by a slash and then the content is used to disambiguate multiple principals for a single user or service. The final component of the principal is the realm. The realm is similar to a domain in DNS in that it logically defines a related group of objects, although rather than hostnames as in DNS, the Kerberos realm defines a group of principals . Each realm can have its own settings including the location of the KDC on the network and supported encryption algorithms. Large organizations commonly create distinct realms to delegate administration of a realm to a group within the enterprise. Realms, by convention, are written in uppercase characters.</p>
</blockquote>
<p>Kerberos assigns tickets to Kerberos principals to enable them to access Kerberos-secured Hadoop services. For the Hadoop daemon principals, the principal names should be of the format service&#x2F;<a href="mailto:&#102;&#117;&#108;&#108;&#121;&#46;&#113;&#117;&#x61;&#108;&#x69;&#102;&#105;&#101;&#100;&#46;&#x64;&#111;&#109;&#97;&#105;&#x6e;&#x2e;&#110;&#x61;&#x6d;&#101;&#64;&#89;&#x4f;&#x55;&#82;&#x2d;&#82;&#69;&#x41;&#x4c;&#x4d;&#x2e;&#x43;&#x4f;&#x4d;">&#102;&#117;&#108;&#108;&#121;&#46;&#113;&#117;&#x61;&#108;&#x69;&#102;&#105;&#101;&#100;&#46;&#x64;&#111;&#109;&#97;&#105;&#x6e;&#x2e;&#110;&#x61;&#x6d;&#101;&#64;&#89;&#x4f;&#x55;&#82;&#x2d;&#82;&#69;&#x41;&#x4c;&#x4d;&#x2e;&#x43;&#x4f;&#x4d;</a>. Here, service in the service&#x2F;<a href="mailto:&#x66;&#117;&#108;&#x6c;&#x79;&#46;&#113;&#117;&#x61;&#108;&#105;&#102;&#105;&#x65;&#x64;&#x2e;&#x64;&#111;&#109;&#97;&#x69;&#x6e;&#x2e;&#x6e;&#x61;&#109;&#101;&#x40;&#89;&#79;&#85;&#82;&#45;&#x52;&#69;&#x41;&#x4c;&#x4d;&#46;&#x43;&#x4f;&#x4d;">&#x66;&#117;&#108;&#x6c;&#x79;&#46;&#113;&#117;&#x61;&#108;&#105;&#102;&#105;&#x65;&#x64;&#x2e;&#x64;&#111;&#109;&#97;&#x69;&#x6e;&#x2e;&#x6e;&#x61;&#109;&#101;&#x40;&#89;&#79;&#85;&#82;&#45;&#x52;&#69;&#x41;&#x4c;&#x4d;&#46;&#x43;&#x4f;&#x4d;</a> principal refers to the username of an existing Unix account that is use    d by Hadoop daemons, such as hdfs or mapred.</p>
<blockquote>
</blockquote>
<p>Human users who want to access the Hadoop cluster also need to have Kerberos principals of the format, <a href="mailto:&#x75;&#115;&#x65;&#114;&#x6e;&#x61;&#x6d;&#101;&#x40;&#89;&#79;&#x55;&#x52;&#x2d;&#82;&#x45;&#x41;&#x4c;&#x4d;&#x2e;&#x43;&#79;&#x4d;">&#x75;&#115;&#x65;&#114;&#x6e;&#x61;&#x6d;&#101;&#x40;&#89;&#79;&#x55;&#x52;&#x2d;&#82;&#x45;&#x41;&#x4c;&#x4d;&#x2e;&#x43;&#79;&#x4d;</a>; in this case, username refers to the username of the user’s Unix account, such as joe or jane. Single-component principal names (such as <a href="mailto:&#x6a;&#x6f;&#x65;&#64;&#x59;&#79;&#x55;&#x52;&#45;&#x52;&#x45;&#65;&#x4c;&#77;&#x2e;&#67;&#79;&#x4d;">&#x6a;&#x6f;&#x65;&#64;&#x59;&#79;&#x55;&#x52;&#45;&#x52;&#x45;&#65;&#x4c;&#77;&#x2e;&#67;&#79;&#x4d;</a>) are typical for client user accounts. Hadoop does not support more than two-component principal names.</p>
<p>TGT类似于护照，Ticket则是签证，而访问特定的服务则好比出游某个国家。与护照一样，TGT可标识你的身份并允许你获得多个Ticket（签证），每个Ticket对应一个特定的服务，TGT和Ticket同样具有有效期，过期后就需要重新认证。</p>
<h1 id="impersonate"><a href="#impersonate" class="headerlink" title="impersonate"></a>impersonate</h1><p>[secure impersonate](<a href="http://hadoop.apache.org/docs/r1.2.1/Secure_Impersonation.html">http://hadoop.apache.org/docs/r1.2.1/Secure_Impersonation.html</a></p>
<p><a href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/Superusers.html#Configurations">proxy user</a></p>
<h1 id="kerberos-常用命令"><a href="#kerberos-常用命令" class="headerlink" title="kerberos 常用命令"></a>kerberos 常用命令</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入kerberos控制台</span></span><br><span class="line">kadmin.local</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加用户，增加实例 add_principal, addprinc, ank</span></span><br><span class="line">addprinc -randkey xxxx@xxxxT.COM</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">为实例生成秘钥</span></span><br><span class="line">xst -k xxxx.keytab xxxx@xxxxT.COM</span><br><span class="line">或</span><br><span class="line">kadmin.local -q &quot;xst -k xxxx.keytab xxxx@xxxxT.COM&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">合并hadoop.keytab和HTTP.keytab为hdfs.keytab</span></span><br><span class="line">ktutil</span><br><span class="line">rkt hadoop.keytab</span><br><span class="line">rkt HTTP.keytab</span><br><span class="line">wkt hdfs.keytab</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看keytab文件</span></span><br><span class="line">klist -ket /etc/krb5.keytab</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">删除用户 delete_principal, delprinc</span></span><br><span class="line">delprinc xxxx@xxxxT.COM</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改用户密码 change_password, cpw</span></span><br><span class="line">cpw xxxx@xxxxT.COM</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看所有用户 list_principals, listprincs, get_principals, getprincs</span></span><br><span class="line">listprincs</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">修改票据属性 modify_principal, modprinc</span></span><br><span class="line">modprinc -maxrenewlife 1week  可在一周内renew</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看票据信息 get_principal, getprinc</span></span><br><span class="line">getprinc xxxx@xxxxT.COM</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">导出keytab文件 ktadd, xst</span></span><br><span class="line"> xst -e aes128-cts-hmac-sha1-96:normal -k /home/dengsc/dengsc.keytab dengsc@XXXX.COM</span><br><span class="line">        -e 执定加密方式</span><br><span class="line">        -k 指定keytab文件名</span><br><span class="line">        注:导出keytab文件时会重新生成密码.</span><br><span class="line">            kadmin.local模式下可添加参数‘-norandkey’,导出keytab文件时不重置密码.</span><br><span class="line">            egg: xst -norandkey -k /home/dengsc/dengsc.keytab</span><br></pre></td></tr></table></figure>

<h1 id="SSL-证书"><a href="#SSL-证书" class="headerlink" title="SSL 证书"></a>SSL 证书</h1><h2 id="Keystore-常用命令"><a href="#Keystore-常用命令" class="headerlink" title="Keystore 常用命令"></a>Keystore 常用命令</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成jks</span></span><br><span class="line">keytool -genkeypair -<span class="built_in">alias</span> prestoservernew -keyalg RSA -keystore presto_keystore_new.jks</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出cer证书</span></span><br><span class="line">keytool -keystore /javahome/jre/lib/security/presto_keystore_new.jks -<span class="built_in">export</span> -<span class="built_in">alias</span> prestoservernew -file /tmp/prestoservernew.cer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入证书到truststore</span></span><br><span class="line">keytool -import -keystore /javahome/jre/lib/security/cacerts -trustcacerts -<span class="built_in">alias</span> prestoservernew -file /tmp/prestoservernew.cer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除信任证书</span></span><br><span class="line">keytool -delete -<span class="built_in">alias</span> prestoservernew -keystore  /javahome/jre/lib/security/cacerts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#检查导入成功：</span></span><br><span class="line">keytool  \</span><br><span class="line">-keystore /javahome/jre/lib/security/cacerts  \</span><br><span class="line">-storepass changeit \</span><br><span class="line">-list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除</span></span><br><span class="line">keytool -delete -<span class="built_in">alias</span> ldapservern2 -keystore  /javahome/jre/lib/security/cacerts</span><br><span class="line"><span class="comment">#changeit</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看证书</span></span><br><span class="line">ubuntu@prestoserver:~/data/presto-server-0.215/etc$ keytool -printcert -v -file   /javahome/jre/lib/security/dc.cer</span><br><span class="line">Owner: CN=al.al.com</span><br><span class="line">Issuer: CN=al-AL-CA-1, DC=al, DC=com</span><br></pre></td></tr></table></figure>

<h2 id="cer-vs-crt"><a href="#cer-vs-crt" class="headerlink" title=".cer vs .crt"></a>.cer vs .crt</h2><p><a href="https://stackoverflow.com/questions/642284/do-i-need-to-convert-cer-to-crt-for-apache-ssl-certificates-if-so-how">Do I need to convert .CER to .CRT for Apache SSL certificates? If so, how?</a></p>
<p><strong>CER</strong> is an X.509 certificate in binary form, <strong>DER</strong> encoded.<br><strong>CRT</strong> is a binary X.509 certificate, encapsulated in text (<strong>base-64</strong>) encoding.</p>
<p>可以互相转：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">When <span class="built_in">type</span> DER returns an error loading certificate (asn1 encoding routines), try the PEM and it shall work.</span></span><br><span class="line">openssl x509 -inform DER -in certificate.cer -out certificate.crt</span><br><span class="line">openssl x509 -inform PEM -in certificate.cer -out certificate.crt</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">pem</span></span><br><span class="line">openssl x509 -inform DER -in certificate.cer -out certificate.pem</span><br></pre></td></tr></table></figure>

<blockquote>
<p>File extensions for cryptographic certificates aren’t really as standardized as you’d expect. Windows by default treats double-clicking a <code>.crt</code> file as a request to import the certificate into the Windows Root Certificate store, but treats a <code>.cer</code> file as a request just to view the certificate. So, they’re different in the sense that Windows has some inherent different meaning for what happens when you double click each type of file.</p>
</blockquote>
<p>But the way that Windows handles them when you double-click them is about the only difference between the two. Both extensions just represent that it contains a public certificate. You can rename a certificate file to use one extension in place of the other in any system or configuration file that I’ve seen. And on non-Windows platforms (and even on Windows), people aren’t particularly careful about which extension they use, and treat them both interchangeably, as there’s no difference between them as long as the contents of the file are correct.</p>
<blockquote>
</blockquote>
<p>Making things more confusing is that there are two standard ways of storing certificate data in a file: One is a “binary” X.509 encoding, and the other is a “text” base64 encoding that usually starts with “<code>-----BEGIN CERTIFICATE-----</code>“. These encode the same data but in different ways. Most systems accept both formats, but, if you need to, you can convert one to the other via openssl or other tools. The encoding within a certificate file is really independent of which extension somebody gave the file.</p>
<h3 id="默认的-certificate-目录"><a href="#默认的-certificate-目录" class="headerlink" title="默认的 certificate 目录"></a>默认的 certificate 目录</h3><p>下边这条命令可以打出目录，这里都是 symbolic link，继续追踪，可以看到文件最终是存放在  <code>/etc/pki/ca-trust/extracted</code>，但是这个文件夹的内容是自动生成的（可以查看该文件夹下的 README）。当执行 <code>update-ca-trust</code> 命令时，会根据 <code>/usr/share/pki/ca-trust-source/</code> and <code>/etc/pki/ca-trust/source/</code> 自动生成 <code>extracted</code> 目录。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python3 -c <span class="string">&quot;import ssl; print(ssl.get_default_verify_paths())&quot;</span></span></span><br><span class="line">DefaultVerifyPaths(cafile=&#x27;/etc/pki/tls/cert.pem&#x27;, capath=&#x27;/etc/pki/tls/certs&#x27;, openssl_cafile_env=&#x27;SSL_CERT_FILE&#x27;, openssl_cafile=&#x27;/etc/pki/tls/cert.pem&#x27;, openssl_capath_env=&#x27;SSL_CERT_DIR&#x27;, openssl_capath=&#x27;/etc/pki/tls/certs&#x27;)</span><br></pre></td></tr></table></figure>

<p>如果需要修改证书，可以使用 <a href="https://www.linux.org/docs/man8/update-ca-trust.html">update-ca-trust</a> 命令。</p>
]]></content>
      <tags>
        <tag>hadoop</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title>linux commands</title>
    <url>/2019/01/23/linux-command/</url>
    <content><![CDATA[<h1 id="chmod-chown"><a href="#chmod-chown" class="headerlink" title="chmod, chown"></a>chmod, chown</h1><p><a href="https://www.linux.com/learn/understanding-linux-file-permissions">understanding linux file permissions</a></p>
<p>File permissions are defined by <strong>permission group</strong> and <strong>permission type</strong></p>
<ol>
<li>permission group<ul>
<li>owner(u)</li>
<li>group(g)</li>
<li>all other users(a)</li>
</ul>
</li>
<li>permission type<ul>
<li>read (r - 4)</li>
<li>write(w - 2)</li>
<li>execute(x - 1)</li>
</ul>
</li>
</ol>
<h2 id="permission-presentation"><a href="#permission-presentation" class="headerlink" title="permission presentation"></a>permission presentation</h2><p>The permission in the command line is displayed as <em><strong>_rwxrwxrwx 1 owner:group</strong></em></p>
<ul>
<li>the first character (underscore <strong>_</strong>  here) is the <strong>special permission flag</strong> that can vary.</li>
<li>the following three groups of <em><strong>rwx</strong></em> represent <strong>permission of owner, group and all other users</strong> respectively. If the owner and all users has no read permission, it is <em><strong>__wxrwx_wx</strong></em></li>
<li>follwing that grouping since the integer displays <strong>the number of hardlinks to the file</strong></li>
<li>the last piece is the owner and group assignment.</li>
</ul>
<h3 id="special-permission-flag"><a href="#special-permission-flag" class="headerlink" title="special permission flag"></a>special permission flag</h3><p>The special permission flag can be:</p>
<ul>
<li><strong>_</strong>: no special permissions</li>
<li><em><strong>d</strong></em>: directory</li>
<li><em><strong>l</strong></em>: the file or dir is a symbolic link</li>
<li><em><strong>s</strong></em>: This indicated the setuid&#x2F;setgid permissions. This is not set displayed in the special permission part of the permissions display, but is represented as a <strong>s</strong> in the read portion of the owner or group permissions.</li>
<li><em><strong>t</strong></em>: This indicates the sticky bit permissions. This is not set displayed in the special permission part of the permissions display, but is represented as a <strong>t</strong> in the executable portion of the all users permissions</li>
</ul>
<h2 id="permission-modification"><a href="#permission-modification" class="headerlink" title="permission modification"></a>permission modification</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># grant read and write permissions to the user and group</span></span><br><span class="line">$ <span class="built_in">chmod</span> ug+rw file1</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove read and write permissions to the user and group</span></span><br><span class="line">$ <span class="built_in">chmod</span> ug-rw file1</span><br><span class="line"></span><br><span class="line"><span class="comment"># set permission using binary references (owner: rwx = 4+2+1, group: rx = 4+1, all users: rx = 4+1)</span></span><br><span class="line">$ <span class="built_in">chmod</span> 755 file1</span><br><span class="line"></span><br><span class="line"><span class="comment"># change the file permission recursively in the file/dir instead of just the files themselves</span></span><br><span class="line">$ <span class="built_in">chmod</span> -R 755 dir1</span><br></pre></td></tr></table></figure>

<h2 id="change-owner-group-assignments"><a href="#change-owner-group-assignments" class="headerlink" title="change owner:group assignments"></a>change owner:group assignments</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># change the owner of file1 to user1 and group to family</span></span><br><span class="line">$ <span class="built_in">chown</span> user1:family file1</span><br></pre></td></tr></table></figure>

<h1 id="find"><a href="#find" class="headerlink" title="find"></a>find</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># find all xml files from the current dir</span></span><br><span class="line">$ find ./* -name <span class="string">&#x27;*.xml&#x27;</span></span><br></pre></td></tr></table></figure>

<p>To find all files modified in the last 24 hours (last full day) in a particular specific directory and its sub-directories:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ find /directory_path -mtime -1 -<span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<p>Should be to your liking</p>
<p>The <code>-</code> before <code>1</code> is important - it means anything changed one day or less ago. A <code>+</code> before <code>1</code> would instead mean anything changed at least one day ago, while having nothing before the <code>1</code> would have meant it was changed exacted one day ago, no more, no less.</p>
<p>Another, more humane way:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /&lt;directory&gt; -newermt <span class="string">&quot;-24 hours&quot;</span> -<span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<p>or:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /&lt;directory&gt; -newermt <span class="string">&quot;1 day ago&quot;</span> -<span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<p>or:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">find /&lt;directory&gt; -newermt <span class="string">&quot;yesterday&quot;</span> -<span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h1 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h1><p>找到文件并删除</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /home/raven -name abc.txt | xargs rm -rf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">不使用 xargs</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list file with creation date and sort by it</span></span><br><span class="line">$ <span class="built_in">ls</span> -lct</span><br></pre></td></tr></table></figure>

<h1 id="du"><a href="#du" class="headerlink" title="du"></a>du</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">du</span> -sh -- * | <span class="built_in">sort</span> -hr</span><br></pre></td></tr></table></figure>

<h1 id="List-users"><a href="#List-users" class="headerlink" title="List users"></a>List users</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cat</span> /etc/passwd | <span class="built_in">cut</span> -d: -f1</span><br></pre></td></tr></table></figure>

<h1 id="pbcopy"><a href="#pbcopy" class="headerlink" title="pbcopy"></a>pbcopy</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># copy file content to clipboard</span></span><br><span class="line">$ pbcopy &lt; test.txt</span><br></pre></td></tr></table></figure>

<h1 id="dstat"><a href="#dstat" class="headerlink" title="dstat"></a>dstat</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ dstat -t -a --tcp --output network.log</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>lombok</title>
    <url>/2019/01/17/lombok/</url>
    <content><![CDATA[<p><a href="https://projectlombok.org/">lombok</a> is a library to help your <strong>write java cleaner and more efficiently</strong>. It’s plugged into the editor and build tool, which works <strong>at compile time</strong>. </p>
<p>Essentially, it modifies the byte-codes by operating AST (abstract semantic tree) at compile time, which is allowed by javac. This is, in fact, a way to modify java grammar.</p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>To use it,</p>
<ol>
<li>install lombok plugin in intellij</li>
<li>add package dependency in project (to use its annotations)</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.16.18<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>See <a href="https://projectlombok.org/features/all">all the annotations</a>. Give some example here:</p>
<h3 id="Data"><a href="#Data" class="headerlink" title="@Data"></a>@Data</h3><p><a href="https://projectlombok.org/features/Data"><code>@Data</code></a> bundles the features of   <a href="https://projectlombok.org/features/ToString"><code>@ToString</code></a>, <a href="https://projectlombok.org/features/EqualsAndHashCode"><code>@EqualsAndHashCode</code></a>, <a href="https://projectlombok.org/features/GetterSetter"><code>@Getter</code> &#x2F; <code>@Setter</code></a> and <a href="https://projectlombok.org/features/constructor"><code>@RequiredArgsConstructor</code></a> together.</p>
<p><strong>With lombok:</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> lombok.AccessLevel;</span><br><span class="line"><span class="keyword">import</span> lombok.Setter;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> lombok.ToString;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span> <span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataExample</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">  <span class="meta">@Setter(AccessLevel.PACKAGE)</span> <span class="keyword">private</span> <span class="type">int</span> age;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">double</span> score;</span><br><span class="line">  <span class="keyword">private</span> String[] tags;</span><br><span class="line">  </span><br><span class="line">  <span class="meta">@ToString(includeFieldNames=true)</span></span><br><span class="line">  <span class="meta">@Data(staticConstructor=&quot;of&quot;)</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Exercise</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> T value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Vanila java:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DataExample</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> age;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">double</span> score;</span><br><span class="line">  <span class="keyword">private</span> String[] tags;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="title function_">DataExample</span><span class="params">(String name)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.name;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(<span class="type">int</span> age)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.age = age;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAge</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.age;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setScore</span><span class="params">(<span class="type">double</span> score)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.score = score;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">getScore</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.score;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> String[] getTags() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.tags;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setTags</span><span class="params">(String[] tags)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.tags = tags;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">   <span class="meta">@Override</span> <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;DataExample(&quot;</span> + <span class="built_in">this</span>.getName() + <span class="string">&quot;, &quot;</span> + <span class="built_in">this</span>.getAge() + <span class="string">&quot;, &quot;</span> + <span class="built_in">this</span>.getScore() + <span class="string">&quot;, &quot;</span> + Arrays.deepToString(<span class="built_in">this</span>.getTags()) + <span class="string">&quot;)&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">canEqual</span><span class="params">(Object other)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> other <span class="keyword">instanceof</span> DataExample;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Override</span> <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="built_in">this</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span> (!(o <span class="keyword">instanceof</span> DataExample)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="type">DataExample</span> <span class="variable">other</span> <span class="operator">=</span> (DataExample) o;</span><br><span class="line">    <span class="keyword">if</span> (!other.canEqual((Object)<span class="built_in">this</span>)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">this</span>.getName() == <span class="literal">null</span> ? other.getName() != <span class="literal">null</span> : !<span class="built_in">this</span>.getName().equals(other.getName())) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">this</span>.getAge() != other.getAge()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (Double.compare(<span class="built_in">this</span>.getScore(), other.getScore()) != <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (!Arrays.deepEquals(<span class="built_in">this</span>.getTags(), other.getTags())) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Override</span> <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">int</span> <span class="variable">PRIME</span> <span class="operator">=</span> <span class="number">59</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">long</span> <span class="variable">temp1</span> <span class="operator">=</span> Double.doubleToLongBits(<span class="built_in">this</span>.getScore());</span><br><span class="line">    result = (result*PRIME) + (<span class="built_in">this</span>.getName() == <span class="literal">null</span> ? <span class="number">43</span> : <span class="built_in">this</span>.getName().hashCode());</span><br><span class="line">    result = (result*PRIME) + <span class="built_in">this</span>.getAge();</span><br><span class="line">    result = (result*PRIME) + (<span class="type">int</span>)(temp1 ^ (temp1 &gt;&gt;&gt; <span class="number">32</span>));</span><br><span class="line">    result = (result*PRIME) + Arrays.deepHashCode(<span class="built_in">this</span>.getTags());</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Exercise</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> T value;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Exercise</span><span class="params">(String name, T value)</span> &#123;</span><br><span class="line">      <span class="built_in">this</span>.name = name;</span><br><span class="line">      <span class="built_in">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; Exercise&lt;T&gt; <span class="title function_">of</span><span class="params">(String name, T value)</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Exercise</span>&lt;T&gt;(name, value);</span><br><span class="line">      &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> T <span class="title function_">getValue</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>.value;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span> <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="string">&quot;Exercise(name=&quot;</span> + <span class="built_in">this</span>.getName() + <span class="string">&quot;, value=&quot;</span> + <span class="built_in">this</span>.getValue() + <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">canEqual</span><span class="params">(Object other)</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> other <span class="keyword">instanceof</span> Exercise;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span> <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (o == <span class="built_in">this</span>) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">      <span class="keyword">if</span> (!(o <span class="keyword">instanceof</span> Exercise)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">      Exercise&lt;?&gt; other = (Exercise&lt;?&gt;) o;</span><br><span class="line">      <span class="keyword">if</span> (!other.canEqual((Object)<span class="built_in">this</span>)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">this</span>.getName() == <span class="literal">null</span> ? other.getValue() != <span class="literal">null</span> : !<span class="built_in">this</span>.getName().equals(other.getName())) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">this</span>.getValue() == <span class="literal">null</span> ? other.getValue() != <span class="literal">null</span> : !<span class="built_in">this</span>.getValue().equals(other.getValue())) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span> <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">final</span> <span class="type">int</span> <span class="variable">PRIME</span> <span class="operator">=</span> <span class="number">59</span>;</span><br><span class="line">      <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">      result = (result*PRIME) + (<span class="built_in">this</span>.getName() == <span class="literal">null</span> ? <span class="number">43</span> : <span class="built_in">this</span>.getName().hashCode());</span><br><span class="line">      result = (result*PRIME) + (<span class="built_in">this</span>.getValue() == <span class="literal">null</span> ? <span class="number">43</span> : <span class="built_in">this</span>.getValue().hashCode());</span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>mime type</title>
    <url>/2018/07/26/mime-type/</url>
    <content><![CDATA[<p>[MIME 类型](MIME 类型) 是用一种标准化的方式来表示文档的性质和格式。浏览器一般通过 MIME 类型（而不是文档扩展名）来确定如何处理文档。因此服务器传输数据时，必须设置正确的 MIME 类型。</p>
<h1 id="通用结构"><a href="#通用结构" class="headerlink" title="通用结构"></a>通用结构</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">type/subtype</span><br></pre></td></tr></table></figure>

<ol>
<li>不允许空格</li>
<li>大小写不敏感，一般都是小写</li>
</ol>
<h1 id="独立类型"><a href="#独立类型" class="headerlink" title="独立类型"></a>独立类型</h1><p>type 可以是独立类型，表示文件的分类，可以是如下值：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>描述</th>
<th>典型示例</th>
</tr>
</thead>
<tbody><tr>
<td><code>text</code></td>
<td>表明文件是普通文本，理论上是可读的语言</td>
<td><code>text/plain</code>, <code>text/html</code>, <code>text/css, text/javascript</code></td>
</tr>
<tr>
<td><code>image</code></td>
<td>表明是某种图像。不包括视频，但是动态图（比如动态gif）也使用image类型</td>
<td><code>image/gif</code>, <code>image/png</code>, <code>image/jpeg</code>, <code>image/bmp</code>, <code>image/webp</code></td>
</tr>
<tr>
<td><code>audio</code></td>
<td>表明是某种音频文件</td>
<td><code>audio/midi</code>, <code>audio/mpeg, audio/webm, audio/ogg, audio/wav</code></td>
</tr>
<tr>
<td><code>video</code></td>
<td>表明是某种视频文件</td>
<td><code>video/webm</code>, <code>video/ogg</code></td>
</tr>
<tr>
<td><code>application</code></td>
<td>表明是某种二进制数据</td>
<td><code>application/octet-stream</code>, <code>application/pkcs12</code>, <code>application/vnd.mspowerpoint</code>, <code>application/xhtml+xml</code>, <code>application/xml</code>,  <code>application/pdf,``application/json</code></td>
</tr>
</tbody></table>
<p>一般是文本，但是具体类型不确定时，就用 <code>test/plain</code>；是二进制数据，而类型不确定时，用 <code>application/octet-stream</code></p>
<h2 id="application-x2F-octet-stream"><a href="#application-x2F-octet-stream" class="headerlink" title="application&#x2F;octet-stream"></a>application&#x2F;octet-stream</h2><p>这是应用程序文件的默认值。意思是 <em>未知的应用程序文件 ，</em>浏览器一般不会自动执行或询问执行。浏览器会将它作为附件来处理，附件类型等信息通过HTTP头<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Disposition"><code>Content-Disposition</code></a> 设置。</p>
<h1 id="Multipart-类型"><a href="#Multipart-类型" class="headerlink" title="Multipart 类型"></a>Multipart 类型</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">multipart/form-data</span><br><span class="line">multipart/byteranges</span><br></pre></td></tr></table></figure>

<p> 顾名思义，这是复合文件的一种表现形式，即传递过来的数据有多重类型。典型的如果表单数据可能有 string、文件、视频、音频等。</p>
<p>它由边界线（一个由<code>&#39;--&#39;</code>开始的字符串）划分出的不同部分组成。每一部分有自己的实体，以及自己的 HTTP 请求头，<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Disposition"><code>Content-Disposition</code></a>和 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type"><code>Content-Type</code></a> 用于文件上传领域，最常用的 (<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Length"><code>Content-Length</code></a> 因为边界线作为分隔符而被忽略）。</p>
<p>例如，如下表单:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;http://localhost:8000/&quot;</span> <span class="attr">method</span>=<span class="string">&quot;post&quot;</span> <span class="attr">enctype</span>=<span class="string">&quot;multipart/form-data&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;myTextField&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;checkbox&quot;</span> <span class="attr">name</span>=<span class="string">&quot;myCheckBox&quot;</span>&gt;</span>Check<span class="tag">&lt;/<span class="name">input</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;file&quot;</span> <span class="attr">name</span>=<span class="string">&quot;myFile&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">button</span>&gt;</span>Send the file<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>请求是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POST / HTTP/1.1</span><br><span class="line">Host: localhost:8000</span><br><span class="line">User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0</span><br><span class="line">Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8</span><br><span class="line">Accept-Language: en-US,en;q=0.5</span><br><span class="line">Accept-Encoding: gzip, deflate</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Upgrade-Insecure-Requests: 1</span><br><span class="line">Content-Type: multipart/form-data; boundary=---------------------------8721656041911415653955004498</span><br><span class="line">Content-Length: 465</span><br><span class="line"></span><br><span class="line">-----------------------------8721656041911415653955004498</span><br><span class="line">Content-Disposition: form-data; name=&quot;myTextField&quot;</span><br><span class="line"></span><br><span class="line">Test</span><br><span class="line">-----------------------------8721656041911415653955004498</span><br><span class="line">Content-Disposition: form-data; name=&quot;myCheckBox&quot;</span><br><span class="line"></span><br><span class="line">on</span><br><span class="line">-----------------------------8721656041911415653955004498</span><br><span class="line">Content-Disposition: form-data; name=&quot;myFile&quot;; filename=&quot;test.txt&quot;</span><br><span class="line">Content-Type: text/plain</span><br><span class="line"></span><br><span class="line">Simple file.</span><br><span class="line">-----------------------------8721656041911415653955004498--</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>rest</tag>
      </tags>
  </entry>
  <entry>
    <title>mybatis 工作原理</title>
    <url>/2018/08/10/mybatis-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="几个核心类"><a href="#几个核心类" class="headerlink" title="几个核心类"></a>几个核心类</h1><p>参见:</p>
<ul>
<li><a href="http://www.mybatis.org/mybatis-3/zh/java-api.html">java api</a></li>
<li><a href="http://www.mybatis.org/mybatis-3/zh/getting-started.html">入门 - 介绍核心使用组件和最佳实践</a></li>
</ul>
<h2 id="SqlSessionFactory"><a href="#SqlSessionFactory" class="headerlink" title="SqlSessionFactory"></a>SqlSessionFactory</h2><p>mybatis 应用以一个 sqlSessionFactory 实例为核心，即一个应用中有一个<strong>单例</strong> <code>SqlSessionFactory</code>，所以数据库 session 都从这里获得。</p>
<p><code>SqlSessionFactory</code> 可以通过 <code>SqlSessionFactoryBuilder</code> 获得，builder 负责从 xml 配置或 java configuration 类获得。xml (或相应的 java configuration 类) 配置了 datasource（数据库连接信息）、mappers 等信息</p>
<h2 id="SqlSessionFactoryBuilder"><a href="#SqlSessionFactoryBuilder" class="headerlink" title="SqlSessionFactoryBuilder"></a>SqlSessionFactoryBuilder</h2><p>它主要就是用来获取 <code>SqlSessionFactory</code>，可以从 xml 或 Java Configuration 类加载配置并构建。提供如下几种方式来获取（参见<a href="http://www.mybatis.org/mybatis-3/zh/java-api.html">java api</a>）：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 从 xml 获取，其中配置了 environment，datasource，mappers  </span></span><br><span class="line">SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 xml 获取，但当 xml 配置了多个 env 中的 datasource 等时，通过 env 指定加载的环境</span></span><br><span class="line">SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream, String environment)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 xml 获取，但可以指定其中使用到的 properties(详见下文的解释)</span></span><br><span class="line">SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream, Properties properties)</span>;</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 从 xml 获取，并指定 env 和使用的 props</span></span><br><span class="line">SqlSessionFactory <span class="title function_">build</span><span class="params">(InputStream inputStream, String env, Properties props)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 Java Configuration 获取</span></span><br><span class="line">SqlSessionFactory <span class="title function_">build</span><span class="params">(Configuration config)</span></span><br></pre></td></tr></table></figure>

<p><code>SqlSessionFactoryBuilder</code> 只是为了创建 <code>SqlSessionFactory</code>，创建完成就可以丢弃 builder 了。所以一般它的生命周期是方法级，是其中的一个局部变量</p>
<h3 id="使用-xml"><a href="#使用-xml" class="headerlink" title="使用 xml"></a>使用 xml</h3><p><strong>先配置一个 <code>config.xml</code>：</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">configuration</span></span></span><br><span class="line"><span class="meta">  <span class="keyword">PUBLIC</span> <span class="string">&quot;-//mybatis.org//DTD Config 3.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">  <span class="string">&quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">environments</span> <span class="attr">default</span>=<span class="string">&quot;development&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">environment</span> <span class="attr">id</span>=<span class="string">&quot;development&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">transactionManager</span> <span class="attr">type</span>=<span class="string">&quot;JDBC&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">dataSource</span> <span class="attr">type</span>=<span class="string">&quot;POOLED&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;driver&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;driver&#125;&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;url&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;url&#125;&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;username&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;username&#125;&quot;</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;password&#125;&quot;</span>/&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">dataSource</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">environment</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">environments</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mappers</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mapper</span> <span class="attr">resource</span>=<span class="string">&quot;org/mybatis/example/BlogMapper.xml&quot;</span>/&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">mappers</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>上边的配置中，<code>environments</code> 配置的是各个环境下的数据库配置。每个环境下，都可以配置 TransactionManager、datasource 等，连接数据库、包括操作数据库的 driver 等信息都是在这里配置的)。</p>
<p><code>$&#123;driver&#125;</code> 这种写法是用的 property。property 可以直接在这个 xml 中配置（使用 <code>&lt;properties&gt;</code> 标签），也是 java 中的 <code>System.getProperties()</code> 中的 property，还可以是在 <code>SqlSessionBuilder</code> 中传递的 <code>props</code> 参数。</p>
<p><strong>构建 <code>SqlSessionFactory</code>：</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">String</span> <span class="variable">resource</span> <span class="operator">=</span> <span class="string">&quot;org/mybatis/example/mybatis-config.xml&quot;</span>;</span><br><span class="line"><span class="type">InputStream</span> <span class="variable">inputStream</span> <span class="operator">=</span> Resources.getResourceAsStream(resource);</span><br><span class="line"><span class="type">SqlSessionFactory</span> <span class="variable">sqlSessionFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SqlSessionFactoryBuilder</span>().build(inputStream);</span><br></pre></td></tr></table></figure>

<h3 id="使用-java-Configuration-类"><a href="#使用-java-Configuration-类" class="headerlink" title="使用 java Configuration 类"></a>使用 java Configuration 类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataSource</span> <span class="variable">dataSource</span> <span class="operator">=</span> BlogDataSourceFactory.getBlogDataSource();</span><br><span class="line"><span class="type">TransactionFactory</span> <span class="variable">transactionFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JdbcTransactionFactory</span>();</span><br><span class="line"><span class="type">Environment</span> <span class="variable">environment</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Environment</span>(<span class="string">&quot;development&quot;</span>, transactionFactory, dataSource);</span><br><span class="line"><span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>(environment);</span><br><span class="line">configuration.addMapper(BlogMapper.class);</span><br><span class="line"><span class="type">SqlSessionFactory</span> <span class="variable">sqlSessionFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SqlSessionFactoryBuilder</span>().build(configuration);</span><br></pre></td></tr></table></figure>

<h2 id="SqlSession"><a href="#SqlSession" class="headerlink" title="SqlSession"></a>SqlSession</h2><p><code>SqlSession</code> 是执行 sql 命令的接口：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SqlSession</span> <span class="variable">session</span> <span class="operator">=</span> sqlSessionFactory.openSession();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="type">BlogMapper</span> <span class="variable">mapper</span> <span class="operator">=</span> session.getMapper(BlogMapper.class);</span><br><span class="line">  <span class="type">Blog</span> <span class="variable">blog</span> <span class="operator">=</span> mapper.selectBlog(<span class="number">101</span>);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  session.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>SqlSession</code> 可以执行所有的 sql 命令、做事务提交、回滚、获取 Mapper 实例等，非常强大。<code>SqlSession</code> 也是方法作用域级别的，并且必须被正确关闭：</p>
<blockquote>
<p>每个线程都应该有它自己的 SqlSession 实例。SqlSession 的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。<strong>绝对不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。</strong>也绝不能将 SqlSession 实例的引用放在任何类型的管理作用域中，比如 Servlet 架构中的 HttpSession。如果你现在正在使用一种 Web 框架，要考虑 SqlSession 放在一个和 HTTP 请求对象相似的作用域中。换句话说，每次收到的 HTTP 请求，就可以打开一个 SqlSession，返回一个响应，就关闭它。这个关闭操作是很重要的，你应该把这个关闭操作放到 finally 块中以确保每次都能执行关闭。下面的示例就是一个确保 SqlSession 关闭的标准模式：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SqlSession</span> <span class="variable">session</span> <span class="operator">=</span> sqlSessionFactory.openSession();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">// do work</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  session.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h2><p><code>Mapper</code> 是资源和数据库实例的映射，提供了相关操作来做转换。可以用两种方式写：xml 或 annotation。</p>
<p>mapper 实例从 <code>SqlSession</code> 获得，所以生命周期和 SqlSession 相同。</p>
<h3 id="xml"><a href="#xml" class="headerlink" title="xml"></a>xml</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span> ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">mapper</span></span></span><br><span class="line"><span class="meta">  <span class="keyword">PUBLIC</span> <span class="string">&quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">  <span class="string">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mapper</span> <span class="attr">namespace</span>=<span class="string">&quot;org.mybatis.example.BlogMapper&quot;</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">select</span> <span class="attr">id</span>=<span class="string">&quot;selectBlog&quot;</span> <span class="attr">resultType</span>=<span class="string">&quot;Blog&quot;</span>&gt;</span></span><br><span class="line">    select * from Blog where id = #&#123;id&#125;</span><br><span class="line">  <span class="tag">&lt;/<span class="name">select</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mapper</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>访问：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Blog</span> <span class="variable">blog</span> <span class="operator">=</span> (Blog) session.selectOne(<span class="string">&quot;org.mybatis.example.BlogMapper.selectBlog&quot;</span>, <span class="number">101</span>);</span><br></pre></td></tr></table></figure>

<p>当然，我们希望通过 java 接口来调用这些方法，所以可以写相应的 <code>mapper</code> 接口 ，只要保证 <code>namespace</code> 是一致的即可。<code>namespace</code> 是实现接口绑定的方式。mybatis 基于命名空间的命名解析规则如下：</p>
<blockquote>
<ul>
<li>完全限定名（比如“com.mypackage.MyMapper.selectAllThings”）将被直接查找并且找到即用。</li>
<li>短名称（比如“selectAllThings”）如果全局唯一也可以作为一个单独的引用。如果不唯一，有两个或两个以上的相同名称（比如“com.foo.selectAllThings ”和“com.bar.selectAllThings”），那么使用时就会收到错误报告说短名称是不唯一的，这种情况下就必须使用完全限定名。</li>
</ul>
</blockquote>
<p>一旦绑定了接口，就可以用如下方式访问 mapper 方法了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">BlogMapper</span> <span class="variable">mapper</span> <span class="operator">=</span> session.getMapper(BlogMapper.class);</span><br><span class="line"><span class="type">Blog</span> <span class="variable">blog</span> <span class="operator">=</span> mapper.selectBlog(<span class="number">101</span>);</span><br></pre></td></tr></table></figure>

<h3 id="annotation"><a href="#annotation" class="headerlink" title="annotation"></a>annotation</h3><p>也可以不依赖于 xml，直接在 mapper 接口上通过 annotation 定义 sql：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.mybatis.example;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">BlogMapper</span> &#123;</span><br><span class="line">  <span class="meta">@Select(&quot;SELECT * FROM blog WHERE id = #&#123;id&#125;&quot;)</span></span><br><span class="line">  Blog <span class="title function_">selectBlog</span><span class="params">(<span class="type">int</span> id)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>annotation 可能更简洁一些，但是 mybatis 目前还是 xml 更强大。大家可以依据需求自由的在两种方式之间切换，mybatis 会自己检测。</p>
<blockquote>
<p>由于 Java 注解的一些限制加之某些 MyBatis 映射的复杂性，XML 映射对于大多数高级映射（比如：嵌套 Join 映射）来说仍然是必须的。有鉴于此，如果存在一个对等的 XML 配置文件的话，MyBatis 会自动查找并加载它（这种情况下， BlogMapper.xml 将会基于类路径和 BlogMapper.class 的类名被加载进来）</p>
</blockquote>
]]></content>
      <tags>
        <tag>orm</tag>
      </tags>
  </entry>
  <entry>
    <title>network</title>
    <url>/2020/07/23/network/</url>
    <content><![CDATA[<p><a href="https://www.youtube.com/watch?v=rL8RSFQG8do&list=PLF360ED1082F6F2A5">Eli the computer guy</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>the whole picture </p>
<p>Speed &amp; storage unit</p>
<p>Physical &amp; logical</p>
<p>modem</p>
<ul>
<li>t1</li>
<li>dsl:<ul>
<li>no faster than 12Mb&#x2F;s</li>
<li>Asynchronous: download faster than upload</li>
</ul>
</li>
<li>cabel</li>
<li>satellite</li>
</ul>
<p>Router</p>
<p>firewall</p>
<ul>
<li>block the internet to get into your network</li>
</ul>
<p>VPN</p>
<ul>
<li>enable the internet to get into your network</li>
<li>client-server</li>
</ul>
<p>Switch</p>
<ul>
<li>Connect everything together</li>
</ul>
<h1 id="网关-gateway"><a href="#网关-gateway" class="headerlink" title="网关(gateway)"></a>网关(gateway)</h1><h2 id="what’s-gateway"><a href="#what’s-gateway" class="headerlink" title="what’s gateway"></a>what’s gateway</h2><p>Generally speaking, any entry to some ‘network’ is called gateway. So for programmers, there’s api gateway, the entry to the backend-service network.</p>
<p>In the IP network context, gateway is used to connect two network.</p>
<blockquote>
<p>e.g. </p>
<p>network A: 192.168.1.1 ~ 192.168.1.254,  mask: 255.255.255.0</p>
<p>network B: 192.168.2.1 ~ 192.168.2.254, mask: 255.255.255.0</p>
<p>A host a in <strong>network A</strong> wants to send data to a host b in <strong>network B</strong>:</p>
<ol>
<li><p>host a send data to gateway A(ip)</p>
</li>
<li><p>gateway A send data to gateway B(ip)</p>
</li>
<li><p>gateway B send data to host b(ip)</p>
</li>
</ol>
</blockquote>
<p>In the above case, </p>
<ol>
<li><p>there’re two gateways. This is the connection-oriented gateway（面向连接的网关）. When the two networks are far and we create a gateway in each side, and then link them.</p>
<ul>
<li>there  is also non-connection gateway（无连接的网关）</li>
</ul>
</li>
</ol>
<p>2- the gateway device must be able to route, which is in fact the router. Thus the ip of the gateway is often the ip of the router.</p>
<ul>
<li><p>because it has to be about to route to the right gateway or host, thus the routing ability is required.</p>
</li>
<li><p>to route, the gateway in fact request the right ip of gateway&#x2F;host from DNS, and then transfer the data there.</p>
</li>
</ul>
<h3 id="explain-with-story"><a href="#explain-with-story" class="headerlink" title="explain with story"></a>explain with story</h3><p>　　假设你的名字叫小不点，你住在一个大院子里，你的邻居有很多小伙伴，在门口传达室还有个看大门的李大爷，李大爷就是你的网关。当你想跟院子里的某个小伙伴玩，只要你在院子里大喊一声他的名字，他听到了就会回应你，并且跑出来跟你玩。</p>
<p>但是你不被允许走出大门，你想与外界发生的一切联系，都必须由门口的李大爷（网关）用电话帮助你联系。假如你想找你的同学小明聊天，小明家住在很远的另外一个院子里，他家的院子里也有一个看门的王大爷（小明的网关）。但是你不知道小明家的电话号码，不过你的班主任老师有一份你们班全体同学的名单和电话号码对照表，<strong>你的老师就是你的DNS服务器</strong>。于是你在家里拨通了门口李大爷的电话，有了下面的对话：</p>
<blockquote>
<p>简单来讲，你老是就是你的域名服务器，你家小区的看门大爷就是你的网关。</p>
</blockquote>
<p>小不点：李大爷，我想找班主任查一下小明的电话号码行吗？<br>李大爷：好，你等着。（接着李大爷给你的班主任挂了一个电话，问清楚了小明的电话）问到了，他家的号码是211.99.99.99<br>小不点：太好了！李大爷，我想找小明，你再帮我联系一下小明吧。<br>李大爷：没问题。（接着李大爷向电话局发出了请求接通小明家电话的请求，最后一关当然是被转接到了小明家那个院子的王大爷那里，然后王大爷把电话给转到小明家）<br>就这样你和小明取得了联系。</p>
<h2 id="default-gateway"><a href="#default-gateway" class="headerlink" title="default gateway"></a>default gateway</h2><p>we can have multiple gateways. And when no gateway works, it goes the the default gateway.</p>
<h1 id="TCP-x2F-IP"><a href="#TCP-x2F-IP" class="headerlink" title="TCP&#x2F;IP"></a>TCP&#x2F;IP</h1><p>ip: internet protocol. How to find a computer.</p>
<p>tcp: transmission control protocol. How to communicate between 2 computers</p>
<p>suite: tcp protocol, ip protocol, etc</p>
<p>tcp windowing</p>
<p>components:</p>
<ul>
<li><p>ip address</p>
</li>
<li><p>subnet</p>
</li>
<li><p>default gateway</p>
</li>
<li><p>dns</p>
</li>
<li><p>dhcp</p>
</li>
<li><p>nat</p>
</li>
</ul>
<p>subnet mask: network identifier, device identifier.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">for</span> windows, first release and renew to ensure to get the latest configurations</span></span><br><span class="line">ipconfig /release</span><br><span class="line">ipconfig /renew</span><br><span class="line">ipconfig /all</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">for</span> linux and mac</span></span><br><span class="line">ifconfig [-a]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ping 10.1.10.11 10 <span class="built_in">times</span> with 60ms ttl</span></span><br><span class="line">ping www.baidu.com -c 10 -m 60</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="keyword">in</span> windows, it<span class="string">&#x27;s tracert. For linux and mac, it&#x27;</span>s traceroute</span></span><br><span class="line">traceroute www.baidu.com</span><br></pre></td></tr></table></figure>

<h2 id="OpenDNS-for-network-security"><a href="#OpenDNS-for-network-security" class="headerlink" title="OpenDNS for network security"></a>OpenDNS for network security</h2><p>dns can be hacked so that you’re redirected to some unwanted websites. Or a virus on your computer tries to pull more viruses  from some virus website. </p>
<p>OpenDNS is a product to prevent such nasty issues.</p>
<ol>
<li><p>With a router, and dhcp on that router (allocating ip&#x2F;subset mask,etc to all your network devices), you config the dns as the opendns</p>
</li>
<li><p>On opendns control panel, add your network (the external ip of your network, i.e. the router ip address) and config the filter for your network.</p>
</li>
<li><p>When accessing unallowed websites, you will be redirected to a block opendns page by opendns.</p>
</li>
</ol>
<p>If you don’t have static ip, install the dynamic ip address from opendns, which will tell the opendns your current network address.</p>
<h1 id="Servers"><a href="#Servers" class="headerlink" title="Servers"></a>Servers</h1><p>server operating system: more robust and expensive, compared to desktop operating system.</p>
<p>specific hardware: for data center. xeon processor, redundant power supply, raid (redundant hard drive).</p>
<h1 id="Voice-over-ip-VOIP"><a href="#Voice-over-ip-VOIP" class="headerlink" title="Voice over ip (VOIP)"></a>Voice over ip (VOIP)</h1><p>At the beginning, telephone system communicate using wires. It’s completely separate to comupter system.</p>
<p>VOIP make the audio transimit through the TCP&#x2F;IP protocol.</p>
<p>Client-Server infrastructure: hard phones &#x2F; soft phones have to install the VOIP client to communicate to VOIP server, which routes all audio communications.</p>
<p>Iphone in fact installs VOIP client and phone through VOIP service. IPhone is the above soft phones.</p>
<p>Gateways. It can connect different communication system, e.g. the old telephone system and VOIP system, so that you can call through VOIP server -&gt; Gateway -&gt; the wireline telephone.</p>
<p>Codec. It encode the audio transmitted on VOIP service and decide what the packet should be like. So it decides the quality and bandwidth it needs.</p>
<p>QOS. quality of service. On switches and routers, config the VOIP transmision as high priority, so that it won’t be influenced by other bandwidth sharer.</p>
<p>Unifed communication. I think it’s the whole idea that make the telephone and computer stay in the same system, so that we can do a lot by this.</p>
<h1 id="Cloud-Computing"><a href="#Cloud-Computing" class="headerlink" title="Cloud Computing"></a>Cloud Computing</h1><p>Web application. If we want some application, but it’s in fact not on our own hardware, and it’s outside somewhere, then it’s in fact cloud computing. It’s just maybe it’s private cloud.</p>
<p>Cluster. And to be a cloud, there also needs to be a cluster, so that when some bad things happen, it can recover itself.</p>
<p>Cluster make the services more robust. It’s a normal way for cloud to provide robustness.</p>
<p>Terminal Services. There’s terminal service server and thin clients. You can access a remote operating system desktop through thin clients. This seems to be the remote connection. Furthermore, the remote system can just be an specific application instead of a desktop. In such case, there’s application server.</p>
<p>This is an old technique. In old days, it’s called mainframe and dumb terminals. Anyway, the thin clients capture all the strokes you made and send them to the terminal service server, and the terminal service server sends the result image back. The teminal service server is the one with processing abilities, and all thin clients share the cpu time, each allocated with one slice of CPU time.</p>
<p>Terminal service is also a cloud related technique to access cloud services.</p>
<p>Virtualization. A tenichque that separate the operating system from the hardware, so that you can transfer the operating system with the applications in it easily. There’re 2 flavours to implement it:</p>
<ol>
<li><p>client installer. This is the normal virtualbox or vmware fusion. You installed this installer on your current operating system, and then you installed another os box using the installer.</p>
</li>
<li><p>hypervision. Hypervision is in fact an operating system. Install hypervision on hardware, and then using the management client on your computer to install anything you want on that hypervision. The hypervision will then allocate a piece of hard drive, ram, etc to the os you asked. In the vmware world, the hypervision is esxi which is always free, the management software is the vsphere which is in charged.</p>
</li>
</ol>
<p>Current cloud computing should be using some techniques like the hypervision. Anyway, they try to separate the os from the hardware, so that you can copy-paste the whole environment easily to another hardware like a file.</p>
]]></content>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>oauth</title>
    <url>/2018/07/27/oauth/</url>
    <content><![CDATA[<h1 id="traditional-authentication"><a href="#traditional-authentication" class="headerlink" title="traditional authentication"></a>traditional authentication</h1><p>传统认证使用  session:</p>
<ol>
<li>client 发送 username、password 给 server</li>
<li>server 查数据库，检查信息，是否正确。正确就把用户登录信息(即用户状态)写到 session 里（即服务器内存中），并将 sessionId 返回给 client。</li>
<li>client 在请求 api 时，在 cookie 中传递 sessionId。server 端根据 sessionId 获取用户登录信息，如果已认证，返回正常响应；反之，401</li>
</ol>
<p><img src="https://camo.githubusercontent.com/f6ea1099ada7ec855919d6e483d0d903f1cc96ca/68747470733a2f2f636d732d6173736574732e74757473706c75732e636f6d2f75706c6f6164732f75736572732f3438372f706f7374732f32323534332f696d6167652f747261646974696f6e616c2d61757468656e7469636174696f6e2d73797374656d2d706e672e706e67" alt="auth image"></p>
<p>这种方式有个缺陷：如果做分布式服务部署，那么需要每个服务器都要同步相同的登录信息，这不是一个好的方式。所以一般 rest 微服务都要求的是 stateless，即 server 端不保存任何用户信息，请求中包含所有需要的信息。</p>
<h1 id="oauth"><a href="#oauth" class="headerlink" title="oauth"></a>oauth</h1><p><a href="https://zh.wikipedia.org/wiki/%E5%BC%80%E6%94%BE%E6%8E%88%E6%9D%83">oauth</a> 是一个开放标准，允许用户让第三方应用访问该用户在某一网站上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A0%81">密码</a>提供给第三方应用。</p>
<p>OAuth允许用户提供一个 <a href="https://zh.wikipedia.org/w/index.php?title=%E4%BB%A4%E7%89%8C&action=edit&redlink=1">令牌</a>，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的网站（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定信息，而非所有内容。</p>
<p> 其令牌可以是 JWT 或其他形式。</p>
<p><img src="https://docs.oracle.com/cd/E74890_01/books/RestAPI/images/OAuth2leg_V.gif" alt="oauth"></p>
<p>ref: <a href="https://my.oschina.net/eyes4/blog/639970">oauth 2.0 的用途</a></p>
<h1 id="Auth0"><a href="#Auth0" class="headerlink" title="Auth0"></a>Auth0</h1><p><a href="https://auth0.com/">autho0</a> 实现了<a href="https://auth0.com/docs/protocols">很多开放标准</a>，包括 oauth。(<a href="https://www.youtube.com/watch?v=QsMK3d3LxYQ">学习视频</a>)</p>
<ol>
<li>要使用 Auth0，首先需要创建一个 App（被称作 client），其中定义了 clientId、domain name、callbackUrl、secret 等。</li>
<li>前端交互：<ol>
<li>当访问某个页面时，查看 localstorage，看用户是否登录；</li>
<li>如果未登录，利用 Auth0 sdk 或 api 登录认证（提供前边 App 中的 clientId、secret 等信息），认证通过将认证信息（token 等）存入 localstorage，并跳转到 callback url</li>
<li>如果登录，直接访问</li>
</ol>
</li>
<li>后端交互：<ol>
<li>前端携带 token 访问 API</li>
<li>server 利用 Auth0 sdk 或 api 验证 token 的有效性；认证通过返回资源，否则 401</li>
</ol>
</li>
</ol>
]]></content>
      <tags>
        <tag>security</tag>
        <tag>oauth</tag>
      </tags>
  </entry>
  <entry>
    <title>obs</title>
    <url>/2019/03/01/obs/</url>
    <content><![CDATA[<p><a href="https://support.huaweicloud.com/productdesc-obs/zh-cn_topic_0045829060.html">Huawei Obs</a> is an object storage service on cloud.</p>
<h1 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h1><h2 id="Object"><a href="#Object" class="headerlink" title="Object"></a>Object</h2><ol>
<li>The real complete file or byte stream to save</li>
<li><strong>object name is the unique id</strong> in a bucket<ol>
<li>it’s used as <strong>part of url path</strong>. The naming restrictions are fit to url path naming restrictions.</li>
</ol>
</li>
<li>Access(based on version in fact)<ol>
<li>Object ACL:<ol>
<li>general control to object: <strong>read object, read&#x2F;write object ACL, only users in the same account</strong></li>
</ol>
</li>
<li>Object policy<ol>
<li>fine-grained control to object: <strong>fine-grained actions(put,delete…) on object, all users</strong></li>
</ol>
</li>
</ol>
</li>
<li><strong>multi-versions</strong><ol>
<li>an object can has multiple versions, each of which has an unique id.</li>
<li>Whether there’s multi-version, it’s a policy set on a bucket.</li>
</ol>
</li>
<li>directory:<ol>
<li><strong>directory is just a view</strong>. Essentially, it’s an empty object end with “&#x2F;“.</li>
<li><strong>all objects in a bucket are on the same level</strong>. There’s no multi-level directory in fact.</li>
<li>to create the directory view, you need to create an object with name ending with “&#x2F;“ explicility, eg. “sub1&#x2F;sub2&#x2F; . It will create a two-level dir in console. There’s no need to create “sub1&#x2F;“ first then “sub1&#x2F;sub2”.</li>
</ol>
</li>
<li>object actions:<ol>
<li>For writing, there’s <strong>only write&#x2F;restricted-append&#x2F;delete, no put</strong></li>
<li><strong>basically-write-once-read-many</strong></li>
</ol>
</li>
<li>upload modes:<ol>
<li>stream</li>
<li>file</li>
<li>multi-part (support breakpoint resume)</li>
<li>append</li>
</ol>
</li>
</ol>
<h2 id="Bucket"><a href="#Bucket" class="headerlink" title="Bucket"></a>Bucket</h2><ol>
<li>The place to save objects</li>
<li><strong>bucket name is the unique id</strong> for one account(a tenant).<ol>
<li>it’s used as <strong>part of domain name</strong> on url. The naming restrictions are fit to domain naming restrictions.</li>
</ol>
</li>
<li>Access<ol>
<li>Bucket ACL: <ol>
<li>general control to bucket and all objects in bucket: <strong>read&#x2F;put buckets, read&#x2F;write bucket ACL, only users in the same account</strong></li>
</ol>
</li>
<li>Bucket policy<ol>
<li>fine-grained control to specific objects in bucket: <strong>fine-grained actions on bucket or specific objects in bucket, all users</strong></li>
</ol>
</li>
</ol>
</li>
<li>storage type<ol>
<li>standard: <ol>
<li><strong>quick access &amp; high throughput</strong>. It’s used for high access requests and not so big files.</li>
</ol>
</li>
<li>warm:<ol>
<li><strong>low access.</strong></li>
</ol>
</li>
<li>cold:<ol>
<li><strong>very very low access</strong></li>
</ol>
</li>
</ol>
</li>
</ol>
<h2 id="region"><a href="#region" class="headerlink" title="region"></a>region</h2><p>The region of nodes where the storage really happens.</p>
<h2 id="signature"><a href="#signature" class="headerlink" title="signature"></a>signature</h2><p>The signature to identify a user when accessing buckets&#x2F;objects.</p>
<ol>
<li>ak(access key): represent a user. one user can have multi aks. It’s kind of like an user role</li>
<li>sk(secret key): one-to-one corresponding with ak. The secret key used for RSA authentication &amp; authorization.</li>
</ol>
]]></content>
      <tags>
        <tag>storage</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>performance for io in java</title>
    <url>/2018/10/15/performance-of-io-in-java/</url>
    <content><![CDATA[<h1 id="java-io-ByteArrayOutputStream"><a href="#java-io-ByteArrayOutputStream" class="headerlink" title="java.io.ByteArrayOutputStream"></a>java.io.ByteArrayOutputStream</h1><p>这一般在用到字节流是会用到。</p>
<p><a href="http://java-performance.info/java-io-bytearrayoutputstream/">java performance tuning guide</a> 这篇文章不建议在 performance-criticted 代码中使用 <code>ByteArrayOutputStream</code>：</p>
<ol>
<li><strong>同步写入，效率低</strong></li>
</ol>
<blockquote>
<p><code>ByteArrayOutputStream</code> allows you to write anything to an internal expandable byte array and use that array as a single piece of output afterwards. Default buffer size is 32 bytes, so if you expect to write something longer, provide an explicit buffer size in the <code>ByteArrayOutputStream(int)</code> constructor</p>
<p> 注：</p>
<ol>
<li><code>ByteArrayOutputStream</code> 内部是一个可变长度的 byte[]（通过扩充实现可变）。它有个初始长度（默认 32），可以在 constructor 中指定.</li>
<li><code>ByteArrayOutputStream</code> 是同步写入，比较影响效率</li>
</ol>
</blockquote>
<ol start="2">
<li><strong>toByteArray() 效率低，使用 toString(charset)</strong></li>
</ol>
<p><code>toByteArray</code> 执行了一遍拷贝，效率低。<code>toString</code> 则使用 <code>String(bytes[])</code> 直接将内部 byte 转成了 String</p>
<p><a href="http://java-performance.info/inefficient-byte-to-string-constructor/">inefficient byte[] to String constructor</a> 指出 <code>String(bytes[])</code>  也是 copy，但 java8 中的源码看了下，似乎不是 copy，待考证……</p>
]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>pipeline process: beam</title>
    <url>/2019/01/30/pipeline-process-beam/</url>
    <content><![CDATA[<h1 id="What’s-beam"><a href="#What’s-beam" class="headerlink" title="What’s beam"></a>What’s beam</h1><p><a href="https://beam.apache.org/get-started/beam-overview/">beam</a> is a open-source, unified model for defining both batched &amp; streaming data-parallel processing pipelines.</p>
<ul>
<li>open-source (apache v2 license)</li>
<li>to define data-parallel processing pipelines</li>
<li>an unified model to define pipelines. The real processing is run by the underlying runner (eg. spark, apache apex, etc.). <a href="https://beam.apache.org/get-started/beam-overview/">all available runners</a></li>
<li>can process both batched  (bounded datasets) &amp; streaming (unbounded datasets) datasets</li>
</ul>
<h1 id="Use-it"><a href="#Use-it" class="headerlink" title="Use it"></a>Use it</h1><p>See the <a href="https://beam.apache.org/get-started/beam-overview/">wordcount examples</a>, <a href="https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/MinimalWordCount.java">wordcount src</a></p>
<p>Now we define a simple pipeline and run it.</p>
<p><code>Transform</code>, <code>Count</code> are all built-in atom operations to define the pipeline scripts.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.beam.examples;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.Pipeline;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.io.TextIO;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.options.PipelineOptions;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.options.PipelineOptionsFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.transforms.Count;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.transforms.Filter;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.transforms.FlatMapElements;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.transforms.MapElements;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.values.KV;</span><br><span class="line"><span class="keyword">import</span> org.apache.beam.sdk.values.TypeDescriptors;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MinimalWordCount</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create a PipelineOptions object. This object lets us set various execution</span></span><br><span class="line">    <span class="comment">// options for our pipeline, such as the runner you wish to use.</span></span><br><span class="line">    <span class="type">PipelineOptions</span> <span class="variable">options</span> <span class="operator">=</span> PipelineOptionsFactory.create();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create the Pipeline object with the options we defined above</span></span><br><span class="line">    <span class="type">Pipeline</span> <span class="variable">p</span> <span class="operator">=</span> Pipeline.create(options);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Concept #1: Apply a root transform to the pipeline; in this case, TextIO.Read to read a set</span></span><br><span class="line">    p.apply(TextIO.read().from(<span class="string">&quot;gs://apache-beam-samples/shakespeare/*&quot;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Concept #2: Apply a FlatMapElements transform the PCollection of text lines.</span></span><br><span class="line">        .apply(</span><br><span class="line">            FlatMapElements.into(TypeDescriptors.strings())</span><br><span class="line">                .via((String word) -&gt; Arrays.asList(word.split(<span class="string">&quot;[^\\p&#123;L&#125;]+&quot;</span>))))</span><br><span class="line">        .apply(Filter.by((String word) -&gt; !word.isEmpty()))</span><br><span class="line">        <span class="comment">// Concept #3: Apply the Count transform to our PCollection of individual words. </span></span><br><span class="line">        .apply(Count.perElement())</span><br><span class="line">        .apply(</span><br><span class="line">            MapElements.into(TypeDescriptors.strings())</span><br><span class="line">                .via(</span><br><span class="line">                    (KV&lt;String, Long&gt; wordCount) -&gt;</span><br><span class="line">                        wordCount.getKey() + <span class="string">&quot;: &quot;</span> + wordCount.getValue()))</span><br><span class="line">        <span class="comment">// Concept #4: Apply a write transform, TextIO.Write, at the end of the pipeline.</span></span><br><span class="line">        .apply(TextIO.write().to(<span class="string">&quot;wordcounts&quot;</span>));</span><br><span class="line"></span><br><span class="line">    p.run().waitUntilFinish();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Some-conceptions"><a href="#Some-conceptions" class="headerlink" title="Some conceptions"></a>Some conceptions</h1><h2 id="I-x2F-O-data-source-x2F-target"><a href="#I-x2F-O-data-source-x2F-target" class="headerlink" title="I&#x2F;O (data source&#x2F;target)"></a>I&#x2F;O (data source&#x2F;target)</h2><p>Beam can process both batched  (bounded datasets) &amp; streaming (unbounded datasets) datasets. <a href="https://beam.apache.org/documentation/io/built-in/">built-in io transforms</a></p>
<p>Take reading as example, you specify the file location (the location must be accessable for the runner), and then the reader pull from datasource. You may also define the trigger to collect input window. When trigger is satisfied, window elements are emitted.</p>
<p>For unbounded datasets, they are split into windows. And each window is again a bounded datasets. In each window, there’re some elements. You can define how the elements are grouped as a window and when to emit the window elements for processing. <a href="https://beam.apache.org/documentation/programming-guide/#windowing">window concept</a></p>
<h2 id="Runner"><a href="#Runner" class="headerlink" title="Runner"></a>Runner</h2><p>Beam is an unified model. It abstracts the conception to define and run a pipeline. The real execution is conducted by the underlying runners.</p>
<p><a href="https://beam.apache.org/get-started/beam-overview/">all available runners</a></p>
<p>For unbounded datasets, the underlying runner must support stream processing.</p>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>distributed computing</tag>
      </tags>
  </entry>
  <entry>
    <title>presto</title>
    <url>/2021/05/10/presto/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Facebook的数据仓库存储在少量大型Hadoop&#x2F;HDFS集群。Hive是Facebook在几年前专为Hadoop打造的一款数据仓库工具。在以前，Facebook的科学家和分析师一直依靠Hive来做数据分析。但Hive使用MapReduce作为底层计算框架，是专为批处理设计的。但随着数据越来越多，使用Hive进行一个简单的数据查询可能要花费几分到几小时，显然不能满足交互式查询的需求。Facebook也调研了其他比Hive更快的工具，但它们要么在功能有所限制要么就太简单，以至于无法操作Facebook庞大的数据仓库。</p>
<p>2012年开始试用的一些外部项目都不合适，他们决定自己开发，这就是Presto。2012年秋季开始开发，目前该项目已经在超过 1000名Facebook雇员中使用，运行超过30000个查询，每日数据在1PB级别。Facebook称Presto的性能比Hive要好上10倍多。2013年Facebook正式宣布开源Presto。</p>
<h1 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h1><p><a href="https://prestodb.io/">presto 官网</a></p>
<blockquote>
<p>Presto is an open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes.</p>
</blockquote>
<p>Presto是一个分布式的查询引擎，本身并不存储数据，但是可以接入多种数据源，并且支持跨数据源的级联查询。Presto是一个OLAP的工具，擅长对海量数据进行复杂的分析；但是对于OLTP场景，并不是Presto所擅长，所以不要把Presto当做数据库来使用。</p>
<p>和大家熟悉的Mysql相比：首先Mysql是一个数据库，具有存储和计算分析能力，而Presto只有计算分析能力；其次数据量方面，Mysql作为传统单点关系型数据库不能满足当前大数据量的需求，于是有各种大数据的存储和分析工具产生，Presto就是这样一个可以满足大数据量分析计算需求的一个工具。</p>
<p>Hive是一个基于HDFS(分布式文件系统)的一个数据库，具有存储和分析计算能力， 支持大数据量的存储和查询。Hive 作为数据源，结合Presto分布式查询引擎，这样大数据量的查询计算速度就会快很多</p>
<h1 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h1><p>Presto需要从其他数据源获取数据来进行运算分析，它可以连接多种数据源，包括Hive、RDBMS（Mysql、Oracle、Tidb等）、Kafka、MongoDB、Redis等</p>
<p>一条Presto查询可以将多个数据源的数据进行合并分析。<br>比如：select * from a join b where a.id&#x3D;b.id;，其中表a可以来自Hive，表b可以来自Mysql。</p>
<h1 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h1><p><a href="https://prestodb.io/docs/current/overview/concepts.html">preto concepts</a></p>
<p>Presto使用Catalog、Schema和Table这3层结构来管理数据。</p>
<p>—- Catalog:就是数据源。Hive是数据源，Mysql也是数据源，Hive 和Mysql都是数据源类型，可以连接多个Hive和多个Mysql，每个连接都有一个名字。一个Catalog可以包含多个Schema，大家可以通过show catalogs 命令看到Presto连接的所有数据源。<br>—- Schema：相当于一个数据库实例，一个Schema包含多张数据表。show schemas from ‘catalog_name’可列出catalog_name下的所有schema。<br>—- Table：数据表，与一般意义上的数据库表相同。show tables from ‘catalog_name.schema_name’可查看’catalog_name.schema_name’下的所有表。</p>
<p>在Presto中定位一张表，一般是catalog为根，例如：一张表的全称为 hive.test_data.test，标识 hive(catalog)下的 test_data(schema)中test表。</p>
<pre><code>    kadmin.local addprinc -randkey $&#123;USER&#125;@FTMS.COM
    kadmin.local xst -k keytabs/$&#123;USER&#125;.keytab $&#123;USER&#125;@FTMS.COM
</code></pre>
<h1 id="OLAP-引擎对比"><a href="#OLAP-引擎对比" class="headerlink" title="OLAP 引擎对比"></a>OLAP 引擎对比</h1><p>为什么presto查询速度比Hive快？</p>
<ul>
<li>presto是常驻任务，接受请求立即执行，全内存并行计算；hive需要用yarn做资源调度，接受查询需要先申请资源，启动进程，并且中间结果会经过磁盘。</li>
</ul>
<p><a href="https://www.cnblogs.com/bonelee/p/12878451.html">开源OLAP引擎测评报告(SparkSql、Presto、Impala、HAWQ、ClickHouse、GreenPlum)</a></p>
<p>多表</p>
<p><img src="http://geek.analysys.cn/static/upload/dailidong/2018-12-11/08519d86-cd1e-420d-a2cc-80e1b5fef8c1.jpeg" alt="img"></p>
<p>单表：</p>
<p><img src="http://geek.analysys.cn/static/upload/dailidong/2018-12-11/bf0bd90a-1209-4be7-b3a2-fb28fe29811a.jpeg" alt="img"></p>
<h1 id="install"><a href="#install" class="headerlink" title="install"></a>install</h1><h2 id="ambari-集成"><a href="#ambari-集成" class="headerlink" title="ambari 集成"></a>ambari 集成</h2><p><a href="https://prestodb.io/ambari-presto-service/">https://prestodb.io/ambari-presto-service/</a></p>
<p><a href="https://www.codenong.com/js87725e1b2144/">https://www.codenong.com/js87725e1b2144/</a></p>
<p><a href="https://www.jianshu.com/p/291e3ee3f981">https://www.jianshu.com/p/291e3ee3f981</a></p>
<p><a href="https://blog.csdn.net/qq_29248935/article/details/98870687">https://blog.csdn.net/qq_29248935/article/details/98870687</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1158362">https://cloud.tencent.com/developer/article/1158362</a></p>
<h1 id="presto-known-limitations"><a href="#presto-known-limitations" class="headerlink" title="presto known limitations"></a>presto known limitations</h1><p><a href="https://docs.treasuredata.com/display/public/PD/Presto+Known+Limitations">limitations</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/89381163">Presto内存管理与相关参数设置</a></p>
]]></content>
      <tags>
        <tag>big data</tag>
      </tags>
  </entry>
  <entry>
    <title>python basic</title>
    <url>/2019/03/26/python-basic/</url>
    <content><![CDATA[<p><a href="https://www.sololearn.com/play/python">great free learning website with quiz</a></p>
<p><a href="http://pythontutor.com/live.html#mode=edit">great online editor &amp; debugger</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/41381773">Python学习资料&#x2F;文章&#x2F;指南整理</a></p>
<h1 id="Zen-of-Python"><a href="#Zen-of-Python" class="headerlink" title="Zen of Python"></a>Zen of Python</h1><p>By typing <code>import this</code>, you can see the zen of python. Some need more explanation:</p>
<p>Explicit is better than implicit: It is best to spell out exactly what your code is doing. This is why adding a numeric string to an integer requires explicit conversion, rather than having it happen behind the scenes, as it does in other languages.<br>Flat is better than nested: Heavily nested structures (lists of lists, of lists, and on and on…) should be avoided.<br>Errors should never pass silently: In general, when an error occurs, you should output some sort of error message, rather than ignoring it.</p>
<h2 id="PEP"><a href="#PEP" class="headerlink" title="PEP"></a>PEP</h2><p><strong>Python Enhancement Proposals (PEP)</strong> are suggestions for improvements to the language, made by experienced Python developers.</p>
<p><strong>PEP 8</strong> is a style guide on the subject of writing readable code<br><strong>PEP 20</strong>: The Zen of Python<br><strong>PEP 257</strong>: Style Conventions for Docstrings</p>
<h3 id="Naming-conventions"><a href="#Naming-conventions" class="headerlink" title="Naming conventions"></a>Naming conventions</h3><p><strong>PEP 8</strong> is a style guide on the subject of writing readable code. It contains a number of guidelines in reference to variable names, which are summarized here:<br>- modules should have short, all-lowercase names;<br>- class names should be in the CapWords style;<br>- most variables and function names should be lowercase_with_underscores;<br>- constants (variables that never change value) should be CAPS_WITH_UNDERSCORES;<br>- names that would clash with Python keywords (such as ‘class’ or ‘if’) should have a trailing underscore.</p>
<h1 id="install"><a href="#install" class="headerlink" title="install"></a>install</h1><h2 id="Brew-install"><a href="#Brew-install" class="headerlink" title="Brew install"></a>Brew install</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ brew install python</span><br></pre></td></tr></table></figure>

<h2 id="install-multiple-version"><a href="#install-multiple-version" class="headerlink" title="install multiple version"></a>install multiple version</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use pyenv to install multiple version</span></span><br><span class="line">$ brew update</span><br><span class="line">$ brew install pyenv</span><br><span class="line"></span><br><span class="line"><span class="comment"># Clone the repository to to get the latest version of pyenv</span></span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/pyenv/pyenv.git ~/.pyenv</span><br><span class="line"></span><br><span class="line"><span class="comment"># define envs</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&#x27;</span> &gt;&gt; ~/.zshrc</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;&#x27;</span> &gt;&gt; ~/.zshrc</span><br><span class="line">$ <span class="built_in">source</span> ~/.zshrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># get all versions that can be installed</span></span><br><span class="line">$ pyenv install --list</span><br><span class="line">$ pyenv install 3.7</span><br><span class="line"></span><br><span class="line"><span class="comment"># all current installed</span></span><br><span class="line">$ pyenv versions</span><br><span class="line"><span class="comment"># current active</span></span><br><span class="line">$ pyenv version</span><br><span class="line"></span><br><span class="line"><span class="comment"># set as gloabl version</span></span><br><span class="line">$ pyenv global 3.7</span><br><span class="line"><span class="comment"># set a local version </span></span><br><span class="line"><span class="comment"># This command creates a .python-version file in your current directory. If you have pyenv active in your environment, this file will automatically activate this version for you.</span></span><br><span class="line">$ pyenv <span class="built_in">local</span> 3.7</span><br><span class="line"><span class="comment"># set as shell version</span></span><br><span class="line"><span class="comment"># This command activates the version specified by setting the PYENV_VERSION environment variable. This command overwrites any applications or global settings you may have. If you want to deactivate the version, you can use the --unset flag.</span></span><br><span class="line">$ pyenv shell 3.7</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># check the version</span></span><br><span class="line">$ python3 --version</span><br><span class="line"></span><br><span class="line"><span class="comment"># add this to ~/.zshrc if the global command not work, to active the pyenv shell features</span></span><br><span class="line">$ <span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(pyenv init -)</span>&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="https://files.realpython.com/media/pyenv-pyramid.d2f35a19ded9.png" alt="Pyenv pyramid for order of resolution"></p>
<p>Other pythons installed:</p>
<ul>
<li>&#x2F;usr&#x2F;local&#x2F;bin</li>
<li>&#x2F;usr&#x2F;local&#x2F;Cellar</li>
</ul>
<h1 id="pip"><a href="#pip" class="headerlink" title="pip"></a>pip</h1><p><a href="https://pypi.org/project/pip/">pip</a> is the package installer for python.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ pip install package-name</span><br></pre></td></tr></table></figure>

<p>On windows, to use <code>pip</code> after python installation, you need to config both the python &amp; pip path.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:c/users/xiaoming/AppData/Programs/Python/Python37:c/users/xiaoming/AppData/Programs/Python/Python37/Scripts</span><br></pre></td></tr></table></figure>

<h2 id="common-used-commands"><a href="#common-used-commands" class="headerlink" title="common used commands"></a>common used commands</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list all installed packages</span></span><br><span class="line">$ pip freeze</span><br><span class="line"></span><br><span class="line"><span class="comment"># downgrade pip</span></span><br><span class="line">$ python -m install pip=20.2.4</span><br><span class="line"><span class="comment"># upgrade pip</span></span><br><span class="line">$ python -m pip install --upgrade pip</span><br></pre></td></tr></table></figure>

<h1 id="Packaging"><a href="#Packaging" class="headerlink" title="Packaging"></a>Packaging</h1><p>In Python, the term <strong>packaging</strong> refers to putting modules you have written in a standard format, so that other programmers can install and use them with ease.<br>This involves use of the modules <strong>setuptools</strong> and <strong>distutils</strong>.</p>
<ol>
<li><p>organize existing files correctly. Place all of the files you want to put in a library in the same parent directory. This directory should also contain a file called <strong>_<em>init</em>_.py</strong>, which can be blank but must be present in the directory. <code>__init__.py</code> turns a directory to a module.<br>This directory goes into another directory containing the readme and license, as well as an important file called <strong>setup.py</strong>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SoloLearn/</span><br><span class="line"> LICENSE.txt</span><br><span class="line"> README.txt</span><br><span class="line"> setup.py</span><br><span class="line"> sololearn/</span><br><span class="line">    __init__.py</span><br><span class="line">    sololearn.py</span><br><span class="line">    sololearn2.py</span><br></pre></td></tr></table></figure>
</li>
<li><p>Write the <strong>setup.py</strong> file. This contains information necessary to assemble the package so it can be uploaded to <strong>PyPI</strong> and installed with <strong>pip</strong> (name, version, etc.).</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> setup(</span><br><span class="line">   name=<span class="string">&#x27;SoloLearn&#x27;</span>, </span><br><span class="line">   version=<span class="string">&#x27;0.1dev&#x27;</span>,</span><br><span class="line">   packages=[<span class="string">&#x27;sololearn&#x27;</span>,],</span><br><span class="line">   license=<span class="string">&#x27;MIT&#x27;</span>, </span><br><span class="line">   long_description=<span class="built_in">open</span>(<span class="string">&#x27;README.txt&#x27;</span>).read(),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Write Other Files   </p>
</li>
<li><p>Build a source distribution, use the command line to navigate to the directory containing setup.py, and run the command <code>python setup.py sdist</code>.</p>
<ol>
<li>Run <code>python setup.py bdist</code> or, for Windows, <code>python setup.py bdist_wininst</code> to build a binary distribution.</li>
</ol>
</li>
<li><p>Upload the package to <strong>PyPI</strong>. Use <code>python setup.py register</code>, followed by <code>python setup.py sdist upload</code> to upload a package.</p>
</li>
<li><p>install a package with <code>python setup.py install</code>.</p>
</li>
</ol>
<h2 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h2><p>In Python, a module is a file containing Python code that defines functions, classes, and variables that can be used in other Python programs. Modules allow code organization, reusability, and encapsulation.</p>
<p>To use a module in your Python program, you need to import it using the <code>import</code> statement. Here’s an example:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the math module</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using functions from the math module</span></span><br><span class="line"><span class="built_in">print</span>(math.sqrt(<span class="number">25</span>))  <span class="comment"># Output: 5.0</span></span><br><span class="line"><span class="built_in">print</span>(math.pi)        <span class="comment"># Output: 3.141592653589793</span></span><br></pre></td></tr></table></figure>

<p>Python also allows you to import specific functions or variables from a module using the <code>from ... import</code> statement. Here’s an example:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing specific functions from the math module</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> sqrt, pi</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using the imported functions directly</span></span><br><span class="line"><span class="built_in">print</span>(sqrt(<span class="number">25</span>))  <span class="comment"># Output: 5.0</span></span><br><span class="line"><span class="built_in">print</span>(pi)        <span class="comment"># Output: 3.141592653589793</span></span><br></pre></td></tr></table></figure>

<p>You can also import a module with a different name using the <code>as</code> keyword. This is useful when you want to provide a shorter or more descriptive alias for the module. </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the math module with an alias</span></span><br><span class="line"><span class="keyword">import</span> math <span class="keyword">as</span> m</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using the alias to access functions and constants</span></span><br><span class="line"><span class="built_in">print</span>(m.sqrt(<span class="number">25</span>))  <span class="comment"># Output: 5.0</span></span><br><span class="line"><span class="built_in">print</span>(m.pi)        <span class="comment"># Output: 3.141592653589793</span></span><br></pre></td></tr></table></figure>

<p>Python also supports creating your own modules by creating Python files with <code>.py</code> extension. For example, let’s assume we have a file named <code>my_module.py</code> containing the following code:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># my_module.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">greet</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Hello, <span class="subst">&#123;name&#125;</span>!&quot;</span>)</span><br><span class="line"></span><br><span class="line">my_variable = <span class="number">42</span></span><br></pre></td></tr></table></figure>

<p>We can then use this module in another Python program:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing a user-defined module</span></span><br><span class="line"><span class="keyword">import</span> my_module</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using functions and variables from the module</span></span><br><span class="line">my_module.greet(<span class="string">&quot;John&quot;</span>)  <span class="comment"># Output: Hello, John!</span></span><br><span class="line"><span class="built_in">print</span>(my_module.my_variable)  <span class="comment"># Output: 42</span></span><br></pre></td></tr></table></figure>

<p>In this case, we import the <code>my_module</code> module and use the <code>greet</code> function and <code>my_variable</code> variable defined in that module.</p>
<p>Modules provide a way to organize and reuse code in Python, allowing you to break your program into smaller, manageable pieces. They help promote code modularity, readability, and maintainability.</p>
<h3 id="python-m"><a href="#python-m" class="headerlink" title="python -m"></a>python -m</h3><p>The <code>python -m</code> syntax is used to execute a module as a script using the Python interpreter. It allows you to run a Python module directly from the command line <strong>without explicitly specifying the module’s file path</strong> (This is the difference between <code>python -m xxx</code> cand <code>python  /path/to/xxx.py</code>).</p>
<p>When you use the <code>python -m</code> syntax, Python treats the specified argument as a module name and looks for that module in the module search path (<code>sys.path</code>). It then executes the module as if it were a script.</p>
<p>Here’s an example to illustrate the usage of <code>python -m</code>:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python -m unittest discover -s tests -p &#x27;*_test.py&#x27;</span><br></pre></td></tr></table></figure>

<p>In this example, <code>python -m unittest</code> is used to run the <code>unittest</code> module as a script. The <code>discover</code> command is passed as an argument to the <code>unittest</code> module, and it is responsible for automatically discovering and running unit tests.</p>
<p>The <code>-s tests</code> option specifies the starting directory for test discovery. In this case, it looks for tests in the <code>tests</code> directory.</p>
<p>The <code>-p &#39;*_test.py&#39;</code> option defines a pattern for discovering test files. It looks for files that end with <code>_test.py</code>.</p>
<p>By using <code>python -m</code>, you ensure that the <code>unittest</code> module is executed as a script, regardless of the specific location of the <code>unittest</code> module file.</p>
<p>This <code>python -m</code> syntax is useful when working with Python modules that provide command-line interfaces or when you want to run a module as a standalone script without specifying the full path to the module’s file.</p>
<h2 id="init-py"><a href="#init-py" class="headerlink" title="_init_.py"></a>_<em>init</em>_.py</h2><p><a href="https://www.cnblogs.com/Lands-ljk/p/5880483.html">Python <strong>init</strong>.py 作用详解</a></p>
<p><code>__init__.py</code> 文件的作用是将文件夹变为一个Python模块,Python 中的每个模块的包中，都有<code>__init__.py</code> 文件。</p>
<p>通常<code>__init__.py</code> 文件为空，但是我们还可以为它增加其他的功能。我们在导入一个包时，实际上是导入了它的<code>__init__.py</code>文件。这样我们可以在<code>__init__.py</code>文件中批量导入我们所需要的模块，而不再需要一个一个的导入。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># package</span><br><span class="line"># __init__.py</span><br><span class="line">import re</span><br><span class="line">import urllib</span><br><span class="line">import sys</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"># a.py</span><br><span class="line">import package </span><br><span class="line">print(package.re, package.urllib, package.sys, package.os)</span><br></pre></td></tr></table></figure>

<p>注意这里访问<code>__init__.py</code>文件中的引用文件，需要加上包名。</p>
<p><code>__init__.py</code>中还有一个重要的变量，<code>__all__</code>, 它用来将模块全部导入。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># __init__.py</span><br><span class="line">__all__ = [&#x27;os&#x27;, &#x27;sys&#x27;, &#x27;re&#x27;, &#x27;urllib&#x27;]</span><br><span class="line"></span><br><span class="line"># a.py</span><br><span class="line">from package import *</span><br></pre></td></tr></table></figure>

<p>这时就会把注册在<code>__init__.py</code>文件中<code>__all__</code>列表中的模块和包导入到当前文件中来。</p>
<p>可以了解到，<code>__init__.py</code>主要控制包的导入行为。</p>
<h2 id="setup-py"><a href="#setup-py" class="headerlink" title="setup.py"></a>setup.py</h2><p><a href="https://setuptools.readthedocs.io/en/latest/">setuptools</a> is the packaging tool for python (like maven&#x2F;gradle for java?)</p>
<p>When coding in local, you can use <code>pip install</code> to install dependency. However, when deploy a python project, you need to package all dependency, modules into one project. You need <code>setup.py</code>.</p>
<p>When organize python in modules, you need to know and import the function in other modules. In compilation stage, you need to feel the other modules&amp;packages. <code>setup.py</code> does the magic. (This is my guess)</p>
<h2 id="Packaging-for-users"><a href="#Packaging-for-users" class="headerlink" title="Packaging for users"></a>Packaging for users</h2><p>For normal users who don’t have python on computer, we need to convert scripts to executables for them.</p>
<p>For Windows, <strong>py2exe</strong> or <strong>PyInstaller</strong> or <strong>cx_Freeze</strong> can be used to package a Python script, along with the libraries it requires, into a single executable.<br>For Macs, use <strong>py2app</strong>, <strong>PyInstaller</strong> or <strong>cx_Freeze</strong>.</p>
<h1 id="Some-special-grammars"><a href="#Some-special-grammars" class="headerlink" title="Some special grammars"></a>Some special grammars</h1><h2 id="if-name-x3D-x3D-‘-main-’"><a href="#if-name-x3D-x3D-‘-main-’" class="headerlink" title="if _name_ &#x3D;&#x3D; ‘__main__’"></a>if _<em>name</em>_ &#x3D;&#x3D; ‘__main__’</h2><p><a href="https://blog.csdn.net/yjk13703623757/article/details/77918633">如何简单地理解Python中的if _<em>name</em>_ &#x3D;&#x3D; ‘__main__’</a></p>
<p>If you are <code>test.py</code>, then other module knows you as <code>__name__==&#39;test&#39;</code>, and you know yourself as <code>__name==&#39;__main__&#39;</code>.</p>
<p>The code block in <code>if __name__ == &#39;__main__&#39;</code> will only be executed when the file is executed directly. If other module import <code>test.py</code> as module, the code block won’t be executed.</p>
<p>It’s kind of like main function in java&#x2F;c, but with big difference. Python is <strong>a script language</strong> — interpretive execution, which can be run without any so-called main entry. You don’t need to make <code>test.py</code> runnable by providing <code>main</code>, but you can provide <code>if __name__ == &#39;__main__&#39;</code> if you want this block only executed when called directly rather than as module.</p>
<h2 id="else"><a href="#else" class="headerlink" title="else"></a>else</h2><p>The <strong>else</strong> statement can be used in:</p>
<ul>
<li>the <strong>if</strong> statement</li>
<li>a <strong>for</strong> or <strong>while</strong> loop, the code within it is called if the loop finishes normally &#x2F; completely (when a <strong>break</strong> statement does not cause an exit from the loop).</li>
<li>the <strong>try&#x2F;except</strong> statements, the code within it is only executed if no error occurs in the <strong>try</strong> statement.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">if_else</span>(<span class="params">a</span>):</span><br><span class="line">  <span class="keyword">if</span> a == <span class="string">&#x27;if&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;this is in if&#x27;</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;this is not if!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">for_else</span>():</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">2</span>:</span><br><span class="line">      <span class="comment"># print(&#x27;Will get here. The else won\&#x27;t be executed&#x27;)</span></span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;first for finish completely&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">10</span>:</span><br><span class="line">      <span class="comment"># print(&#x27;Never get here. The else will be executed&#x27;)</span></span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;second for finish completely&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">try_else</span>():</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">5</span>/<span class="number">0</span>)</span><br><span class="line">  <span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;there is exception, the first else won\&#x27;t be executed&#x27;</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;first try finished successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">5</span>/<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;there is no exception, the else will be executed&#x27;</span>)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;second try finished successfully&#x27;</span>)</span><br><span class="line"></span><br><span class="line">if_else(<span class="string">&#x27;not_if&#x27;</span>) <span class="comment"># this is not if!</span></span><br><span class="line">for_else() <span class="comment"># second for finish completely</span></span><br><span class="line">try_else()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">there is exception, the first else won&#x27;t be executed</span></span><br><span class="line"><span class="string">5.0</span></span><br><span class="line"><span class="string">second try finished successfully</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h1 id="class"><a href="#class" class="headerlink" title="class"></a>class</h1><p>Classes are created using the keyword <strong>class</strong> and an indented block, which contains class <strong>methods</strong> (which are functions). All methods must have <strong>self</strong> as their first parameter, you do not need to include it when you call the methods. Within a method definition, <strong>self</strong> refers to the instance calling the method.</p>
<p>To inherit a class from another class, put the superclass name in parentheses after the class name.</p>
<p>Classes can also have <strong>class attributes</strong>, created by assigning variables within the body of the class. These can be accessed either from instances of the class, or the class itself.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Animal</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, color</span>):</span><br><span class="line">    self.name = name</span><br><span class="line">    self.color = color</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">shout</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;ha&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dog</span>(<span class="title class_ inherited__">Animal</span>):</span><br><span class="line">  legs = <span class="number">4</span>    <span class="comment"># the class attribute</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">shout</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;wong&#x27;</span>)</span><br><span class="line">    <span class="built_in">super</span>().shout()    <span class="comment"># call super method</span></span><br><span class="line"></span><br><span class="line">Dog.legs    <span class="comment"># 4</span></span><br><span class="line">d = Dog(<span class="string">&#x27;heidou&#x27;</span>, <span class="string">&#x27;black&#x27;</span>)</span><br><span class="line">d.legs    <span class="comment"># 4</span></span><br><span class="line">d.name     <span class="comment"># &#x27;heidou&#x27;</span></span><br><span class="line">d.shout()    </span><br><span class="line"><span class="comment"># wong</span></span><br><span class="line"><span class="comment"># ha</span></span><br></pre></td></tr></table></figure>

<h2 id="new-vs-init"><a href="#new-vs-init" class="headerlink" title="__new__ vs __init__"></a><code>__new__</code> vs <code>__init__</code></h2><p><a href="https://www.agiliq.com/blog/2012/06/__new__-python/">_<em>new</em>_ in python</a></p>
<p>_<em>new</em>_ is a static method which creates an instance. It allocates memory for an object. __init__ initialize the value of the object (instance). <code>__new__</code> is rarely overriden.</p>
<p>When you are instantiate an instance by calling the class, the <code>__new__</code> gets called first to create the object in memory, and then <code>__init__</code> is called to initialize it.</p>
<p>_<em>new</em>_ must return the created object. Only when <code>__new__</code> returns the created instance then <code>__init__</code> gets called. If <code>__new__</code> does not return an instance then <code>__init__</code> would not be called.</p>
<p>The <code>__new__</code> definition:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">__new__(cls, *args, **kwargs)    </span><br></pre></td></tr></table></figure>

<p>An example:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime <span class="keyword">as</span> dt</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__new__</span>(<span class="params">cls, *args, **kwargs</span>):</span><br><span class="line">    <span class="built_in">print</span>(cls)</span><br><span class="line">    <span class="built_in">print</span>(args)</span><br><span class="line">    <span class="built_in">print</span>(kwargs)</span><br><span class="line">    obj = <span class="built_in">object</span>.__new__(cls)</span><br><span class="line">    <span class="built_in">setattr</span>(obj, <span class="string">&#x27;created_at&#x27;</span>, dt.datetime.now())</span><br><span class="line">    <span class="keyword">return</span> obj <span class="comment"># if no return here, __init__ won&#x27;t be called later</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, a, named</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;in init&#x27;</span>)</span><br><span class="line">    self.a = a</span><br><span class="line">    self.b = named</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;a=&#123;0&#125;, b=&#123;1&#125;, created_at: &#123;2&#125;&#x27;</span>.<span class="built_in">format</span>(self.a, self.b, self.created_at)</span><br><span class="line"></span><br><span class="line">a = A(<span class="number">1</span>, named=<span class="number">2</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&lt;class &#x27;__main__.A&#x27;&gt;</span></span><br><span class="line"><span class="string">(1,)</span></span><br><span class="line"><span class="string">&#123;&#x27;named&#x27;: 2&#125;</span></span><br><span class="line"><span class="string">in init</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(a) <span class="comment"># a=1, b=2, created_at: 2020-10-19 15:22:19.558501</span></span><br></pre></td></tr></table></figure>

<h2 id="del"><a href="#del" class="headerlink" title="__del__"></a><code>__del__</code></h2><p>Destruction of an object occurs when its <strong>reference count</strong> reaches zero.</p>
<p>The <strong>del</strong> statement reduces the reference count of an object by one, and this often leads to its deletion.<br>The magic method for the <strong>del</strong> statement is <code>__del__</code>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="number">5</span></span><br><span class="line"><span class="keyword">del</span> a</span><br></pre></td></tr></table></figure>

<h2 id="private"><a href="#private" class="headerlink" title="private"></a>private</h2><p>The Python philosophy is often stated as <strong>“we are all consenting adults here”</strong>, meaning that you shouldn’t put arbitrary restrictions on accessing parts of a class. Hence there are no ways of enforcing a method or attribute be strictly private. However, there are ways to discourage people from accessing parts of a class, such as by denoting that it is an implementation detail, and should be used at their own risk.</p>
<p>Weakly private methods and attributes have a <strong>single underscore</strong> at the beginning. This signals that they are private, and <strong>shouldn’t be</strong> used by external code. Its only actual effect is that <strong>from module_name import *</strong> won’t import variables that start with a single underscore.</p>
<p>Strongly private methods and attributes have a <strong>double underscore</strong> at the beginning of their names. This causes their names to be mangled, which means that they can’t be accessed from outside the class by the name. The purpose of this isn’t to ensure that they are kept private, but to avoid bugs if there are subclasses that have methods or attributes with the same names. Basically, Python protects those members by internally changing the name to include the class name.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>:</span><br><span class="line">  __egg = <span class="number">7</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, a</span>):</span><br><span class="line">    self.__a = a</span><br><span class="line"></span><br><span class="line">A._A__egg <span class="comment"># 7</span></span><br><span class="line">a = A(<span class="string">&#x27;a&#x27;</span>)</span><br><span class="line">a._A__a <span class="comment"># &#x27;a&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="class-methods-vs-instance-methods-vs-static-methods"><a href="#class-methods-vs-instance-methods-vs-static-methods" class="headerlink" title="class methods vs instance methods vs static methods"></a>class methods vs instance methods vs static methods</h2><p><strong>Instance methods</strong> are called by a instance, which is passed to the <strong>self</strong> parameter of the method.</p>
<p><strong>Class methods</strong> are called by a class, which is passed to the <strong>cls</strong> parameter of the method.<br>A common use of these are factory methods, which instantiate an instance of a class, using different parameters than those usually passed to the class constructor.<br>Class methods are marked with a <strong>classmethod decorator</strong>.</p>
<p><strong>Static methods</strong> are similar to class methods, except they don’t receive any additional arguments; they are identical to normal functions that belong to a class.<br>They are marked with the <strong>staticmethod</strong> decorator.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Rectangle</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, a, b</span>):</span><br><span class="line">    self.a = a</span><br><span class="line">    self.b = b</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">area</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">print</span>(self.a * self.b)</span><br><span class="line"><span class="meta">  @classmethod</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">new_square</span>(<span class="params">cls, a</span>):</span><br><span class="line">    <span class="keyword">return</span> cls(a, a)</span><br><span class="line"><span class="meta">  @staticmethod</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">validate_int</span>(<span class="params">a</span>):</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(a, <span class="built_in">int</span>), <span class="string">&#x27;must be int&#x27;</span></span><br><span class="line"></span><br><span class="line">r = Rectangle(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">r.area() <span class="comment"># 20</span></span><br><span class="line">s = Rectangle.new_square(<span class="number">4</span>)</span><br><span class="line">s.area() <span class="comment"># 16</span></span><br><span class="line">Rectangle.validate_int(<span class="string">&#x27;fd&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><p><strong>Properties</strong> are created by putting the <strong>property</strong> decorator above a method, which means when the instance attribute with the same name as the method is accessed, the method will be called instead.<br>One common use of a property is to make an attribute <strong>read-only</strong>.</p>
<p>Properties can also be set by defining <strong>setter&#x2F;getter</strong> functions.<br>The <strong>setter</strong> function sets the corresponding property’s value. To define a <strong>setter</strong>, you need to use a decorator of the same name as the property, followed by a dot and the <strong>setter</strong> keyword.</p>
<p>​&#96;&#96;&#96;python<br>class Pizza:<br>  def <strong>init</strong>(self, a):<br>    self._a &#x3D; a<br>  @property<br>  def a_list(self):<br>    return [self._a] * 10<br>  @a_list.setter<br>  def a_list(self, value):<br>    self._a &#x3D; value[0]</p>
<p>p &#x3D; Pizza(7)<br>p.a_list # [7, 7, 7, 7, 7, 7, 7, 7, 7, 7]<br>p.a_list &#x3D; [1]<br>p.a_list # [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## Magic Methods</span><br><span class="line"></span><br><span class="line">**Magic methods** are special methods which have **double underscores** at the beginning and end of their names. They are used to create functionality that can&#x27;t be represented as a normal method.</span><br><span class="line"></span><br><span class="line">`__init__` is the constructor.</span><br><span class="line"></span><br><span class="line">Magic methods for common operators (operator overload):</span><br><span class="line"></span><br><span class="line">`__add__` for -</span><br><span class="line">`__sub__` for -</span><br><span class="line">`__mul__` for *</span><br><span class="line">`__truediv__` for /</span><br><span class="line">`__floordiv__` for //</span><br><span class="line">`__mod__` for %</span><br><span class="line">`__pow__` for **</span><br><span class="line">`__and__` for &amp;</span><br><span class="line">`__xor__` for ^</span><br><span class="line">`__or__` for |</span><br><span class="line"></span><br><span class="line">Magic methods for comparisons (If `__ne__` is not implemented, it returns the opposite of `__eq__`):</span><br><span class="line"></span><br><span class="line">`__lt__` for &lt;</span><br><span class="line">`__le__` for &lt;=</span><br><span class="line">`__eq__` for ==</span><br><span class="line">`__ne__` for !=</span><br><span class="line">`__gt__` for &gt;</span><br><span class="line">`__ge__` for &gt;=</span><br><span class="line"></span><br><span class="line">Magic methods for making classes act like containers:</span><br><span class="line">`__len__` for len()</span><br><span class="line">`__getitem__` for indexing</span><br><span class="line">`__setitem__` for assigning to indexed values</span><br><span class="line">`__delitem__` for deleting indexed values</span><br><span class="line">`__iter__` for iteration over objects (e.g., in for loops)</span><br><span class="line">`__contains__` for in</span><br><span class="line"></span><br><span class="line">Magic methods for converting objects to built-in types:</span><br><span class="line">`__int__` for int()</span><br><span class="line">`__str__` for str()</span><br><span class="line"></span><br><span class="line">### `r` methods&lt;a name = &quot;r-methods&quot; /&gt;</span><br><span class="line"></span><br><span class="line">There are equivalent **r** methods for all magic methods that overloads operators. For example, the expression **x + y** is translated into **x.__add__(y)**. However, if x hasn&#x27;t implemented __add__, and x and y are of different types, then **y.__radd__(x)** is called.</span><br><span class="line"></span><br><span class="line">&quot;r&quot; stands for &quot;right&quot;, meaning that the operator passed is on the right. If the conversion of the 1st type to the 2nd isn&#x27;t supported, it simply tries calling the inverse one (2nd conversion to the 1st) for the other type.</span><br><span class="line"></span><br><span class="line">**r** methods can be used when you want to overload operator between a thirt lib type and your type. Since you may not modify the third library, you can add the reverse **r** method in your type.</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">class PairNumber:</span><br><span class="line">def __init__(self, n1, n2):</span><br><span class="line">  self.n1 = n1</span><br><span class="line">  self.n2 = n2</span><br><span class="line">def __floordiv__(self, other):</span><br><span class="line">  return PairNumber(self.n1//other.n1, self.n2 // other.n2)</span><br><span class="line">def __rtruediv__(self, other):</span><br><span class="line">  return PairNumber(other/self.n1, other/self.n2)</span><br><span class="line">def __repr__(self):</span><br><span class="line">  return &#x27;PairNumber&#123;0&#125;&#x27;.format((self.n1, self.n2))</span><br><span class="line">def __str__(self):</span><br><span class="line">  return str((self.n1, self.n2))</span><br><span class="line"></span><br><span class="line">class IntPairNumber(PairNumber):</span><br><span class="line">def __int__(self):</span><br><span class="line">  return self.n1 + self.n2</span><br><span class="line"></span><br><span class="line">p1 = IntPairNumber(4, 10)</span><br><span class="line">p2 = IntPairNumber(3, 19)</span><br><span class="line">p1 // p2 # PairNumber(1, 0)</span><br><span class="line">print(p1 // p2) # (1, 0)</span><br><span class="line">str(2 / p1)        # PairNumber(0.5, 0.2)</span><br><span class="line">int(p1)                # 14</span><br></pre></td></tr></table></figure>

<h3 id="call-method"><a href="#call-method" class="headerlink" title="__call__ method"></a><code>__call__</code> method</h3><p><code>__call__</code> method can call an object as a function. Thus you can transfer the object as a func parameter in a function.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PairNumber</span>:</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n1, n2</span>):</span><br><span class="line">    self.n1 = n1</span><br><span class="line">    self.n2 = n2</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, other</span>):</span><br><span class="line">    <span class="keyword">return</span> self.n1 + self.n2 + other</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">addTwice</span>(<span class="params">func, other</span>):</span><br><span class="line">  <span class="keyword">return</span> func(other) + other</span><br><span class="line"></span><br><span class="line">p1 = PairNumber(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">p1(<span class="number">4</span>)        <span class="comment"># 7</span></span><br><span class="line">addTwice(p1, <span class="number">4</span>)    <span class="comment"># 11</span></span><br></pre></td></tr></table></figure>

<h3 id="str-vs-repr"><a href="#str-vs-repr" class="headerlink" title="__str__ vs __repr__"></a><code>__str__</code> vs <code>__repr__</code></h3><p>In short, the goal of <code>__repr__</code> is to be unambiguous and <code>__str__</code> is to be readable. If <code>__repr__</code> is defined, and <code>__str__</code> is not, the object will behave as though <code>__str__=__repr__</code>.</p>
<p>The commandline will show the content in <code>__repr__</code> when you simply type the object. And when print(some_obj), it will show the content in <code>__str__</code> of that object. So many would say: <code>__repr__</code> is for developers, <code>__str__</code> is for customers. e.g. obj &#x3D; uuid.uuid1(), obj._<em>str__() is “2d7fc7f0-7706-11e9-94ae-0242ac110002” and obj.__repr</em>_() is “UUID(‘2d7fc7f0-7706-11e9-94ae-0242ac110002’)”.</p>
<p><strong>To sum up</strong>: implement <code>__repr__</code> for any class you implement. This should be second nature. Implement <code>__str__</code> if you think it would be useful to have a string version which errs on the side of readability.</p>
<p>See example in <a href="#r-methods">r <strong>method</strong></a></p>
<h1 id="Opening-Files"><a href="#Opening-Files" class="headerlink" title="Opening Files"></a>Opening Files</h1><p>You can specify the <strong>mode</strong> used to open a file by applying a second argument to the <strong>open</strong> function.<br>Sending “r” means open in read mode, which is the default.<br>Sending “w” means write mode, for <em><strong>rewriting</strong></em> the contents of a file.<br>Sending “a” means append mode, for adding new content to the end of the file.</p>
<p>Adding “b” to a mode opens it in <strong>binary</strong> mode, which is used for non-text files (such as image and sound files).<br><strong>For example:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># write mode</span></span><br><span class="line"><span class="built_in">open</span>(<span class="string">&quot;filename.txt&quot;</span>, <span class="string">&quot;w&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># read mode</span></span><br><span class="line"><span class="built_in">open</span>(<span class="string">&quot;filename.txt&quot;</span>, <span class="string">&quot;r&quot;</span>)</span><br><span class="line"><span class="built_in">open</span>(<span class="string">&quot;filename.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># binary write mode</span></span><br><span class="line"><span class="built_in">open</span>(<span class="string">&quot;filename.txt&quot;</span>, <span class="string">&quot;wb&quot;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>You can use the + sign with each of the modes above to give them extra access to files. For example, r+ opens the file for both reading and writing.</p>
<p>Use <code>help(open)</code> to see the complete file modes supported.</p>
</blockquote>
<ul>
<li><p>“r”<br>Read from file - YES<br>Write to file - NO<br><strong>Create file if not exists - NO</strong><br>Truncate file to zero length - NO<br>Cursor position - BEGINNING</p>
</li>
<li><p>“r+”  &#x3D;&#x3D;&#x3D;&#x3D;&gt; Opens a file for both reading and writing (write from the current cursor, that is, if you already call <code>file.read()</code>, then it means cursor is already at the end, then the writing is appending. However, if you start with <code>file.write()</code>, the cursor is at the beginning, thus it will <em><strong>rewrite</strong></em> from the beginning)<br>Read from file - YES<br>Write to file - YES<br><strong>Create file if not exists - NO</strong><br><strong>Truncate file to zero length - NO</strong><br>Cursor position - BEGINNING</p>
</li>
<li><p>“w”<br>Read from file - NO<br>Write to file - YES<br><strong>Create file if not exists - YES</strong><br><strong>Truncate file to zero length - YES</strong><br>Cursor position - BEGINNING</p>
</li>
<li><p>“w+” &#x3D;&#x3D;&#x3D;&gt; Opens a file for both writing and reading<br>Read from file - YES<br>Write to file - YES<br><strong>Create file if not exists - YES</strong><br><strong>Truncate file to zero length - YES</strong><br>Cursor position - BEGINNING</p>
</li>
<li><p>“a”<br>Read from file - NO<br>Write to file - YES<br><strong>Create file if not exists - YES</strong><br><strong>Truncate file to zero length - NO</strong><br>Cursor position - END</p>
</li>
<li><p>“a+” &#x3D;&#x3D;&#x3D;&gt; Opens a file for both appending and reading<br>Read from file - YES<br>Write to file - YES<br><strong>Create file if not exists - YES</strong><br><strong>Truncate file to zero length - NO</strong><br>Cursor position - END</p>
</li>
</ul>
<h1 id="Iterable-containers"><a href="#Iterable-containers" class="headerlink" title="Iterable containers"></a>Iterable containers</h1><h2 id="List-x2F-string-x2F-tuple-slicing"><a href="#List-x2F-string-x2F-tuple-slicing" class="headerlink" title="List&#x2F;string&#x2F;tuple slicing"></a>List&#x2F;string&#x2F;tuple slicing</h2><p>slice can have 3 parameters:</p>
<ol>
<li>Start index (included, count from end of the list if negative, default as 0)</li>
<li>End index (excluded, count from end of the list if negative, default as end of the list)</li>
<li>Step</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">str</span>    = <span class="string">&#x27;0123456&#x27;</span></span><br><span class="line">tp = <span class="built_in">tuple</span>(<span class="built_in">str</span>)    <span class="comment"># (&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;)</span></span><br><span class="line">lst = <span class="built_in">list</span>(<span class="built_in">str</span>) <span class="comment"># [&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># get first 2</span></span><br><span class="line"><span class="built_in">str</span>[:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># get last 2</span></span><br><span class="line"><span class="built_in">str</span>[<span class="number">5</span>:]</span><br><span class="line"><span class="built_in">str</span>[-<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># get odd number (the third number is the step)</span></span><br><span class="line"><span class="built_in">str</span>[<span class="number">1</span>::<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># reverse</span></span><br><span class="line"><span class="built_in">str</span>[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># get the 3 number from 1(included) and reverse it</span></span><br><span class="line"><span class="built_in">str</span>[<span class="number">3</span>:<span class="number">0</span>:-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<h2 id="List-Comprehensions"><a href="#List-Comprehensions" class="headerlink" title="List Comprehensions"></a>List Comprehensions</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cubes = [i**<span class="number">3</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]    <span class="comment"># [0, 1, 8, 27, 64]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># with if statement</span></span><br><span class="line">evenSquares = [i**<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>) <span class="keyword">if</span> i ** <span class="number">2</span> % <span class="number">2</span> == <span class="number">0</span>] <span class="comment"># [0, 4, 16]</span></span><br><span class="line">evenSquares = [i**<span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">5</span>,<span class="number">2</span>)] <span class="comment"># [0, 4, 16]</span></span><br><span class="line">evens =  [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>) <span class="keyword">if</span> i%<span class="number">2</span> == <span class="number">0</span>] <span class="comment"># [0, 2, 4]</span></span><br></pre></td></tr></table></figure>

<h3 id="all-amp-any"><a href="#all-amp-any" class="headerlink" title="all &amp; any"></a>all &amp; any</h3><p>use all() &#x2F; any() to check a list of bool.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">all</span>([i &gt; <span class="number">5</span> <span class="keyword">for</span> i <span class="keyword">in</span> nums]):</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&quot;All larger than 5&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">any</span>([i % <span class="number">2</span> == <span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> nums]):</span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&quot;At least one is even&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Tuple"><a href="#Tuple" class="headerlink" title="Tuple"></a>Tuple</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># define a tuple</span></span><br><span class="line">t1 = <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span></span><br><span class="line">t2 = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">t1 == t2 <span class="comment"># True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># unpack a tuple</span></span><br><span class="line">a,b,*c,d = <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">a <span class="comment"># 0</span></span><br><span class="line">b <span class="comment"># 1</span></span><br><span class="line">c <span class="comment"># [2,3,4,5,6,7,8]</span></span><br><span class="line">d <span class="comment"># 9</span></span><br></pre></td></tr></table></figure>

<h2 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h2><p><strong>Generators</strong> are a type of iterable, like lists or tuples. Unlike lists, they <strong>don’t allow indexing with arbitrary indices</strong>, but they can still be iterated through with <strong>for</strong> loops.<br>They can be created using functions and the <strong>yield</strong> statement.</p>
<p>Using <strong>generators</strong> results in improved performance, which is the result of the lazy (on demand) generation of values, which translates to lower memory usage. Furthermore, we do not need to wait until all the elements have been generated before we start to use them.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">spell</span>():</span><br><span class="line">  word = <span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="keyword">for</span> c <span class="keyword">in</span> <span class="string">&#x27;spam&#x27;</span>:</span><br><span class="line">    word += c</span><br><span class="line">    <span class="keyword">yield</span> word</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> spell():</span><br><span class="line">  <span class="built_in">print</span>(w)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(spell()))    <span class="comment"># to normal list [&#x27;s&#x27;, &#x27;sp&#x27;, &#x27;spa&#x27;, &#x27;spam&#x27;]</span></span><br></pre></td></tr></table></figure>

<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>Sets can be combined using mathematical operations (list, tuple, dict do not support these operators)<br>The <strong>union</strong> operator <strong>|</strong> combines two sets to form a new one containing items in either.<br>The <strong>intersection</strong> operator <strong>&amp;</strong> gets items only in both.<br>The <strong>difference</strong> operator <strong>-</strong> gets items in the first set but not in the second.<br>The <strong>symmetric difference</strong> operator <strong>^</strong> gets items in either set, but not both.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s1 = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;</span><br><span class="line">s2 = &#123;<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(s1 | s2) <span class="comment"># union: &#123;1,2,3,4,5,6,7&#125;</span></span><br><span class="line"><span class="built_in">print</span>(s1 &amp; s2) <span class="comment"># intersection: &#123;3,4,5&#125;</span></span><br><span class="line"><span class="built_in">print</span>(s1 - s2) <span class="comment"># in s1 but not s2: &#123;1,2&#125;</span></span><br><span class="line"><span class="built_in">print</span>(s2 - s1) <span class="comment"># in s2 but not s1: &#123;6,7&#125;</span></span><br><span class="line"><span class="built_in">print</span>(s1 ^ s2) <span class="comment"># not in s1 or not in s2: &#123;1,2,6,7&#125;</span></span><br></pre></td></tr></table></figure>

<h1 id="String-format"><a href="#String-format" class="headerlink" title="String format"></a>String format</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">####### hello world hello</span></span><br><span class="line"><span class="string">&#x27;&#123;0&#125; &#123;1&#125; &#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="string">&#x27;hello&#x27;</span>, <span class="string">&#x27;world&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#123;x&#125; &#123;y&#125; &#123;x&#125;&#x27;</span>.<span class="built_in">format</span>(x=<span class="string">&#x27;hello&#x27;</span>, y=<span class="string">&#x27;world&#x27;</span>)    <span class="comment"># use name</span></span><br><span class="line"></span><br><span class="line"><span class="string">r&#x27;fdjks/fjdkls&#x27;</span> <span class="comment"># r means raw, so you don&#x27;t need to escape any character</span></span><br></pre></td></tr></table></figure>

<h1 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h1><h2 id="Function-Arguments"><a href="#Function-Arguments" class="headerlink" title="Function Arguments"></a>Function Arguments</h2><p>Using <strong><code>*args</code></strong> as a function parameter enables you to pass an arbitrary number of arguments to that function. The arguments are then accessible as the <strong>tuple</strong> args in the body of the function.</p>
<p>*<strong>*kwargs</strong> (standing for keyword arguments) allows you to handle named arguments that you have not defined in advance. The keyword arguments return a dictionary in which the keys are the argument names, and the values are the argument values.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">some_func</span>(<span class="params">a, some_default=<span class="string">&#x27;this is a default value&#x27;</span>, *args, **kwargs</span>):</span><br><span class="line">  <span class="built_in">print</span>(a)</span><br><span class="line">  <span class="built_in">print</span>(some_default)</span><br><span class="line">  <span class="built_in">print</span>(args)</span><br><span class="line">  <span class="built_in">print</span>(kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">some_func(<span class="string">&#x27;this is a&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">this is a</span></span><br><span class="line"><span class="string">this is a default value</span></span><br><span class="line"><span class="string">()</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">some_func(<span class="string">&#x27;this is a&#x27;</span>, <span class="string">&#x27;value rather than default&#x27;</span>, <span class="string">&#x27;first arg&#x27;</span>, <span class="string">&#x27;second arg&#x27;</span>, first_kwarg=<span class="string">&#x27;1&#x27;</span>, second_kwarg=<span class="string">&#x27;2&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">this is a</span></span><br><span class="line"><span class="string">value rather than default</span></span><br><span class="line"><span class="string">(&#x27;first arg&#x27;, &#x27;second arg&#x27;)</span></span><br><span class="line"><span class="string">&#123;&#x27;first_kwarg&#x27;: &#x27;1&#x27;, &#x27;second_kwarg&#x27;: &#x27;2&#x27;&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h2><p>A lambda defines an anoymous function. It consists of the <strong>lambda</strong> keyword followed by a list of arguments, a colon, and the <strong>expression</strong> to evaluate and return.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## use named function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cube</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">3</span>    </span><br><span class="line"><span class="built_in">print</span>(cube(<span class="number">3</span>))    <span class="comment"># 27</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## use lambda</span></span><br><span class="line">cube = <span class="keyword">lambda</span> x: x ** <span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(cube(<span class="number">3</span>))    <span class="comment"># 27</span></span><br></pre></td></tr></table></figure>

<h3 id="Common-used-functors"><a href="#Common-used-functors" class="headerlink" title="Common used functors:"></a>Common used functors:</h3><p>map, filter</p>
<p>module <strong>itertools</strong> is a standard library that contains several functions that are useful in FP.</p>
<p>One type of function it produces is infinite iterators.<br>The function <strong>count</strong> counts up infinitely from a value.<br>The function <strong>cycle</strong> infinitely iterates through an iterable (for instance a list or string).<br>The function <strong>repeat</strong> repeats an object, either infinitely or a specific number of times.<br><strong>takewhile -</strong> takes items from an iterable while a predicate function remains true;<br><strong>chain -</strong> combines several iterables into one long one;<br><strong>accumulate -</strong> returns a running total of values in an iterable.<br><strong>product</strong> - get possible combinations of some iterables<br><strong>permutation</strong> - get permutation of an iterable</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> accumulate, takewhile, product, permutations</span><br><span class="line"></span><br><span class="line">nums = <span class="built_in">list</span>(accumulate(<span class="built_in">range</span>(<span class="number">5</span>)))    <span class="comment"># [0,1,3,6,10]</span></span><br><span class="line"><span class="built_in">list</span>(takewhile(<span class="keyword">lambda</span> x: x &lt;<span class="number">6</span>, nums)) <span class="comment"># [0,1,3]</span></span><br><span class="line"></span><br><span class="line">letters = (<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="built_in">list</span>(product(letters, <span class="built_in">range</span>(<span class="number">2</span>)))    <span class="comment"># [(a,0), (a,1), (b,0), (b,1)] The result is always iterable of tuple</span></span><br><span class="line"><span class="built_in">list</span>(permutations(letters))    <span class="comment"># [(&#x27;a&#x27;, &#x27;b&#x27;), (&#x27;b&#x27;, &#x27;a&#x27;)]</span></span><br></pre></td></tr></table></figure>

<h2 id="Decorator"><a href="#Decorator" class="headerlink" title="Decorator"></a>Decorator</h2><p>Decorators provide a way to modify functions using other functions.</p>
<p>Python provides support to wrap a function in a decorator by pre-pending the function definition with a decorator name and the @ symbol.</p>
<blockquote>
<p>You can use a decorator if you want to modify more than one function in the same way. It’s the common template of multiple functions.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="comment">## define two decorators</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">input_print_deca</span>(<span class="params">func</span>):</span><br><span class="line">  <span class="comment">## this annotation make the callback return the original func&#x27;s name instead of the wrap function&#x27;s name.</span></span><br><span class="line"><span class="meta">  @wraps</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">wrap</span>():</span><br><span class="line">    x = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;x: &#x27;</span>))</span><br><span class="line">    y = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&#x27;y: &#x27;</span>))</span><br><span class="line">    res = func(x, y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;the res: &#123;0&#125;&#x27;</span>.<span class="built_in">format</span>(res))</span><br><span class="line">  <span class="keyword">return</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="comment">## use a decorator, and replace the origin method with the decorated one</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">x,y</span>):</span><br><span class="line">  <span class="keyword">return</span> x+y</span><br><span class="line">add = input_print_deca(add)    <span class="comment"># if the add method is a function from third library, you may want to add function to it, this way will help. However, you don&#x27;t need to replace the original method, and you can just assign it to a new one.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## use @ grammar to quick add common code to a function. This has the same effect as the above equation.</span></span><br><span class="line"><span class="meta">@input_print_deca</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">diff</span>(<span class="params">x, y</span>):</span><br><span class="line">  <span class="keyword">return</span> x - y</span><br><span class="line"><span class="meta">@input_print_deca</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">divide</span>(<span class="params">x, y</span>):</span><br><span class="line">  <span class="keyword">assert</span> y != <span class="number">0</span>, <span class="string">&#x27;cannot divide zero&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> x / y</span><br><span class="line"></span><br><span class="line"><span class="comment">## call the decorated functions, notice now there&#x27;s no input</span></span><br><span class="line">add()</span><br><span class="line">diff()</span><br><span class="line">divide()</span><br></pre></td></tr></table></figure>

<p>A single function can have multiple decorators. They are used from top to down. Everytime the original func is called, the current decorator is used.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## define anther two decorators</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">success_deca</span>(<span class="params">func</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">wrap</span>(<span class="params">x,y</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;in success deca&#x27;</span>)</span><br><span class="line">    res = func(x,y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;yay success!&#x27;</span> + <span class="string">&#x27;*&#x27;</span> * <span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">  <span class="keyword">return</span> wrap</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">success_deca2</span>(<span class="params">func</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">wrap</span>(<span class="params">x,y</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;in success deca2&#x27;</span>)</span><br><span class="line">    res = func(x,y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;yay success 2&#x27;</span> + <span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">  <span class="keyword">return</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="comment">## use all these decorators</span></span><br><span class="line"><span class="meta">@input_print_deca</span></span><br><span class="line"><span class="meta">@success_deca</span></span><br><span class="line"><span class="meta">@success_deca</span></span><br><span class="line"><span class="meta">@success_deca2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">diff</span>(<span class="params">x,y</span>):</span><br><span class="line">    <span class="keyword">return</span> x - y</span><br><span class="line"></span><br><span class="line"><span class="comment">## call the decorated func</span></span><br><span class="line">diff()</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">x: 5        # the call to diff() trigger the input_print_deca decorator</span></span><br><span class="line"><span class="string">y: 6</span></span><br><span class="line"><span class="string">in success deca            # in input_print_deca, the call to func trigger the first success_deca decorator</span></span><br><span class="line"><span class="string">in success deca            # in success_deca, the call to func trigger the second success_deca decorator</span></span><br><span class="line"><span class="string">in success deca2        # in the second success_deca, the call to func trigger the success_deca2 decorator</span></span><br><span class="line"><span class="string">yay success 2----------    # the success_deca2 first return</span></span><br><span class="line"><span class="string">yay success!**********    # the second success_deca return</span></span><br><span class="line"><span class="string">yay success!**********    # the first success_deca return</span></span><br><span class="line"><span class="string">the res: -1                            # the input_print_deca return</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="Generator-1"><a href="#Generator-1" class="headerlink" title="Generator"></a>Generator</h2><p>see <strong>Iterable Containers &#x2F; Generator</strong> above.</p>
<h2 id="async-x2F-await"><a href="#async-x2F-await" class="headerlink" title="async&#x2F;await"></a>async&#x2F;await</h2><p>some links: </p>
<ul>
<li><p><a href="https://www.youtube.com/watch?v=E-1Y4kSsAFc">Fear and Awaiting in Async: A Savage Journey to the Heart of the Coroutine Dream - youtube</a></p>
</li>
<li><p><a href="https://github.com/dabeaz/curio">GitHub - dabeaz&#x2F;curio: Good Curio!</a> a library to separate the asynchronus world and synchronus world by the author of the above video.</p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/38575715">Python Asyncio与多线程&#x2F;多进程那些事</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/27258289">Python Async&#x2F;Await入门指南</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/25354747">从0到1，Python网络编程的入门之路</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/25228075">从0到1，Python异步编程的演进之路</a></p>
</li>
</ul>
<p> <code>async</code> create a coroutine which should be excuted when called. Use <code>await</code> in an async function to hung up the coroutine itself until the awaited coroutine finished. <code>await</code> can only be used in <code>async</code> functions. The  object after <code>await</code> must be an <code>Awaitable</code> (as long as you implement <code>__await__()</code>, it’s an <code>Awaitable</code>.  <code>Coroutine</code> extends from <code>Awaitable</code>)</p>
<p> <code>async</code> can be used anywhere except for:</p>
<ul>
<li><p>lambda</p>
</li>
<li><p>list comprehension (available since python 3.6)</p>
</li>
<li><p>default methods (e.g. <code>__init__()</code>), but we can use metaclass to make <code>__init__</code> awaitable.</p>
</li>
</ul>
<h3 id="eventloop"><a href="#eventloop" class="headerlink" title="eventloop"></a>eventloop</h3><p>The essence of aysncio is an eventloop. All awaitables are added to the eventloop and  wait for executing sequentially. If an event is interrupted by IO or sth, another event will be executed. </p>
<p>For every thread, it has its own eventloop. Events in different eventloops cannot communicate.</p>
<p>So basically, events in asyncio are executed sequentially, whereas their requests to IO may be paralled.</p>
<p>And the <code>await</code> keyword means to emit the Awaitable event at once and the program will wait until it finishes. Thus if we want to emit two or more Awaitable events at almost the same time, we use <code>asyncio.create_task(awaitable)</code>. </p>
<blockquote>
<p>(function) create_task: (coro: Generator[Any, None, _T@create_task] | Coroutine[Any, Any, _T@create_task], *, name: str | None &#x3D; …) -&gt; Task[_T@create_task]</p>
<hr>
<p>Schedule the execution of a coroutine object in a spawn task. </p>
<p>Return a Task object.</p>
</blockquote>
<p>When using <code>create_task</code>, the Awaitable is told to be emited as soon as possible. </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time, time_ns</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ns_to_time</span>(<span class="params">nanoseconds</span>):</span><br><span class="line">    <span class="keyword">return</span> timedelta(microseconds=(nanoseconds/<span class="number">1000</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">now</span>():</span><br><span class="line">  <span class="keyword">return</span> ns_to_time(time_ns())</span><br><span class="line"></span><br><span class="line">first_times = []</span><br><span class="line">second_times = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">print_first</span>(<span class="params">n, if_print = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;now()&#125;</span>: first print start.&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        anow = time_ns()</span><br><span class="line">        first_times.append(anow)</span><br><span class="line">        <span class="keyword">if</span> if_print:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;ns_to_time(anow)&#125;</span>: first-<span class="subst">&#123;i&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(<span class="number">0.1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;now()&#125;</span>: first print end.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">print_second</span>(<span class="params">n, if_print = <span class="literal">True</span></span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;now()&#125;</span>: second print start.&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        anow = time_ns()</span><br><span class="line">        second_times.append(anow)</span><br><span class="line">        <span class="keyword">if</span> if_print:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;ns_to_time(anow)&#125;</span>: second-<span class="subst">&#123;i&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(<span class="number">0.1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;now()&#125;</span>: second print end.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># task1 &amp; task2 are emitted immediately</span></span><br><span class="line">    task1 = asyncio.create_task(print_first(<span class="number">5</span>))</span><br><span class="line">    task2 = asyncio.create_task(print_second(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># wait for the two tasks to finish, or the program will end while the tasks are still running.</span></span><br><span class="line">    <span class="keyword">await</span> task1</span><br><span class="line">    <span class="keyword">await</span> task2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># no intersection and the print result shows that all the events are executed sequentially</span></span><br><span class="line">    <span class="built_in">print</span>(first_times)</span><br><span class="line">    <span class="built_in">print</span>(second_times)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;the intersected times: <span class="subst">&#123;<span class="built_in">set</span>(first_times) &amp; <span class="built_in">set</span>(second_times)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>

<h3 id="async-amp-decorator"><a href="#async-amp-decorator" class="headerlink" title="async &amp; decorator"></a>async &amp; decorator</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个 anotation, 可以根据 function 是否在 async 环境运行</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">from_coro</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">bool</span>(sys._getframe(n).f_code.co_flags &amp; <span class="number">0x80</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">coro</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        coro.send(<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">except</span> StopIteration <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> e.value</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">awaitable</span>(<span class="params">syncfunc</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decorator</span>(<span class="params">asyncfunc</span>):</span><br><span class="line"><span class="meta">        @wraps(<span class="params">asyncfunc</span>)</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">            <span class="keyword">if</span> from_coro(<span class="number">2</span>):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;from coro...&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span> asyncfunc(*args, **kwargs)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;not from coro...&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span> syncfunc(*args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> wrapper</span><br><span class="line">    <span class="keyword">return</span> decorator</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">spam</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;the blue one&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@awaitable(<span class="params">spam</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">spam</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;the red one&#x27;</span>)</span><br><span class="line"></span><br><span class="line">spam()</span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">await</span> spam()</span><br></pre></td></tr></table></figure>

<h3 id="Awaitable-amp-Coroutine-class"><a href="#Awaitable-amp-Coroutine-class" class="headerlink" title="Awaitable &amp; Coroutine class"></a>Awaitable &amp; Coroutine class</h3><p>The object after <code>await</code> must be an <code>Awaitable</code> (as long as you implement <code>__await__()</code>, it’s an <code>Awaitable</code>. <code>Coroutine</code> extends from <code>Awaitable</code>.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The abstract `Awaitable` and `Coroutine` class:</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Awaitable</span>(metaclass=ABCMeta):</span><br><span class="line">    __slots__ = ()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__await__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">yield</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__subclasshook__</span>(<span class="params">cls, C</span>):</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">is</span> Awaitable:</span><br><span class="line">            <span class="keyword">return</span> _check_methods(C, <span class="string">&quot;__await__&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NotImplemented</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Coroutine</span>(<span class="title class_ inherited__">Awaitable</span>):</span><br><span class="line">    __slots__ = ()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">send</span>(<span class="params">self, value</span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">throw</span>(<span class="params">self, typ, val=<span class="literal">None</span>, tb=<span class="literal">None</span></span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close</span>(<span class="params">self</span>):</span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__subclasshook__</span>(<span class="params">cls, C</span>):</span><br><span class="line">        <span class="keyword">if</span> cls <span class="keyword">is</span> <span class="type">Coroutine</span>:</span><br><span class="line">            <span class="keyword">return</span> _check_methods(C, <span class="string">&#x27;__await__&#x27;</span>, <span class="string">&#x27;send&#x27;</span>, <span class="string">&#x27;throw&#x27;</span>, <span class="string">&#x27;close&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NotImplemented</span></span><br></pre></td></tr></table></figure>

<h2 id="Some-convinent-functions"><a href="#Some-convinent-functions" class="headerlink" title="Some convinent functions"></a>Some convinent functions</h2><ul>
<li><code>help</code>: eg. <code>help(Exception)</code> or <code>help(e)</code>, to get the methods &amp; data in a class&#x2F;object</li>
<li><code>dir</code> : eg. <code>dir(Exception)</code> or <code>dir(e)</code>, is a simple version of <code>help</code>, shows all members as a string</li>
<li><code>inspect.getmro(type(e))</code>: get the class hierachy of a type</li>
</ul>
<h1 id="Major-3rd-Party-Libraries"><a href="#Major-3rd-Party-Libraries" class="headerlink" title="Major 3rd-Party Libraries"></a>Major 3rd-Party Libraries</h1><p><strong>Django</strong>: The most frequently used web framework written in Python, Django powers websites that include Instagram and Disqus. It has many useful features, and whatever features it lacks are covered by extension packages.<br><strong>CherryPy</strong> and <strong>Flask</strong> are also popular web frameworks.<br><strong>BeautifulSoup</strong> is very useful when scraping data from websites, and leads to better results than building your own scraper with regular expressions.</p>
<p>A number of third-party modules are available that make it much easier to carry out scientific and mathematical computing with Python.<br>The module <strong>matplotlib</strong> allows you to create graphs based on data in Python.<br>The module <strong>NumPy</strong> allows for the use of multidimensional arrays that are much faster than the native Python solution of nested lists. It also contains functions to perform mathematical operations such as matrix transformations on the arrays.<br>The library <strong>SciPy</strong> contains numerous extensions to the functionality of <strong>NumPy</strong>.</p>
<p>Python can also be used for <strong>game development</strong>.<br>Usually, it is used as a scripting language for games written in other languages, but it can be used to make games by itself.<br>For 3D games, the library <strong>Panda3D</strong> can be used. For 2D games, you can use <strong>pygame</strong>.</p>
<h1 id="Issues"><a href="#Issues" class="headerlink" title="# Issues"></a># Issues</h1><h2 id="Make-class-method-return-self-type"><a href="#Make-class-method-return-self-type" class="headerlink" title="Make class method return self type"></a>Make class method return self type</h2><p><a href="https://stackoverflow.com/questions/33533148/how-do-i-type-hint-a-method-with-the-type-of-the-enclosing-class">https://stackoverflow.com/questions/33533148/how-do-i-type-hint-a-method-with-the-type-of-the-enclosing-class</a></p>
<p>If you are using Python 3.10 or later, it just works. As of today (2019) in 3.7+ you must turn this feature on using a future statement (<code>from __future__ import annotations</code>) - for Python 3.6 or below use a string.</p>
<h3 id="Python-3-7-from-future-import-annotations"><a href="#Python-3-7-from-future-import-annotations" class="headerlink" title="Python 3.7+: from __future__ import annotations"></a>Python 3.7+: <code>from __future__ import annotations</code></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> annotations</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Position</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__add__</span>(<span class="params">self, other: Position</span>) -&gt; Position:</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<h3 id="Python-lt-3-7-use-a-string"><a href="#Python-lt-3-7-use-a-string" class="headerlink" title="Python &lt;3.7: use a string"></a>Python &lt;3.7: use a string</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Position</span>:</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__add__</span>(<span class="params">self, other: <span class="string">&#x27;Position&#x27;</span></span>) -&gt; <span class="string">&#x27;Position&#x27;</span>:</span><br><span class="line">       ...</span><br></pre></td></tr></table></figure>

<h2 id="Circular-import"><a href="#Circular-import" class="headerlink" title="Circular import"></a>Circular import</h2><p><a href="https://zhuanlan.zhihu.com/p/66228942">circular import</a></p>
<p>modify the position of import to fix the issues</p>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>python subprocess</title>
    <url>/2018/09/03/python-subprocess/</url>
    <content><![CDATA[<p>Synchronous vs multiprocessing vs multithreading vs async</p>
<p>Concurrency vs Parralism.</p>
<p>asyncio &amp; threading can run multiple I&#x2F;O operations at the same time.</p>
<p>Async runs one block of code at a time while threading just one line of code at a time. With async, we have better control of when the execution is given to other block of code but we have to release the execution ourselves.</p>
<ul>
<li><strong>IO bound problems</strong>: use async if your libraries support it and if not, use threading.</li>
<li><strong>CPU bound problems</strong>: use multi-processing.</li>
<li><strong>None above is a problem:</strong> you are probably just fine with synchronous code. You may still want to use async to have the feeling of responsiveness in case your code interacts with a user.</li>
</ul>
<p>Reference: </p>
<ul>
<li><a href="http://www.cnblogs.com/vamei/archive/2012/09/23/2698014.html">blog: subprocess</a></li>
</ul>
<p>subprocess.call()<br>父进程等待子进程完成<br>返回退出信息(returncode，相当于exit code，见<a href="http://www.cnblogs.com/vamei/archive/2012/09/20/2694466.html">Linux进程基础</a>)</p>
<p>subprocess.check_call()</p>
<p>父进程等待子进程完成</p>
<p>返回0</p>
<p>检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性，可用try…except…来检查(见<a href="http://www.cnblogs.com/vamei/archive/2012/07/10/2582787.html">Python错误处理</a>)。</p>
<p>subprocess.check_output()</p>
<p>父进程等待子进程完成</p>
<p>返回子进程向标准输出的输出结果</p>
<p>检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性和output属性，output属性为标准输出的输出结果，可用try…except…来检查。</p>
<ul>
<li><a href="https://docs.python.org/3.7/library/subprocess.html">official doc: subprocess</a></li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">subprocess.run(args, *, stdin=<span class="literal">None</span>, <span class="built_in">input</span>=<span class="literal">None</span>, stdout=<span class="literal">None</span>, stderr=<span class="literal">None</span>, capture_output=<span class="literal">False</span>, shell=<span class="literal">False</span>, cwd=<span class="literal">None</span>, timeout=<span class="literal">None</span>, check=<span class="literal">False</span>, encoding=<span class="literal">None</span>, errors=<span class="literal">None</span>, text=<span class="literal">None</span>, env=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><a href="https://docs.python.org/3.7/library/subprocess.html">config env in subprojcess</a></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">new_env = os.environ.copy()</span><br><span class="line">new_env[&#x27;MEGAVARIABLE&#x27;] = &#x27;MEGAVALUE&#x27;</span><br><span class="line">subprocess.Popen(&#x27;path&#x27;, env=new_env)</span><br></pre></td></tr></table></figure>

<p>an example to use subprojcess:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">                subprocess.check_output([<span class="string">&#x27;java&#x27;</span>,</span><br><span class="line">                                         <span class="string">&#x27;-DCOMMAND=&#x27;</span> + command,</span><br><span class="line">                                         <span class="string">&#x27;-DTENANT_ID=&#x27;</span> + tenant_id,</span><br><span class="line">                                         <span class="string">&#x27;-DMODEL_ID=&#x27;</span> + model_id,</span><br><span class="line">                                         <span class="string">&#x27;-jar&#x27;</span>, <span class="string">&#x27;xxx.jar&#x27;</span>,</span><br><span class="line">                                         ])</span><br><span class="line">            <span class="keyword">except</span> subprocess.CalledProcessError <span class="keyword">as</span> e:</span><br><span class="line">                db_util.reopx_solver - <span class="number">1.0</span> - SNAPSHOT - <span class="built_in">all</span>.jarport_status(tenant_id, model_id=model_id,</span><br><span class="line">                                                                           msg=<span class="string">f&#x27;Failed runner for &quot;<span class="subst">&#123;command&#125;</span>&quot;...&#x27;</span>)</span><br><span class="line">                logger.exception(<span class="string">&#x27;Could not start solver jar: &#x27;</span>, e.output)</span><br><span class="line">                <span class="keyword">raise</span> OPXException(<span class="string">f&#x27;Could not start runner for &quot;<span class="subst">&#123;command&#125;</span>&quot;.&#x27;</span>, e.stderr)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>the jar must be in the same directory as parent process dir</p>
</blockquote>
]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>react native components &amp; apis</title>
    <url>/2022/10/22/react-native-components-apis/</url>
    <content><![CDATA[<p>react 提倡组件化开发，以促进复用。react native 也一样是组件化开发思想。不同的是，react 中是使用原生的 html 组件作为基本组件（div、a…），而 react native 使用的是另一些原生组件。用户的自定义组件也是基于这些原生组件。</p>
<p>所以要用 react native，必须了解这些原生组件（就跟学 html 组件差不多）</p>
<h1 id="general-props"><a href="#general-props" class="headerlink" title="general props"></a>general props</h1><p>一些所有组件或大部分组件都有的属性。</p>
<h2 id="style"><a href="#style" class="headerlink" title="style"></a><a href="https://reactnative.cn/docs/0.51/style.html#content">style</a></h2><p>所有的核心组件都接受名为 <code>style</code> 的属性（类似 html 标签中的 <code>html</code>）。这些样式名基本上是遵循了 web 上的 CSS 的命名，只是按照 JS 的语法要求使用了驼峰命名法，例如将 <code>background-color</code> 改为<code>backgroundColor</code>。</p>
<p>实际开发中组件的样式会越来越复杂，我们建议使用StyleSheet.create来集中定义组件的样式。常见的做法是按顺序声明和使用 <code>style</code> 属性，以借鉴 CSS 中的“层叠”做法（即后声明的属性会覆盖先声明的同名属性）。比如像下面这样：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123; <span class="title class_">Component</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">AppRegistry</span>, <span class="title class_">StyleSheet</span>, <span class="title class_">Text</span>, <span class="title class_">View</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react-native&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">LotsOfStyles</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.red&#125;</span>&gt;</span>just red<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.bigblue&#125;</span>&gt;</span>just bigblue<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;[styles.bigblue,</span> <span class="attr">styles.red</span>]&#125;&gt;</span>bigblue, then red<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;[styles.red,</span> <span class="attr">styles.bigblue</span>]&#125;&gt;</span>red, then bigblue<span class="tag">&lt;/<span class="name">Text</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> styles = <span class="title class_">StyleSheet</span>.<span class="title function_">create</span>(&#123;</span><br><span class="line">  <span class="attr">bigblue</span>: &#123;</span><br><span class="line">    <span class="attr">color</span>: <span class="string">&#x27;blue&#x27;</span>,</span><br><span class="line">    <span class="attr">fontWeight</span>: <span class="string">&#x27;bold&#x27;</span>,</span><br><span class="line">    <span class="attr">fontSize</span>: <span class="number">30</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">red</span>: &#123;</span><br><span class="line">    <span class="attr">color</span>: <span class="string">&#x27;red&#x27;</span>,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册应用(registerComponent)后才能正确渲染</span></span><br><span class="line"><span class="comment">// 注意：只把应用作为一个整体注册一次，而不是每个组件/模块都注册</span></span><br><span class="line"><span class="title class_">AppRegistry</span>.<span class="title function_">registerComponent</span>(<span class="string">&#x27;LotsOfStyles&#x27;</span>, <span class="function">() =&gt;</span> <span class="title class_">LotsOfStyles</span>);</span><br></pre></td></tr></table></figure>

<h3 id="组件宽度高度"><a href="#组件宽度高度" class="headerlink" title="组件宽度高度"></a><a href="https://reactnative.cn/docs/0.51/height-and-width.html#content">组件宽度高度</a></h3><p>有两种设定方法：</p>
<p><strong>1. 指定宽高</strong></p>
<p>最简单的给组件设定尺寸的方式就是在样式中指定固定的 <code>width</code>和 <code>height</code>。React Native中的尺寸都是无单位的，表示的是与设备像素密度无关的逻辑像素点。</p>
<p><strong>2. 弹性宽高</strong></p>
<p>在组件样式中使用 <code>flex</code> 可以使其在可利用的空间中动态地扩张或收缩。一般而言我们会使用 <code>flex:1</code> 来指定某个组件扩张以撑满所有剩余的空间。如果有多个并列的子组件使用了 <code>flex:1</code>，则这些子组件会平分父容器中剩余的空间。如果这些并列的子组件的 <code>flex</code> 值不一样，则谁的值更大，谁占据剩余空间的比例就更大（即占据剩余空间的比等于并列组件间 <code>flex</code> 值的比）。</p>
<blockquote>
<p>组件能够撑满剩余空间的前提是其父容器的尺寸不为零。如果父容器既没有固定的 <code>width</code> 和 <code>height</code>，也没有设定 <code>flex</code>，则父容器的尺寸为零。其子组件如果使用了 <code>flex</code>，也是无法显示的。</p>
</blockquote>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123; <span class="title class_">Component</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123; <span class="title class_">AppRegistry</span>, <span class="title class_">View</span> &#125; <span class="keyword">from</span> <span class="string">&#x27;react-native&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">FlexDimensionsBasics</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="comment">// 试试去掉父View中的`flex: 1`。</span></span><br><span class="line">      <span class="comment">// 则父View不再具有尺寸，因此子组件也无法再撑开。</span></span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;flex:</span> <span class="attr">1</span>&#125;&#125;&gt;</span></span></span><br><span class="line"><span class="language-xml">      // 这里设定的是固定宽高</span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;width:</span> <span class="attr">50</span>, <span class="attr">height:</span> <span class="attr">50</span>, <span class="attr">backgroundColor:</span> &#x27;<span class="attr">powderblue</span>&#x27;&#125;&#125; /&gt;</span></span></span><br><span class="line"><span class="language-xml">        // 弹性宽高</span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;flex:</span> <span class="attr">2</span>, <span class="attr">backgroundColor:</span> &#x27;<span class="attr">skyblue</span>&#x27;&#125;&#125; /&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;&#123;flex:</span> <span class="attr">3</span>, <span class="attr">backgroundColor:</span> &#x27;<span class="attr">steelblue</span>&#x27;&#125;&#125; /&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="title class_">AppRegistry</span>.<span class="title function_">registerComponent</span>(<span class="string">&#x27;AwesomeProject&#x27;</span>, <span class="function">() =&gt;</span> <span class="title class_">FlexDimensionsBasics</span>);</span><br></pre></td></tr></table></figure>

<h3 id="flexbox-布局"><a href="#flexbox-布局" class="headerlink" title="flexbox 布局"></a><a href="https://reactnative.cn/docs/0.51/layout-with-flexbox.html#content">flexbox 布局</a></h3><p>一般用以下三个属性就可以完成布局的要求了，完整的布局样式属性参照 <a href="https://reactnative.cn/docs/0.51/layout-props.html">这篇文章</a>（也可以参考<a href="https://weibo.com/1712131295/CoRnElNkZ?ref=collection&type=comment#_rnd1526464804589">图解布局模式</a>）：</p>
<ol>
<li><code>flexDirection</code>: 定义布局主轴。<code>row</code>（水平轴）、<code>column</code>（default）</li>
<li><code>justifyContent</code>: 定义主轴上元素排列的方式。<code>flex-start</code>、<code>center</code>、<code>flex-end</code>、<code>space-around</code>（元素在主轴上均匀分布）、<code>space-between</code>(元素间距均匀分布)</li>
<li><code>alignItems</code>: 定义子元素在次轴（与主轴垂直）上的排列方式。<code>flex-start</code>、<code>flex-end</code>、<code>center</code>、<code>stretch</code>（要使 <code>stretch</code> 选项生效的话，子元素在次轴方向上不能有固定的尺寸）</li>
</ol>
<h1 id="核心组件-components"><a href="#核心组件-components" class="headerlink" title="核心组件 components"></a>核心组件 components</h1><p>react native 提供了很多内置的 components，社区也有很多开发者提供有很多实用的 components（可以直接从 npm 搜 <a href="https://www.npmjs.com/search?q=react-native&page=1&ranking=optimal"><code>react native</code></a>，或者查看 <a href="http://www.awesome-react-native.com/#components">awesome react native</a> 里总结的一些列表）</p>
<p>大部分组件，最终都是基于下边这些基本组件写的。<a href="https://facebook.github.io/react-native/docs/components-and-apis.html#user-interface">components &amp; apis</a> 总结了 basic components、用于 ui 渲染的、list 的、ios specific 的、android specific 的（学习这些相当于是学习 html 基本组件的过程）</p>
<h2 id="View"><a href="#View" class="headerlink" title="View"></a><a href="https://reactnative.cn/docs/0.51/view.html#content">View</a></h2><p>View 常用作其他组件的容器，来帮助控制布局和样式（类似于 div）</p>
<h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a><a href="https://reactnative.cn/docs/0.51/text.html#content">Text</a></h2><p>写文本的</p>
<h2 id="TextInput"><a href="#TextInput" class="headerlink" title="TextInput"></a><a href="https://reactnative.cn/docs/0.51/textinput.html#content">TextInput</a></h2><p>是一个允许用户输入文本的基础组件</p>
<h2 id="Image"><a href="#Image" class="headerlink" title="Image"></a><a href="https://reactnative.cn/docs/0.51/image.html#content">Image</a></h2><p>放图片的</p>
<h2 id="SrollView"><a href="#SrollView" class="headerlink" title="SrollView"></a><a href="https://reactnative.cn/docs/0.51/scrollview.html#content">SrollView</a></h2><p><code>ScrollView</code> 是一个通用的可滚动的容器，你可以在其中放入多个组件和视图，而且这些组件并不需要是同类型的。<code>ScrollView</code> 不仅可以垂直滚动，还能水平滚动（通过 <code>horizontal</code> 属性来设置）。</p>
<h2 id="StyleSheet"><a href="#StyleSheet" class="headerlink" title="StyleSheet"></a><a href="https://reactnative.cn/docs/0.51/stylesheet.html#content">StyleSheet</a></h2><p>这其实是一个接口</p>
<p>StyleSheet提供了一种类似CSS样式表的抽象</p>
<h2 id="FlatList"><a href="#FlatList" class="headerlink" title="FlatList"></a><a href="https://reactnative.cn/docs/0.51/flatlist.html#content">FlatList</a></h2><p>react native 有几种用于显示长列表的组件：<code>flatlist</code>、<code>sectionlist</code>、<code>scrollview</code> 等。</p>
<p><code>FlatList</code> 组件用于显示一个垂直的滚动列表，其中的元素之间结构近似而仅数据不同，且元素个数可以增删。和 <code>ScrollView</code> 不同的是，<code>FlatList</code> 并不立即渲染所有元素，而是优先渲染屏幕上可见的元素。而那些已经渲染好了但移动到了屏幕之外的元素，则会从原生视图结构中移除（以提高性能）.</p>
<p><code>FlatList</code> 组件必须的两个属性是 <code>data</code> 和 <code>renderItem</code>。<code>data</code> 是列表的数据源，而 <code>renderItem</code> 则从数据源中逐个解析数据，然后返回一个设定好格式的组件来渲染。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">FlatListBasics</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.container&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">FlatList</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">data</span>=<span class="string">&#123;[</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Devin</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Jackson</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">James</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Joel</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">John</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Jillian</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Jimmy</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">key:</span> &#x27;<span class="attr">Julie</span>&#x27;&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          ]&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">renderItem</span>=<span class="string">&#123;(&#123;item&#125;)</span> =&gt;</span> <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.item&#125;</span>&gt;</span>&#123;item.key&#125;<span class="tag">&lt;/<span class="name">Text</span>&gt;</span>&#125;</span></span><br><span class="line"><span class="language-xml">        /&gt;</span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="SectionList"><a href="#SectionList" class="headerlink" title="SectionList"></a><a href="https://reactnative.cn/docs/0.51/sectionlist.html#content">SectionList</a></h2><p>如果要渲染的是一组需要分组的数据，也许还带有分组标签的，那么 <code>SectionList</code> 将是个不错的选择</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">View</span> <span class="attr">style</span>=<span class="string">&#123;styles.container&#125;</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">SectionList</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">sections</span>=<span class="string">&#123;[</span></span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">title:</span> &#x27;<span class="attr">D</span>&#x27;, <span class="attr">data:</span> [&#x27;<span class="attr">Devin</span>&#x27;]&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">            &#123;<span class="attr">title:</span> &#x27;<span class="attr">J</span>&#x27;, <span class="attr">data:</span> [&#x27;<span class="attr">Jackson</span>&#x27;, &#x27;<span class="attr">James</span>&#x27;, &#x27;<span class="attr">Jillian</span>&#x27;, &#x27;<span class="attr">Jimmy</span>&#x27;, &#x27;<span class="attr">Joel</span>&#x27;, &#x27;<span class="attr">John</span>&#x27;, &#x27;<span class="attr">Julie</span>&#x27;]&#125;,</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          ]&#125;</span></span></span><br><span class="line"><span class="tag"><span class="language-xml">          <span class="attr">renderItem</span>=<span class="string">&#123;(&#123;item&#125;)</span> =&gt;</span> <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.item&#125;</span>&gt;</span>&#123;item&#125;<span class="tag">&lt;/<span class="name">Text</span>&gt;</span>&#125;</span></span><br><span class="line"><span class="language-xml">          renderSectionHeader=&#123;(&#123;section&#125;) =&gt; <span class="tag">&lt;<span class="name">Text</span> <span class="attr">style</span>=<span class="string">&#123;styles.sectionHeader&#125;</span>&gt;</span>&#123;section.title&#125;<span class="tag">&lt;/<span class="name">Text</span>&gt;</span>&#125;</span></span><br><span class="line"><span class="language-xml">        /&gt;</span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">View</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><p>接口其实是仅提供接口功能的简单组件。这些组件可能没有渲染功能。</p>
]]></content>
      <tags>
        <tag>react native</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title>react setState 的坑</title>
    <url>/2018/06/05/react-set-state/</url>
    <content><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p><code>setState</code> 是更新 <code>state</code> 的 API，进而会引发组件的重新渲染。然而在使用过程中发现有些坑(参见 <a href="https://doc.react-china.org/docs/state-and-lifecycle.html#%E6%AD%A3%E7%A1%AE%E5%9C%B0%E4%BD%BF%E7%94%A8%E7%8A%B6%E6%80%81">react 正确使用状态</a>)：</p>
<blockquote>
<ol>
<li><strong><code>setState(obj)</code>一般情况下不会立即更新 <code>state</code> 的值；</strong></li>
<li><strong>同一 cycle 的多次 <code>setState</code> 调用可能会合并（性能考虑）</strong></li>
</ol>
</blockquote>
<p>对于第一点，引用下边的例子：</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">incrementMultiple</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setState</span>(&#123;<span class="attr">count</span>: <span class="variable language_">this</span>.<span class="property">state</span>.<span class="property">count</span> + <span class="number">1</span>&#125;);</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setState</span>(&#123;<span class="attr">count</span>: <span class="variable language_">this</span>.<span class="property">state</span>.<span class="property">count</span> + <span class="number">1</span>&#125;);</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setState</span>(&#123;<span class="attr">count</span>: <span class="variable language_">this</span>.<span class="property">state</span>.<span class="property">count</span> + <span class="number">1</span>&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码运行时，虽然是对 <code>state</code> 加了三次，但是每次加操作都是针对初始的 <code>state</code>，所以最终相当于仅加了一次。即上述代码等同于下边的代码：</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="title class_">Object</span>.<span class="title function_">assign</span>(</span><br><span class="line">  previousState,</span><br><span class="line">  &#123;<span class="attr">quantity</span>: state.<span class="property">quantity</span> + <span class="number">1</span>&#125;,</span><br><span class="line">  &#123;<span class="attr">quantity</span>: state.<span class="property">quantity</span> + <span class="number">1</span>&#125;,</span><br><span class="line">  ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h1 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h1><h2 id="从-react-生命周期看-setState-生效时间"><a href="#从-react-生命周期看-setState-生效时间" class="headerlink" title="从 react 生命周期看 setState 生效时间"></a>从 react 生命周期看 setState 生效时间</h2><p>要理解其原因，我们要先看一下 <a href="https://github.com/superman66/Front-End-Blog/issues/2">react 生命周期</a>：</p>
<p><img src="https://cloud.githubusercontent.com/assets/12592949/24903814/1b2ff98c-1ee1-11e7-9f5a-59eb84171b53.png" alt="react 生命周期"></p>
<p><code>setState</code> 引起状态更新涉及四个函数：</p>
<ul>
<li>shouldComponentUpdate（默认 true）</li>
<li>componentWillUpdate</li>
<li>render</li>
<li>componentDidUpdate</li>
</ul>
<p><strong>但直到 <code>render</code> 被调用时，<code>state</code> 才被更新</strong>。</p>
<p>（如果 <code>shouldComponentUpdate</code> 返回 <code>false</code>，则 <code>render</code> 不会被执行，但是 <code>state</code> 会被更新）</p>
<p>因此多次调用 <code>setState</code> 时，不能依靠 <code>this.state</code> 来计算下一个 <code>state</code> 的值，因为 <code>this.state</code> 一直没更新。</p>
<blockquote>
<p>setState() does not always immediately update the component. It may batch or defer the update until later. This makes reading this.state right after calling setState() a potential pitfall.</p>
</blockquote>
<p>但是可以使用 setState(func) api 来解决上述问题</p>
<h2 id="setState-api"><a href="#setState-api" class="headerlink" title="setState api"></a><a href="https://doc.react-china.org/docs/react-component.html#setstate">setState api</a></h2><p><code>setState</code> api 如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="title function_">setState</span>(updater[, callback])</span><br></pre></td></tr></table></figure>

<p>其中，<code>callback</code> 是在 <code>setState</code> 完成且组件 re-render 完成后执行（一般建议用 <code>componentDidUpdate</code> 来实现类似逻辑）。</p>
<p>而 <code>updater</code> 可以是：</p>
<ul>
<li>obj：异步将 obj <strong>shallow merge</strong> 到旧 <code>state</code>，构建新 <code>state</code></li>
<li>func：形式如下：</li>
</ul>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">(prevState, props) =&gt; stateChange</span><br></pre></td></tr></table></figure>

<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>上述例子做如下修改即可实现真正的累加：</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> <span class="title function_">increment</span>(<span class="params">state</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> &#123;<span class="attr">count</span>: state.<span class="property">count</span> + <span class="number">1</span>&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">incrementMultiple</span>(<span class="params"></span>) &#123;</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setState</span>(increment);</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setState</span>(increment);</span><br><span class="line">  <span class="variable language_">this</span>.<span class="title function_">setState</span>(increment);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p><a href="https://www.jianshu.com/p/9278c4835c55">更详细请点击参考这篇文章</a></p>
]]></content>
      <tags>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title>redux</title>
    <url>/2018/05/29/redux/</url>
    <content><![CDATA[<h1 id="what’s-redux"><a href="#what’s-redux" class="headerlink" title="what’s redux"></a>what’s redux</h1><p><a href="https://cn.redux.js.org/">redux 中文文档</a> 中的几个关键特性：</p>
<ol>
<li><strong>状态容器</strong>，提供<strong>可预测化</strong>的状态管理</li>
<li>跨平台，客户端、服务端、原生应用都能用</li>
<li>易于测试</li>
<li>轻量，支持 react 等界面库</li>
</ol>
<p>其中第一点，讲明了 redux 的主要用途：<strong>状态容器</strong></p>
<p>以 react 为例，页面是渲染状态树得到，有静态状态（<code>props</code>）、动态状态（<code>state</code>）。通过在代码中 <code>setState</code> 来修改状态树，状态自上而下传递到各个子组件，最终触发组件树的重新渲染。</p>
<p>使用 redux，我们就将状态的定义和允许的迁移 function 挪出去，放到一个状态容器里，来有效管理组件的所有状态和状态迁移。此时 <code>component</code> 代码中就没有 <code>state</code>、<code>setState</code> 等定义了。</p>
<h2 id="counter-without-redux"><a href="#counter-without-redux" class="headerlink" title="counter without redux"></a>counter without redux</h2><p>以计数器为例，不使用 redux，即直接在本地定义 <code>state</code>，并通过 <code>setState</code> 修改状态，以实现重现渲染。(<a href="https://github.com/HFCherish/react-learning/blob/master/redux/counter/src/Counter.js">源代码</a>)</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123;<span class="title class_">Component</span>&#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">Counter</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line">  state = &#123;</span><br><span class="line">    <span class="attr">value</span>: <span class="number">0</span>,</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        &#123;this.state.value&#125;</span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;this.increment&#125;</span>&gt;</span>+<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;this.decrement&#125;</span>&gt;</span>-<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  decrement = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="title function_">setState</span>(&#123;</span><br><span class="line">      <span class="attr">value</span>: <span class="variable language_">this</span>.<span class="property">state</span>.<span class="property">value</span> - <span class="number">1</span></span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  increment = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="title function_">setState</span>(&#123;</span><br><span class="line">      <span class="attr">value</span>: <span class="variable language_">this</span>.<span class="property">state</span>.<span class="property">value</span> + <span class="number">1</span></span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="counter-with-redux"><a href="#counter-with-redux" class="headerlink" title="counter with redux"></a>counter with redux</h2><p>如果使用 redux，就是将原本的 <code>state</code> 存储到一个 <code>store</code> 中，通过 <code>dispatch</code> 一个 <code>action</code>(eg. <code>&#123;type: &#39;INCREMENT&#39;&#125;</code>)触发状态变化，<code>action</code> 如何改变 <code>state</code> 是由一个纯函数 <code>reducer</code> 定义的。（<a href="https://github.com/HFCherish/react-learning/blob/master/redux/counter/src/CounterWithRedux.js">源代码</a>）</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line"><span class="comment">// counter.js</span></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span>, &#123;<span class="title class_">Component</span>&#125; <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">class</span> <span class="title class_">Counter</span> <span class="keyword">extends</span> <span class="title class_ inherited__">Component</span> &#123;</span><br><span class="line"></span><br><span class="line">  <span class="title function_">render</span>(<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">      <span class="language-xml"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        &#123;this.props.store.getState()&#125;</span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;this.increment&#125;</span>&gt;</span>+<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">onClick</span>=<span class="string">&#123;this.decrement&#125;</span>&gt;</span>-<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  decrement = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">  <span class="comment">// 改变内部 state 惟一方法是 dispatch 一个 action。</span></span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">props</span>.<span class="property">store</span>.<span class="title function_">dispatch</span>(&#123;<span class="attr">type</span>: <span class="string">&#x27;DECREMENT&#x27;</span>&#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  increment = <span class="function">() =&gt;</span> &#123;</span><br><span class="line">    <span class="variable language_">this</span>.<span class="property">props</span>.<span class="property">store</span>.<span class="title function_">dispatch</span>(&#123;<span class="attr">type</span>: <span class="string">&#x27;INCREMENT&#x27;</span>&#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// reducer.js</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 这是一个 reducer，形式为 (state, action) =&gt; state 的纯函数。</span></span><br><span class="line"><span class="comment"> * 描述了 action 如何把 state 转变成下一个 state。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> <span class="keyword">function</span> <span class="title function_">counter</span>(<span class="params">state = <span class="number">0</span>, action</span>) &#123;</span><br><span class="line">  <span class="keyword">switch</span> (action.<span class="property">type</span>) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;INCREMENT&#x27;</span>:</span><br><span class="line">      <span class="keyword">return</span> state + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;DECREMENT&#x27;</span>:</span><br><span class="line">      <span class="keyword">return</span> state - <span class="number">1</span>;</span><br><span class="line">    <span class="attr">default</span>:</span><br><span class="line">      <span class="keyword">return</span> state;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// index.js</span></span><br><span class="line"><span class="keyword">import</span> <span class="title class_">React</span> <span class="keyword">from</span> <span class="string">&#x27;react&#x27;</span>;</span><br><span class="line"><span class="keyword">import</span> * <span class="keyword">as</span> <span class="title class_">ReactDOM</span> <span class="keyword">from</span> <span class="string">&quot;react-dom&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> <span class="title class_">Counter</span> <span class="keyword">from</span> <span class="string">&quot;./Counter&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> counter <span class="keyword">from</span> <span class="string">&quot;./reducer&quot;</span>;</span><br><span class="line"><span class="keyword">import</span> &#123;createStore&#125; <span class="keyword">from</span> <span class="string">&#x27;redux&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(counter);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">render</span> = (<span class="params"></span>) =&gt; <span class="title class_">ReactDOM</span>.<span class="title function_">render</span>(</span><br><span class="line">  <span class="language-xml"><span class="tag">&lt;<span class="name">Counter</span> <span class="attr">store</span>=<span class="string">&#123;store&#125;/</span>&gt;</span></span>,</span><br><span class="line">  <span class="variable language_">document</span>.<span class="title function_">getElementById</span>(<span class="string">&#x27;root&#x27;</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="title function_">render</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// store 的订阅接口，注册 listener（这里即 render）来订阅 store 的状态更新。</span></span><br><span class="line">store.<span class="title function_">subscribe</span>(render);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="why-redux"><a href="#why-redux" class="headerlink" title="why redux"></a>why redux</h1><p>不使用 redux 时，</p>
<ol>
<li><strong>状态（model）、状态如何被改变（controller）、页面模板&#x2F;html（view）是耦合在一块的。</strong><font color='gray'>（react 提供的就是一种界面库，render 函数其实写的就是页面模板，将 model 填充进去，渲染得到最后的 view）</font></li>
<li><strong>组件之间强耦合，难以确定状态的改变是在哪里被谁触发，bug 追踪难。</strong></li>
</ol>
<p>使用 redux 后，</p>
<ol>
<li><strong>model 被抽出来了</strong>（即当前视图所对应的 model 对象），而且这个 model 对象不是一个贫血模型，它提供基本的 action 来保证 model 的完整性。</li>
<li>由于状态的变更只能通过 <code>dispatch</code> 来触发，<strong>解耦了父子组件之间的状态变更传递</strong>，易于定位. （可以利用 <a href="http://cn.redux.js.org/docs/advanced/Middleware.html">middleware</a> 记录 state 变更日志，即可实现 state 变化过程透明和可预测）</li>
</ol>
<h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><p>redux 是一个状态容器，它解决了： </p>
<ul>
<li>状态在哪：<code>createStore()</code></li>
<li>状态是什么：<code>store.getState()</code></li>
<li>状态怎么变： reducer，即 <code>(preState, action) =&gt; nextState</code> 函数</li>
<li>触发状态变更：<code>store.dispatch(action)</code></li>
<li>谁关心状态变化：<code>store.subscribe(callback)</code></li>
</ul>
<h2 id="reducer"><a href="#reducer" class="headerlink" title="reducer"></a><a href="http://cn.redux.js.org/docs/basics/Reducers.html">reducer</a></h2><p>Reducers 指定了应用状态的变化如何响应 actions 并发送到 store 的，记住 <strong>actions 只是描述了有事情发生了</strong>这一事实，并没有描述应用如何更新 state。reducer 函数形式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(preState, action) =&gt; nextState</span><br></pre></td></tr></table></figure>

<p>因为 <code>state</code> 有很多属性，针对属性的处理也有很多，全放在一块就太大、难管理，所以可以拆 reducer（称为 slice reducer），再利用 <a href="http://cn.redux.js.org/docs/api/combineReducers.html"><code>combineReducer</code></a> 组合。<font color='gray'>（redux 总是一个根，多个子：一个 store，多个子状态；一个根 reducer，多个 slice reducers）</font></p>
<p>使用 <code>combineReducer</code> 后有两个问题：</p>
<ol>
<li>store state 和 slice reducer state 的关系？</li>
<li>slice reducer 如何被调用执行？</li>
</ol>
<h3 id="store-state-和-slice-reducer-state-的关系？"><a href="#store-state-和-slice-reducer-state-的关系？" class="headerlink" title="store state 和 slice reducer state 的关系？"></a>store state 和 slice reducer state 的关系？</h3><p><a href="http://cn.redux.js.org/docs/api/combineReducers.html">官方 API 描述</a></p>
<blockquote>
<p><strong><code>combineReducers()</code> 返回的 <code>state</code> 对象，会将传入的每个 reducer 返回的 <code>state</code> 按其传递给 <code>combineReducers()</code> 时对应的 key 进行命名，并将所有 slice reducer 返回的结果合并</strong> </p>
</blockquote>
<p>举例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">reducer1</span>  = (<span class="params">state=<span class="string">&#x27;initA&#x27;</span>, action</span>) =&gt; &#123;...&#125;</span><br><span class="line"><span class="keyword">const</span> <span class="title function_">reducer2</span>  = (<span class="params">state=<span class="string">&#x27;initB&#x27;</span>, action</span>) =&gt; &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里 `&#123;reducer1, reducer2&#125;` 使用的是 es2015 的 shorthand property names。</span></span><br><span class="line"><span class="comment">// 等价于 `&#123;reducer1: reducer1, reducer2: reducer2&#125;`</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(<span class="title function_">combineReducer</span>(&#123;reducer1, reducer2&#125;));</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//&#123;reducer1: &#x27;initA&#x27;, reducer2: &#x27;initB&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 也可以指定 key 名称</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(<span class="title function_">combineReducer</span>(&#123;<span class="attr">a</span>:reducer1, <span class="attr">b</span>:reducer2&#125;));</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//&#123;a: &#x27;initA&#x27;, b: &#x27;initB&#x27;&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="slice-reducer-如何被调用执行？"><a href="#slice-reducer-如何被调用执行？" class="headerlink" title="slice reducer 如何被调用执行？"></a>slice reducer 如何被调用执行？</h3><p><a href="http://cn.redux.js.org/docs/api/combineReducers.html">官方 API 描述</a></p>
<blockquote>
<p>返回值：<br>(Function)：<strong>一个调用 reducers 对象里所有 reducer 的 reducer，并且构造一个与 reducers 对象结构相同的 state 对象。</strong></p>
</blockquote>
<p>即 combinedReducer 会调用执行所有的 slice reducer，以实现分层处理</p>
<h2 id="初始化-state"><a href="#初始化-state" class="headerlink" title="初始化 state"></a><a href="http://cn.redux.js.org/docs/recipes/reducers/InitializingState.html">初始化 state</a></h2><p>有两种方式：</p>
<ol>
<li>使用 <code>createStore(reducers, [preloadedState], [enhancers])</code> 中的 <code>preloadedState</code></li>
<li>使用 reducer 中的默认属性（<code>function someReducer(state=&#123;defaultValue&#125;, action)&#123;&#125;</code>）</li>
</ol>
<p>这其中有两条规则：</p>
<ol>
<li><strong>preloadedState 先于 reducer 去填充 state</strong></li>
<li><strong>创建 store 后，redux 会 <code>dispatch</code> 一个虚拟的 <code>action</code> 到 reducer，以触发其中的默认值来填充 state。</strong></li>
</ol>
<h3 id="使用单一简单-reducer"><a href="#使用单一简单-reducer" class="headerlink" title="使用单一简单 reducer"></a>使用单一简单 reducer</h3><blockquote>
<p><em>使用 <code>preloadedState</code> 后，单一 reducer 的默认 state 赋值<strong>会</strong>失效，因为流程是这样的：</em></p>
</blockquote>
<ol>
<li>创建 store，并根据 <code>preloadedState</code> 填充 <code>state</code>；</li>
<li><code>dispatch</code> 虚拟 <code>action</code> 来使用 reducer 默认值填充 <code>state</code>。而此时 <code>state</code> 已经不是 <code>undefind</code>，因此，这个默认值填充是无效的</li>
</ol>
<p>举一个例子：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// reducer</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">counterReducer</span>(<span class="params">state=<span class="number">0</span>, action</span>) &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 仅使用 reducer 初始化</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(counterReducer);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 同时使用 preloadedState 和 reducer</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(counterReducer, <span class="number">42</span>);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//42</span></span><br></pre></td></tr></table></figure>

<h3 id="使用-combineReducer"><a href="#使用-combineReducer" class="headerlink" title="使用 combineReducer()"></a>使用 <code>combineReducer()</code></h3><blockquote>
<p><em>使用 <code>preloadedState</code> 后，使用了 <code>combineReducers</code> 的 reducer 默认 state 赋值<strong>可能会</strong>失效，因为流程是这样的：</em></p>
</blockquote>
<ol>
<li>创建 store，并根据 <code>preloadedState</code> 填充 <code>state</code>；</li>
<li><code>dispatch</code> 虚拟 <code>action</code> 来调用所有子 reducers，<ul>
<li>如果 <code>preloadedState</code> 中定义了当前 <code>reducer</code> 的属性，则对当前 reducer，<code>state</code> 已经不是 <code>undefind</code>，此时默认值填充是无效的</li>
<li>如果 <code>preloadedState</code> 中没有定义当前 <code>reducer</code> 的属性，则对当前 reducer，<code>state</code> 是 <code>undefind</code>，默认值填充有效</li>
</ul>
</li>
</ol>
<p>同样看一个例子：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// reducer</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">reducer1</span>  = (<span class="params">state=<span class="string">&#x27;initA&#x27;</span>, action</span>) =&gt; &#123;...&#125;</span><br><span class="line"><span class="keyword">const</span> <span class="title function_">reducer2</span>  = (<span class="params">state=<span class="string">&#x27;initB&#x27;</span>, action</span>) =&gt; &#123;...&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> combinedReducer = <span class="title function_">combineReducers</span>(&#123;<span class="attr">a</span>: reducer1, <span class="attr">b</span>: reducer2&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 仅使用 reducer 初始化</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(combinedReducer);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//&#123;a: &#x27;initA&#x27;, b: &#x27;initB&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 同时使用 preloadedState 和 reducer</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(counterReducer, &#123;<span class="attr">a</span>: <span class="string">&#x27;initInPreload&#x27;</span>&#125;);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//&#123;a: &#x27;initInPreload&#x27;, b: &#x27;initB&#x27;&#125;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>使用 <code>combineReducers</code> 时，<code>preloadedState</code> 必须包含 slice reducer 中的属性，与传入的 keys 保持同样的结构</em> (参见 <a href="http://cn.redux.js.org/docs/api/createStore.html">createStore API 说明</a>)</p>
</blockquote>
<p>举例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">reducer1</span> = (<span class="params">state=<span class="string">&#x27;initA&#x27;</span>, action</span>) =&gt; &#123;...&#125;</span><br><span class="line"><span class="keyword">const</span> combinedReducer = <span class="title function_">combineReducers</span>(&#123;<span class="attr">a</span>: reducer1, <span class="attr">b</span>: reducer2&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 正确用法</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(combinedReducer, &#123;<span class="attr">b</span>: <span class="string">&#x27;bala&#x27;</span>&#125;);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//&#123;a: &#x27;initA&#x27;, b: &#x27;bala&#x27;&#125;;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 错误用法. 此时不会包含 c 属性。</span></span><br><span class="line"><span class="comment">// 因为所有的 state 都必须映射到 reducer 上，必须保持同样的结构，映射不到的就会被忽略</span></span><br><span class="line"><span class="keyword">const</span> store = <span class="title function_">createStore</span>(combinedReducer, &#123;<span class="attr">c</span>: <span class="string">&#x27;bala&#x27;</span>&#125;);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(store.<span class="title function_">getState</span>()); <span class="comment">//&#123;a: &#x27;initA&#x27;, b: &#x27;initB&#x27;&#125;;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul>
<li><a href="http://redux.js.org/docs/basics/UsageWithReact.html">usage with react</a></li>
<li><a href="http://redux.js.org/docs/basics/UsageWithReact.html">显示和容器组件</a></li>
<li><a href="https://www.zhihu.com/question/41312576">为什么用redux？原理？</a></li>
<li><a href="https://github.com/jasonslyvia/a-cartoon-intro-to-redux-cn">看漫画学redux</a></li>
</ul>
]]></content>
      <tags>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title>rest and hateoas</title>
    <url>/2019/06/04/rest-and-hateoas/</url>
    <content><![CDATA[<h1 id="why-REST"><a href="#why-REST" class="headerlink" title="why REST?"></a>why REST?</h1><blockquote>
<p>The World Wide Web is arguably the world’s largest distributed application. Understanding the key architectural principles underlying the Web can help explain its technical success and may lead to improvements in other distributed applications, particularly those that are amenable to the same or similar methods of interaction. REST contributes both the rationale behind the modern Web’s software architecture and a significant lesson in how software engineering principles can be systematically applied in the design and evaluation of a real software system. —- Fielding’s REST dissertation</p>
</blockquote>
<p>In summary, to meet the needs of an Internet-scale distributed hypermedia system, some properties are promoted: <strong>scalability, interoperability, simplicity, and flexibility</strong>. To do this, the REST(Representational State Transfer) architecture is developed for designing good networked applications.</p>
<p>REST is a coordinated set of architectural constraints that attempts to minimize latency and network communication while at the same time maximizing the independence and scalability of component implementations. This is achieved by placing constraints on connector semantics where other styles have focused on component semantics. REST enables the caching and reuse of interactions, dynamic substitutability of components, and processing of actions by intermediaries, thereby meeting the needs of an Internet-scale distributed hypermedia system.</p>
<blockquote>
<p>RESTful 架构风格是对互联网架构的反思。那么互联网架构的核心在于开放性和扩展性，因而 RESTful 架构风格的核心也是<em><strong>开放性和扩展性</strong></em>。因为开放，使得 RESTful API 的供应者不会对客户端作出任何假设。就好像互联网服务器并不会假设它的客户端只有浏览器一样，wget、telnet 等等都是可能的客户端；而因为扩展性，RESTful API 只会为客户端提供最基本的功能，大量的计算被分布到了客户端侧进行。</p>
<p>这种架构的假设是不同于企业应用的客户端与服务器架构的，在企业应用架构的语境中，客户端与服务器有更多的耦合。服务端更多地是为客户端提供服务，而不是保持自己开放和稳定。那么为什么 RESTful API 最终还是成为“行业主流”了呢（虽然真的会，和真的用的人并不多）？<em><strong>因为从大趋势上来说，将企业内的能力（而不仅仅是后台）构造成开放 API，并围绕着开放 API，形成企业内生态是大势。在这个大势之下，RESTful API、MicroService、企业内生态、能力平台、中台形成了一条清晰的企业架构现代化之路</strong></em>。仅仅服务于某些（或者某个）前台的后台服务，终将会淡出历史的舞台。</p>
</blockquote>
<h1 id="What’s-REST"><a href="#What’s-REST" class="headerlink" title="What’s REST"></a>What’s REST</h1><p>REST is an architectural style that defines a set of constraints and elements for designing networked applications.</p>
<h2 id="Constraints-Deriving-REST"><a href="#Constraints-Deriving-REST" class="headerlink" title="Constraints(Deriving REST)"></a>Constraints(Deriving REST)</h2><p>These constraints are developed step by step along the development of WWW.</p>
<h3 id="Client-Server"><a href="#Client-Server" class="headerlink" title="Client-Server"></a>Client-Server</h3><p><strong>Constraint:</strong></p>
<p>Separating the user interface concerns from the data storage concerns. <strong>Separation of concerns</strong> is the principle behind the client-server constraints.</p>
<p><strong>Why client-server constraint:</strong></p>
<p>By separating the user interface concerns from the data storage concerns, we improve the <strong><u>portability</u></strong> of the user interface across multiple platforms and improve <strong><u>scalability</u></strong> by simplifying the server components. Perhaps most significant to the Web, however, is that the separation allows the components to <strong><u>evolve independently</u></strong>, thus supporting the Internet-scale requirement of multiple organizational domains.</p>
<h3 id="Stateless"><a href="#Stateless" class="headerlink" title="Stateless"></a>Stateless</h3><p><strong>Constraint:</strong></p>
<p>Communication must be stateless in nature. The server does not maintain any client state between requests. Each request from the client must contain all the necessary information for the server to understand and process it. Session state is therefore kept entirely on the client.</p>
<p><strong>Why stateless constraint</strong>:</p>
<p>It’s a design trade-off.</p>
<p>It induces the properties of <strong><u>visibility</u></strong>, <strong><u>reliability</u></strong>, and <strong><u>scalability</u></strong>. Visibility is improved because a monitoring system does not have to look beyond a single request datum in order to determine the full nature of the request. Reliability is improved because it eases the task of recovering from partial failures [<a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/references.htm#ref_133">133</a>]. Scalability is improved because not having to store state between requests allows the server component to quickly free resources, and further simplifies implementation because the server doesn’t have to manage resource usage across requests.</p>
<p>The disadvantage is that it may <u>decrease network performance</u> by increasing the repetitive data (per-interaction overhead) sent in a series of requests, since that data cannot be left on the server in a shared context. In addition, placing the application state on the client-side <u>reduces the server’s control over consistent application behavior</u>, since the application becomes dependent on the correct implementation of semantics across multiple client versions.</p>
<h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><p><strong>Constraint:</strong></p>
<p>Require that the data within a response to a request be implicitly or explicitly labeled as cacheable or non-cacheable. If a response is cacheable, then a client cache is given the right to reuse that response data for later, equivalent requests.</p>
<p>REST supports caching at various levels (client, server, and intermediary) to improve performance and reduce the load on the server.</p>
<p><strong>Why cache constraint</strong>:</p>
<p>To improve network <strong><u>efficiency</u></strong>.</p>
<p>The trade-off, however, is that a cache can <strong><u>decrease reliability</u></strong> if stale data within the cache differs significantly from the data that would have been obtained had the request been sent directly to the server.</p>
<h3 id="Uniform-Interface"><a href="#Uniform-Interface" class="headerlink" title="Uniform Interface"></a>Uniform Interface</h3><p>From here, the constraints are added to the Web’s architectural style in order to guide the extensions that form the modern Web architecture.</p>
<p>Emphasis on a uniform interface between components is the <strong>central feature</strong> that distinguishes the REST architectural style from other network-based styles.</p>
<p><strong>Constraint:</strong></p>
<p>Use a uniform set of interfaces to communicate among components. For example, standard methods (GET, POST, PUT, PATCH, DELETE) for manipulating resources, resource identification through URLs, and hypermedia as the engine of application state (HATEOAS), which allows clients to discover and navigate resources dynamically.</p>
<p><strong>Why uniform interface constraint:</strong></p>
<p>By applying the software engineering principle of generality to the component interface, the overall system architecture is <strong><u>simplified</u></strong> and the <strong><u>visibility</u></strong> of interactions is improved. Implementations are decoupled from the services they provide, which encourages <strong><u>independent evolvability</u></strong>.</p>
<p>The trade-off, though, is that a uniform interface <strong><u>degrades efficiency</u></strong>, since information is transferred in a standardized form rather than one which is specific to an application’s needs. The REST interface is designed to be efficient for <strong>large-grain hypermedia data transfer</strong>, optimizing for the common case of the Web, but resulting in an interface that is not optimal for other forms of architectural interaction.</p>
<h4 id="Interface-Constraints"><a href="#Interface-Constraints" class="headerlink" title="Interface Constraints"></a>Interface Constraints</h4><p>In order to obtain a uniform interface, multiple architectural constraints are needed to guide the behavior of components. REST is defined by four interface constraints: <strong><u>identification of resources</u>; <u>manipulation of resources through representations</u>; <u>self-descriptive messages</u>; and, <u>hypermedia as the engine of application state</u>.</strong></p>
<h5 id="Resource-amp-Resource-Identifiers"><a href="#Resource-amp-Resource-Identifiers" class="headerlink" title="Resource &amp; Resource Identifiers"></a>Resource &amp; Resource Identifiers</h5><p>RESTful systems are built around the concept of resources, which are identified by unique URLs (Uniform Resource Locators).</p>
<p>Resource is a concept. The real entities or data it denotes may vary by time.</p>
<p>REST defines a resource to be the semantics of what the author intends to identify, rather than the value corresponding to those semantics at the time the reference is created.</p>
<blockquote>
<p>A resource is <strong>a <u><em>conceptual</em></u> mapping</strong> to a set of entities, not the entity that corresponds to the mapping at any particular point in time.</p>
<p>More precisely, a resource <em>R</em> is <strong>a temporally varying membership function</strong> <em>M</em>R*(t)*, which for time <em>t</em> maps to a set of entities, or values, which are equivalent. The values in the set may be <em>resource representations</em> and&#x2F;or <em>resource identifiers</em>. Some resources are static in the sense that, when examined at any time after their creation, they always correspond to the same value set.</p>
<p>For example, the “authors’ preferred version” of an academic paper is a mapping whose value changes over time, whereas a mapping to “the paper published in the proceedings of conference X” is static. These are two distinct resources, even if they both map to the same value at some point in time. The distinction is necessary so that both resources can be identified and referenced independently. A similar example from software engineering is the separate identification of a version-controlled source code file when referring to the “latest revision”, “revision number 1.2.7”, or “revision included with the Orange release.”</p>
</blockquote>
<p>While there is some conceptual alignment between storage systems and REST APIs, a service with a resource-oriented API is not necessarily a database, and has enormous flexibility in how it interprets resources and methods. For example, creating a calendar event (resource) may create additional events for attendees, send email invitations to attendees, reserve conference rooms, and update video conference schedules.</p>
<h5 id="Representaion"><a href="#Representaion" class="headerlink" title="Representaion"></a>Representaion</h5><p>When transferring resource among components, it’s transferring a representation (e.g. HTTP Message entity) of that resource in a format (e.g. JSON&#x2F;XML) . TA representation is a snapshot of a resource’s state at a particular point in time. Clients interact with resources by sending representations in requests and receiving representations in responses. The representation contains:</p>
<ul>
<li><p>data</p>
</li>
<li><p>metadata: may include both representation metadata and resource metadata: information about the resource that is not specific to the supplied representation.</p>
</li>
<li><p>metadata to describe the metadata</p>
</li>
<li><p>control data:  a kind of metadata. It defines the purpose of a message between components, such as the action being requested or the meaning of a response. e.g. cacheable info, reponse status, http method, etc.</p>
</li>
<li><p>media type: The data format of a representation is a media type. It can directly impact the user-perceived performance. See <a href="#Media-Type">Media Type</a></p>
</li>
</ul>
<blockquote>
<p>Other commonly used but less precise names for a representation include: document, file, and HTTP message entity, instance, or variant.</p>
<p>Depending on the message control data, a given representation may indicate the current state of the requested resource, the desired state for the requested resource, or the value of some other resource, such as a representation of the input data within a client’s query form, or a representation of some error condition for a response.</p>
</blockquote>
<p>Whether the representation is in the same format as the raw source (e.g. data in a relational database), or is derived from the source, remains hidden behind the interface. This brings the separation of concerns of the client-server style without the server scalability problem, allows information hiding through a generic interface to enable encapsulation and evolution of services.</p>
<h5 id="Self-descriptive-Messages"><a href="#Self-descriptive-Messages" class="headerlink" title="Self-descriptive Messages"></a>Self-descriptive Messages</h5><p>REST enables intermediate processing by constraining messages to be self-descriptive: interaction is stateless between requests, standard methods and media types are used to indicate semantics and exchange information, and responses explicitly indicate cacheability.</p>
<h5 id="HATEOAS"><a href="#HATEOAS" class="headerlink" title="HATEOAS"></a>HATEOAS</h5><p>HATEOAS (Hypermedia as the Engine of Application State) emphasizes the use of hypermedia links in API responses to enable clients to discover and navigate resources dynamically. With HATEOAS, the server includes relevant links alongside the resource representation, providing clients with information on what actions they can take next. See <a href="#HATEOAS-1">HATEOAS</a>.</p>
<h3 id="Layered-System"><a href="#Layered-System" class="headerlink" title="Layered System"></a>Layered System</h3><p><strong>Constraint:</strong></p>
<p>Allow an architecture to be composed of hierarchical layers by constraining component behavior such that each component cannot “see” beyond the immediate layer with which they are interacting.</p>
<p><strong>Why layered system constraint:</strong></p>
<p>By restricting knowledge of the system to a single layer, we place a <strong><u>bound on the overall system complexity</u></strong> and promote substrate <strong><u>independence</u></strong>. Layers can be used to <strong><u>encapsulate</u></strong> legacy services and to protect new services from legacy clients, simplifying components by moving infrequently used functionality to a shared intermediary. Intermediaries can also be used to improve system <strong><u>scalability</u></strong> by enabling load balancing of services across multiple networks and processors.</p>
<p>The primary disadvantage is that they add overhead and latency to the processing of data, reducing user-perceived performance.</p>
<p>Within REST, intermediary components can actively transform the content of messages because the messages are self-descriptive and their semantics are visible to intermediaries, and the server is stateless so that the message contains all the necessary information.</p>
<h3 id="Code-On-Demand-Optional"><a href="#Code-On-Demand-Optional" class="headerlink" title="Code-On-Demand (Optional)"></a>Code-On-Demand (Optional)</h3><p>This is an optional constraint.</p>
<p><strong>Constraint:</strong></p>
<p>Allow client functionality to be extended by downloading from server and executing code in the form of applets or scripts.</p>
<p><strong>Why code-on-demand constraint:</strong></p>
<p>This <strong><u>simplifies</u></strong> clients by reducing the number of features required to be pre-implemented. Allowing features to be downloaded after deployment improves system <strong><u>extensibility</u></strong>.</p>
<p>However, it also <strong><u>reduces visibility</u></strong>, and thus is only an optional constraint within REST.</p>
<p>Here’s a simplified code example to demonstrate the concept of code-on-demand in REST using JavaScript:</p>
<p>Suppose you have a RESTful API that provides a resource, such as “books”. The server includes a link to executable JavaScript code in the response, allowing the client to dynamically fetch and execute that code.</p>
<p>Server response:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The Hitchhiker&#x27;s Guide to the Galaxy&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Douglas Adams&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;link&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://example.com/scripts/book-script.js&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>Client-side code:</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Fetch the resource from the server</span></span><br><span class="line"><span class="title function_">fetch</span>(<span class="string">&#x27;http://example.com/api/books/42&#x27;</span>)</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">response</span> =&gt;</span> response.<span class="title function_">json</span>())</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// Check if a script link is provided in the response</span></span><br><span class="line">    <span class="keyword">if</span> (data.<span class="property">link</span>) &#123;</span><br><span class="line">      <span class="comment">// Fetch the script file from the provided link</span></span><br><span class="line">      <span class="keyword">return</span> <span class="title function_">fetch</span>(data.<span class="property">link</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// No script link provided, continue processing the data</span></span><br><span class="line">      <span class="keyword">return</span> <span class="title class_">Promise</span>.<span class="title function_">resolve</span>(<span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">scriptResponse</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// Execute the fetched script (if available)</span></span><br><span class="line">    <span class="keyword">if</span> (scriptResponse) &#123;</span><br><span class="line">      <span class="keyword">return</span> scriptResponse.<span class="title function_">text</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="title class_">Promise</span>.<span class="title function_">resolve</span>(<span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;)</span><br><span class="line">  .<span class="title function_">then</span>(<span class="function"><span class="params">scriptCode</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="comment">// Execute the fetched script code (if available)</span></span><br><span class="line">    <span class="keyword">if</span> (scriptCode) &#123;</span><br><span class="line">      <span class="built_in">eval</span>(scriptCode); <span class="comment">// Execute the script code</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Continue processing the resource data or perform other actions</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure>

<p>The JavaScript code fetched from the server can extend the functionality of the client, modify the UI, or perform other custom operations based on the specific logic defined in the script. This dynamic execution of code-on-demand allows the server to provide additional behavior or features to the client without requiring the client to have prior knowledge of them.</p>
<p>Note that the usage of <code>eval()</code> in this example is for demonstration purposes only. In real-world scenarios, you should carefully evaluate the security implications and consider using safer alternatives like <code>Function()</code>, strict sandboxing, or other approaches depending on your specific requirements.</p>
<h1 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h1><p>RPC (Remote Procedure Call) is a communication protocol that allows a program on one computer to invoke a procedure or method in another computer or distributed system. It enables programs to communicate and exchange data across different machines or network boundaries.</p>
<p>In RPC, the calling program (client) sends a request to a remote program (server), specifying the desired procedure to be executed along with any necessary parameters. The server processes the request, executes the procedure, and returns the result to the client.</p>
<h2 id="RPC-example"><a href="#RPC-example" class="headerlink" title="RPC example"></a>RPC example</h2><p>Here’s an example of RPC implementation using Java and Python:</p>
<p>Java Example:</p>
<ol>
<li>Define an interface for the remote procedure:</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">CalculatorService</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Implement the server that provides the remote procedure:</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CalculatorServiceImpl</span> <span class="keyword">implements</span> <span class="title class_">CalculatorService</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Create a server that exposes the remote procedure:</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.rmi.registry.Registry;</span><br><span class="line"><span class="keyword">import</span> java.rmi.registry.LocateRegistry;</span><br><span class="line"><span class="keyword">import</span> java.rmi.RemoteException;</span><br><span class="line"><span class="keyword">import</span> java.rmi.server.UnicastRemoteObject;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Server</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">CalculatorService</span> <span class="variable">calculator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CalculatorServiceImpl</span>();</span><br><span class="line">            <span class="type">CalculatorService</span> <span class="variable">stub</span> <span class="operator">=</span> (CalculatorService) UnicastRemoteObject.exportObject(calculator, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">Registry</span> <span class="variable">registry</span> <span class="operator">=</span> LocateRegistry.createRegistry(<span class="number">1099</span>);</span><br><span class="line">            registry.bind(<span class="string">&quot;CalculatorService&quot;</span>, stub);</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;Server started&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Server exception: &quot;</span> + e.toString());</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Create a client that invokes the remote procedure:</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.rmi.registry.LocateRegistry;</span><br><span class="line"><span class="keyword">import</span> java.rmi.registry.Registry;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Client</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">Registry</span> <span class="variable">registry</span> <span class="operator">=</span> LocateRegistry.getRegistry(<span class="string">&quot;localhost&quot;</span>, <span class="number">1099</span>);</span><br><span class="line">            <span class="type">CalculatorService</span> <span class="variable">calculator</span> <span class="operator">=</span> (CalculatorService) registry.lookup(<span class="string">&quot;CalculatorService&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> calculator.add(<span class="number">5</span>, <span class="number">3</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;Result: &quot;</span> + result);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            System.err.println(<span class="string">&quot;Client exception: &quot;</span> + e.toString());</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Python Example:</p>
<ol>
<li><p>Install the <code>xmlrpc</code> library if needed: <code>pip install xmlrpc.client</code></p>
</li>
<li><p>Implement the server that provides the remote procedure:</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> xmlrpc.server <span class="keyword">import</span> SimpleXMLRPCServer</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line">server = SimpleXMLRPCServer((<span class="string">&quot;localhost&quot;</span>, <span class="number">8000</span>))</span><br><span class="line">server.register_function(add, <span class="string">&quot;add&quot;</span>)</span><br><span class="line">server.serve_forever()</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Create a client that invokes the remote procedure:</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xmlrpc.client</span><br><span class="line"></span><br><span class="line">proxy = xmlrpc.client.ServerProxy(<span class="string">&quot;http://localhost:8000/&quot;</span>)</span><br><span class="line">result = proxy.add(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Result:&quot;</span>, result)</span><br></pre></td></tr></table></figure>

<h2 id="API-vs-RPC"><a href="#API-vs-RPC" class="headerlink" title="API vs RPC"></a>API vs RPC</h2><p>RPC (Remote Procedure Call) and HTTP API (Application Programming Interface) calls are two different approaches for communication between distributed systems. Let’s compare them based on a few key aspects:</p>
<ol>
<li><p>Communication Protocol:</p>
<ul>
<li>RPC: Typically uses a binary protocol with a defined interface and specific methods or procedures.</li>
<li>HTTP API: Uses the HTTP protocol with a request-response model, where requests and responses are typically in a textual format (e.g., JSON, XML).</li>
</ul>
</li>
<li><p>Interface Definition:</p>
<ul>
<li>RPC: In RPC, the interface is usually defined using a specific interface definition language (IDL), which allows for a strongly typed contract between the client and server.</li>
<li>HTTP API: The interface is defined through HTTP methods (GET, POST, PUT, DELETE) and resource endpoints, and the data format is often described using open standards like OpenAPI (formerly known as Swagger).</li>
</ul>
</li>
<li><p>Data Representation:</p>
<ul>
<li>RPC: Typically focuses on remote method invocations and parameter passing. The data exchanged is often binary or serialized objects.</li>
<li>HTTP API: Supports a broader range of data representations, including JSON, XML, or other formats. It allows for more flexible data exchange and handling.</li>
</ul>
</li>
<li><p>Transport:</p>
<ul>
<li>RPC: Can use various transport protocols, including TCP, UDP, or custom protocols optimized for performance and low latency.</li>
<li>HTTP API: Primarily uses HTTP as the transport protocol, allowing for easy interoperability and leveraging existing infrastructure like web servers and proxies.</li>
</ul>
</li>
<li><p>Semantic Meaning:</p>
<ul>
<li>RPC: Typically emphasizes the invocation of specific procedures or methods and is closely tied to the implementation details of the server.</li>
<li>HTTP API: Focuses on resource-oriented design and follows REST principles. It provides a more abstract and standardized approach for building web services, emphasizing resource identification, manipulation, and statelessness.</li>
</ul>
</li>
</ol>
<h3 id="Higher-Performance"><a href="#Higher-Performance" class="headerlink" title="Higher Performance"></a>Higher Performance</h3><p>RPC is often perceived to provide higher performance compared to HTTP APIs.</p>
<p>RPC protocols are typically designed to be more efficient in terms of serialization and deserialization of data. They can be designed to use lower-level network protocols, such as TCP or UDP, or custom protocols tailored for specific performance requirements. They often use binary formats and optimize data transmission for specific programming languages, leading to reduced overhead compared to textual data formats used in HTTP APIs like JSON or XML.</p>
<p>However, Performance can vary depending on the specific implementation, use case, and optimization efforts. While RPC can provide advantages in certain scenarios, the performance difference may not always be significant compared to well-designed and optimized HTTP APIs.</p>
<h3 id="RPC-Drawbacks"><a href="#RPC-Drawbacks" class="headerlink" title="RPC Drawbacks"></a>RPC Drawbacks</h3><p>There are some drawbacks to consider when comparing it with HTTP API:</p>
<ol>
<li><p>Complexity: RPC can introduce additional complexity compared to HTTP APIs. It often requires generating and maintaining code bindings for different programming languages. This can add overhead in terms of development time, debugging, and maintenance.</p>
</li>
<li><p>Tight Coupling: RPC tends to create tighter coupling between the client and server. Both the client and server need to understand the RPC protocol and share the same data types and contracts. This can limit the flexibility to evolve and modify the system independently.</p>
</li>
<li><p>Firewall and Proxy Limitations: RPC may face challenges when crossing firewalls or proxies. Some RPC frameworks use custom protocols or ports that can be blocked or restricted by network policies. HTTP, on the other hand, is widely supported and passes through most network infrastructures.</p>
</li>
<li><p>Limited Interoperability: RPC frameworks often have language-specific implementations, which can limit interoperability between different programming languages. It may require additional effort to support cross-language communication compared to the more standardized nature of HTTP APIs.</p>
</li>
<li><p>Scalability and Load Balancing: Scaling RPC-based systems can be more complex compared to HTTP APIs. Load balancing, service discovery, and fault tolerance mechanisms need to be implemented at the RPC framework level or handled manually.</p>
</li>
<li><p>Tooling and Ecosystem: The ecosystem around RPC frameworks may not be as mature or extensive as that of HTTP APIs. HTTP has a wide range of tools, libraries, and frameworks that support various aspects of API development, testing, documentation, and monitoring.</p>
</li>
</ol>
<h2 id="API-or-RPC"><a href="#API-or-RPC" class="headerlink" title="API or RPC"></a>API or RPC</h2><p>On the Internet, HTTP REST APIs have been hugely successful. In 2010, about 74% of public network APIs were HTTP REST (or REST-like) APIs, most using JSON as the wire format.</p>
<p>While HTTP&#x2F;JSON APIs are very popular on the Internet, the amount of traffic they carry is smaller than traditional RPC APIs. For example, about half of Internet traffic in America at peak time is <strong>video content</strong>, and few people would consider using HTTP&#x2F;JSON APIs to deliver such content for obvious <strong>performance reasons</strong>. Inside data centers, many companies use socket-based RPC APIs to carry most network traffic, which can involve orders of magnitude more data (measured in bytes) than public HTTP&#x2F;JSON APIs.</p>
<p>RPC is often favored in scenarios where performance and low-level control are critical, such as high-performance computing or distributed systems. On the other hand, HTTP APIs are widely used for building web services, enabling interoperability, and leveraging the extensive tooling and infrastructure available for the HTTP protocol. API provides a more flexible, standardized, and widely supported approach for integrating applications and services in the cloud environment.</p>
<h2 id="RPC-Application"><a href="#RPC-Application" class="headerlink" title="RPC Application"></a>RPC Application</h2><p>Sure! Here are a few examples of business products or systems that may use RPC internally to implement certain functions:</p>
<ol>
<li><p>Distributed File Systems: Distributed file systems like Hadoop Distributed File System (HDFS) or Google File System (GFS) use RPC for communication between different components. RPC enables data transfer, coordination, and metadata operations across multiple nodes in the distributed file system.</p>
</li>
<li><p>Microservices Architecture: In a microservices-based architecture, where applications are divided into small, independent services, RPC can be used for inter-service communication. Services can use RPC calls to invoke specific functions or exchange data with other services, allowing them to work together to provide a cohesive application.</p>
</li>
<li><p>Service-Oriented Architecture (SOA): In a service-oriented architecture, RPC can be used for communication between services. RPC calls allow services to invoke methods or procedures on remote services to access their functionality or exchange data. This enables the composition and integration of different services within the overall system.</p>
</li>
<li><p>Cloud Computing Platforms: Cloud computing platforms like Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP) often use RPC internally for various purposes. RPC enables communication between different components of the platform, such as virtual machines, storage systems, and network infrastructure, allowing them to work together to provide cloud services.</p>
</li>
<li><p>Enterprise Resource Planning (ERP) Systems: ERP systems typically involve multiple modules and components that need to communicate with each other. RPC can be used internally to enable communication and data exchange between different modules within the ERP system, facilitating seamless integration and functionality across various business processes.</p>
</li>
</ol>
<p>It’s worth noting that while these examples highlight the use of RPC in certain business products or systems, the specific implementation details may vary. RPC is just one of several communication mechanisms available, and its adoption depends on the specific requirements and architecture of the system being developed.</p>
<h3 id="HDFS-application"><a href="#HDFS-application" class="headerlink" title="HDFS application"></a>HDFS application</h3><p>Hadoop Distributed File System (HDFS) and Google File System (GFS) use RPC internally for various communication tasks. Here’s how RPC is typically used in these distributed file systems:</p>
<ol>
<li><p>Metadata Operations: Both HDFS and GFS employ RPC for metadata operations, such as retrieving file system metadata, creating directories, renaming files, and managing permissions. Clients make RPC calls to the metadata server or master node, which handles these operations and maintains the file system’s metadata.</p>
</li>
<li><p>Data Transfer: When a client wants to read or write data to the distributed file system, it needs to communicate with the appropriate data nodes that store the data blocks. RPC is used to coordinate and facilitate data transfer between the client and data nodes. The client sends an RPC request to the data node, specifying the block it wants to read or write, and the data node responds accordingly.</p>
</li>
<li><p>Heartbeat and Health Monitoring: Both HDFS and GFS use RPC for heartbeat messages between different nodes in the cluster. Nodes periodically send heartbeat RPC requests to indicate their availability and health status to the central server or master node. This helps in detecting failed or slow nodes and enables the system to take appropriate actions.</p>
</li>
<li><p>Coordination and Control: RPC is used for coordination and control tasks within the distributed file system. For example, in HDFS, the NameNode communicates with the DataNodes using RPC to maintain a consistent view of the file system and to control replication and block allocation policies. Similarly, in GFS, the master node coordinates activities among chunk servers through RPC calls.</p>
</li>
</ol>
<p>These are just a few examples of how HDFS and GFS leverage RPC internally to facilitate communication, coordination, and data transfer in their distributed file systems. RPC allows different components of the file system to interact and work together seamlessly, enabling efficient storage and retrieval of data across multiple nodes in the cluster.</p>
<h1 id="HATEOAS-1"><a href="#HATEOAS-1" class="headerlink" title="HATEOAS"></a><a name="hateoas" />HATEOAS</h1><p>HATEOAS (Hypermedia as the Engine of Application State) emphasizes the use of hypermedia links in API responses to enable clients to discover and navigate resources dynamically.</p>
<p>HATEOAS promotes loose coupling between the client and server, as clients rely on the hypermedia links to discover and interact with resources. It promotes scalability and enables the server to evolve the API without breaking client functionality, as long as the hypermedia links and their semantics remain consistent.</p>
<h2 id="Application-State"><a href="#Application-State" class="headerlink" title="Application State"></a>Application State</h2><p>In the context of HATEOAS (Hypermedia as the Engine of Application State), the term “application state” refers to the current condition or status of the application from the client’s perspective. It represents the combination of data, resources, and possible actions that are available for the client to interact with at a given point in time.</p>
<p>Application state encapsulates the information needed by the client to understand what it can do next within the application. It includes details about <strong>the current resource being accessed, the available actions that can be performed on that resource, and any related resources that can be explored.</strong></p>
<p>In a HATEOAS-compliant API, the server includes hypermedia links within API responses, which provide the necessary information to drive the application state. These links act as navigational cues for the client, guiding it to the next set of available actions or transitions.</p>
<p>Application state in REST is represented and transferred through representations exchanged between client and server. The model application is therefore an engine that moves from one state to the next by examining and choosing from among the alternative state transitions in the current set of representations.</p>
<h2 id="Pros-amp-Cons"><a href="#Pros-amp-Cons" class="headerlink" title="Pros &amp; Cons"></a>Pros &amp; Cons</h2><p>While HATEOAS promotes discoverability and decoupling between clients and servers, its practical adoption may vary based on the specific requirements and constraints of an API.</p>
<p><strong>Advantages</strong>:</p>
<ol>
<li><p>Discoverability: HATEOAS provides self-descriptive APIs by including links in API responses. This allows clients to discover available actions dynamically without relying heavily on prior knowledge or documentation.</p>
</li>
<li><p>Flexibility and Evolution: With HATEOAS, servers can evolve the API by adding new resources, endpoints, or actions without breaking existing clients. Clients that understand and navigate the provided links can adapt to changes more easily.</p>
</li>
<li><p>Reduced Coupling: Clients that follow hypermedia links are less tightly coupled to the API structure. They can navigate resources and interact with the API based on the available links, which allows for more flexibility in server-side changes.</p>
</li>
</ol>
<p><strong>Considerations</strong>:</p>
<ol>
<li><p>Learning Curve: While HATEOAS promotes dynamic exploration of API capabilities, it requires clients to understand and interpret the provided links. Clients may need to invest additional effort in parsing and processing the hypermedia links to effectively interact with the API.</p>
</li>
<li><p>Tooling and Documentation: Many existing client libraries and tools are built around static API documentation rather than dynamic exploration of hypermedia links. Clients may rely on API documentation to understand available endpoints, request structures, and response formats.</p>
</li>
<li><p>Standardization and Consistency: HATEOAS lacks standardization in terms of link formats, semantics, and conventions. API providers need to ensure consistency and clarity in the representation of links to avoid ambiguity and confusion for clients.</p>
</li>
</ol>
<p>In essence, the concept of application state in HATEOAS emphasizes the dynamic nature of APIs, where clients can determine their next steps based on the information presented to them through hypermedia links, rather than relying solely on predefined knowledge or fixed API structures.</p>
<p>In practice, the adoption of HATEOAS varies depending on the goals, complexity, and constraints of the API. The level of its implementation may vary based on the trade-offs between discoverability and the practicality of client development and tooling. API providers need to carefully consider the needs of their client developers and strike a balance between HATEOAS and traditional documentation approaches.</p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>Here’s an example to illustrate HATEOAS in a simple API response:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">123</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;John Doe&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="number">30</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;links&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;rel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;self&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;href&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/users/123&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;rel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;update&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;href&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/users/123&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PUT&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;rel&quot;</span><span class="punctuation">:</span> <span class="string">&quot;delete&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;href&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/users/123&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span> <span class="string">&quot;DELETE&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>In the above example, the API response provides the representation of a user resource with the fields <code>id</code>, <code>name</code>, and <code>age</code>. Additionally, it includes a <code>links</code> array that contains hypermedia links related to the resource.</p>
<p>By including these hypermedia links, the server guides the client on the available actions it can take on the resource without requiring prior knowledge of the API’s structure or endpoints. Clients can dynamically navigate the API by following the provided links and perform actions based on the resources’ available state transitions.</p>
<h2 id="Auto-Generation"><a href="#Auto-Generation" class="headerlink" title="Auto Generation"></a>Auto Generation</h2><p>Here are some patterns that can be used to generate HATEOAS links:</p>
<ol>
<li><p>Resource-based Links: In this pattern, the HATEOAS links are generated based on the resources and their relationships. For example, if you have a “users” resource, you can generate links like “&#x2F;users&#x2F;{userId}” to retrieve a specific user or “&#x2F;users” to retrieve a list of users.</p>
</li>
<li><p>CRUD Operations: HATEOAS links can be generated based on the CRUD operations (Create, Read, Update, Delete) supported by the API. For example, you can generate links like “&#x2F;users&#x2F;{userId}” for retrieving a user, “&#x2F;users&#x2F;{userId}” for updating a user, and “&#x2F;users&#x2F;{userId}” for deleting a user.</p>
</li>
<li><p>Pagination Links: If your API supports pagination, you can generate links for navigating through the paginated results. For example, you can include links like “prev”, “next”, “first”, and “last” to allow users to navigate to the previous, next, first, and last pages of the results.</p>
</li>
<li><p>Related Resources: HATEOAS links can be generated to represent relationships between resources. For example, if a user has associated orders, you can include a link to retrieve the orders for that user.</p>
</li>
</ol>
<h1 id="Media-Type"><a href="#Media-Type" class="headerlink" title="Media Type"></a><a name="media-type" />Media Type</h1><p>Impact data transfer efficiency, parsing speed, network overhead, and ease of interaction.</p>
<ol>
<li><p>JSON vs. XML:</p>
<ul>
<li>JSON (JavaScript Object Notation) is a lightweight data interchange format known for its simplicity and efficiency. Compared to XML (eXtensible Markup Language), JSON typically requires less bandwidth and is easier to parse, resulting in faster data transfer and improved performance.</li>
</ul>
</li>
<li><p>Protocol Buffers:</p>
<ul>
<li>Protocol Buffers is a binary serialization format developed by Google. It offers a compact representation of structured data, allowing for efficient encoding and decoding. The smaller message size and faster parsing of Protocol Buffers can enhance the performance of a hypermedia system, especially in scenarios with limited network bandwidth.</li>
</ul>
</li>
<li><p>HAL (Hypertext Application Language):</p>
<ul>
<li>HAL is a media type that provides a simple and consistent way to express hypermedia links and resources. It defines conventions for embedding links within JSON or XML representations. By promoting standardized link formats, HAL enables clients to easily navigate and interact with hypermedia resources, leading to improved usability and perceived performance.</li>
</ul>
</li>
<li><p>GraphQL:</p>
<ul>
<li>GraphQL is a query language and runtime for APIs that allows clients to request specific data structures and reduce over-fetching. The design of GraphQL enables clients to retrieve precisely the data they need, reducing network round trips and improving performance. This flexibility and granularity in data retrieval can significantly impact the perceived performance of a hypermedia system.</li>
</ul>
</li>
<li><p>MsgPack:</p>
<ul>
<li>MsgPack is a binary serialization format that aims to be more efficient than JSON or XML. It offers compact representation, fast encoding&#x2F;decoding, and supports a wide range of data types. The reduced message size and efficient serialization provided by MsgPack can enhance the performance of data transfer in a distributed hypermedia system.</li>
</ul>
</li>
</ol>
<h1 id="Best-Practices"><a href="#Best-Practices" class="headerlink" title="Best Practices"></a>Best Practices</h1><p>Some design ideas can reference <a href="https://cloud.google.com/apis/design">Google API Design Guide</a>. For example:</p>
<ul>
<li><p>how to use the standard methods</p>
</li>
<li><p>keep a limited set of custom methods</p>
</li>
<li><p>some standard fields naming and semantics</p>
</li>
<li><p>common error codes &amp; status</p>
</li>
</ul>
<h2 id="PUT-vs-PATCH"><a href="#PUT-vs-PATCH" class="headerlink" title="PUT vs PATCH"></a>PUT vs PATCH</h2><p>PUT:</p>
<ul>
<li>PUT is typically used when you want to completely replace the existing resource with the new representation provided in the request payload.</li>
<li>If the resource exists, PUT will overwrite it with the new representation. If it doesn’t exist, PUT may create a new resource with the provided representation.</li>
<li>An API with an <code>Update</code> method that supports resource creation <strong>should</strong> also provide a <code>Create</code> method. Rationale is that it is not clear how to create resources if the <code>Update</code> method is the only way to do it.</li>
<li>PUT is idempotent, meaning that sending the same request multiple times will have the same effect as sending it once.</li>
</ul>
<p>PATCH:</p>
<ul>
<li>PATCH is used when you want to apply a partial update to the resource, modifying only specific fields or properties.</li>
<li>PATCH is not necessarily idempotent since multiple patch requests can have different effects based on the state of the resource.</li>
</ul>
<p>While both PUT and PATCH have their uses, PUT is often seen as less commonly used compared to PATCH in practice. Because it means a full resource update, which’s not recommended:</p>
<ol>
<li><p>Overhead: It can result in unnecessary data transfer, especially if the resource is large or contains many fields. This can increase network bandwidth usage and add overhead to the update process.</p>
</li>
<li><p>Concurrency Issues: In multi-user or distributed systems, if multiple clients attempt to update the same resource simultaneously, conflicts can occur when the complete representation is used. Granular updates that only modify specific fields or properties of the resource can help mitigate these conflicts.</p>
</li>
<li><p>Data Integrity and Validation: In some cases, a full resource update may bypass data validation and integrity checks that would be applied when updating specific fields.</p>
</li>
<li><p>Caching and Performance Optimization: Full resource updates may invalidate the cached representations, leading to increased load on the server and reduced caching effectiveness.</p>
</li>
</ol>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><p>“Representational State Transfer (REST)” - This is the official chapter from the Fielding Dissertation, where REST was introduced by Roy Fielding, one of its creators:</p>
<ul>
<li>Link: <a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm">Fielding Dissertation</a></li>
</ul>
</li>
<li><p>“HTTP&#x2F;1.1 Semantics and Content” - This document describes the HTTP protocol and its request methods, headers, and response codes, which are foundational for RESTful APIs:</p>
<ul>
<li>Link: <a href="https://tools.ietf.org/html/rfc7231">RFC 7231</a></li>
</ul>
</li>
<li><p>“RESTful Web Services” - This is the official documentation for Java’s JAX-RS API, which provides a set of annotations and tools for building RESTful web services:</p>
<ul>
<li>Link: <a href="https://jax-rs-spec.java.net/">JAX-RS Specification</a></li>
</ul>
</li>
<li><p>“Building Web APIs with ASP.NET Core” - Microsoft’s official documentation on creating RESTful APIs using ASP.NET Core framework:</p>
<ul>
<li>Link: <a href="https://docs.microsoft.com/en-us/aspnet/core/web-api/?view=aspnetcore-5.0">ASP.NET Core Web API Documentation</a></li>
</ul>
</li>
<li><p>“Building and Documenting Web APIs with Django Rest Framework” - Django Rest Framework (DRF) is a powerful toolkit for building RESTful APIs with Django. The official documentation provides comprehensive guides and examples:</p>
<ul>
<li>Link: <a href="https://www.django-rest-framework.org/">Django Rest Framework Documentation</a></li>
</ul>
</li>
<li><p>“Building RESTful Web Services with Node.js” - This is the official documentation for Express.js, a popular Node.js framework for building web applications and RESTful APIs:</p>
<ul>
<li>Link: <a href="https://expressjs.com/">Express.js Documentation</a></li>
</ul>
</li>
<li><p>“API Design Guide” - This is Google’s API design guide, which provides best practices and guidelines for designing RESTful APIs:</p>
<ul>
<li>Link: <a href="https://cloud.google.com/apis/design">Google API Design Guide</a></li>
</ul>
</li>
<li><p>“REST API Tutorial” - This tutorial by RestfulAPI.net covers the basics of RESTful APIs, HTTP methods, status codes, and more:</p>
<ul>
<li>Link: <a href="https://restfulapi.net/">REST API Tutorial</a></li>
</ul>
</li>
<li><p><a href="https://medium.com/@andreasreiser94/why-hateoas-is-useless-and-what-that-means-for-rest-a65194471bc8">why hateoas is useless and what that means for REST</a></p>
</li>
<li><p><a href="https://softwareengineering.stackexchange.com/questions/384704/what-does-hateoas-have-to-do-with-application-state">what does hateoas have to do with Application State</a></p>
</li>
</ol>
]]></content>
      <tags>
        <tag>rest</tag>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title>responsive-web-design</title>
    <url>/2018/12/13/responsive-web-design/</url>
    <content><![CDATA[<p>自适应一般是设定基准值，宽、高、字体大小都指定为基准值的百分比。当基准值改变时，页面元素、宽高也会按比例变化。</p>
<h1 id="自适应宽度"><a href="#自适应宽度" class="headerlink" title="自适应宽度"></a>自适应宽度</h1><h2 id="不使用绝对宽度"><a href="#不使用绝对宽度" class="headerlink" title="不使用绝对宽度"></a>不使用绝对宽度</h2><p>网页宽度默认等于屏幕宽度。所以大部分时候只要不适用绝对宽度即可实现自适应宽度：</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">body</span>: &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="comment">// or width: auto;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果元素是图片，也可以使用 <code>max-width</code> 属性，参见<a href="https://www.w3schools.com/css/css_rwd_images.asp">responsive web design: image</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">img &#123;</span><br><span class="line">  max-width: 100%;</span><br><span class="line">  height: auto;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="使用-media"><a href="#使用-media" class="headerlink" title="使用 media"></a>使用 media</h2><p>这适用于需要针对不同的屏幕，显示不同的排版。利用 <a href="https://developer.mozilla.org/zh-CN/docs/Web/CSS/@media"><code>@media</code></a> 的 css 规则，可实现根据一个或多个基于设备类型、具体特点和环境的媒体查询来应用样式。</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Media query */</span></span><br><span class="line"><span class="keyword">@media</span> screen <span class="keyword">and</span> (<span class="attribute">min-width</span>: <span class="number">900px</span>) &#123;</span><br><span class="line">  <span class="selector-tag">article</span> &#123;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">1rem</span> <span class="number">3rem</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Nested media query */</span></span><br><span class="line"><span class="keyword">@supports</span> (<span class="attribute">display</span>: flex) &#123;</span><br><span class="line">  <span class="keyword">@media</span> screen <span class="keyword">and</span> (<span class="attribute">min-width</span>: <span class="number">900px</span>) &#123;</span><br><span class="line">    <span class="selector-tag">article</span> &#123;</span><br><span class="line">      <span class="attribute">display</span>: flex;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="css-规则"><a href="#css-规则" class="headerlink" title="css 规则"></a>css 规则</h3><p><a href="https://developer.mozilla.org/zh-CN/docs/Web/CSS/At-rule">css 规则</a> 相当于给 css 增加的函数。原本 css 只是简单的 json 对象，现在希望 css 更多样化、更容易维护，所以增加了 css 规则。</p>
<p><code>@media</code> 这种属于条件规则组，即接收两个参数，第一个参数是个 bool 条件，第二个参数是执行的语句。仅当条件为 true 时，其后的语句才会执行。</p>
<h1 id="自适应高度"><a href="#自适应高度" class="headerlink" title="自适应高度"></a>自适应高度</h1><p>同样的，要使得高度自适应，也必须指定一个基准值。但不同于宽度（默认是屏幕宽度），高度通常是不固定的，要确定基准值也就麻烦些。</p>
<h2 id="父容器的高度可确定"><a href="#父容器的高度可确定" class="headerlink" title="父容器的高度可确定"></a>父容器的高度可确定</h2><blockquote>
<p>For the height of a div to be responsive, it must be inside a parent element with a defined height to derive it’s relative height from.</p>
</blockquote>
<p>如果父容器的高度可确定，则同上，采用百分比即可实现自适应。</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">parent: &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100px</span>;</span><br><span class="line"></span><br><span class="line">    child: &#123;</span><br><span class="line">        <span class="attribute">height</span>: <span class="number">80%</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="根据宽度变化，同比例改变高度"><a href="#根据宽度变化，同比例改变高度" class="headerlink" title="根据宽度变化，同比例改变高度"></a>根据宽度变化，同比例改变高度</h2><p>页面宽度的自适应容易实现，可以基于宽度的变化，同比例更改高度。</p>
<h3 id="利用-padding"><a href="#利用-padding" class="headerlink" title="利用 padding"></a>利用 <code>padding</code></h3><p>参见<a href="https://stackoverflow.com/questions/11535827/responsive-height-proportional-to-width">responsive height proportional to width</a>，设定 <code>height</code> 为 0，<code>padding</code> 为百分比</p>
<blockquote>
<p>In all browsers, when padding is specified in %, it’s calculated relative to the parent element’s width. </p>
</blockquote>
<p>Html:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content&quot;</span>&gt;</span></span><br><span class="line">    Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum.</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span>/&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;wrapper&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;content2&quot;</span>&gt;</span></span><br><span class="line">Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>Css:</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.content</span> &#123;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">0</span>;</span><br><span class="line">    <span class="attribute">padding-bottom</span>: <span class="number">30%</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#7ad</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.wrapper</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: relative;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">padding-bottom</span>: <span class="number">30%</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#7ad</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.wrapper</span> <span class="selector-class">.content2</span> &#123;</span><br><span class="line">    <span class="attribute">position</span>: absolute;</span><br><span class="line">    <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#7da</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="利用-viewport-units"><a href="#利用-viewport-units" class="headerlink" title="利用 viewport units"></a>利用 viewport units</h3><p>新版本的浏览器支持 <a href="https://caniuse.com/#feat=viewport-units">viewport units</a>，eg.</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="attribute">width</span>: <span class="number">100vw</span>;</span><br><span class="line"><span class="attribute">height</span>: <span class="number">30vw</span>; <span class="comment">/* 30% of width */</span></span><br></pre></td></tr></table></figure>

<h2 id="使用-media-1"><a href="#使用-media-1" class="headerlink" title="使用 media"></a>使用 media</h2><p>同宽度，指定不同 media 情况下，高度显示不同。</p>
]]></content>
      <tags>
        <tag>javascript</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title>sqoop</title>
    <url>/2020/11/10/sqoop/</url>
    <content><![CDATA[<h1 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h1><p>Sqoop: sq are the first two of “sql”, oop are the last three of “hadoop”. It <strong>transfers bulk data between hdfs and relational database servers</strong>. It supports:</p>
<ul>
<li>Full Load</li>
<li>Incremental Load</li>
<li>Parallel Import&#x2F;Export (throught mapper jobs)</li>
<li>Compression</li>
<li>Kerberos Security Integration</li>
<li>Data  loading directly to HIVE</li>
</ul>
<blockquote>
<p>Sqoop cannot import .csv files into hdfs&#x2F;hive. It only support databases &#x2F; mainframe datasets import.</p>
</blockquote>
<h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p>Sqoop provides CLI, thus you can use a simple command to conduct import&#x2F;export.</p>
<p>The import&#x2F;export are executes in fact through map tasks.</p>
<p><img src="/images/sqoop-20201110134912159.png" alt="sqoop-20201110134912159.png"></p>
<p>When Import from DB:</p>
<ul>
<li>it split to some map tasks. And each map task will connect to DB, and fetch some rows&#x2F;tables, and write it to a file into HDFS</li>
</ul>
<p>When export to DB:</p>
<ul>
<li>it also split to some map tasks. And each map task will fetch a HDFS file, and write each record in the file as a row by specified delimiter to some table.</li>
</ul>
<p><img src="/images/sqoop-20201110135220097.png" alt="sqoop-20201110135220097.png"></p>
<h1 id="Sqoop-v-s-Spark-jdbc"><a href="#Sqoop-v-s-Spark-jdbc" class="headerlink" title="Sqoop v.s. Spark jdbc"></a>Sqoop v.s. Spark jdbc</h1><p>sqoop uses mapreduce technique, while spark is a revolutionary engine to replace mapreduce technique with its in-memory execution and DAG smartness. Thus Spark jdbc is way faster than sqoop.</p>
<ol>
<li>You can combine all the read, transform and write operations into one script&#x2F;program instead of reading it separately through SQOOP in one script and then doing transformation and write in another.</li>
<li>You can define a new split column on the fly (using functions like ORA_HASH) if you want the data to be partitioned in a proper way.</li>
<li>You can control the number of connection to the database. Increasing the number of connection will surely speed up your data import.</li>
</ol>
<h1 id="Common-Commands"><a href="#Common-Commands" class="headerlink" title="Common Commands"></a>Common Commands</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$  sqoop import \</span><br><span class="line">	--connect jdbc:mysql://&lt;ipaddress&gt;/&lt;database name&gt;</span><br><span class="line">	--table &lt;my_table name&gt;</span><br><span class="line">	--username &lt;username_for_my_sql&gt; --password &lt;password&gt;</span><br><span class="line">  --target-dir &lt;target <span class="built_in">dir</span> <span class="keyword">in</span> HDFS <span class="built_in">where</span> data needs to be imported&gt;</span><br><span class="line">  </span><br><span class="line">$  sqoop <span class="built_in">export</span> \</span><br><span class="line">	--connect jdbc:mysql://&lt;ipaddress&gt;/&lt;database name&gt;</span><br><span class="line">	--table &lt;my_table name&gt;</span><br><span class="line">	--username &lt;username_for_my_sql&gt; --password &lt;password&gt;</span><br><span class="line">  --export-dir &lt;target <span class="built_in">dir</span> <span class="keyword">in</span> HDFS <span class="built_in">where</span> data needs to be exported&gt;</span><br></pre></td></tr></table></figure>

<h1 id="Incremental-Import"><a href="#Incremental-Import" class="headerlink" title="Incremental Import"></a>Incremental Import</h1><p>增量导入时，sqoop 需要识别到增量数据，有三种方法：</p>
<ol>
<li>根据自增字段识别新数据（append 模式）：可以直接识别新数据并导入到 hive 中</li>
<li>根据修改时间识别新数据（lastmodified 模式）：要求这个字段会随数据的改变而改变，但是似乎只能导入到 hdfs 中，不能直接导入到 hive 中。导入时，可以通过制定<code>--merge-key id</code> 来按 id 字段进行合并，或者之后通过 <code>sqoop merge</code> 功能单独运行</li>
<li>根据 where 或 query 识别新数据：可能之后只能通过 <code>sqoop merge</code> 来 merge 数据</li>
</ol>
<blockquote>
<p>目前 <strong>sqoop 导入时不能识别删除数据</strong>，都需要通过其他方式来解决（对比数据，或者数据上有 delete 标识符时，通过 <a href="https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.6.5/bk_data-access/content/incrementally-updating-hive-table-with-sqoop-and-ext-table.html">Incrementally Updating a Table</a> 来实现）</p>
</blockquote>
<h2 id="append-模式"><a href="#append-模式" class="headerlink" title="append 模式"></a>append 模式</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/doit_mall \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--table oms_order \</span><br><span class="line">--target-dir  /tmp/query  \</span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table doit12.oms_order \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--compress   \</span><br><span class="line">--compression-codec gzip \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--incremental append \	<span class="comment"># append 模式</span></span><br><span class="line">--check-column <span class="built_in">id</span> \			<span class="comment"># 自增字段</span></span><br><span class="line">--last-value 22 \				<span class="comment"># 自增字段的 last value</span></span><br><span class="line">-m 2 </span><br></pre></td></tr></table></figure>

<h2 id="lastmodified-模式"><a href="#lastmodified-模式" class="headerlink" title="lastmodified 模式"></a>lastmodified 模式</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/dicts \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--table doit_stu \</span><br><span class="line">--target-dir  /doit_stu/2020-02-09  \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--incremental lastmodified \		<span class="comment"># lastmodified 模式</span></span><br><span class="line">--check-column update_time \		<span class="comment"># 时间字段</span></span><br><span class="line">--last-value <span class="string">&#x27;2020-02-09 23:59:59&#x27;</span> \	<span class="comment"># 上一次获取的数据时间</span></span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--merge-key <span class="built_in">id</span> \					<span class="comment">#按照id字段进行合并</span></span><br><span class="line">-m 1 </span><br></pre></td></tr></table></figure>

<h2 id="条件查询"><a href="#条件查询" class="headerlink" title="条件查询"></a>条件查询</h2><p>这里写的都是全量导入 hive。如果要增量，只能先导入到 hdfs，然后再做 merge</p>
<h3 id="–where"><a href="#–where" class="headerlink" title="–where"></a>–where</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/doit_mall \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--table oms_order \</span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table doit12.oms_order \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--compress   \</span><br><span class="line">--compression-codec gzip \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">-m 2   \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--<span class="built_in">where</span> <span class="string">&quot;delivery_company is null&quot;</span> \	<span class="comment"># filter condition</span></span><br><span class="line">--hive-overwrite</span><br></pre></td></tr></table></figure>

<h3 id="–query"><a href="#–query" class="headerlink" title="–query"></a>–query</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://192.168.33.2:3306/doit_mall \</span><br><span class="line">--username root \</span><br><span class="line">--password root \</span><br><span class="line">--target-dir  /tmp/query  \		<span class="comment"># sqoop 导入数据到 hive，本质就是先将数据导入到 hdfs，然后再去 hive 数据库创建元数据。这里需要手动指定中间临时目标目录（不太清楚为啥）</span></span><br><span class="line">--hive-import \</span><br><span class="line">--hive-table doit12.oms_order \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--as-textfile \</span><br><span class="line">--fields-terminated-by <span class="string">&#x27;,&#x27;</span> \</span><br><span class="line">--compress   \</span><br><span class="line">--compression-codec gzip \</span><br><span class="line">--split-by <span class="built_in">id</span> \</span><br><span class="line">--null-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--null-non-string <span class="string">&#x27;\\N&#x27;</span> \</span><br><span class="line">--hive-overwrite \</span><br><span class="line">--query <span class="string">&quot;select id,member_id,order_sn,total_amount,pay_amount,status from oms_order where status=4 and \$CONDITIONS&quot;</span>  \			<span class="comment"># 查询语句，也支持复杂查询</span></span><br><span class="line">-m 2</span><br></pre></td></tr></table></figure>

<h1 id="运行-sqoop-action"><a href="#运行-sqoop-action" class="headerlink" title="运行 sqoop action"></a>运行 sqoop action</h1><p>在数据接入时，特别是连接数据库增量导入数据时，这种周期性任务的执行，有很多种方式：</p>
<ol>
<li>写一个 long running 脚本，不断执行增量 import</li>
<li><a href="https://www.cnblogs.com/xing901022/p/6091306.html">采用 Oozie 等调度工具来运行</a></li>
</ol>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>test principles</title>
    <url>/2018/10/12/test-principles/</url>
    <content><![CDATA[<p><a href="https://www.petrikainulainen.net/programming/unit-testing/3-reasons-why-we-should-not-use-inheritance-in-our-tests/">three reasons why we should not use inheritance in tests</a></p>
<p>大概意思是：</p>
<ol>
<li>很多测试里的继承用的不合适。测试也是代码，必须符合继承的原则。</li>
</ol>
<blockquote>
<p>The point of inheritance is to <strong>take advantage of polymorphic behavior NOT to reuse code</strong>, and people miss that, they see inheritance as a cheap way to add behavior to a class. When I design code I like to think about options. When I inherit, I reduce my options. I am now sub-class of that class and cannot be a sub-class of something else. I have permanently fixed my construction to that of the superclass, and I am at a mercy of the super-class changing APIs. My freedom to change is fixed at compile time.</p>
</blockquote>
<p>多态的定义：</p>
<blockquote>
<p>Polymorphism is the provision of a single interface to entities of different types</p>
</blockquote>
<ol start="2">
<li>可能会影响性能。</li>
</ol>
<p>并不是所有的测试可能都会用到测试基类里的东西，而 beforeClass、beforeTest 在执行所有测试时都会被1. 查找，2. 执行，这些都导致了 CPU 的浪费。</p>
<p>此外，其他人也提到，比如 springboottest 中，基类中配置 <code>@SpringBootTest</code> ，最终可能导致在每个测试中配置 <code>@DirtyContext</code>等，严重影响性能。</p>
<ol start="3">
<li>很影响 reading</li>
</ol>
<p>测试即文档，而很多东西却是需要读多个类</p>
<p>这个问题仁者见仁，智者见智。duplicate code 也是问题。两者相权，如何处理？但对于目前的代码，如果没有问题，还是保持现状比较好。对于符合继承规则这点，倒是需要注意的。</p>
<p>作者在 <a href="https://www.petrikainulainen.net/programming/testing/writing-clean-tests-it-starts-from-the-configuration/">writing clean test</a> 中提出了些解决方法，但感觉还是有些片面。当然他写了一个系列的文章：<a href="https://www.petrikainulainen.net/writing-clean-tests/">writing clean test series</a>。</p>
<p>另外读书：<a href="https://www.amazon.cn/dp/1935182579/ref=sr_1_2?ie=UTF8&qid=1539322654&sr=8-2&keywords=Effective+Unit+Testing:+A+guide+for+Java+developers">effective unit testing</a></p>
]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>yarn</title>
    <url>/2019/01/09/yarn/</url>
    <content><![CDATA[<h1 id="yarn-architecture"><a href="#yarn-architecture" class="headerlink" title="yarn architecture"></a><a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">yarn architecture</a></h1><p>Yarn is used to <strong>manage&#x2F;allocate cluster resource</strong> &amp; <strong>schedule&#x2F;moniter jobs</strong>. These parts – resource manager – are split up from hadoop framework.</p>
<p><img src="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif" alt="yarn architecture"></p>
<p>Yarn has two main components:</p>
<ul>
<li><strong>Schedular</strong>: manage resources (cpu, memory, network, disk, etc.) and allocate it the applications.<ul>
<li>node manager will tell Schedular the node resource info (node status)</li>
<li>application master will ask Schedular for resources.</li>
<li>When partitioning resources among various queues, applications, Schedular supports pluggable policies. For example:<ul>
<li><a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html">CapacityScheduler</a> allocate resources by tenant request. It’s used especially for <strong>multi-tenant scenario</strong>, designed to allow sharing a large cluster while giving each <strong>organization</strong> capacity guarantees. Each client&#x2F;tenant can request any resources that are not used by others. And there’s strict ACLs to ensure the <strong>security</strong> of resources between tenants. The primary abstraction is queue. Different tenant use different queue to utilize the resources. And <strong>hierachical queues</strong> are provided to support data separation in one tenant.</li>
<li><a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html">FairScheduler</a> assigning resources to appliations such that all apps get, <strong>on average</strong>, <strong>an equal shares of resources over time</strong>. It’s mainly designed to share cluster between <strong>a number of users</strong>. It lets short apps are completed in a reasonable time while not starving long-lived apps. (resources might free up when new apps are submitted).</li>
</ul>
</li>
</ul>
</li>
<li><strong>ApplicationManager</strong>: accept job-submisons, negotiate to exeuct application masters, and moniter reboot app master when failure.<ul>
<li>AppMaster are the one who <ul>
<li>apply to Schedular for resources</li>
<li>boot up job execution</li>
<li>moniter the job execution status</li>
<li>tell app manager if the job fails or succeeds.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Other components:</p>
<ul>
<li><a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ReservationSystem.html">ReservationSystem</a>: reserve some resources to ensure the predictable execution of important jobs.</li>
<li><a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/Federation.html">YARN Federation</a>: join clusters to scale and allow multiple independent clusters.</li>
</ul>
<h2 id="an-example"><a href="#an-example" class="headerlink" title="an example"></a>an example</h2><p>Take hive as example:</p>
<h3 id="load-data-–-non-distributed-computing-jobs"><a href="#load-data-–-non-distributed-computing-jobs" class="headerlink" title="load data – non-distributed-computing jobs"></a>load data – non-distributed-computing jobs</h3><ol>
<li>user uses hive command to load data into hive table. (eg. <code>LOAD DATA LOCAL INPATH &#39;/path/to/datafile/&#39; OVERWRITE INTO TABLE table_name;</code>)</li>
<li>hive calls hdfs to write data.</li>
<li>node inform schedular the new node status.</li>
</ol>
<h3 id="query-data-–-distributed-computing-jobs"><a href="#query-data-–-distributed-computing-jobs" class="headerlink" title="query data – distributed computing jobs"></a>query data – distributed computing jobs</h3><ol>
<li>user uses hive command to query data (eg. <code>select count(*) from xxx</code>)</li>
<li>hive submits a map-reduce job to appliction manager</li>
<li>application manager applies to Schedular (??? not sure) for a container to execute application master and boots it.</li>
<li>application master applies to Schedular for resoures to excute map-reduce job and boots the job.</li>
<li>the map-reduce job get input data from hdfs, and write output data into hdfs</li>
<li>the map-reduce job informs the application master the status of the job.</li>
<li>application manager will restart application master on failure (application failure&#x2F;hardware failure). (when application failed, the job informs the app master, and app manager knows it, and then reboot it)</li>
</ol>
<h1 id="JobHistoryServer"><a href="#JobHistoryServer" class="headerlink" title="JobHistoryServer"></a>JobHistoryServer</h1><p>On YARN all applications page, here’s a link to job history. However, you must config to make it take effect.</p>
<p>Follow the instructions <a href="https://blog.csdn.net/xiaoduan_/article/details/79689882">config of johhistory in hadoop</a>. Also, see <a href="https://hadoop.apache.org/docs/r2.7.1/hadoop-project-dist/hadoop-common/ClusterSetup.html">Hadoop Cluster Setup</a> to get info about starting log and jobhistory server. See <a href="https://hadoop.apache.org/docs/r2.4.1/hadoop-yarn/hadoop-yarn-site/HistoryServerRest.html">History Server Rest API</a>, <a href="https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/apidocs/index.html?org/apache/hadoop/mapreduce/v2/hs/package-tree.html">JobHistoryServer javadoc</a></p>
<blockquote>
<p>Notes:</p>
<p>The host of <code>mapreduce.jobhistory.webapp.address</code> and <code>mapreduce.jobhistory.address</code> may need to be set as the real ip (get from <code>ipconfig getifaddr en0</code>) or some other host (eg. cncherish.local) instead of <code>localhost</code>.</p>
<p>When start history server, you can see the start host in the log. It may look like this:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">STARTUP_MSG: Starting JobHistoryServer</span><br><span class="line">STARTUP_MSG:   host = CNcherish.local/192.168.xx.xxx</span><br><span class="line">STARTUP_MSG:   args = []</span><br><span class="line">STARTUP_MSG:   version = 3.1.1</span><br></pre></td></tr></table></figure>

<p>This might be because the JobHistoryServer told <a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/WebApplicationProxy.html#Configurations">yarn web proxy</a> that its host is ‘cncherish.local&#x2F;192.168.xx.xxx’ (mapping host ‘cncherish.local’ to the real ip ‘192.168.xx.xxx’), while yarn knows that history host for map-reduce job is ‘localhost’ from <code>mapred-site.xml</code> — the config for map-reduced jobs. The incompatible info reduce the jobhistory link is unreachable.</p>
</blockquote>
<p>1.add the following properties into the <code>mapred-site.xml</code> (config the map-reduce framework)</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- config to persist the jobhistory logs in hdfs --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.cleaner.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置jobhistoryserver 没有配置的话 history入口不可用 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>192.168.x.xxx:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置web端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>192.168.x.xxx:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置正在运行中的日志在hdfs上的存放路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/history/done_intermediate<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置运行过的日志存放在hdfs上的存放路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/history/done<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>2.add the following properties into the <code>yarn-site.xml</code> (config the yarn — resource manager)</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>3.start the historyserver</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The following command will run server as a background daemon</span></span><br><span class="line">$ mapred --daemon start historyserver</span><br><span class="line"></span><br><span class="line"><span class="comment"># The following command will run server on the current terminal.</span></span><br><span class="line"><span class="comment"># In this way, you can know how the server is started, stopped and what it does.</span></span><br><span class="line"><span class="comment"># Also you can know the real server host from the log, which should be aligned by the mapred-site.xml</span></span><br><span class="line">$ mapred historyserver</span><br></pre></td></tr></table></figure>

<h1 id="rest-api"><a href="#rest-api" class="headerlink" title="rest api"></a>rest api</h1><ul>
<li>yarn rest api:  throught postman <a href="http://localhost:8088/ws/v1/cluster/apps">http://localhost:8088/ws/v1/cluster/apps</a> (get all the apps)</li>
<li>history rest api: <a href="http://cnpzzheng.local:19888/ws/v1/history">http://cnpzzheng.local:19888/ws/v1/history</a> (get server info)<ul>
<li>use 19888 instead of 10020</li>
</ul>
</li>
</ul>
<h1 id="CheatSheet"><a href="#CheatSheet" class="headerlink" title="CheatSheet"></a>CheatSheet</h1><p><a href="https://www.jianshu.com/p/f510a1f8e5f0">link</a></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看正在运行的程序资源使用情况</span></span><br><span class="line">$ yarn top</span><br><span class="line">$ yarn node -all -list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看指定queue使用情况</span></span><br><span class="line">$ yarn queue -status root.users.xxx</span><br><span class="line">$ yarn application -movetoqueue application_1528080031923_0067 -queue root.users.xxx</span><br><span class="line"></span><br><span class="line">$ yarn application -list -appStates [ALL,NEW,NEW_SAVING,SUBMITTED,ACCEPTED,RUNNING,FINISHED,FAILED,KILLED]</span><br><span class="line">$ yarn application -list -appTypes [SUBMITTED, ACCEPTED, RUNNING]</span><br><span class="line">$ yarn applicationattempt -list application_1528080031923_0064</span><br><span class="line"></span><br><span class="line">$ yarn application -<span class="built_in">kill</span> application_1528080031923_0067</span><br><span class="line"></span><br><span class="line">$ yarn logs -applicationId application_1528080031923_0064</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>big data</tag>
        <tag>hadoop</tag>
        <tag>distributed computing</tag>
        <tag>resource manager</tag>
      </tags>
  </entry>
  <entry>
    <title>spark</title>
    <url>/2019/01/10/spark/</url>
    <content><![CDATA[<h1 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h1><p><a href="https://spark.apache.org/docs/latest/">spark</a> is a fast and general-purpose cluster computing system like Hadoop Map-reduce.  It runs on the clusters.</p>
<h2 id="Spark-Ecosystem"><a href="#Spark-Ecosystem" class="headerlink" title="Spark Ecosystem"></a>Spark Ecosystem</h2><p><strong><a href="http://data-flair.training/blogs/apache-spark-ecosystem-components/">The components of Apache Spark Ecosystem</a></strong></p>
<p><img src="https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2017/07/apache-spark-ecosystem-components.jpg" alt="ecosystem"></p>
<ul>
<li>spark core: <strong>cluster computing system</strong>. Provide API to  write computing functions.</li>
<li><a href="https://spark.apache.org/docs/2.4.0/sql-programming-guide.html">Spark SQL</a>. SQL for data processing, like hive?</li>
<li><a href="https://spark.apache.org/docs/2.4.0/ml-guide.html">MLlib</a> for machine learning.</li>
<li><a href="https://spark.apache.org/docs/2.4.0/graphx-programming-guide.html">GraphX</a> for graph processing</li>
<li><a href="https://spark.apache.org/docs/2.4.0/streaming-programming-guide.html">Spark Streaming</a>.</li>
</ul>
<h2 id="Core-concepts"><a href="#Core-concepts" class="headerlink" title="Core concepts???"></a>Core concepts???</h2><ul>
<li><strong>RDDs (Resilient Distributed Datasets)</strong>: RDDs are the fundamental data structure in Spark. They are immutable and can be split into multiple partitions that can be processed in parallel.</li>
<li><strong>Transformations:</strong> Transformations are operations that are applied to RDDs to create new RDDs. Transformations are lazy, which means that they are not executed until an action is called.</li>
<li><strong>Actions:</strong> Actions are operations that are applied to RDDs to produce a result. Actions trigger the execution of all of the transformations that have been applied to the RDD.</li>
<li><strong>DAG (Directed Acyclic Graph)</strong>: A DAG is a graph that represents the dependencies between transformations. Spark uses DAGs to schedule and execute transformations.</li>
<li><strong>SparkContext:</strong> The SparkContext is the entry point to the Spark API. It provides methods for creating RDDs, submitting jobs, and managing resources.</li>
<li><strong>SparkSession:</strong> The SparkSession is a newer API that provides a simpler and more concise way to use Spark. It is built on top of the SparkContext and provides a number of additional features, such as support for SQL and machine learning.</li>
</ul>
<p>Spark Core is the foundation of Apache Spark and provides the essential functionality and APIs for distributed data processing. Here are some key Spark Core concepts explained with examples:</p>
<ol>
<li>Resilient Distributed Datasets (RDDs): RDDs are the fundamental data structure in Spark Core. They represent an immutable distributed collection of objects that can be processed in parallel across a cluster. RDDs can be created from data in Hadoop Distributed File System (HDFS), local file systems, or by transforming existing RDDs. Here’s an example of creating an RDD from a list of numbers:</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> numbers = <span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">val</span> rdd = sparkContext.parallelize(numbers)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Transformations: Transformations are operations performed on RDDs to create new RDDs. Transformations are lazy and do not execute immediately but build a lineage graph to track the transformations applied. Examples of transformations include <code>map</code>, <code>filter</code>, <code>flatMap</code>, and <code>reduceByKey</code>. Here’s an example of applying a transformation to square each element of an RDD:</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> squaredRDD = rdd.map(num =&gt; num * num)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Actions: Actions are operations that trigger the execution of computations and return results or write data to external systems. Actions initiate the evaluation of RDDs and can trigger lineage-based optimizations. Examples of actions include <code>collect</code>, <code>count</code>, <code>reduce</code>, and <code>saveAsTextFile</code>. Here’s an example of performing a sum operation on an RDD:</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> sum = squaredRDD.reduce((a, b) =&gt; a + b)</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Spark Context: The Spark Context (<code>sparkContext</code>) is the entry point and the central coordinator for Spark Core. It establishes a connection to the Spark cluster and manages the execution environment. The Spark Context is used to create RDDs and perform operations on them. Here’s an example of creating a Spark Context:</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;MySparkApp&quot;</span>).setMaster(<span class="string">&quot;local[*]&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> sparkContext = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br></pre></td></tr></table></figure>

<p>These are the core concepts of Spark Core that lay the foundation for distributed data processing in Apache Spark. By understanding RDDs, transformations, actions, and the Spark Context, you can build powerful and scalable data processing applications using Spark.</p>
<h3 id="Spark-Core"><a href="#Spark-Core" class="headerlink" title="Spark Core"></a>Spark Core</h3><p>Spark Core is the fundamental unit of the whole Spark project. Its key features are:</p>
<ul>
<li>It is in charge of essential I&#x2F;O functionalities.</li>
<li>Provide API to defines and manipulate the RDDs. Significant in programming and observing the role of the <strong><a href="http://data-flair.training/blogs/install-apache-spark-multi-node-cluster/">Spark cluster</a></strong>.</li>
<li>Task dispatching, scheduling</li>
<li>Fault recovery.</li>
<li>It overcomes the snag of**<a href="http://data-flair.training/blogs/hadoop-mapreduce-introduction-tutorial-comprehensive-guide/"> MapReduce</a>** by using in-memory computation.</li>
</ul>
<p>Spark makes use of Special data structure known as <strong><a href="http://data-flair.training/blogs/rdd-in-apache-spark/">RDD (Resilient Distributed Dataset)</a></strong>. Spark Core is distributed execution engine with all the functionality attached on its top. For example, MLlib, <strong><a href="http://data-flair.training/blogs/spark-sql-tutorial/">SparkSQL</a></strong>, GraphX, <strong><a href="http://data-flair.training/blogs/apache-spark-streaming-comprehensive-guide/">Spark Streaming</a></strong>. Thus, allows diverse workload on single platform. All the basic functionality of Apache Spark Like <strong><a href="http://data-flair.training/blogs/apache-spark-in-memory-computing/">in-memory computation</a>, <a href="http://data-flair.training/blogs/apache-spark-streaming-fault-tolerance/">fault tolerance</a></strong>, memory management, monitoring, task scheduling is provided by Spark Core.<br>Apart from this Spark also provides the basic connectivity with the data sources. For example, <strong><a href="http://data-flair.training/blogs/category/hbase/">HBase</a></strong>, Amazon S3, **<a href="http://data-flair.training/blogs/comprehensive-hdfs-guide-introduction-architecture-data-read-write-tutorial/">HDFS </a>**etc.</p>
<h4 id="Action-Job-Stage-Task"><a href="#Action-Job-Stage-Task" class="headerlink" title="Action, Job, Stage, Task"></a>Action, Job, Stage, Task<a name="action-job-stage-task" /></h4><p><strong>Actions</strong> are RDD’s operation. <em>reduce, collect, takeSample, take, first, saveAsTextfile, saveAsSequenceFile, countByKey, foreach</em> are common actions in Apache spark.</p>
<p>In a Spark application, when you invoke an action on RDD, a <strong>job</strong> is created. Jobs are the main function that has to be done and is submitted to Spark. The jobs are divided into <strong>stages</strong> depending on how they can be separately carried out (mainly on shuffle boundaries). Then, these stages are divided into <strong>tasks</strong>. Tasks are the smallest unit of work that has to be done the executor.</p>
<p>When you call <code>collect()</code> on an RDD or Dataset, the whole data is sent to the <strong>Driver</strong>. This is why you should be careful when calling <code>collect()</code>.</p>
<p> <strong>An example:</strong></p>
<p><a href="https://stackoverflow.com/questions/28973112/what-is-spark-job">What is Spark Job ?</a></p>
<blockquote>
<p>let’s say you need to do the following:</p>
<ol>
<li>Load a file with people names and addresses into RDD1</li>
<li>Load a file with people names and phones into RDD2</li>
<li>Join RDD1 and RDD2 by name, to get RDD3</li>
<li>Map on RDD3 to get a nice HTML presentation card for each person as RDD4</li>
<li>Save RDD4 to file.</li>
<li>Map RDD1 to extract zipcodes from the addresses to get RDD5</li>
<li>Aggregate on RDD5 to get a count of how many people live on each zipcode as RDD6</li>
<li>Collect RDD6 and prints these stats to the stdout.</li>
</ol>
<p>So,</p>
<ol>
<li>The *<strong>driver program*</strong> is this entire piece of code, running all 8 steps.</li>
<li>Producing the entire HTML card set on step 5 is a *<strong>job*</strong> (clear because we are using the <em>save</em> action, not a transformation). Same with the <em>collect</em> on step 8</li>
<li>Other steps will be organized into *<strong>stages*</strong>, with each job being the result of a sequence of stages. For simple things a job can have a single stage, but the need to repartition data (for instance, the join on step 3) or anything that breaks the locality of the data usually causes more stages to appear. </li>
<li>You can think of stages as computations that produce intermediate results, which can in fact be persisted. For instance, we can persist RDD1 since we’ll be using it more than once, avoiding recomputation.</li>
<li>All 3 above basically talk about how the <em>logic</em> of a given algorithm will be broken. In contrast, a *<strong>task*</strong> is a particular <em>piece of data</em> that will go through a given stage, on a given executor.</li>
</ol>
</blockquote>
<h3 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h3><p>RDD 数据模型</p>
<table>
<thead>
<tr>
<th align="center">属性名</th>
<th align="center">成员类型</th>
<th align="center">属性含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">dependencies</td>
<td align="center">变量</td>
<td align="center">生成该RDD所依赖的父RDD</td>
</tr>
<tr>
<td align="center">compute</td>
<td align="center">方法</td>
<td align="center">生成该RDD的计算接口</td>
</tr>
<tr>
<td align="center">partitions</td>
<td align="center">变量</td>
<td align="center">该RDD的所有数据分片实体</td>
</tr>
<tr>
<td align="center">partitioner</td>
<td align="center">方法</td>
<td align="center">划分数据分片的规则</td>
</tr>
<tr>
<td align="center">preferredLocations</td>
<td align="center">变量</td>
<td align="center">数据分片的物理位置偏好</td>
</tr>
</tbody></table>
<h2 id="SparkContext"><a href="#SparkContext" class="headerlink" title="SparkContext"></a>SparkContext</h2><p><a href="https://data-flair.training/blogs/learn-apache-spark-sparkcontext/">SparkContext</a> is the entry point of Spark functionality. The most important step of any Spark driver application is to generate SparkContext. <strong>It allows your Spark Application to access Spark Cluster</strong> with the help of Resource Manager. </p>
<p>If you want to create SparkContext, first <strong>SparkConf</strong> should be made. The SparkConf has a configuration parameter that our Spark driver application will pass to SparkContext. Some of these parameter defines properties of Spark driver application. While some are used by Spark to allocate resources on the cluster, like the number, memory size, and cores used by executor running on the worker nodes.<br>In short, <strong>it guides how to access the Spark cluster</strong>. After the creation of a SparkContext object, we can invoke functions such as <strong>textFile, sequenceFile, parallelize</strong> etc.<br>Once the SparkContext is created, it can be used to <strong><a href="http://data-flair.training/blogs/how-to-create-rdds-in-apache-spark/">create RDDs</a></strong>, broadcast variable, and accumulator, ingress Spark service and run jobs. All these things can be carried out until SparkContext is stopped.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> add</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(sys.argv) != <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Usage: wordcount &lt;file&gt;&quot;</span>, file=sys.stderr)</span><br><span class="line">        sys.exit(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the builder here defines the sparkConf, and then create a sparkSession with an underlying SparkContext `spark.sparkContext`</span></span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">&quot;PythonWordCount&quot;</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># here by `spark.read.text(&#x27;some.txt&#x27;)`, we use SparkContext create an DataFrame</span></span><br><span class="line">    lines = spark.read.text(sys.argv[<span class="number">1</span>]).rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> r: r[<span class="number">0</span>])</span><br><span class="line">    counts = lines.flatMap(<span class="keyword">lambda</span> x: x.split(<span class="string">&#x27; &#x27;</span>)) \</span><br><span class="line">                  .<span class="built_in">map</span>(<span class="keyword">lambda</span> x: (x, <span class="number">1</span>)) \</span><br><span class="line">                  .reduceByKey(add)</span><br><span class="line">    <span class="comment"># this is the spark action `collect`</span></span><br><span class="line">    output = counts.collect()</span><br><span class="line">    <span class="keyword">for</span> (word, count) <span class="keyword">in</span> output:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;%s: %i&quot;</span> % (word, count))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># this in fact stop the sparkContext</span></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure>

<p><img src="https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2017/08/functions-of-sparkcontext-in-apache-spark.jpg" alt="10 Important Functions of SparkContext in Apache Spark"></p>
<h1 id="How-does-it-run"><a href="#How-does-it-run" class="headerlink" title="How does it run"></a>How does it run</h1><p><a href="https://spark.apache.org/docs/latest/cluster-overview.html">Cluster Mode Overview - Spark 3.4.1 Documentation</a></p>
<p>Spark core contains the main api, driver engine, scheduler… to support the cluster computing. The real computing is completed on the cluster. Spark can connect to many cluster managers(spark’s own standalone cluster manager, mesos, yarn) to complete the jobs. Typically, the process is like this:</p>
<ol>
<li>The user submits a spark application using the <code>spark-submit</code> command.</li>
<li>Spark-submit launches the driver program on the same node in (client mode) or on the cluster (cluster mode) and invokes the main method specified by the user.</li>
<li>The driver program contacts the cluster manager to ask for resources to launch executor JVMs based on the configuration parameters supplied.</li>
<li>The cluster manager launches executor JVMs on worker nodes.</li>
<li>The driver process scans through the user application. Based on the RDD actions and transformations in the program, Spark creates an operator graph.</li>
<li>When an action (such as collect) is called, the graph is submitted to a DAG scheduler. The DAG scheduler divides the operator graph into stages.</li>
<li>A stage comprises tasks based on partitions of the input data. The driver sends work to executors in the form of tasks.</li>
<li>The executors process the task and the result sends back to the driver through the cluster manager.</li>
</ol>
<p><img src="https://spark.apache.org/docs/latest/img/cluster-overview.png" alt="cluster mode overview"></p>
<p><img src="https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2017/08/Internals-of-job-execution-in-spark.jpg" alt="Complete Picture of Apache Spark Job Execution Flow."></p>
<h2 id="Execution-Framework"><a href="#Execution-Framework" class="headerlink" title="Execution Framework???"></a>Execution Framework???</h2><p>The execution framework in Apache Spark is responsible for executing the computations on RDDs and managing the distributed processing across a cluster. Spark provides a flexible execution model that optimizes the execution of transformations and actions based on the directed acyclic graph (DAG) of the computation. Let’s explore the execution framework with examples:</p>
<ol>
<li>DAG Scheduling: Spark’s execution framework utilizes a DAG scheduler to analyze the sequence of transformations applied on RDDs and determine an optimal execution plan. It breaks down the computation into stages, where each stage represents a set of transformations that can be executed independently. For example:</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sparkContext.parallelize(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">val</span> squaredRDD = rdd.map(num =&gt; num * num)</span><br><span class="line"><span class="keyword">val</span> sum = squaredRDD.reduce((a, b) =&gt; a + b)</span><br></pre></td></tr></table></figure>

<p>In this example, Spark recognizes that the <code>map</code> transformation can be executed in a single stage, and the <code>reduce</code> action requires a separate stage.</p>
<ol start="2">
<li>Task Execution: Spark’s execution framework assigns tasks to the available executors in the cluster. Each task is a unit of computation that operates on a subset of the data. The tasks are sent to the executors, where they are executed in parallel. Spark dynamically partitions the data and assigns partitions to different tasks for efficient parallel processing. For example:</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sparkContext.parallelize(<span class="number">1</span> to <span class="number">1000</span>)</span><br><span class="line"><span class="keyword">val</span> filteredData = data.filter(num =&gt; num % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">val</span> count = filteredData.count()</span><br></pre></td></tr></table></figure>

<p>In this example, Spark distributes the data across the cluster and assigns tasks to different partitions of the RDD for parallel execution.</p>
<ol start="3">
<li>Lazy Evaluation: Spark’s execution framework incorporates lazy evaluation, which means that transformations on RDDs are not executed immediately. Instead, Spark builds a lineage graph that tracks the transformations applied to the RDDs. The transformations are evaluated only when an action is triggered. This allows Spark to optimize the execution plan based on the entire computation flow. For example:</li>
</ol>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sparkContext.parallelize(<span class="type">List</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">val</span> squaredRDD = rdd.map(num =&gt; num * num)</span><br><span class="line"><span class="keyword">val</span> filteredRDD = squaredRDD.filter(num =&gt; num &gt; <span class="number">10</span>)</span><br><span class="line"><span class="keyword">val</span> count = filteredRDD.count()</span><br></pre></td></tr></table></figure>

<p>In this example, Spark defers the execution of transformations until the <code>count</code> action is called. It optimizes the execution plan by combining the <code>map</code> and <code>filter</code> operations into a single stage.</p>
<ol start="4">
<li><p>Data Shuffling: Spark’s execution framework handles data shuffling, which is the process of redistributing data across the cluster. Shuffling occurs when operations like groupBy, sortBy, or join require data to be redistributed to ensure that related data is co-located. The execution framework optimizes data shuffling by minimizing data movement and leveraging in-memory operations when possible.</p>
</li>
<li><p>Fault Tolerance: Spark’s execution framework provides fault tolerance by maintaining the lineage information of RDDs. If a partition or task fails, Spark can use the lineage graph to recompute the lost or corrupted data. This ensures the resiliency and reliability of computations.</p>
</li>
</ol>
<p>Overall, Spark’s execution framework efficiently manages the distributed execution of transformations and actions on RDDs. It optimizes the execution plan, leverages parallel processing, and provides fault tolerance to ensure fast and reliable data processing across large-scale clusters.</p>
<p>The Spark execution framework consists of the following components:</p>
<ul>
<li><strong>SparkContext:</strong> The SparkContext is the entry point to the Spark API. It provides methods for creating RDDs, submitting jobs, and managing resources.</li>
<li><strong>DAGScheduler:</strong> The DAGScheduler is responsible for scheduling Spark jobs. It creates a Directed Acyclic Graph (DAG) of transformations and then schedules the execution of the DAG.</li>
<li><strong>TaskScheduler:</strong> The TaskScheduler is responsible for executing Spark jobs. It assigns tasks to executors and monitors the progress of tasks.</li>
<li><strong>Executors:</strong> Executors are the worker nodes in a Spark cluster. They are responsible for executing tasks.</li>
<li><strong>Driver:</strong> The driver is the main process in a Spark cluster. It is responsible for submitting jobs, managing resources, and collecting results.</li>
</ul>
<p>The Spark execution framework works as follows:</p>
<ol>
<li>A user submits a Spark job to the driver.</li>
<li>The driver creates a SparkContext.</li>
<li>The SparkContext creates a DAG of transformations.</li>
<li>The DAGScheduler schedules the execution of the DAG.</li>
<li>The TaskScheduler assigns tasks to executors.</li>
<li>The executors execute the tasks.</li>
<li>The driver collects the results of the tasks.</li>
</ol>
<p>The Spark execution framework is a powerful and flexible system that can be used to run a wide variety of Spark jobs. It is designed to be efficient and scalable, and it can be used to run jobs on a variety of cluster sizes.</p>
<p>Here are some examples of how the Spark execution framework can be used:</p>
<ul>
<li>To run a simple word count job, you can use the following code:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import org.apache.spark.sql.SparkSession</span><br><span class="line"></span><br><span class="line">object WordCount &#123;</span><br><span class="line"></span><br><span class="line">  def main(args: Array[String]) &#123;</span><br><span class="line"></span><br><span class="line">    // Create a SparkSession</span><br><span class="line">    val spark = SparkSession.builder.appName(&quot;WordCount&quot;).getOrCreate()</span><br><span class="line"></span><br><span class="line">    // Read the input data</span><br><span class="line">    val inputData = spark.read.text(&quot;input.txt&quot;)</span><br><span class="line"></span><br><span class="line">    // Split the input data into words</span><br><span class="line">    val words = inputData.flatMap(_.split(&quot; &quot;))</span><br><span class="line"></span><br><span class="line">    // Count the number of occurrences of each word</span><br><span class="line">    val counts = words.countByValue()</span><br><span class="line"></span><br><span class="line">    // Print the results</span><br><span class="line">    counts.show()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><p>You can write spark function (eg. map function, reduce funciton) using Java&#x2F;scala&#x2F;python&#x2F;R API. See <a href="https://spark.apache.org/docs/latest/">api docs</a>.</p>
<h1 id="Installation-On-Yarn"><a href="#Installation-On-Yarn" class="headerlink" title="Installation On Yarn"></a>Installation On Yarn</h1><p>See <a href="https://spark.apache.org/docs/2.4.0/running-on-yarn.html">run spark on Yarn</a>, <a href="https://www.linode.com/docs/databases/hadoop/install-configure-run-spark-on-top-of-hadoop-yarn-cluster/">https://www.linode.com/docs/databases/hadoop/install-configure-run-spark-on-top-of-hadoop-yarn-cluster/</a></p>
<h2 id="understand-spark-installation"><a href="#understand-spark-installation" class="headerlink" title="understand spark installation"></a>understand spark installation</h2><p>Here, we have:</p>
<ul>
<li><p><strong>machine ‘A’</strong>: which is the place to install spark and run <code>spark-submit</code> script</p>
<ul>
<li><p>this can be inside or outside of yarn cluster</p>
</li>
<li><p>spark is installed here</p>
</li>
<li><p>yarn configuration files(e.g. <code>yarn-site.xml</code>), hadoop configuration files (e.g. <code>core-site.xml</code>) must be maintained here. And in the <code>spark-env.sh</code>, <code>HADOOP_CONF_DIR</code> and <code>YARN_CONF_DIR</code> must be set to point the these configuration files.</p>
</li>
</ul>
</li>
<li><p><strong>yarn cluster</strong>: where the spark applications really run. </p>
<ul>
<li><p>We don’t need to pre-install spark here.</p>
</li>
<li><p>YARN will take care of distributing the necessary Spark binaries (JAR) to the nodes dynamically when you submit a Spark application.</p>
</li>
</ul>
</li>
<li><p><strong><code>spark.yarn.jars</code> Configuration</strong> (used in <code>spark-submit</code>)</p>
<ul>
<li>specifies the Spark JARs that will be distributed to the YARN cluster when you submit your application. This version should match the Spark version installed on machine ‘A’.</li>
<li>If not specified, the default jars, located in <code>lib</code> directory of your Spark installation on machine ‘A’</li>
</ul>
</li>
<li><p>Key properties in <code>yarn-site.xml</code> that can be relevant for Spark on a client machine:</p>
</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- YARN ResourceManager address --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;<span class="name">YARN_RESOURCEMANAGER_ADDRESS</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>Key properties in <code>core-site.xml</code> that can be relevant for Spark on a client machine:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Hadoop NameNode address --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;<span class="name">HADOOP_NAMENODE_ADDRESS</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="spark-versions"><a href="#spark-versions" class="headerlink" title="spark versions"></a>spark versions</h3><p>There are 4 versions in topic:</p>
<ol>
<li><p><strong>Version 1: Spark Dependency Version (Application Code):</strong></p>
<ul>
<li>This is the version of Spark that your application code depends on when you write and build your Spark application. It includes Spark libraries and APIs used in your code.</li>
</ul>
</li>
<li><p><strong>Version 2: Installed Spark Version on Machine ‘A’ (spark-submit):</strong></p>
<ul>
<li>This is the version of Spark installed on the machine from which you submit your Spark application using <code>spark-submit</code>. It is the Spark version that the <code>spark-submit</code> script uses to package and submit your application to the cluster.</li>
</ul>
</li>
<li><p><strong>Version 3: Spark Version for Driver and Executors (spark.yarn.jars):</strong></p>
<ul>
<li>This is the Spark version used by the driver program and executors running on the YARN cluster. The <code>spark.yarn.jars</code> configuration points to the Spark JARs (libraries) that will be distributed to the YARN cluster for executing your application.</li>
<li>If <code>spark.yarn.jars</code> not specified, this version is the same as the Version 2, as the jar of that installed spark is used.</li>
</ul>
</li>
<li><p><strong>Version 4: Spark Version Installed on YARN Cluster:</strong></p>
<ul>
<li>This is the version of Spark installed on the machines in the YARN cluster where your Spark application will run. This is in fact the same as Version 3.  Version 3 is the configuration, and Version 4 is the final distributed binaries based on this configuration.</li>
</ul>
</li>
</ol>
<p>Generally speaking, all these versions, in fact the first 3 versions, should point to the same spark binary distribution to avoid compatibility issues. Version 1 and Version 3 must be the same. Even though when <code>spark.yarn.jars</code> provided, the Version 2 may not influence at all. We still recommend to keep it the same to avoid some unknown compatible issues.</p>
<h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><ol>
<li><p><a href="https://spark.apache.org/downloads.html">downloads page</a> download the spark</p>
</li>
<li><p><code>tar -xvf spark-xxx.tgz</code></p>
</li>
<li><p>configuration</p>
</li>
</ol>
<ul>
<li>config in <code>/conf/spark-env.sh</code></li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># config this to specify the installed HADOOP path</span></span><br><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> YARN_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br></pre></td></tr></table></figure>

<ul>
<li>config in <code>/conf/spark-default.conf</code>. (<a href="https://spark.apache.org/docs/2.4.0/configuration.html#spark-properties">all configuration properties</a>)</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># config the spark master</span></span><br><span class="line">spark.master                     yarn</span><br><span class="line">spark.driver.memory    512m</span><br><span class="line">spark.yarn.am.memory    512m</span><br><span class="line">spark.executor.memory          512m</span><br></pre></td></tr></table></figure>



<h2 id="history-server-config"><a href="#history-server-config" class="headerlink" title="history server config"></a>history server config</h2><p>When the spark job is running, you can access the job log by <code>localhost:4040</code>. When the job is finished, by default, the log is not persisted which means you can’t access it. To access the logs later, need to config the following: (see <a href="https://spark.apache.org/docs/latest/monitoring.html">spark Monitoring and Instrumentation</a> and <a href="https://spark.apache.org/docs/2.4.0/running-on-yarn.html#using-the-spark-history-server-to-replace-the-spark-web-ui">using history server to replace the spark web ui</a>)</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># in /conf/spark-default.conf</span></span><br><span class="line"><span class="comment"># config history server</span></span><br><span class="line">spark.ui.filters         org.apache.spark.deploy.yarn.YarnProxyRedirectFilter</span><br><span class="line"></span><br><span class="line"><span class="comment"># tell spark use history server url as the trackint url</span></span><br><span class="line">spark.yarn.historyServer.allowTracking  <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># enable log persistence</span></span><br><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># log write dir. Here use the hdfs dir and you must create the dir in hdfs first</span></span><br><span class="line">spark.eventLog.<span class="built_in">dir</span>               hdfs://localhost:9000/spark-logs</span><br><span class="line"></span><br><span class="line"><span class="comment"># log read dir. Sometimes logs are transfered.</span></span><br><span class="line">spark.history.fs.logDirectory     hdfs://localhost:9000/spark-logs</span><br></pre></td></tr></table></figure>

<h2 id="example-execution"><a href="#example-execution" class="headerlink" title="example execution"></a>example execution</h2><ul>
<li>Start histroy server: <code>sbin/start-history-server.sh</code></li>
<li>execute spark job:</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \</span><br><span class="line">    --master yarn \</span><br><span class="line">    --deploy-mode client \</span><br><span class="line">    --driver-memory 4g \</span><br><span class="line">    --executor-memory 2g \</span><br><span class="line">    --executor-cores 1 \</span><br><span class="line">    examples/jars/spark-examples*.jar \</span><br><span class="line">    10</span><br></pre></td></tr></table></figure>

<p>Then you can:</p>
<ul>
<li><p>Check the job&#x2F;application info in yarn: <code>http://localhost:8088/cluster/apps</code></p>
</li>
<li><p>Check the job&#x2F;application using Spark history server: <code>http://localhost:18080/</code></p>
</li>
</ul>
<h1 id="Glossary"><a href="#Glossary" class="headerlink" title="Glossary"></a>Glossary</h1><p><a href="https://spark.apache.org/docs/latest/cluster-overview.html#glossary">glossary</a></p>
<p>NoteThe following table summarizes terms you’ll see used to refer to cluster concepts:</p>
<table>
<thead>
<tr>
<th align="left">Term</th>
<th align="left">Meaning</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Application</td>
<td align="left">User program built on Spark. Consists of a <em>driver program</em> and <em>executors</em> on the cluster.</td>
</tr>
<tr>
<td align="left">Application jar</td>
<td align="left">A jar containing the user’s Spark application. In some cases users will want to create an “uber jar” containing their application along with its dependencies**. The user’s jar should never include Hadoop or Spark libraries, however, these will be added at runtime.**</td>
</tr>
<tr>
<td align="left">Driver program</td>
<td align="left">The process running the main() function of the application and creating the SparkContext</td>
</tr>
<tr>
<td align="left">Cluster manager</td>
<td align="left">An external service for acquiring resources on the cluster (e.g. standalone manager, Mesos, YARN)</td>
</tr>
<tr>
<td align="left">Deploy mode</td>
<td align="left">Distinguishes where the driver process runs. In “cluster” mode, the framework launches the driver inside of the cluster. In “client” mode, the submitter launches the driver outside of the cluster.</td>
</tr>
<tr>
<td align="left">Worker node</td>
<td align="left">Any node that can run application code in the cluster</td>
</tr>
<tr>
<td align="left">Executor</td>
<td align="left">A process launched for an application on a worker node, that runs tasks and keeps data in memory or disk storage across them. Each application has its own executors.</td>
</tr>
<tr>
<td align="left">Task</td>
<td align="left">A unit of work that will be sent to one executor</td>
</tr>
<tr>
<td align="left">Job</td>
<td align="left">A parallel computation consisting of multiple tasks that gets spawned in response to a Spark action (e.g. <code>save</code>, <code>collect</code>); you’ll see this term used in the driver’s logs.</td>
</tr>
<tr>
<td align="left">Stage</td>
<td align="left">Each job gets divided into smaller sets of tasks called <em>stages</em> that depend on each other (similar to the map and reduce stages in MapReduce); you’ll see this term used in the driver’s logs.</td>
</tr>
</tbody></table>
<h1 id="Deploy-mode"><a href="#Deploy-mode" class="headerlink" title="Deploy mode"></a>Deploy mode</h1><h2 id="yarn-client-vs-yarn-cluster"><a href="#yarn-client-vs-yarn-cluster" class="headerlink" title="yarn-client vs yarn-cluster"></a>yarn-client vs yarn-cluster</h2><p><a href="https://www.cnblogs.com/ittangtang/p/7967386.html">yarn-client vs yarn-cluster 深度剖析</a></p>
<p><a href="https://stackoverflow.com/questions/41124428/spark-yarn-cluster-vs-client-how-to-choose-which-one-to-use">stackoverflow</a></p>
<h1 id="spark-shell-vs-spark-submit"><a href="#spark-shell-vs-spark-submit" class="headerlink" title="spark-shell vs spark-submit"></a>spark-shell vs spark-submit</h1><p>Spark shell is only intended to be use for testing and perhaps development of small applications - is only an interactive shell and should not be use to run production spark applications. For production application deployment you should use spark-submit. The last one will also allow you to run applications in yarn-cluster mode</p>
<h1 id="Spark-DataFrame"><a href="#Spark-DataFrame" class="headerlink" title="Spark DataFrame"></a>Spark DataFrame</h1><h2 id="auto-increment-id"><a href="#auto-increment-id" class="headerlink" title="auto increment id"></a>auto increment id</h2><p><a href="https://blog.csdn.net/k_wzzc/article/details/84996172">two ways for auto increment id</a></p>
<h3 id="Row-number"><a href="#Row-number" class="headerlink" title="Row_number"></a>Row_number</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 设置窗口函数的分区以及排序，因为是全局排序而不是分组排序，所有分区依据为空</span></span><br><span class="line"><span class="comment">  * 排序规则没有特殊要求也可以随意填写</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="keyword">val</span> spec = <span class="type">Window</span>.partitionBy().orderBy($<span class="string">&quot;lon&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> df1 = dataframe.withColumn(<span class="string">&quot;id&quot;</span>, row_number().over(spec))</span><br><span class="line"></span><br><span class="line">df1.show()</span><br></pre></td></tr></table></figure>

<h3 id="rdd-zipWithIndex"><a href="#rdd-zipWithIndex" class="headerlink" title="rdd.zipWithIndex"></a>rdd.zipWithIndex</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在原Schema信息的基础上添加一列 “id”信息</span></span><br><span class="line"> <span class="keyword">val</span> schema: <span class="type">StructType</span> = dataframe.schema.add(<span class="type">StructField</span>(<span class="string">&quot;id&quot;</span>, <span class="type">LongType</span>))</span><br><span class="line"></span><br><span class="line"> <span class="comment">// DataFrame转RDD 然后调用 zipWithIndex</span></span><br><span class="line"> <span class="keyword">val</span> dfRDD: <span class="type">RDD</span>[(<span class="type">Row</span>, <span class="type">Long</span>)] = dataframe.rdd.zipWithIndex()</span><br><span class="line"></span><br><span class="line"> <span class="keyword">val</span> rowRDD: <span class="type">RDD</span>[<span class="type">Row</span>] = dfRDD.map(tp =&gt; <span class="type">Row</span>.merge(tp._1, <span class="type">Row</span>(tp._2)))</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 将添加了索引的RDD 转化为DataFrame</span></span><br><span class="line"> <span class="keyword">val</span> df2 = spark.createDataFrame(rowRDD, schema)</span><br><span class="line"></span><br><span class="line"> df2.show()</span><br></pre></td></tr></table></figure>

<h2 id="Add-constant-column"><a href="#Add-constant-column" class="headerlink" title="Add constant column"></a>Add constant column</h2><p><a href="https://stackoverflow.com/questions/32788322/how-to-add-a-constant-column-in-a-spark-dataframe">add constant column</a></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.typedLit</span><br><span class="line"></span><br><span class="line">df.withColumn(<span class="string">&quot;some_array&quot;</span>, typedLit(<span class="type">Seq</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)))</span><br><span class="line">df.withColumn(<span class="string">&quot;some_struct&quot;</span>, typedLit((<span class="string">&quot;foo&quot;</span>, <span class="number">1</span>, <span class="number">0.3</span>)))</span><br><span class="line">df.withColumn(<span class="string">&quot;some_map&quot;</span>, typedLit(<span class="type">Map</span>(<span class="string">&quot;key1&quot;</span> -&gt; <span class="number">1</span>, <span class="string">&quot;key2&quot;</span> -&gt; <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">from pyspark.sql.functions <span class="keyword">import</span> lit</span><br><span class="line">df.withColumn(&#x27;new_column&#x27;, lit(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<h2 id="select-latest-record"><a href="#select-latest-record" class="headerlink" title="select latest record"></a>select latest record</h2><p><a href="https://stackoverflow.com/questions/55615716/select-latest-record-from-spark-dataframe">stackoverflow</a></p>
<h1 id="Hive-Hints"><a href="#Hive-Hints" class="headerlink" title="Hive Hints"></a>Hive Hints</h1><p><a href="https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-hints.html#partitioning-hints">hive hints</a></p>
<h1 id="PySpark"><a href="#PySpark" class="headerlink" title="PySpark???"></a>PySpark???</h1><h2 id="context-switching"><a href="#context-switching" class="headerlink" title="context switching"></a>context switching</h2><p>When executing Python code, such as Pandas or PySpark UDFs, the related data is processed within the executor’s Python interpreter. The executor’s Python interpreter operates directly on the data available on the executor node, without the need to transfer the data back to the driver node.</p>
<p>This is one of the benefits of using PySpark and executing Python code within the Spark framework. The data is distributed across the worker nodes, and the Python code is executed in parallel on the executor nodes where the data resides. This avoids unnecessary data transfer between the executor nodes and the driver node, which can improve performance and reduce network overhead.</p>
<p>When you invoke Python code, such as a Pandas or PySpark UDF, on a Spark DataFrame, the processing happens in a distributed manner on the executor nodes. Each executor processes the corresponding subset of the data and applies the Python code to that subset independently. The results are then combined, and the final result is returned to the driver node.</p>
<p>It’s worth noting that the data transfer between the executor nodes and the driver node typically occurs when there is a need to <strong>exchange intermediate results, aggregate data, or perform actions that require collecting data to the driver</strong>, such as calling <code>collect()</code> or <code>toPandas()</code>. In those cases, the relevant data is transferred from the executor nodes to the driver node. However, for processing performed within the executor’s Python interpreter, the data remains on the executor node and is processed locally within the Python environment of each executor.</p>
<p>Within each executor process on the worker nodes, there is an instance of the Spark engine. The Spark engine is responsible for coordinating the execution of tasks, managing data partitions, optimizing query plans, and handling data distribution and parallelization.</p>
<p>The Spark engine within the executor process, often referred to as the “Spark Task Execution Engine,” is implemented in Java and runs within the JVM portion of the executor. It handles the coordination and execution of tasks assigned to that executor, manages data partitioning, and applies optimizations to the execution plan.</p>
<p>The Python interpreter within the executor process interacts with the Spark engine through a bridge, commonly known as the PySpark API or PySpark Gateway. This bridge facilitates the communication and coordination between the Python interpreter and the Spark engine. It allows the Python interpreter to send instructions and data to the Spark engine, and the Spark engine to send results and intermediate data back to the Python interpreter.</p>
<p>The PySpark API acts as a bridge between the Python code and the Spark engine, enabling seamless integration between Python and Spark. It allows Python code, including Pandas or PySpark UDFs, to interact with the Spark engine’s distributed computing capabilities and leverage its optimizations and parallel processing.</p>
<p>Through this bridge, the Python interpreter can issue Spark operations, manipulate distributed data, and coordinate with the Spark engine for task execution, data shuffling, and data serialization. The Spark engine, in turn, manages the execution plan, coordinates task execution across worker nodes, and optimizes the execution for distributed processing.</p>
<p>So, in summary, there is a Spark engine within each executor process on the worker nodes, and there is a bridge (PySpark API) that facilitates communication between the Python interpreter and the Spark engine within the executor process.</p>
<p>————–wrong????———————–</p>
<ol>
<li>The Python interpreter referred to in the context of PySpark is primarily associated with the driver program. The driver program runs the user code and coordinates the execution of the Spark job. It initiates the execution of tasks on the worker nodes (executors) and manages the overall workflow of the Spark application.</li>
</ol>
<p>When a PySpark UDF is used, the UDF code itself runs within the Python interpreter on the driver. However, the data on which the UDF operates is distributed across the worker nodes. PySpark leverages a client-server architecture to transfer the necessary data from the worker nodes to the Python interpreter on the driver. This means that when the UDF is applied to a DataFrame column, the data required for computation is shipped from the executor nodes to the driver node. This movement of data incurs serialization and deserialization overhead.</p>
<ol start="2">
<li><p>When using PySpark to define a UDF, the UDF operates within the Python environment. The UDF defined in Python is not directly converted to a Scala UDF. Instead, PySpark provides a bridge between Python and the underlying Spark engine, allowing the execution of Python code within the Spark framework. The UDF is executed by the Python interpreter on the driver, and the necessary data is shipped from the executors to the driver for computation.</p>
</li>
<li><p>Let’s dive into the practices mentioned in more detail:</p>
</li>
</ol>
<ul>
<li><p>Use Broadcast Variables: Spark’s broadcast variables allow you to efficiently share small read-only data structures across all the tasks in a Spark job. Instead of sending the data separately to each executor, the data is broadcasted to all the nodes, reducing the need for repeated serialization and deserialization. This is particularly useful when you have small lookup tables or configuration data that is required by multiple tasks. Broadcasting such variables helps in avoiding the overhead of transferring the same data to each task individually.</p>
</li>
<li><p>Utilize Vectorized Operations: Vectorized operations refer to performing operations on entire arrays or columns of data instead of individual elements. Libraries like NumPy and Pandas provide vectorized operations, which process data in bulk using optimized low-level operations. By leveraging these libraries within PySpark, you can take advantage of efficient vectorized operations and reduce the need for individual serialization and deserialization of data. This can significantly improve performance, especially when working with large datasets.</p>
</li>
</ul>
<p>By using broadcast variables and utilizing vectorized operations, you can optimize the performance of your PySpark applications by reducing the serialization overhead and minimizing data movement across the Python and Java&#x2F;Scala runtime environments.</p>
<ol>
<li><p>The bridge between Python and the underlying Spark engine is primarily established on the driver node. PySpark acts as a connector between the Python code running on the driver and the Spark engine, which is typically implemented in Scala and Java. The driver node runs the Python interpreter and coordinates the execution of Spark tasks on the executor nodes.</p>
</li>
<li><p>The Scala UDF definition&#x2F;registration is sent to the executor nodes during the execution of a Spark job. When you define or register a Scala UDF, it is part of the overall job’s execution plan. When the job is submitted to Spark for execution, the plan is distributed to the worker nodes (executors). The necessary functions, including the Scala UDF, are then available on each executor to perform the required computations.</p>
</li>
<li><p>When utilizing vectorized operations with libraries like Pandas or NumPy within PySpark, it is correct that the data required for processing needs to be sent from the data nodes to the driver node. This transfer of data incurs serialization and deserialization overhead. However, vectorized operations are designed to process data in bulk, leveraging highly optimized low-level operations. This allows for efficient computation within the Python interpreter on the driver node, potentially reducing the overall processing time. It’s important to consider the trade-off between the serialization overhead and the performance gain achieved through vectorized operations. This approach is most effective when the benefits of vectorized operations outweigh the cost of data transfer between the nodes.</p>
</li>
</ol>
<p>Certainly! Let’s walk through the end-to-end process and the components involved when a PySpark application is submitted. We’ll consider a scenario where both Spark UDFs and Python UDFs are registered and used, and Pandas is utilized to process certain columns. The example will cover the key components and steps involved in the process:</p>
<ol>
<li><p>Driver Node and Application Submission:</p>
<ul>
<li>The driver node is a machine where the PySpark application is submitted and executed.</li>
<li>The driver node runs the Python interpreter and initiates the execution of the Spark application.</li>
</ul>
</li>
<li><p>Spark Context and Session:</p>
<ul>
<li>The Spark Context (SparkContext) is created on the driver node as the entry point to the Spark application.</li>
<li>The Spark Session (SparkSession) is a higher-level API that provides a unified interface for interacting with Spark and enables DataFrame and Dataset operations.</li>
</ul>
</li>
<li><p>Job Execution and Task Distribution:</p>
<ul>
<li>The PySpark application code, including the registration of Spark UDFs and Python UDFs, is executed on the driver node.</li>
<li>The application code defines transformations and actions on Spark DataFrames or RDDs.</li>
<li>Spark breaks down the transformations into a directed acyclic graph (DAG) of stages and tasks.</li>
<li>The tasks are distributed across the worker nodes (executors) for parallel execution.</li>
</ul>
</li>
<li><p>Data Processing:</p>
<ul>
<li>When a transformation or action is invoked, Spark creates a logical plan that represents the computations required.</li>
<li>If a Python UDF is used, data required for processing is transferred from the executor nodes to the driver node for UDF computation.</li>
<li>If a Spark UDF is used, the UDF computation occurs within the Spark engine on the executor nodes, without data transfer to the driver.</li>
</ul>
</li>
<li><p>Serialization and Deserialization:</p>
<ul>
<li>Data serialization and deserialization occur when transferring data between the Python and Java&#x2F;Scala runtime environments.</li>
<li>When using Pandas to process columns, the data may need to be serialized for transfer to the driver and deserialized back into Pandas DataFrame structures.</li>
</ul>
</li>
<li><p>Spark Catalyst Optimizer and Execution:</p>
<ul>
<li>Spark’s Catalyst optimizer analyzes the logical plan and optimizes it by applying various rule-based transformations to generate an optimized physical plan.</li>
<li>The optimized physical plan is executed by the Spark engine on the executor nodes, leveraging Spark’s execution engine components such as the Task Scheduler, Shuffle Manager, and Memory Management.</li>
</ul>
</li>
<li><p>Result Aggregation and Return:</p>
<ul>
<li>The results of transformations and actions are aggregated and returned to the driver node.</li>
<li>If required, Pandas can be used to process the result data on the driver node, leveraging its functionality for further analysis or visualization.</li>
</ul>
</li>
</ol>
<p>It’s important to note that the components and steps involved can vary depending on the specifics of the PySpark application and the cluster configuration. The example provided highlights the major components and steps, focusing on the interactions between the driver node, executor nodes, and data transfer between Python and Java&#x2F;Scala environments.</p>
<p>—————-wrong????——————</p>
<h2 id="pyspark-udf-vs-scala-udf"><a href="#pyspark-udf-vs-scala-udf" class="headerlink" title="pyspark udf vs scala udf"></a>pyspark udf vs scala udf</h2><p>Certainly! Let’s delve into the performance aspect of using UDFs defined in Scala versus PySpark in more detail:</p>
<ol>
<li><p>Execution Engine Integration: Scala UDFs have a closer integration with Spark’s execution engine since Scala is the native language for Spark. This tight integration allows Scala UDFs to leverage Spark’s Catalyst optimizer and take advantage of advanced query optimization techniques. This can potentially lead to better query planning and execution, resulting in improved performance.</p>
</li>
<li><p>Serialization and Deserialization Overhead: When using PySpark UDFs, data must be serialized and deserialized between the Python and Java&#x2F;Scala runtime environments. This incurs additional overhead and can impact performance, especially when working with large datasets. In contrast, Scala UDFs avoid this serialization overhead since they operate directly within the Spark engine.</p>
</li>
<li><p>JIT Compilation: Scala benefits from just-in-time (JIT) compilation provided by the Java Virtual Machine (JVM). This means that Scala UDFs can be optimized at runtime, potentially resulting in better performance. In contrast, Python code executed within PySpark does not have the same level of JIT compilation, which can lead to slower execution.</p>
</li>
<li><p>Data Movement and Shuffling: Both Scala and PySpark UDFs may involve data movement and shuffling operations, which can impact performance. However, since Scala UDFs have a closer integration with Spark’s execution engine, they may enable more efficient data processing and minimize data shuffling, leading to better performance in certain scenarios.</p>
</li>
</ol>
<p>It’s important to note that the performance impact of using UDFs can vary depending on the specific workload, data size, and operations performed. In some cases, the overhead introduced by PySpark UDFs may not be significant, especially if the UDFs themselves are not the main bottleneck in the application. Additionally, other factors such as cluster configuration, data skew, and overall data processing pipeline design can also influence performance.</p>
<p>To determine the performance implications of using UDFs, it’s recommended to benchmark and profile your specific Spark application using both Scala and PySpark implementations. This will provide insights into the actual performance differences and help you make an informed decision based on your specific requirements and constraints.</p>
<h2 id="Arrow"><a href="#Arrow" class="headerlink" title="Arrow"></a>Arrow</h2><p><a href="https://spark.apache.org/docs/latest/api/python/user_guide/sql/arrow_pandas.html">Apache Arrow in PySpark 3.4.1 documentation</a></p>
<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><p><a href="https://www.youtube.com/watch?v=daXEp4HmS-E">deep dive - spark optimization</a></p>
<p><a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html">performance tuning</a></p>
<h2 id="Get-Baseline"><a href="#Get-Baseline" class="headerlink" title="Get Baseline"></a>Get Baseline</h2><ol>
<li>利用 spark-ui 观察任务运行情况（long stages，spill，laggard tasks, etc.）</li>
<li>利用 yarn 等观察资源利用情况（CPU 利用率 etc.）</li>
</ol>
<h2 id="Memory-spill"><a href="#Memory-spill" class="headerlink" title="Memory spill"></a>Memory spill<a name = "memory-spill" /></h2><p>Spark 运行时会分配一定的 memory（可以<a href="#specify-resources">指定资源需求</a>)， 分 storage 和 working memory。</p>
<ul>
<li>storage memory 是 persist 会用的 memory。当调用 persist（或 cache，一种使用 <code>StorageLevel.MemoryAndDisk</code> 的 persist）时，如果指定的 storage_level 有 memory，那么就会将数据存到 memory。</li>
<li>working memory 是 spark 运算所需要的 memory，这个大小是动态变化的。当 storage memory 占用过多内存时，working memory 就不够了。然后就会有 spill，就会慢。</li>
</ul>
<p>memory spill 表示 working memory 不够，spark 开始使用 disk。而 disk 的 I&#x2F;O 效率是极低的。所以一旦出现 spill，性能就会大大降低。</p>
<p>working memory 不够有很多原因：</p>
<ol>
<li>Memory 资源申请的太少了，就是不够 &#x3D;&#x3D;&#x3D;&#x3D;》 增加 <code>spark.executor.memory</code><ol>
<li>数据在 memory&#x2F;disk 的存储一般是 serialized，以节省空间。但数据 load 到 working memory 时，一般都是 deserialized 的，处理更快，但是更占空间。</li>
</ol>
</li>
<li>资源可以了，partition 太少，每个 partition 处理的数据太多，所以 spill 了 &#x3D;&#x3D;&#x3D;&#x3D;》 增加 <a href="shuffle-partition">shuffle partition</a></li>
<li>有不均衡出现，导致某些 task 处理的数据尤其多 &#x3D;&#x3D;&#x3D;&#x3D;》see <a href="#balance">balance</a></li>
<li>有太多 persist，持久化了太多东西，占用过多的 storage memory &#x3D;&#x3D;&#x3D;&#x3D;》see <a href="#persistence">persistence</a></li>
</ol>
<p><img src="/../images/spark-storage-hierachy.png" alt="image-20210319124829765"></p>
<p><img src="/../images/spark-memory-overhead.png" alt="memory overhead"></p>
<h2 id="指定资源需求"><a href="#指定资源需求" class="headerlink" title="指定资源需求"></a>指定资源需求<a name="specify-resources" /></h2><p>Spark-submit 运行时，可通过指定以下参数来定义运行所需的资源：</p>
<ul>
<li><code>--conf spark.num.executors=xx</code> (或 <code>--num-executors xx</code>)：指定运行时需要几个 executor（也可以通过 <a href="#dynamic-allocation">dynamic allocation</a> 来根据运算动态分配 executors）</li>
<li><code>--conf spark.executor.memory=xxG</code>（或 <code>--executor-memory xxG</code>）：指定每个 executor 所需要的内存</li>
<li><code>--conf spark.executor.cores=xx</code>（或 <code>--executor-cores xx</code>）：指定每个 executor 所需要的 cores</li>
<li><code>--conf spark.driver.memory=xxG</code>（或 <code>--driver-memory xxG</code>）：指定每个 driver 所需要的内存。当执行 <code>df.collect()</code>时，会将数据 collect 到 driver，此时就需要 driver 有很多的 memory</li>
<li><code>--conf spark.driver.cores=xx</code>（或 <code>--driver-cores xx</code>）：指定每个 driver 所需要的 cores</li>
</ul>
<h2 id="Some-issues"><a href="#Some-issues" class="headerlink" title="Some issues"></a>Some issues</h2><h3 id="–executor-cores-settinng-not-working"><a href="#–executor-cores-settinng-not-working" class="headerlink" title="–executor-cores settinng not working"></a>–executor-cores settinng not working</h3><p>需要配置 <code>yarn.scheduler.capacity.resource-calculator=org.apache.hadoop.yarn.util.resource.DominantResourceCalculator</code>，因为默认的使用的是 <a href="https://apache.googlesource.com/hadoop-common/+/e0c9f893b684246feb5b4adbb95a05a436cdb790/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/resource/DefaultResourceCalculator.java">DefaultResourceCalculator</a>，它只看 memory(–executor-memory)，DominantResourceCalculator 则同时考虑 cpu 和 memory</p>
<p>see <a href="https://stackoverflow.com/questions/33248108/spark-executor-on-yarn-client-does-not-take-executor-core-count-configuration">stackoverflow</a></p>
<h3 id="–spark-dynamicAllocation-maxExecutors-not-working"><a href="#–spark-dynamicAllocation-maxExecutors-not-working" class="headerlink" title="–spark.dynamicAllocation.maxExecutors not working"></a>–spark.dynamicAllocation.maxExecutors not working<a name="dynamic-allocation" /></h3><p>这个需要和其他配置配合使用</p>
<blockquote>
<p>spark.dynamicAllocation.enabled &#x3D; true<br>This requires <code>spark.shuffle.service.enabled</code> or <code>spark.dynamicAllocation.shuffleTracking.enabled</code> to be set. The following configurations are also relevant: <code>spark.dynamicAllocation.minExecutors</code>, <code>spark.dynamicAllocation.maxExecutors</code>, and <code>spark.dynamicAllocation.initialExecutors</code> <code>spark.dynamicAllocation.executorAllocationRatio</code></p>
</blockquote>
<p>如果还不工作，可能要按 [spark dynamic allocation not working](https://community.cloudera.com/t5/Support-Questions/Spark-dynamic-allocation-dont-work/td-p/140227 设置各 nodemanager 并重启</p>
<p>See <a href="https://spark.apache.org/docs/latest/configuration.html#dynamic-allocation">spark dynamic allocation</a></p>
<h2 id="Partitions"><a href="#Partitions" class="headerlink" title="Partitions"></a>Partitions</h2><p>接下来从输入、运行、输出三个阶段的 partition 优化来看</p>
<p>一般 1 partition -&gt; 1 task，分多少个 partition，就拆多少个 task 来运行。</p>
<ol>
<li><strong>Avoid the spills</strong></li>
<li><strong>Maximize parallelism</strong><ol>
<li>utilize all cores</li>
<li>provision only the cores you need</li>
</ol>
</li>
</ol>
<h3 id="输入（input）"><a href="#输入（input）" class="headerlink" title="输入（input）"></a>输入（input）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.default.parallelism (don&#x27;t use)</span><br><span class="line">spark.sql.files.maxPartitionBytes (mutable，控制每个 partition 读的文件大小)</span><br></pre></td></tr></table></figure>

<h3 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle<a name="shuffle-partition" /></h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">spark.sql.shuffle.partitions（控制使用多少个 partition 来 shuffle）</span><br><span class="line">spark.default.parallelism（控制 rdd 的 partition 数目？？？？？？）</span><br></pre></td></tr></table></figure>

<p>如果配置了 <code>spark.conf.set(&quot;spark.sql.adaptive.enabled&quot;, &#39;true&#39;)</code> 或 <code>spark.sql.adaptive.coalescePartitions.enabled</code> ，它会动态控制 parition count （参见 <a href="https://spark.apache.org/docs/latest/sql-performance-tuning.html#coalescing-post-shuffle-partitions">coalescing post shuffle partitions</a>），根据 shuffle 数据大小来动态设置 partition 数目。但是这个设置可能不合理，因为 shuffle 过程中，最终操作的数据可能远大于 shuffle read 的大小，这个过程中存在 deserialize 等。如果配置了动态控制，依然出现了 shuffle spill，那么可以先关掉这个配置，手动控制 shuffle partitions 大小。</p>
<h3 id="输出（output）"><a href="#输出（output）" class="headerlink" title="输出（output）"></a>输出（output）</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">coalesce</span><br><span class="line">repartition</span><br><span class="line">repartition(range) ===&gt; range partitioner???</span><br><span class="line">df.localCheckPoint().repartition().... ==&gt; how to use tis</span><br></pre></td></tr></table></figure>

<h2 id="Balance"><a href="#Balance" class="headerlink" title="Balance"></a>Balance<a name="balance" /></h2><p>When some partitions are significantly larger than most, there is skew.</p>
<p>Balance 体现在很多方面：网络、GC、数据，当然最常见的问题是数据的不均匀。</p>
<p>通过查看 spark ui 可以看到不均匀的任务（这个时候需要停掉重跑）：</p>
<ol>
<li>查看 straggling tasks<ol>
<li>查看 stage 执行进度：stage 里剩余几个 task 执行特别慢，这个时候各个 task 处理的数据肯定存在不均匀，导致那几个 task 处理的尤其慢<ol>
<li><img src="/../images/spark-straggling-task1.png" alt="image-20210317130715804"></li>
</ol>
</li>
<li>查看 stage 执行 metric：大部分时候没有 spill，但是 max 的时候有 spill；或者大部分的时候 read size 和 max read size 有很大差别<ol>
<li><img src="/../images/spark-straggling-task2.png" alt="image-20210317130618356"></li>
</ol>
</li>
</ol>
</li>
<li>查看 stage 里各个节点的 GC time，GC time 分布不均匀，也是有问题的（什么问题？？）<ol>
<li><img src="/../images/spark-gc-skew.png" alt="image-20210317130839506"></li>
</ol>
</li>
<li></li>
</ol>
<h2 id="Persistence"><a href="#Persistence" class="headerlink" title="Persistence"></a>Persistence<a name="persistence" /></h2><p>当 execution plan 中，有些 superset 被多个 subset 所使用，superset 计算复杂、耗时久，这个时候就可以选择将 superset persist，从而避免重复运算。</p>
<blockquote>
<p><a href="#action-job-stage-task">spark core</a> 中有几个概念，其中只有 action 会触发一次 dag 的运行。同一段代码，可能会生成不同的 dag，每次都需要执行。所以如果被多次使用的 superset，最好将它 cache，避免后续的重复运算。</p>
</blockquote>
<p>persist&#x2F;cache 要慎用，因为：</p>
<ol>
<li>占资源。当 persist 消耗了太多的 storage memory 时，就会出现 <a href="#memory-spill">memory spill</a></li>
<li>也有时间损耗（serialize, deserialize, I&#x2F;O)。persist 一般都以 serialized 的形式存储，节省空间，而 load 到 working memory 时，又需要 deserialiize</li>
</ol>
<blockquote>
<p>In Python, stored objects will always be serialized with the <a href="https://docs.python.org/3/library/pickle.html">Pickle</a> library, so it does not matter whether you choose a serialized level. The available storage levels in Python include <code>MEMORY_ONLY</code>, <code>MEMORY_ONLY_2</code>, <code>MEMORY_AND_DISK</code>, <code>MEMORY_AND_DISK_2</code>, <code>DISK_ONLY</code>, <code>DISK_ONLY_2</code>, and <code>DISK_ONLY_3</code>.*</p>
</blockquote>
<h3 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h3><p>Cache 是选择 default 的 persist。persist 可以选择不同的 <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence">persistence storage level</a> </p>
<p>With <code>cache()</code>, you use only the default storage level :</p>
<ul>
<li><code>MEMORY_ONLY</code> for <strong>RDD</strong></li>
<li><code>MEMORY_AND_DISK</code> for <strong>Dataset</strong></li>
</ul>
<p>With <code>persist()</code>, you can specify which storage level you want for both <strong>RDD</strong> and <strong>Dataset</strong>.</p>
<p>From the official docs:</p>
<blockquote>
<ul>
<li>You can mark an <code>RDD</code> to be persisted using the <code>persist</code>() or <code>cache</code>() methods on it.</li>
<li>each persisted <code>RDD</code> can be stored using a different <code>storage level</code></li>
<li>The <code>cache</code>() method is a shorthand for using the default storage level, which is <code>StorageLevel.MEMORY_ONLY</code> (store deserialized objects in memory).</li>
</ul>
</blockquote>
<p>Use <code>persist()</code> if you want to assign a storage level other than :</p>
<ul>
<li><code>MEMORY_ONLY</code> to the <strong>RDD</strong></li>
<li>or <code>MEMORY_AND_DISK</code> for <strong>Dataset</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">spark.catalog.cacheTable(<span class="string">&quot;tableName&quot;</span>)</span><br><span class="line">spark.catalog.uncacheTable(<span class="string">&quot;tableName&quot;</span>)</span><br><span class="line"></span><br><span class="line">dataFrame.cache()</span><br></pre></td></tr></table></figure>

<h2 id="broadcast-join"><a href="#broadcast-join" class="headerlink" title="broadcast join"></a>broadcast join</h2><p><a href="https://zhuanlan.zhihu.com/p/58765338">spark 执行 map-join 优化</a></p>
<p><a href="https://www.jianshu.com/p/2c7689294a73">spark broadcast join</a></p>
<p>几种方式：</p>
<h3 id="1-spark-自动识别小表-broadcast"><a href="#1-spark-自动识别小表-broadcast" class="headerlink" title="1. spark 自动识别小表 broadcast"></a>1. spark 自动识别小表 broadcast</h3><p><code>spark.sql.statistics.fallBackToHdfs=True</code>, 这样它会直接分析文件的大小，而不是 metastore 数据</p>
<h3 id="2-使用-hint"><a href="#2-使用-hint" class="headerlink" title="2. 使用 hint"></a>2. 使用 hint</h3><p><a href="https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-hints.html#partitioning-hints">hive hints</a></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="comment">/*+ BROADCAST (b) */</span> <span class="operator">*</span> <span class="keyword">from</span> a <span class="keyword">where</span> id <span class="keyword">not</span> <span class="keyword">in</span> (<span class="keyword">select</span> id <span class="keyword">from</span> b)</span><br></pre></td></tr></table></figure>

<h3 id="3-使用-dataframe-api"><a href="#3-使用-dataframe-api" class="headerlink" title="3. 使用 dataframe api"></a>3. 使用 dataframe api</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> broadcast</span><br><span class="line">broadcast(spark.table(<span class="string">&quot;b&quot;</span>)).join(spark.table(<span class="string">&quot;a&quot;</span>), <span class="string">&quot;id&quot;</span>).show()</span><br></pre></td></tr></table></figure>

<h2 id="cache-vs-broadcast"><a href="#cache-vs-broadcast" class="headerlink" title="cache vs broadcast"></a>cache vs broadcast</h2><p><a href="https://stackoverflow.com/questions/38056774/spark-cache-vs-broadcast">cache vs broadcast</a></p>
<blockquote>
<p>RDDs are divided into <em>partitions</em>. These partitions themselves act as an immutable subset of the entire RDD. When Spark executes each stage of the graph, each partition gets sent to a worker which operates on the subset of the data. In turn, each worker can <em>cache</em> the data if the RDD needs to be re-iterated.</p>
<p>Broadcast variables are used to send some immutable state <em>once</em> to each worker. You use them when you want a local copy of a variable.</p>
<p>These two operations are quite different from each other, and each one represents a solution to a different problem.</p>
</blockquote>
<h2 id="小文件问题"><a href="#小文件问题" class="headerlink" title="小文件问题"></a>小文件问题</h2><p><a href="https://blog.csdn.net/lhxsir/article/details/87882128">spark-sql 优化小文件过多</a></p>
<p><a href="https://medium.com/airbnb-engineering/on-spark-hive-and-small-files-an-in-depth-look-at-spark-partitioning-strategies-a9a364f908">On Spark, Hive, and Small Files: An In-Depth Look at Spark Partitioning Strategies</a></p>
<h4 id="为什么会有小文件？"><a href="#为什么会有小文件？" class="headerlink" title="为什么会有小文件？"></a>为什么会有小文件？</h4><p>当 spark 要 write 到 hive 表时，这实际也是一个 shuffle stage，就会分很多个 sPartition (spark partition)。每个 sPartition 在处理时，都会生成一个文件（如果是动态分区，则更严重，因为每个 sPartition 的数据分布式均匀的，每个 sPartition 可能包含很多个 hive paritition key，spark 每遇到一个 partition key 就生成一个文件），那么 sPartition 数目越多（动态分区的情况下，会更不可控），文件数就会越多。</p>
<p>简单来说，就是 spark 的一个 stage 分成了很多个 task（shuffle partitions 控制这个数量），即 sPartition，每个 sPartition 可能对应多个 hPartitiion（hive partition）key，多个 sPartition 也对应一个 hPartition key。而每个 sPartition 里对应的每个 hPartition key，都会生成一个文件。</p>
<p>那么，如果一个 sPartition 和 hPartition 只是一个 <strong>多（可控数目，对应最后每个 hPartitiion 的文件数）对一</strong> 的情况，那么文件数就是可控的。</p>
<blockquote>
<p>使用 hive 时，不会有小文件问题。hive 里只需要设置下边的这些参数，就</p>
<p>In pure Hive pipelines, there are configurations provided to automatically collect results into reasonably sized files, nearly transparently from the perspective of the developer, such as <em>hive.merge.smallfiles.avgsize</em>, or <em>hive.merge.size.per.task</em>.</p>
</blockquote>
<h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><ol>
<li>coalesce</li>
<li>repartition</li>
<li>Distribute by</li>
<li>adaptive execution</li>
</ol>
<p><a href="http://www.jasongj.com/spark/adaptive_execution/">Adaptive Execution 让 Spark SQL 更高效更智能</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 启用 Adaptive Execution ，从而启用自动设置 Shuffle Reducer 特性</span><br><span class="line">spark.conf.set(&quot;spark.sql.adaptive.enabled&quot;, &#x27;true&#x27;)</span><br><span class="line"># 设置每个 Reducer 读取的目标数据量，单位为字节。默认64M，一般改成集群块大小</span><br><span class="line">spark.conf.set(&quot;spark.sql.adaptive.shuffle.targetPostShuffleInputSize&quot;, &#x27;134217728&#x27;)</span><br></pre></td></tr></table></figure>

<h2 id="python-udf-vs-scala-udf"><a href="#python-udf-vs-scala-udf" class="headerlink" title="python udf vs scala udf"></a>python udf vs scala udf</h2><p><a href="https://medium.com/quantumblack/spark-udf-deep-insights-in-performance-f0a95a4d8c62">python udf vs scala udf</a></p>
<p><img src="https://miro.medium.com/max/1570/1*ddtDqMvoDGhxsw0CDEnfag.png" alt="img"></p>
<p><img src="https://miro.medium.com/max/1415/1*SMlxTZJBsAPKmpdRH5VFVw.png" alt="img"></p>
<p><img src="https://miro.medium.com/max/1500/1*FFi8Yk6mwSc6AvI-avWcYw.png" alt="img"></p>
<h1 id="Issues"><a href="#Issues" class="headerlink" title="Issues"></a>Issues</h1><h2 id="Null-aware-predicate-sub-queries-cannot-be-used-in-nested-conditions"><a href="#Null-aware-predicate-sub-queries-cannot-be-used-in-nested-conditions" class="headerlink" title="Null-aware predicate sub-queries cannot be used in nested conditions"></a>Null-aware predicate sub-queries cannot be used in nested conditions</h2><p><code>not in</code> 不能和 <code>or</code> 之类的 condition 一块用。现在好像还没有修复，参见：<a href="https://github.com/apache/spark/pull/22141">SPARK-25154</a></p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><p>Apache Spark Documentation: The official documentation for Apache Spark is an excellent resource to understand Spark’s concepts, APIs, and optimization techniques. It includes a Quick Start guide and in-depth documentation on Spark’s features and optimizations.</p>
</li>
<li><p>Hadoop Definitive Guide: Although this is a book, it is freely available online. “Hadoop: The Definitive Guide” by Tom White provides a comprehensive understanding of Hadoop and its ecosystem. It covers various optimization techniques and best practices for managing Hadoop clusters.</p>
</li>
<li><p>YouTube Tutorials:</p>
<ul>
<li>Simplilearn’s Spark Tutorial: Simplilearn offers a comprehensive Spark tutorial series on YouTube, covering various aspects of Spark programming, optimization, and cluster management.</li>
<li>Hadoop Tutorials by edureka!: edureka! provides a playlist of Hadoop tutorials on YouTube that cover the basics of Hadoop, including optimization and cluster management topics.</li>
</ul>
</li>
<li><p>Apache Hadoop YouTube Channel: The official Apache Hadoop YouTube channel hosts a collection of videos covering different topics related to Hadoop. You can find videos on optimization techniques, cluster management, and other Hadoop-related aspects.</p>
</li>
<li><p>Hortonworks Community Connection (HCC): Hortonworks Community Connection is a platform where Hadoop enthusiasts share knowledge and resources. It includes articles, tutorials, and videos related to Hadoop optimization and cluster management. You can explore the HCC website to find relevant resources.</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>hadoop</tag>
        <tag>distributed computing</tag>
      </tags>
  </entry>
  <entry>
    <title>c# contextual keywords: yield</title>
    <url>/2020/03/10/yield/</url>
    <content><![CDATA[<p><a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/yield">yield</a> is a contextual keywords. When it shows in a statement, it means the method or get accessor in which it appears is an iterator. Thus it provides a simple way to define an iterator, rather than a class that implements <code>IEnumerable</code> or <code>IEnumerator</code>.</p>
<blockquote>
<p>When you use the <code>yield</code> <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/#contextual-keywords">contextual keyword</a> in a statement, you indicate that the method, operator, or <code>get</code> accessor in which it appears is an iterator. Using <code>yield</code> to define an iterator removes the need for an explicit extra class (the class that holds the state for an enumeration, see <a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerator-1">IEnumerator</a> for an example) when you implement the <a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.ienumerable">IEnumerable</a> and <a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.ienumerator">IEnumerator</a> pattern for a custom collection type.</p>
</blockquote>
<h2 id="Grammar"><a href="#Grammar" class="headerlink" title="Grammar"></a>Grammar</h2><figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">yield</span> <span class="keyword">return</span> expression;	<span class="comment">// return an element in the iterator</span></span><br><span class="line"><span class="keyword">yield</span> <span class="keyword">break</span>;	<span class="comment">// end the iterator</span></span><br></pre></td></tr></table></figure>



<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q &amp; A"></a>Q &amp; A</h2><h4 id="What’s-an-iterator"><a href="#What’s-an-iterator" class="headerlink" title="What’s an iterator?"></a>What’s an iterator?</h4><p>An iterator means that it can be looped in <code>foreach</code> or LINQ query. In this case, it means the method or get accessor containing <code>yield</code> can be consumed by <code>foreach</code> or LINQ query.</p>
<h4 id="what-does-yield-means-in-this-iterator"><a href="#what-does-yield-means-in-this-iterator" class="headerlink" title="what does yield means in this iterator?"></a>what does <code>yield</code> means in this iterator?</h4><p>The <code>yield return</code> will return an element in the iterator. During the loop, the iterator use <code>MoveNext</code> to get i (take <a href="#yield-in-method">power method</a> as an example), and the <code>MoveNext</code> stop at the next <code>yield return</code> expression, and the <code>Current</code> property of the iterator is updated as this value, too.</p>
<h4 id="when-does-the-iterator-stopped"><a href="#when-does-the-iterator-stopped" class="headerlink" title="when does the iterator stopped?"></a>when does the iterator stopped?</h4><ul>
<li>when there’s <code>yield break</code></li>
<li>when the method body is end</li>
</ul>
<h4 id="what’s-the-requirements-to-define-such-iterator"><a href="#what’s-the-requirements-to-define-such-iterator" class="headerlink" title="what’s the requirements to define such iterator?"></a>what’s the requirements to define such iterator?</h4><ul>
<li>The return type must be <a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.ienumerable">IEnumerable</a>, <a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1">IEnumerable</a>, <a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.ienumerator">IEnumerator</a>, or <a href="https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerator-1">IEnumerator</a>.</li>
<li>The declaration can’t have any <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/in-parameter-modifier">in</a> <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/ref">ref</a> or <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/out-parameter-modifier">out</a> parameters.</li>
<li>Don’t use <code>yield</code> in <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/lambda-expressions">Lambda expressions</a> and <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/operators/delegate-operator">anonymous methods</a>.</li>
<li>Don’t use <code>yield</code> in methods that contain unsafe blocks. For more information, see <a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/unsafe">unsafe</a>.</li>
<li>Don’t use <code>yield return</code> in a try-catch block. A <code>yield return</code> statement can be located in the try block of a try-finally statement.</li>
<li><code>yield break</code> can be located in a try block or a catch block but not a finally block</li>
</ul>
<h1 id="examples"><a href="#examples" class="headerlink" title="examples"></a>examples</h1><h3 id="yield-in-method"><a href="#yield-in-method" class="headerlink" title="yield in method"></a>yield in method<a name = 'yield-in-method' /></h3><figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  	<span class="keyword">var</span> powers = Power(<span class="number">2</span>, <span class="number">10</span>);	<span class="comment">// won&#x27;t execute the body of Power</span></span><br><span class="line">    <span class="keyword">foreach</span> (<span class="keyword">var</span> i <span class="keyword">in</span> powers)</span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">$&quot;<span class="subst">&#123;i&#125;</span> &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// =================== yield in method ========================</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> IEnumerable&lt;<span class="built_in">int</span>&gt; <span class="title">Power</span>(<span class="params"><span class="built_in">int</span> number, <span class="built_in">int</span> exponent</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">int</span> result = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; exponent; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        result = result * number;</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="yield-in-get-accessor"><a href="#yield-in-get-accessor" class="headerlink" title="yield in get accessor"></a>yield in get accessor<a name = 'yield-in-get-accessor' /></h3><figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">foreach</span> (<span class="function"><span class="keyword">var</span> i <span class="keyword">in</span> <span class="keyword">new</span> <span class="title">Galaxies</span>().AllGalaxies)</span></span><br><span class="line">    &#123;</span><br><span class="line">        Console.WriteLine(<span class="string">$&quot;<span class="subst">&#123;i.Name&#125;</span>, <span class="subst">&#123;i.Age&#125;</span>&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title">Galaxies</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// =================== yield in get accessor ========================</span></span><br><span class="line">    <span class="keyword">public</span> IEnumerable&lt;Galaxy&gt; AllGalaxies</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">get</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="function"><span class="keyword">yield</span> <span class="keyword">return</span> <span class="keyword">new</span> <span class="title">Galaxy</span>(<span class="params"><span class="string">&quot;The milky way&quot;</span>, <span class="number">1000</span></span>)</span>;</span><br><span class="line">            <span class="function"><span class="keyword">yield</span> <span class="keyword">return</span> <span class="keyword">new</span> <span class="title">Galaxy</span>(<span class="params"><span class="string">&quot;Tadpole&quot;</span>, <span class="number">1000</span></span>)</span>;</span><br><span class="line">            <span class="function"><span class="keyword">yield</span> <span class="keyword">return</span> <span class="keyword">new</span> <span class="title">Galaxy</span>(<span class="params"><span class="string">&quot;Andromeda&quot;</span>, <span class="number">1000</span></span>)</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title">Galaxy</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">string</span> Name &#123; <span class="keyword">get</span>; &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">int</span> Age &#123; <span class="keyword">get</span>; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Galaxy</span>(<span class="params"><span class="built_in">string</span> name, <span class="built_in">int</span> age</span>)</span></span><br><span class="line">    &#123;</span><br><span class="line">        Name = name;</span><br><span class="line">        Age = age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>c#</tag>
      </tags>
  </entry>
  <entry>
    <title>多维数据模型</title>
    <url>/2020/12/21/%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/159061537">数据仓库建模</a></p>
<p><a href="https://www.cnblogs.com/cyechina/p/5425842.html">数据仓库的多维数据模型</a></p>
<p><a href="http://webdataanalysis.net/web-data-warehouse/multidimensional-data-model/">数据仓库的多维数据模型 – 非常好的一系列文章</a></p>
<h1 id="Kimball-维度建模"><a href="#Kimball-维度建模" class="headerlink" title="Kimball 维度建模"></a>Kimball 维度建模</h1><p><strong>维度建模就是时刻考虑如何能够提供简单性，以业务为驱动，以用户理解性和查询性能为目标</strong></p>
<p><a href="https://segmentfault.com/a/1190000038938864">kimball维度建模详解</a></p>
<p>维度建模分为两种表：事实表和维度表</p>
<ol>
<li><strong>事实表</strong>：必然存在的一些数据，像采集的日志文件，订单表，都可以作为事实表</li>
</ol>
<p>特征：<strong>是一堆主键的集合</strong>，每个主键对应维度表中的一条记录，客观存在的，根据主题确定出需要使用的数据</p>
<ol>
<li><strong>维度表</strong>：维度就是所分析的数据的一个量，维度表就是以合适的角度来创建的表，分析问题的一个角度：时间、地域、终端、用户等角度</li>
</ol>
<h1 id="多维数据模型的定义和作用"><a href="#多维数据模型的定义和作用" class="headerlink" title="多维数据模型的定义和作用"></a>多维数据模型的定义和作用</h1><p>　　多维数据模型是为了满足用户从多角度多层次进行数据查询和分析的需要而建立起来的基于事实和维的数据库模型，其基本的应用是为了实现OLAP（Online Analytical Processing）。</p>
<p>　　当然，通过多维数据模型的数据展示、查询和获取就是其作用的展现，但其真的作用的实现在于，通过数据仓库可以根据不同的数据需求建立起各类多维模型，并组成数据集市开放给不同的用户群体使用，也就是根据需求定制的各类数据商品摆放在数据集市中供不同的数据消费者进行采购。</p>
<p><strong>多维数据模型最大的优点就是其基于分析优化的数据组织和存储模式。</strong></p>
<h2 id="主题建模"><a href="#主题建模" class="headerlink" title="主题建模"></a>主题建模</h2><p><a href="https://zhuanlan.zhihu.com/p/113790356">多维分析仓库构建-面向主题的建模</a></p>
<h3 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h3><p>主题建模是对原始数据、原始业务理解的基础上，将数据归类为多个主题（e.g. 销量主题、维修订单主题、线索转化主题…）。</p>
<p>一般，一个主题就是由一张事实表、多张维表、以及结果聚合表所组成。</p>
<ol>
<li>基于多维数据模型构建底层：事实表+维表</li>
<li>基于上述模型，聚合结果，生成聚合数据。</li>
</ol>
<p>事实表要尽可能宽，尽可能容纳此主题下所有指标，如果有新指标需求，则动态添加指标。但是事实表太宽可能导致后续计算资源不足，如果需要拆分事实，拆分事实表的过程即拆分子主题。对事实表的拆分不明确，即主题不明确，会导致后续资源的浪费或者维护成本的提高。因为后续可能出现衍生指标需要两个主题出的情况，那么需要再新出一个综合主题。</p>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><p>主题建模是对数据的分类，这需要对领域或企业内数据特征有深刻理解。清晰的主题规划往往是数仓设计成败的关键。</p>
<p>与主题建模相对的，是按需输出数据，按照产品的需求出对应指标。</p>
<p>按需出指标，不必等待多维分析数仓建立完成即可开始，前期开发周期短。</p>
<p>主题建模是提前将维度和指标的全集定义好，聚合尽可能多的维度属性和指标的组合，与产品需求解耦，不会随产品需求增加而将数仓变得臃肿，可维护性好，长远来看性能上也更好。</p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>原子指标、衍生指标的增长：需要增加结果表的schema，所有数据库是兼容的，产生结果表的SQL修改其中读取事实表的查询，可以向后兼容</p>
<p>维度属性的增长：在维度表中增加具体的维度属性即可，不需要其他修改。</p>
<p>维度的增长：产生结果表的SQL增加新的维度表，结果表的schema也进行相应修改。</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>在看实例前，这里需要先了解两个概念：<strong>事实表和维表</strong>。事实表是用来记录具体事件的，包含了每个事件的具体要素，以及具体发生的事情；维表则是对事实表中事件的要素的描述信息。比如一个事件会包含时间、地点、人物、事件，事实表记录了整个事件的信息，但对时间、地点和人物等要素只记录了一些关键标记，比如事件的主角叫“Michael”，那么Michael到底“长什么样”，就需要到相应的维表里面去查询“Michael”的具体描述信息了。基于事实表和维表就可以构建出多种多维模型，包括星形模型、雪花模型和星座模型。这里不再展开了，解释概念真的很麻烦，而且基于我的理解的描述不一定所有人都能明白，还是直接上实例吧：</p>
<p><img src="http://webdataanalysis.net/wp-content/uploads/2010/08/Star-Schemas.png" alt="Star-Schemas"></p>
<p>事实表里面主要包含两方面的信息：<strong>维和度量</strong>，维的具体描述信息记录在维表，事实表中的维属性只是一个关联到维表的键，并不记录具体信息；度量一般都会记录事件的相应数值，比如这里的产品的销售数量、销售额等。维表中的信息一般是可以分层的，比如时间维的年月日、地域维的省市县等，这类分层的信息就是为了满足事实表中的度量可以在不同的粒度上完成聚合，比如2010年商品的销售额，来自上海市的销售额等。</p>
<h2 id="事实表"><a href="#事实表" class="headerlink" title="事实表"></a>事实表</h2><p>事实表是用来记录具体事件的，包含了每个事件的具体要素，以及具体发生的事情；如<strong>系统</strong>的<strong>日志</strong>、<strong>销售记录</strong>、<strong>用户访问日志</strong>等信息，<strong>事实表的记录是动态的增长的</strong>，所以<strong>体积是大于维度表</strong>。<strong>即：用户关心的业务数据，如销售数量，库存数量，销售金额</strong></p>
<h2 id="维表"><a href="#维表" class="headerlink" title="维表"></a>维表</h2><p>维表则是对事实表中事件的要素的描述信息。比如一个事件会包含时间、地点、人物、事件，事实表记录了整个事件的信息，但对时间、地点和人物等要素只记录了一些关键标记，比如事件的主角叫“Michael”，那么Michael到底“长什么样”，就需要到相应的维表里面去查询“Michael”的具体描述信息了。</p>
<p><strong>维度表</strong>（Dimension Table）也称为<strong>查找表</strong>（Lookup Table）是<strong>与事实表相对应的表</strong>，这个表保存了<strong>维度的属性值</strong>，可以跟事实表做关联，<strong>相当于</strong>是将<strong>事实表</strong>中<strong>经常重复的数据抽取</strong>、<strong>规范出来用一张表管理</strong>，常见的有日期（日、周、月、季度等属性）、地区表等，所以<strong>维度表的变化通常不会太大</strong>。<strong>即：用来描述业务数据的数据，如日期、产品数据、地区、渠道</strong></p>
<p>基于事实表和维表就可以构建出多种多维模型，包括星形模型、雪花模型和星座模型。</p>
<h2 id="星型模型"><a href="#星型模型" class="headerlink" title="星型模型"></a>星型模型</h2><p>当所有维表都直接连接到“事实表”上时，整个图解就像星星一样，故将该模型称为星型模型。<strong>数据有一定的冗余</strong></p>
<p><img src="https://pic3.zhimg.com/80/v2-1d39380d9238ca7c5876ac92d27750b2_1440w.jpg" alt="img"></p>
<h2 id="雪花模型"><a href="#雪花模型" class="headerlink" title="雪花模型"></a>雪花模型</h2><p>当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，其图解就像多个雪花连接在一起，故称雪花模型。<strong>雪花模型是对星型模型的扩展</strong>。它对星型模型的维表进一步层次化，原有的各维表可能被扩展为小的事实表，形成一些局部的 “层次 “ 区域，这些被分解的表都连接到主维度表而不是事实表。如图 2，将地域维表又分解为国家，省份，城市等维表。它的优点是：<strong>通过最大限度地减少数据存储量以及联合较小的维表来改善查询性能。雪花型结构去除了数据冗余</strong>。</p>
<p><img src="https://pic4.zhimg.com/80/v2-e7e1a7403be3ffb217f623d89771a573_1440w.jpg" alt="img">****</p>
]]></content>
      <tags>
        <tag>big data</tag>
        <tag>design</tag>
        <tag>data modeling</tag>
      </tags>
  </entry>
</search>
