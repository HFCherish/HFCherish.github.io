---
title: 数据平台技术方案
toc: true
date: 2021-01-28 11:42:21
tags:
	- big data
---

## 我们做的是什么？

我们做的是一汽的基于 Hadoop 构建的的面向分析的分布式集成化数据管理平台，为企业提供决策支持

1. 数据浏览：（？？？）数据会慢慢接入这个数据平台，并创建这些数据的数据目录，通过数据目录来浏览有哪些数据，通过 superset、jupyter、clickhouse 等开放数据给其他服务访问分析
2. 数据治理：定义数据标准(新项目按标准执行)，按数据标准接入数据，检查接入数据的质量，并输出质量报告
3. 数据分析：接入数据处理后的指标、客户画像数据会放入数据集市，数据分析师可以通过 superset、jupyter、clickhouse 对这些数据做 OLAP 分析。
4. 数据任务开发框架：会提供一套框架，能够实现快速、简易的数据接入、数仓建设、指标、标签开发等

## 我们的架构是什么

我们采用 HDP 发行版的 Hadoop 分布式数据平台

1. 源数据 ods 层：这一层将原始数据接过来，不做任何处理
   1. 离线结构化数据接入：spark-sql（sqoop 由于一些局限，暂时未采用）
   2. 离线半结构化数据接入：spark
   3. 离线非结构化数据接入：flume + kafka
   4. 实时数据接入：flink + kafka
   5. 目前支持接入的数据源
      1. oracle（tact）
         1. 接入方案……
      2. mongo（adms）
         1. 接入方案……
2. 数据仓库层：整理和转换生成面向主题的数据，使得数据能够应用于分析
   1. **多维数据模型最大的优点就是其基于分析优化的数据组织和存储模式**
   2. Why multi-dimension data model
      1. Flexibal, remove redudancy, faster
   3. 我们的聚合做到什么程度呢？是以什么样的方式扩展呢？是不是一开始要尽量多的产生一些聚合结果呢？这样它上层需要什么结果，就可以基于这个轻度聚合直接获取到了
3. 数据应用层：数据平台的主要价值体现。这里会应用数据仓库中的数据，做扩展性应用（报表、smart bi、数据挖掘、数据分析...）

## Why we are better than others???



## The work process

### analysis/design process????

1. what analyses do we want to conduct? ------ research
2. to analyse, which indicators or tags characterizing customers we need to calculate? ------ research
3. ~~Busisness model~~ -------- research
4. ~~Domain model~~ ------- ddd
5. logical model ------ 
6. physical model ------ multi-dimension data model

### development process

1. ods：data import
2. dw：all etl processes to implement the physical model
   1. ???? ~~我们的数仓 dw 层应该是面向一汽（A 卡顾客）建立的企业数据模型~~，为什么有两个 dim_customer (还有个 adms 的)，还是这只是一个暂时的
3. Dm: etl processes to implement the indicators/tags...
   1. ？？？？我们现在的数据集市是针对什么建的数据集市？还是只是一个命名？我们的 dm 里放的是什么呢？



# 现状的问题：

1. ~~是否流失、是否保有，这些是否是车辆的维度属性？~~
2. 某一天是否是周指标、月指标、年指标要，是不是也是日期维度的一个维度属性？目前月度指标，是通过 airflow 月调度来做，有几个问题，一个是月度和daily 代码基本一样，只是周期不同，需要写两份；一个是 airflow 的月度周期控制，是不是只能计算上个月的指标？如果是的话，我们的指标取计算日期的逻辑是不是要改？
3. 生成指标表时，是否做尽量多的维度属性和原子指标的组合，来得到聚合结果？目前是选定了一些组合，而不是全集？？？
4. 为什么维度模型适合做 olap？其他模型是什么样的？为什么不适合？
5. 加一个 all 的粒度
6. 一个表里，既有 all，又有单个，不同粒度，是否需要将不同粒度的拆到不同表里？？或者，这里就都放一个粒度的，不要放 all 粒度的？





通过数据仓库可以根据不同的数据需求建立起各类多维模型，并组成数据集市开放给不同的用户群体使用，也就是根据需求定制的各类数据商品摆放在数据集市中供不同的数据消费者进行采购。







大数据时代，大多数企业的架构必然向着分布式、可扩展及多元化发展，所谓合久必分，不再有一种技术能包打天下了， 这冲击着传统企业集中化的技术外包模式，挑战是巨大的。

大数据计算通过将可执行的代码分发到大规模的服务器集群上进行分布式计算，以处理大规模的数据，即所谓的移动计算比移动数据更划算。但是这样的计算方式必然不会很快，即使一个规模不太大的数据集上的一次简单计算，MapReduce也可能需要几分钟，Spark快一点，也至少需要数秒的时间。

![image-20210128152850393](/Users/zhenzheng/code/hfcherish.github.io/source/images/dataplat-20210128152850393.png)



数据库就是基于hadoop的分布式数据库hive

Hadoop的HIVE是传统数据仓库的一种分布式替代。应用在传统ETL中的数据的清洗、过滤、转化及直接汇总等场景很适合，数据量越大，它的性价比越高。但目前为止看，其支撑的数据分析场景也是有限的， 简单的离线的海量分析计算是它所擅长的，相对应的，复杂的关联交叉运算其速度很慢。

Hadoop: 开源的数据分析平台，解决了大数据（大到一台计算机无法进行存储，一台计算机无法在要求的时间内进行处理）的可靠存储和处理。适合处理非结构化数据，包括HDFS，MapReduce基本组件。



由于是分布式的，所以技术上可以很容易的实现扩容

hadoop到了X000台集群的规模也撑不住了,当前很多企业的数据量应该会超过这个数量，除了像阿里等自身有研发能力的企业（比如ODPS），是否也要走向按照业务拆分Hadoop集群的道路？诸如浙江移动已经拆分了固网、移网、创新等多个hadoop集群。





可以解决上PB容量的数据下的高效计算的问题

不像oracle，升级一下就很贵



Hadoop的SPARK的很适合机器学习的迭代，但能否大规模的应用于数据关联分析，能否一定程度替代MPP，还需要实践来验证。

　　MPP应该来说，是采用分布式架构对于传统数据仓库最好的替代，毕竟其实际上是变了种的关系型数据库，对于SQL提供完整支持，在HIVE做了转化分析后，数据仓库的融合建模用它来做性能绰绰有余，其性价比较传统DB2更好一点，比如经过实用，Gbase30-40台集群就能超过2台顶配的IBM 780。



[数据平台建设的方案介绍](https://cloud.tencent.com/developer/article/1715857)

[什么样的大数据平台架构，才是最适合你的？](https://cloud.tencent.com/developer/article/1047738)：讲的挺全面，high level 讲到了主要的分层、每个分层可选用的组件及简单对比，大数据平台架构的特性之类。

[大数据平台架构及主要技术分享](https://www.modb.pro/db/42249)：详细的介绍了一个实施的大数据平台所选用的组件及搭建过程。

扩容方式对比（大数据平台架构和传统数据仓库的不同）---》 图 (基于 hive 的数据仓库 vs 基于 oracle 的数据仓库)

Hadoop分布式系统架构，在各种云产品内的对比

从角色出发





分别介绍各个组件，如何支持分布式

Spark是一款分布式内存计算模型，其计算是基于内存的，所以计算速度较其他计算引擎是很快的，Spark基于一套统一的数据模型（RDD)和编程模型（Trans/Action)之上，构建出SparkSQL，SparkStreaming，Mlib，GraphX等分支。

HDFS：提供了一种跨服务器的弹性数据存储系统。

MapReduce：技术提供了感知数据位置的标准化处理流程：读取数据，对数据进行映射（Map），使用某个键值对数据进行重排，然后对数据进行化简（Reduce）得到最终的输出。

MapReduce、Hive、Spark等进行的计算处理被称作是离线计算，HDFS存储的数据被称为离线数据。相对的，用户实时请求需要计算的数据称为在线数据，这些数据由用户实时产生，进行实时在线计算，并把结果数据实时返回用户，这个计算过程中涉及的数据主要是用户自己一次请求产生和需要的数据，数据规模非常小，内存中一个线程上下文就可以处理。

HBASE很好用，基于列存储，查询速度毫秒级，对于一般的百亿级的记录查询那也是能力杠杠的，具有一定的高可用性，我们生产上的详单查询、指标库查询都是很好的应用场景。但读取数据方面只支持通过key或者key范围读取，因此要设计好rowkey。

[Redis](https://cloud.tencent.com/product/crs?from=10680)是K-V数据库，读写速度比HBASE更快，大多时候，HBASE能做的，Redis也能做，但Redis是基于内存的，主要用在key-value 的内存缓存，有丢失数据的可能，当前标签实时查询会用到它，合作过的互联网或广告公司大多采用该技术，但如果数据越来越大，那么，HBASE估计就是唯一的选择了？

另外已经基于IMPALA提供互联网日志的实时在线查询应用，也在尝试在营销平台采用SQLFire和GemFire实现分布式的基于内存的SQL关联分析，虽然速度可以，但也是BUG多多，引入和改造的代价较大。

Kylin当前算是基于hadoop/SPARK的多维分析的杀手级工具，应用的场景非常多，希望有机会使用。

![一文详解被阿里腾讯视作核心机密的大数据平台架构](https://imgconvert.csdnimg.cn/aHR0cDovL3AzLnBzdGF0cC5jb20vbGFyZ2UvcGdjLWltYWdlLzZjMzg1M2U3MTAyMTQ3OTdiZDFmMDRlOThkN2ZlNjYw?x-oss-process=image/format,png)



大数据架构越上层越不稳定，因为变化太快，以下是运营商对外变现当前阶段还算通用的一张应用规划图，供参考：

![img](https://ask.qcloudimg.com/http-save/yehe-1296778/xkmsti71sm.jpeg?imageView2/2/w/1620)



# 一个清晰的方案

[美团的大数据平台架构实践](https://zhuanlan.zhihu.com/p/26359613)

![dataplat-v2-356aa0e00aa2f23083a2525819462bed_r](/Users/zhenzheng/code/hfcherish.github.io/source/images/dataplat-v2-356aa0e00aa2f23083a2525819462bed_r.jpg)



# issues

1. **敏捷型数据集市**里是什么东西？如何实现敏捷建模，并且大幅提升数据的处理速度？
2. 一定程度讲，比如企业客户统一视图宽表用HIVE做比较低效，因为涉及到多方数据的整合，但不是不可以做，最多慢点嘛，还是要讲究个平衡 ???
3. 数据挖掘是怎么做？做什么？为什么数据挖掘、机器学习迭代适合用 spark